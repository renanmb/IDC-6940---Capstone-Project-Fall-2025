{
  "hash": "2076957a3309cfad3a081fe5a7168d07",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Dataset Exploration - Week 12\"\ndescription: \"For Week 12 we are reviewing Steve code to make it presentable\"\nauthor:\n  - name: Renan Monteiro Barbosa\n    url: https://github.com/renanmb\n# date: 10-24-2022\ncategories: [report, week 12, renan]\nimage: images/spongebob-imagination.jpg\ndraft: false\nbibliography: references.bib\nlink-citations: true\n---\n\n## Introduction\n\nReproducing Steve code in **baseFirthFlic1116.qmd** and **RFirth11116asfactor_allbutflac.R** using the dataset [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).\n\n## 1. Setup and Data Loading\n\nFirst, we need to load the required R packages and the dataset. The dataset is publicly available on Kaggle and was originally created by McKinsey & Company @fedesorianoStrokePredictionDatasetKaggle.\n\n### 1.1 Load Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\npackages <- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\")\n# install.packages(packages)\n```\n:::\n\n\nWe can use this to check installed packages:\n\n```{{r}}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlapply(packages, library, character.only = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\" \"datasets\"  \"utils\"    \n[7] \"methods\"   \"base\"     \n\n[[2]]\n [1] \"car\"       \"carData\"   \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\"\n [7] \"datasets\"  \"utils\"     \"methods\"   \"base\"     \n\n[[3]]\n [1] \"ResourceSelection\" \"car\"               \"carData\"          \n [4] \"dplyr\"             \"stats\"             \"graphics\"         \n [7] \"grDevices\"         \"datasets\"          \"utils\"            \n[10] \"methods\"           \"base\"             \n\n[[4]]\n [1] \"caret\"             \"lattice\"           \"ggplot2\"          \n [4] \"ResourceSelection\" \"car\"               \"carData\"          \n [7] \"dplyr\"             \"stats\"             \"graphics\"         \n[10] \"grDevices\"         \"datasets\"          \"utils\"            \n[13] \"methods\"           \"base\"             \n\n[[5]]\n [1] \"pROC\"              \"caret\"             \"lattice\"          \n [4] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n [7] \"carData\"           \"dplyr\"             \"stats\"            \n[10] \"graphics\"          \"grDevices\"         \"datasets\"         \n[13] \"utils\"             \"methods\"           \"base\"             \n\n[[6]]\n [1] \"logistf\"           \"pROC\"              \"caret\"            \n [4] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n [7] \"car\"               \"carData\"           \"dplyr\"            \n[10] \"stats\"             \"graphics\"          \"grDevices\"        \n[13] \"datasets\"          \"utils\"             \"methods\"          \n[16] \"base\"             \n\n[[7]]\n [1] \"Hmisc\"             \"logistf\"           \"pROC\"             \n [4] \"caret\"             \"lattice\"           \"ggplot2\"          \n [7] \"ResourceSelection\" \"car\"               \"carData\"          \n[10] \"dplyr\"             \"stats\"             \"graphics\"         \n[13] \"grDevices\"         \"datasets\"          \"utils\"            \n[16] \"methods\"           \"base\"             \n\n[[8]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[9]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[10]]\n [1] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n [4] \"logistf\"           \"pROC\"              \"caret\"            \n [7] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[10] \"car\"               \"carData\"           \"dplyr\"            \n[13] \"stats\"             \"graphics\"          \"grDevices\"        \n[16] \"datasets\"          \"utils\"             \"methods\"          \n[19] \"base\"             \n\n[[11]]\n [1] \"lubridate\"         \"forcats\"           \"stringr\"          \n [4] \"purrr\"             \"readr\"             \"tidyr\"            \n [7] \"tibble\"            \"tidyverse\"         \"summarytools\"     \n[10] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n[13] \"pROC\"              \"caret\"             \"lattice\"          \n[16] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[19] \"carData\"           \"dplyr\"             \"stats\"            \n[22] \"graphics\"          \"grDevices\"         \"datasets\"         \n[25] \"utils\"             \"methods\"           \"base\"             \n\n[[12]]\n [1] \"knitr\"             \"lubridate\"         \"forcats\"          \n [4] \"stringr\"           \"purrr\"             \"readr\"            \n [7] \"tidyr\"             \"tibble\"            \"tidyverse\"        \n[10] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n[13] \"logistf\"           \"pROC\"              \"caret\"            \n[16] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[19] \"car\"               \"carData\"           \"dplyr\"            \n[22] \"stats\"             \"graphics\"          \"grDevices\"        \n[25] \"datasets\"          \"utils\"             \"methods\"          \n[28] \"base\"             \n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\n# Set seed for reproducibility\nset.seed(123)\n```\n:::\n\n\nMight need to deal with the conflicts later:\n\n\n### 1.2 Load Data\n\nWe will load the dataset and handle the data given the exploration done in Week5. The id column is unnecessary for prediction as well there are only 2 genders significant for prediction.\n\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nfind_git_root <- function(start = getwd()) {\n  path <- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path <- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root <- find_git_root()\ndatasets_path <- file.path(repo_root, \"datasets\")\n\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path <- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n```\n:::\n\n\nCoding the Predictors and Omitting irrelevant values\n\nBecause we are using Logistic Regression a Quantitative tool, all predictors and the outcome variable must also be coded to quantitative equivalents. We also had to deal with N/A... so there were predictor variables in the dataset that had \"N/A\", Unknown, Children and Other. It would be easier to recode all the irrelevant values as \"N/A\" and get rid of them all at the same time. We also recoded gender to 1 as male and 2 as female. We also limited the bmi predictor to 2 places after the decimal.Finally we recoded all text categorical variables into numeric variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] <- NA\nstroke1$bmi <- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] <- 1\nstroke1$gender[stroke1$gender == \"Female\"] <- 2\nstroke1$gender <- as.numeric(stroke1$gender)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: NAs introduced by coercion\n```\n\n\n:::\n\n```{.r .cell-code}\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] <- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] <- 2\nstroke1$ever_married <- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] <- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] <- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] <- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] <- 4\nstroke1$work_type <- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] <- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] <- 2\nstroke1$Residence_type <- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level <- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease <- as.numeric(stroke1$heart_disease)\nstroke1$hypertension <- as.numeric(stroke1$hypertension)\nstroke1$age <- round(as.numeric(stroke1$age), 2)\nstroke1$stroke <- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] <- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] <- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] <- 3\nstroke1$smoking_status <- as.numeric(stroke1$smoking_status)\nstroke1 <- stroke1[, !(names(stroke1) %in% \"id\")]\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstroke1$stroke <- as.factor(stroke1$stroke)\nstroke1_clean <- na.omit(stroke1)\nstrokeclean <- stroke1_clean\nfourassume <- stroke1_clean\n```\n:::\n\n\n\nShowing Descriptive Statistics for all variables, Mean, Std Deviation, and Interquartile Range\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfSummary(strokeclean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData Frame Summary  \nstrokeclean  \nDimensions: 3357 x 11  \nDuplicates: 0  \n\n----------------------------------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values             Freqs (% of Valid)     Graph                  Valid      Missing  \n---- ------------------- -------------------------- ---------------------- ---------------------- ---------- ---------\n1    gender              Min  : 1                   1 : 1305 (38.9%)       IIIIIII                3357       0        \n     [numeric]           Mean : 1.6                 2 : 2052 (61.1%)       IIIIIIIIIIII           (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n2    age                 Mean (sd) : 49.4 (18.3)    70 distinct values             . : .          3357       0        \n     [numeric]           min < med < max:                                    . . : : : : .   :    (100.0%)   (0.0%)   \n                         13 < 50 < 82                                        : : : : : : : : :                        \n                         IQR (CV) : 28 (0.4)                               : : : : : : : : : :                        \n                                                                           : : : : : : : : : :                        \n\n3    hypertension        Min  : 0                   0 : 2949 (87.8%)       IIIIIIIIIIIIIIIII      3357       0        \n     [numeric]           Mean : 0.1                 1 :  408 (12.2%)       II                     (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n4    heart_disease       Min  : 0                   0 : 3151 (93.9%)       IIIIIIIIIIIIIIIIII     3357       0        \n     [numeric]           Mean : 0.1                 1 :  206 ( 6.1%)       I                      (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n5    ever_married        Min  : 1                   1 : 2599 (77.4%)       IIIIIIIIIIIIIII        3357       0        \n     [numeric]           Mean : 1.2                 2 :  758 (22.6%)       IIII                   (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n6    work_type           Mean (sd) : 2 (0.6)        1 :  514 (15.3%)       III                    3357       0        \n     [numeric]           min < med < max:           2 : 2200 (65.5%)       IIIIIIIIIIIII          (100.0%)   (0.0%)   \n                         1 < 2 < 4                  3 :  629 (18.7%)       III                                        \n                         IQR (CV) : 0 (0.3)         4 :   14 ( 0.4%)                                                  \n\n7    Residence_type      Min  : 1                   1 : 1709 (50.9%)       IIIIIIIIII             3357       0        \n     [numeric]           Mean : 1.5                 2 : 1648 (49.1%)       IIIIIIIII              (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n8    avg_glucose_level   Mean (sd) : 108.4 (47.9)   2861 distinct values     :                    3357       0        \n     [numeric]           min < med < max:                                  . :                    (100.0%)   (0.0%)   \n                         55.1 < 92.3 < 271.7                               : : :                                      \n                         IQR (CV) : 39 (0.4)                               : : :                                      \n                                                                           : : : : . . . . .                          \n\n9    bmi                 Mean (sd) : 30.4 (7.2)     364 distinct values      . :                  3357       0        \n     [numeric]           min < med < max:                                    : :                  (100.0%)   (0.0%)   \n                         11.5 < 29.2 < 92                                    : :                                      \n                         IQR (CV) : 8.8 (0.2)                                : : :                                    \n                                                                           . : : : .                                  \n\n10   smoking_status      Mean (sd) : 1.7 (0.8)      1 : 1798 (53.6%)       IIIIIIIIII             3357       0        \n     [numeric]           min < med < max:           2 :  824 (24.5%)       IIII                   (100.0%)   (0.0%)   \n                         1 < 1 < 3                  3 :  735 (21.9%)       IIII                                       \n                         IQR (CV) : 1 (0.5)                                                                           \n\n11   stroke              1. 0                       3177 (94.6%)           IIIIIIIIIIIIIIIIII     3357       0        \n     [factor]            2. 1                        180 ( 5.4%)           I                      (100.0%)   (0.0%)   \n----------------------------------------------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\nLooking at the distribution of all the predictor indicators and the outcome indicator with Histograms\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram of gender\nggplot(strokeclean, aes(x = gender)) +\n  geom_bar(fill = \"blue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of gender\", \n       x = \"gender\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of Age\nggplot(strokeclean, aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"green\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Age\", \n       x = \"Age\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of hypertension\nggplot(strokeclean, aes(x = hypertension)) +\n  geom_bar(fill = \"purple\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of hypertension\", \n       x = \"hypertension\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of heart_disease\nggplot(strokeclean, aes(x = heart_disease)) +\n  geom_bar( fill = \"orange\",\n            color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of heart_disease\", \n       x = \"HeartDisease\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of ever_married\nggplot(strokeclean, aes(x = ever_married)) +\n  geom_bar(fill = \"aquamarine\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of ever_married\", \n       x = \"EverMarried\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of work_type\nggplot(strokeclean, aes(x = work_type)) +\n  geom_bar(fill = \"steelblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of work_type\", \n       x = \"WorkType\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-6.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of Residence_type\nggplot(strokeclean, aes(x = Residence_type)) +\n  geom_bar(fill = \"magenta\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Residence_type\", \n       x = \"Residence_type\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-7.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of avg_gloucose_level\nggplot(strokeclean, aes(x = avg_glucose_level)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"chartreuse\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of avg_gloucose_level\",\n       x = \"avg-glucose_level\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-8.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of bmi\nggplot(strokeclean, aes(x = bmi)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"gold\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of bmi\", \n       x = \"bmi\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-9.png){width=672}\n:::\n\n```{.r .cell-code}\n# smoking_status\nggplot(strokeclean, aes(x = smoking_status)) +\n  geom_bar(fill = \"deepskyblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"smoking_status\", \n       x = \"smoking_status\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-10.png){width=672}\n:::\n\n```{.r .cell-code}\n# Histogram of Age\nggplot(strokeclean, aes(x = stroke)) +\n  geom_bar(fill = \"tan\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Age\", \n       x = \"stroke\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-11.png){width=672}\n:::\n:::\n\n\n### **Review of Logistic Regression**\n\nLogistic regression is a statistical modeling technique that predicts the probability of a binary outcome (such as 0 or 1) using one or more independent variables.\n\n#### Mathematics Behind Logistic Regression\n\nThe key idea is to model the **log odds** (also called the logit) of the probability of the event as a linear function of the predictors:\n\n-   The key idea is to model the **log odds** (also called the logit) of the probability of the event as a linear function of the predictors:\n\n    log⁡(p1−p)=β0+β1x1+β2x2+...+βkxklog(1−pp)=β0+β1x1+β2x2+...+βkxk\n\n    where pp is the probability of the outcome (e.g., stroke), the xixi are predictors, and the βiβi are their coefficients.​\n\n-   Solving for pp, the equation becomes:\n\n    p=11+e−(β0+β1x1+...+βkxk)p=1+e−(β0+β1x1+...+βkxk)1\n\n    This is the **logistic function**, which always outputs values between 0 and 1, making it ideal for probabilities.​\n\n#### Core Concepts\n\n**(1) Odds** are defined as p/(1−p)p/(1-p)p/(1−p), the ratio of the probability of the event to the probability of its complement.\n\n\\(2\\) The **logit** transformation (natural log of the odds) turns this nonlinear problem into a linear one, so standard linear modeling techniques can be used for estimation.\n\n\\(3\\) Coefficients (β\\betaβ) are commonly estimated using **maximum likelihood** methods, not ordinary least squares.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula <- stroke ~ gender + age + hypertension + heart_disease + ever_married +\n  work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n```\n:::\n\n\nA comparison between Logistic Regression and Multiple Regression is shown below\n\n| Feature | Multiple Regression | Logistic Regression |\n|------------------------|------------------------|------------------------|\n| Outcome variable type | Continuous (real numbers) | Categorical/Binary (e.g., 0 or 1) |\n| Example prediction | Predicting house prices | Predicting disease presence/absence |\n| Model equation | Linear combination of predictors | Log odds/logit (S-shaped curve: logistic function) |\n| Estimation method | Least squares | Maximum likelihood |\n| Output type | Actual values (e.g., \\$125,000) | Probability of being in a category (e.g., 87%) |\n| Usage | Continuous outcome (income, cost, score) | Categorical outcome (yes/no, 0/1) |\n\nAs you can see the prediction of having a stroke or not with the outcome variable clearly shows we should use Logistic Regression. Note. The predictor variables can be either categorical or continuous. Its the outcome variable that is critical in choosing.\n\nBut before we can run the all the models of Logistic Regression, there are 4 assumptions of Logistic Regression that we need to determine if the dataset and models can run without violating any or all of the assumptions of Logistic Regression. Note testing the assumptions are done for numerical predictors only statistically speaking. Categorical predictors are tested visually with the histograms above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assumption 1: The Outcome Variable is 0 or 1\nunique(fourassume$stroke)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 0\nLevels: 0 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Assumption 2: There is linear relationship between the outcome variable and each predictor that is numeric. Categorical predictors are reviewed in the histograms avove\nfourassume$ageadj <- fourassume$age + abs(min(fourassume$age)) + 1\nfourassume$avg_glucose_leveladj <- fourassume$avg_glucose_level + abs(min(fourassume$avg_glucose_level)) + 1\nfourassume$bmiadj <- fourassume$bmi + abs(min(fourassume$bmi)) + 1\nstr(fourassume)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [3,357 × 14] (S3: tbl_df/tbl/data.frame)\n $ gender              : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age                 : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension        : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease       : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married        : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type           : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type      : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level   : num [1:3357] 229 106 171 174 186 ...\n $ bmi                 : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status      : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke              : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n $ ageadj              : num [1:3357] 81 94 63 93 95 88 83 95 75 68 ...\n $ avg_glucose_leveladj: num [1:3357] 285 162 227 230 242 ...\n $ bmiadj              : num [1:3357] 49.1 45 46.9 36.5 41.5 39.9 35.3 42.2 49.3 39.8 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\nnumeric_vars <- sapply(fourassume, is.numeric)\nfourassume_numeric <- fourassume[, numeric_vars]\nrcorr(as.matrix(fourassume_numeric))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nageadj                -0.06  1.00         0.26          0.26        -0.49\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nageadj                    0.14          -0.02              0.24  0.04\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender                        -0.08  -0.06                -0.07  -0.02\nage                            0.03   1.00                 0.24   0.04\nhypertension                  -0.01   0.26                 0.17   0.13\nheart_disease                  0.06   0.26                 0.14   0.00\never_married                  -0.06  -0.49                -0.12  -0.13\nwork_type                     -0.02   0.14                 0.03  -0.02\nResidence_type                -0.04  -0.02                 0.01   0.01\navg_glucose_level              0.01   0.24                 1.00   0.16\nbmi                            0.03   0.04                 0.16   1.00\nsmoking_status                 1.00   0.03                 0.01   0.03\nageadj                         0.03   1.00                 0.24   0.04\navg_glucose_leveladj           0.01   0.24                 1.00   0.16\nbmiadj                         0.03   0.04                 0.16   1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nageadj               0.0000    0.3076         0.0000            0.0144\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender               0.0000         0.0012 0.0000               0.2487\nage                  0.0448         0.0000 0.0000               0.0144\nhypertension         0.7537         0.0000 0.0000               0.0000\nheart_disease        0.0005         0.0000 0.0000               0.8185\never_married         0.0009         0.0000 0.0000               0.0000\nwork_type            0.3764         0.0000 0.0467               0.3243\nResidence_type       0.0208         0.3076 0.6427               0.5689\navg_glucose_level    0.7679         0.0000 0.0000               0.0000\nbmi                  0.0925         0.0144 0.0000               0.0000\nsmoking_status                      0.0448 0.7679               0.0925\nageadj               0.0448                0.0000               0.0144\navg_glucose_leveladj 0.7679         0.0000                      0.0000\nbmiadj               0.0925         0.0144 0.0000                     \n```\n\n\n:::\n\n```{.r .cell-code}\nfourAdj <- fourassume\nfourAdj <- fourAdj[ , !(names(fourAdj) %in% c(\"age\", \"heart_disease\", \"avg_glucose_level\", \"bmi\")) ]\nmodel4 <- glm(stroke ~ ageadj + avg_glucose_leveladj + bmiadj, data=fourAdj, family=binomial)\nresidualPlots(model4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Test stat Pr(>|Test stat|)\nageadj                  1.9958           0.1577\navg_glucose_leveladj    0.0070           0.9331\nbmiadj                  0.3549           0.5514\n```\n\n\n:::\n\n```{.r .cell-code}\n# Assumption 3: Assess Influentional Outliers that are numeric. Categorical predictors are reviewed n the hhistrams above\nalias(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel :\nstroke ~ ageadj + avg_glucose_leveladj + bmiadj\n```\n\n\n:::\n\n```{.r .cell-code}\nrcorr(as.matrix(fourassume_numeric))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nageadj                -0.06  1.00         0.26          0.26        -0.49\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nageadj                    0.14          -0.02              0.24  0.04\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender                        -0.08  -0.06                -0.07  -0.02\nage                            0.03   1.00                 0.24   0.04\nhypertension                  -0.01   0.26                 0.17   0.13\nheart_disease                  0.06   0.26                 0.14   0.00\never_married                  -0.06  -0.49                -0.12  -0.13\nwork_type                     -0.02   0.14                 0.03  -0.02\nResidence_type                -0.04  -0.02                 0.01   0.01\navg_glucose_level              0.01   0.24                 1.00   0.16\nbmi                            0.03   0.04                 0.16   1.00\nsmoking_status                 1.00   0.03                 0.01   0.03\nageadj                         0.03   1.00                 0.24   0.04\navg_glucose_leveladj           0.01   0.24                 1.00   0.16\nbmiadj                         0.03   0.04                 0.16   1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nageadj               0.0000    0.3076         0.0000            0.0144\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender               0.0000         0.0012 0.0000               0.2487\nage                  0.0448         0.0000 0.0000               0.0144\nhypertension         0.7537         0.0000 0.0000               0.0000\nheart_disease        0.0005         0.0000 0.0000               0.8185\never_married         0.0009         0.0000 0.0000               0.0000\nwork_type            0.3764         0.0000 0.0467               0.3243\nResidence_type       0.0208         0.3076 0.6427               0.5689\navg_glucose_level    0.7679         0.0000 0.0000               0.0000\nbmi                  0.0925         0.0144 0.0000               0.0000\nsmoking_status                      0.0448 0.7679               0.0925\nageadj               0.0448                0.0000               0.0144\navg_glucose_leveladj 0.7679         0.0000                      0.0000\nbmiadj               0.0925         0.0144 0.0000                     \n```\n\n\n:::\n\n```{.r .cell-code}\ninfluencePlot(model4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        StudRes          Hat       CookD\n17    2.3495313 0.0040917969 0.014793349\n83    2.5500288 0.0045425981 0.026906139\n87    3.0778217 0.0004677603 0.012890963\n131   3.2110607 0.0003364260 0.014101935\n186  -0.7488292 0.0184781611 0.001532740\n2583 -0.7113787 0.0167417735 0.001232964\n```\n\n\n:::\n\n```{.r .cell-code}\n# Assumption 4: Assess Multicollinearity for numeric predictors\nvif(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              ageadj avg_glucose_leveladj               bmiadj \n            1.070909             1.081460             1.101382 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit of the Model with Nagelkerke R\nhoslem.test(model4$y, fitted(model4), g = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tHosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model4$y, fitted(model4)\nX-squared = 8.8522, df = 8, p-value = 0.3549\n```\n\n\n:::\n\n```{.r .cell-code}\nnagelkerke(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$Models\n                                                                                \nModel: \"glm, stroke ~ ageadj + avg_glucose_leveladj + bmiadj, binomial, fourAdj\"\nNull:  \"glm, stroke ~ 1, binomial, fourAdj\"                                     \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1713030\nCox and Snell (ML)                  0.0691131\nNagelkerke (Cragg and Uhler)        0.2022700\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq   p.value\n      -3     -120.21 240.42 7.721e-52\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Predictive Capability\nmodel4_CM <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=fourassume, family = binomial)\n```\n:::\n\n\nThe three different models of Logistic Regression: Baseline, Firth and Flic Corrections. We are creating 3 different models to really test to see if the dataset had a stroke percentage that is less than the real percentage of stroke to population ratio in the US. Because this is a so called \"rare event\" Firth regression takes this into account as does its refinement FLIC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Baseline Logistic Regression\nmodel_base <- glm(formula, data=strokeclean, family=binomial)\nprob_base <- predict(model_base, type=\"response\")\n\n# Firth Logistic Regression\nmodel_firth <- logistf(formula, data=strokeclean)\nprob_firth <- predict(model_firth, type=\"response\")\n\n# FLIC Correction (this correction changes the intercept)\nmodel_flic <- flic(formula, data=strokeclean)\nprob_flic <- predict(model_flic, type=\"response\")\n\nlabels <- strokeclean$stroke\n```\n:::\n\n\nCreating Youdens J. Youden's J is a good way to look at how well each model balances sensitivity and selectivity. The closer to the curve, a Youden's J is the better the model can distinguish between sensitiviy and selectivity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyouden_point <- function(roc_obj) {\n  coords <- coords(roc_obj, \"best\", best.method = \"youden\", ret=c(\"threshold\", \"sensitivity\", \"specificity\", \"youden\"))\n  return(coords)\n}\n```\n:::\n\n\nThe Three Types of Prediction with 0.5 for consistency\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictions with default threshold 0.5 (for output consistency)\npred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))\npred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))\npred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))\n```\n:::\n\n\nThe Function to Compute Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))\npred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))\npred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))\n\nmetrics <- function(pred, prob, labels, name) {\n  cm <- confusionMatrix(pred, labels, positive = \"1\")\n  roc_obj <- roc(labels, as.numeric(prob))\n  auc_val <- auc(roc_obj)\n  precision <- cm$byClass[\"Pos Pred Value\"]\n  recall <- cm$byClass[\"Sensitivity\"]\n  f1 <- 2 * ((precision * recall) / (precision + recall))\n  youden <- youden_point(roc_obj)\n  # All list arguments separated by commas only, no '+'\n  list(\n    confusion = cm$table,\n    precision = precision,\n    recall = recall,\n    f1 = f1,\n    auc = auc_val,\n    roc_obj = roc_obj,\n    youden = youden,\n    model = name\n  )\n}\n```\n:::\n\n\nIntialize Results. We have to initialize results before calling the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_base <- metrics(pred_base, prob_base, labels, \"Baseline LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nresults_firth <- metrics(pred_firth, prob_firth, labels, \"firth LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\nSetting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nresults_flic <- metrics(pred_flic, prob_flic, labels, \"flic LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\nSetting direction: controls < cases\n```\n\n\n:::\n:::\n\n\nPrint Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"\\n== Baseline Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== Baseline Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_base[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_base$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.06934436   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n== Firth Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== Firth Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_firth[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3176  178\n         1    1    2\n\n$precision\nPos Pred Value \n     0.6666667 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02185792 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_firth$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.07100345   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n== FLIC Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== FLIC Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_flic[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_flic$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.06935441   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n:::\n\n\nPlot the ROC curves and Annotate Youden's J on each of the Curves\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(results_base$roc_obj, col=\"cyan\", main=\"ROC Curves: Baseline (blue) vs Firth (red)\")\nplot(results_firth$roc_obj, col=\"magenta\", add=TRUE)\nplot(results_flic$roc_obj, col =\"gold\", add=TRUE)\nauc(results_base$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\nauc(results_firth$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\nauc(results_flic$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\npoints(\n  1-results_base$youden[\"specificity\"],\n  results_base$youden[\"sensitivity\"],\n  col=\"cyan\", pch=19, cex=1.5\n)\npoints(\n  1-results_firth$youden[\"specificity\"],\n  results_firth$youden[\"sensitivity\"],\n  col=\"magenta\", pch=19, cex=1.5\n)\npoints(\n  1-results_flic$youden[\"specificity\"],\n  results_flic$youden[\"sensitivity\"],\n  col=\"gold\", pch=19, cex=1.5\n)\n\nlegend(\"bottomright\", legend=c(\"Baseline\", \"Firth\",\"flic\"), col=c(\"cyan\", \"magenta\", \"gold\"), lwd=2)\n\ntext(\n  x=1-results_base$youden[\"specificity\"], y=results_base$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_base$youden[\"youden\"], 3)),\n  pos=4, col=\"cyan\"\n)\ntext(\n  x=1-results_firth$youden[\"specificity\"], y=results_firth$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_firth$youden[\"youden\"], 3)),\n  pos=4, col=\"magenta\"\n)\ntext(\n  x=1-results_flic$youden[\"specificity\"], y=results_flic$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_flic$youden[\"youden\"], 3)),\n  pos=4, col=\"gold\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nHere we see the results. Note that overlaying the curves and Youden's J is EXACTLY the same for all three models. This is a strong indication that the dataset is currently balanced enough to distinguish between stroke and non stroke. The bias if any would have shown up in a different AUC curve, and a different Youden's J. It does not.\n\nPlot the Confusion Matrices\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(3, 1), mar = c(6, 5, 6, 2))  # more top margin for all\nfourfoldplot(results_base$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Baseline Confusion Matrix\")\nfourfoldplot(results_firth$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Firth Confusion Matrix\")\nfourfoldplot(results_flic$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Flic Confusion Matrix\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1,1), mar = c(5, 4, 4, 2)) # Reset to default after\n```\n:::\n\n\nThe results indicate exactly that the confusion matrices are exactly the same. So the conclusion we can reach is the there was no significant bias in the dataset. The dataset can distinguish between stroke and non stroke events with sufficient selectivity.\n\n\n<!-- ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⠀⠀⠀⢀⣠⠤⠖⠈⠉⠉⠀⠀⠀⠀⠉⠢⡀⠀⠀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⠀⠀⣴⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢦⡀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠞⠋⢙⣦⡈⣷⡄⠀⠀⠀ -->\n<!-- ⠀⣀⠶⠁⠀⠀⣀⣀⡀⠀⠀⠀⠀⠀⡴⠁⠀⠀⠿⢿⡟⣌⢿⠀⠀⠀ -->\n<!-- ⣠⡿⠀⢠⣜⠉⠀⠀⠙⢷⢄⠀⠀⠀⢧⠀⠀⠀⠀⠀⠀⠘⡆⢧⡀⠀ -->\n<!-- ⣯⠃⠀⢾⣿⠗⠀⠀⠀⠀⡽⠀⠀⠀⠈⠳⢄⣀⠀⠀⠀⡰⠃⠘⣵⡄ -->\n<!-- ⡏⠀⠀⠘⡄⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠀⠉⠉⠁⠀⠀⠀⢱⡇ -->\n<!-- ⡅⠀⠀⠀⠙⠒⠔⠚⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇ -->\n<!-- ⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⠀⠀⠀⠀⠀⠀⠀⡗ -->\n<!-- ⡿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡀⠀⠀⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⣇ -->\n<!-- ⠹⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠷⣤⣤⣤⣤⠞⠁⠀⠀⠀⠀⠀⠀⣸ -->\n<!-- ⠀⠸⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⠇ -->\n<!-- ⠀⠀⢇⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡏⠀ -->\n<!-- ⠀⠀⠈⠀⠀⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ -->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# stroke1 <- read.csv(\"stroke.csv\")\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] <- NA\nstroke1$bmi <- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] <- 1\nstroke1$gender[stroke1$gender == \"Female\"] <- 2\nstroke1$gender <- as.numeric(stroke1$gender)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstroke1$stroke <- as.factor(stroke1$stroke)\nstroke1_clean <- na.omit(stroke1)\nstrokeclean <- stroke1_clean\n```\n:::\n\n\nThe model For Logistic Regression predicting Stroke\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula <- stroke ~ gender + age + hypertension + heart_disease + ever_married +\n  work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n```\n:::\n\n\nHistograms for all the predictors and the Outcome variable\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = gender)) +\n  geom_bar(fill = \"blue\", \n           color = \"white\") +\n  labs(title = \"Histogram of gender\", \n       x = \"gender\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"green\", \n                 color = \"white\") +\n  labs(title = \"Histogram of Age\", \n       x = \"Age\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = hypertension)) +\n  geom_bar(fill = \"purple\", \n           color = \"white\") +\n  labs(title = \"Histogram of hypertension\", \n       x = \"hypertension\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = heart_disease)) +\n  geom_bar( fill = \"orange\",\n            color = \"white\") +\n  labs(title = \"Histogram of heart_diseasd\", \n       x = \"Age\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = ever_married)) +\n  geom_bar(fill = \"aquamarine\", \n           color = \"white\") +\n  labs(title = \"Histogram of ever_married\", \n       x = \"Age\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-5.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = work_type)) +\n  geom_bar(fill = \"steelblue\", \n           color = \"white\") +\n  labs(title = \"Histogram of work_type\", \n       x = \"Age\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-6.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = Residence_type)) +\n  geom_bar(fill = \"magenta\", \n           color = \"white\") +\n  labs(title = \"Histogram of Residence_type\", \n       x = \"Residence_type\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-7.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = avg_glucose_level)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"chartreuse\", \n                 color = \"white\") +\n  labs(title = \"Histogram of avg_gloucose_level\",\n       x = \"avg-glucose_level\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-8.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = bmi)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"gold\", \n                 color = \"white\") +\n  labs(title = \"Histogram of bmi\", \n       x = \"bmi\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-9.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = smoking_status)) +\n  geom_bar(fill = \"deepskyblue\", \n           color = \"white\") +\n  labs(title = \"smoking_status\", \n       x = \"smoking_status\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-10.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(strokeclean, aes(x = stroke)) +\n  geom_bar(fill = \"tan\", \n           color = \"white\") +\n  labs(title = \"Histogram of Age\", \n       x = \"stroke\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-11.png){width=672}\n:::\n:::\n\n\nThe Three different Models of Logistic Regression: Baseline Firth and Flic Correction\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Baseline Logistic Regression\nmodel_base <- glm(formula, data=strokeclean, family=binomial)\nprob_base <- predict(model_base, type=\"response\")\n\n# Firth Logistic Regression\nmodel_firth <- logistf(formula, data=strokeclean)\nprob_firth <- predict(model_firth, type=\"response\")\n\n# FLIC Correction (this correction changes the intercept)\nmodel_flic <- flic(formula, data=strokeclean)\nprob_flic <- predict(model_flic, type=\"response\")\n\nlabels <- strokeclean$stroke\n```\n:::\n\n\nCreating Youdens J\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyouden_point <- function(roc_obj) {\n  coords <- coords(roc_obj, \"best\", best.method = \"youden\", ret=c(\"threshold\", \"sensitivity\", \"specificity\", \"youden\"))\n  return(coords)\n}\n```\n:::\n\n\nThe Three Types of Prediction with 0.5 for consistency\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictions with default threshold 0.5 (for output consistency)\npred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))\npred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))\npred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))\n```\n:::\n\n\nThe Function to Compute Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  pred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))\n  pred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))\n  pred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))\n\n  metrics <- function(pred, prob, labels, name) {\n    cm <- confusionMatrix(pred, labels, positive = \"1\")\n    roc_obj <- roc(labels, as.numeric(prob))\n    auc_val <- auc(roc_obj)\n    precision <- cm$byClass[\"Pos Pred Value\"]\n    recall <- cm$byClass[\"Sensitivity\"]\n    f1 <- 2 * ((precision * recall) / (precision + recall))\n    youden <- youden_point(roc_obj)\n    # All list arguments separated by commas only, no '+'\n    list(\n      confusion = cm$table,\n      precision = precision,\n      recall = recall,\n      f1 = f1,\n      auc = auc_val,\n      roc_obj = roc_obj,\n      youden = youden,\n      model = name\n    )\n  }\n```\n:::\n\n\nIntialize Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_base <- metrics(pred_base, prob_base, labels, \"Baseline LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nresults_firth <- metrics(pred_firth, prob_firth, labels, \"firth LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\nSetting direction: controls < cases\n```\n\n\n:::\n\n```{.r .cell-code}\nresults_flic <- metrics(pred_flic, prob_flic, labels, \"flic LR\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSetting levels: control = 0, case = 1\nSetting direction: controls < cases\n```\n\n\n:::\n:::\n\n\nPrint Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"\\n== Baseline Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== Baseline Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_base[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_base$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.06934436   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n== Firth Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== Firth Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_firth[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3176  178\n         1    1    2\n\n$precision\nPos Pred Value \n     0.6666667 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02185792 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_firth$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.07100345   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n== FLIC Logistic Regression ==\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n== FLIC Logistic Regression ==\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_flic[1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) < 180 cases (labels 1).\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nYouden's J (optimal threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(results_flic$youden)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   threshold sensitivity specificity   youden\n1 0.06935441   0.7444444   0.7777778 1.522222\n```\n\n\n:::\n:::\n\n\nPlot the ROC curves and Annotate Youden's J on each of the Curves\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(results_base$roc_obj, col=\"cyan\", main=\"ROC Curves: Baseline (blue) vs Firth (red)\")\nplot(results_firth$roc_obj, col=\"magenta\", add=TRUE)\nplot(results_flic$roc_obj, col =\"gold\", add=TRUE)\nauc(results_base$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\nauc(results_firth$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\nauc(results_flic$roc_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.8285\n```\n\n\n:::\n\n```{.r .cell-code}\npoints(\n  1-results_base$youden[\"specificity\"],\n  results_base$youden[\"sensitivity\"],\n  col=\"cyan\", pch=19, cex=1.5\n)\npoints(\n  1-results_firth$youden[\"specificity\"],\n  results_firth$youden[\"sensitivity\"],\n  col=\"magenta\", pch=19, cex=1.5\n)\npoints(\n  1-results_flic$youden[\"specificity\"],\n  results_flic$youden[\"sensitivity\"],\n  col=\"gold\", pch=19, cex=1.5\n)\n\nlegend(\"bottomright\", legend=c(\"Baseline\", \"Firth\",\"flic\"), col=c(\"cyan\", \"magenta\", \"gold\"), lwd=2)\n\ntext(\n  x=1-results_base$youden[\"specificity\"], y=results_base$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_base$youden[\"youden\"], 3)),\n  pos=4, col=\"cyan\"\n)\ntext(\n  x=1-results_firth$youden[\"specificity\"], y=results_firth$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_firth$youden[\"youden\"], 3)),\n  pos=4, col=\"magenta\"\n)\ntext(\n  x=1-results_flic$youden[\"specificity\"], y=results_flic$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_flic$youden[\"youden\"], 3)),\n  pos=4, col=\"gold\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nPlot the Confusion Matrices\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nfourfoldplot(results_base$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Baseline Confusion Matrix\")\nfourfoldplot(results_firth$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Firth Confusion Matrix\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfourfoldplot(results_flic$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Flic Confusion Matrix\")\n\npar(mfrow=c(1,1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n:::\n\n\n<!-- ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⠀⠀⠀⢀⣠⠤⠖⠈⠉⠉⠀⠀⠀⠀⠉⠢⡀⠀⠀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⠀⠀⣴⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢦⡀⠀⠀⠀⠀ -->\n<!-- ⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠞⠋⢙⣦⡈⣷⡄⠀⠀⠀ -->\n<!-- ⠀⣀⠶⠁⠀⠀⣀⣀⡀⠀⠀⠀⠀⠀⡴⠁⠀⠀⠿⢿⡟⣌⢿⠀⠀⠀ -->\n<!-- ⣠⡿⠀⢠⣜⠉⠀⠀⠙⢷⢄⠀⠀⠀⢧⠀⠀⠀⠀⠀⠀⠘⡆⢧⡀⠀ -->\n<!-- ⣯⠃⠀⢾⣿⠗⠀⠀⠀⠀⡽⠀⠀⠀⠈⠳⢄⣀⠀⠀⠀⡰⠃⠘⣵⡄ -->\n<!-- ⡏⠀⠀⠘⡄⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠀⠉⠉⠁⠀⠀⠀⢱⡇ -->\n<!-- ⡅⠀⠀⠀⠙⠒⠔⠚⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇ -->\n<!-- ⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⠀⠀⠀⠀⠀⠀⠀⡗ -->\n<!-- ⡿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡀⠀⠀⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⣇ -->\n<!-- ⠹⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠷⣤⣤⣤⣤⠞⠁⠀⠀⠀⠀⠀⠀⣸ -->\n<!-- ⠀⠸⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⠇ -->\n<!-- ⠀⠀⢇⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡏⠀ -->\n<!-- ⠀⠀⠈⠀⠀⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ -->\n\n\n### References\n\n::: {#refs}\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}