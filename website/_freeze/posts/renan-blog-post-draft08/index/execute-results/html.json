{
  "hash": "b9a105d4fadce71ee6fc184441f082c1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Draft v08 --- Predicting stroke risk from common health indicators: a binary logistic regression analysis\"\ndescription: \"Shree sent back draft with changes\"\nauthor:\n  - name: Renan Monteiro Barbosa\n    url: https://github.com/renanmb\n    affiliation: Master of Data Science Program @ The University of West Florida (UWF)\n  - name: \"Shree Krishna M.S Basnet\"\n  - name: \"Supervisor: Dr. Cohen\"\ndate: \"December 2 2025\"\ncategories: [draft, renan, shree]\n# citation:\n#   url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/\nimage: images/spongebob-imagination.jpg\ndraft: false\nbibliography: references.bib\nlink-citations: true\n---\n\n\n\n\n\n# Introduction\n\nStroke is a global health crisis, causing widespread mortality and disability [@WHO2025]. Because strokes occur suddenly and often lead to long-term neurological damage, early detection in high-risk individuals is critical for prevention and prompt intervention. By using data-driven risk prediction models, clinicians and public health experts can better identify high-risk populations, allowing for targeted clinical management and lifestyle counseling.\n\nLogistic Regression (LR) is one of the most widely used methods for modeling binary outcomes, such as the presence or absence of a disease [@sperandei2014understanding]. It extends linear regression to categorical outcomes, providing interpretable coefficients that explain how specific factors influence the probability of an event. LR has been applied across diverse fields, including child health [@asmare2024determinants], road safety [@rahman2021identification; @chen2024binary; @chen2020modeling], healthcare resource management [@hutchinson2023predictors], and fraud detection [@samara2024using]. These varied applications demonstrate LR’s flexibility and suitability for real-world decision-making.\n\nIn this project, we analyze a publicly available stroke dataset containing key demographic, behavioral, and clinical predictors—such as age, gender, hypertension, heart disease, marital status, work type, residence, smoking status, Body Mass Index (BMI), and average glucose level. These variables are well-documented in cardiovascular literature as significant risk determinants. We cleaned and recoded this data into appropriate numeric formats to develop a series of supervised learning models.\n\nWe establish Logistic Regression as our primary, interpretable baseline model and compare its performance against more complex machine learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, $k$-Nearest Neighbours, and Support Vector Machine (radial).\n\n# Methodology\n\nThis section outlines our data, how we prepared it, and the modeling framework we used to compare different classifiers.\n\nWe started with a dataset of 5,110 observations and 11 predictors commonly linked to stroke risk. We filtered out missing data and inconsistent entries—such as \"Unknown,\" \"N/A,\" or rare labels like \"children\"—which left us with a final group of 3,357 individuals. This clean dataset is stored in the object **`strokeclean`**.\n\nBecause our goal is to predict a binary outcome (Yes/No), Logistic Regression is our primary approach for determining if a patient has had a stroke ($Y=1$) or not ($Y=0$) [@hosmer2013applied; @james2021isl].\n\n**Variables**\n\nThe key predictors used in our analysis are listed below:\n\n| Variable | Type | Description |\n| :--- | :--- | :--- |\n| **age** | Numeric | Age of the individual (years) |\n| **gender** | Categorical | Biological sex (Male/Female) |\n| **hypertension** | Binary (0/1) | Prior hypertension diagnosis |\n| **heart_disease** | Binary (0/1) | Presence of heart disease |\n| **ever_married** | Binary | Marital status |\n| **work_type** | Categorical | Employment category |\n| **Residence_type** | Binary | Urban vs. Rural |\n| **smoking_status** | Categorical | Never / Former / Smokes |\n| **bmi** | Numeric | Body Mass Index |\n| **avg_glucose_level**| Numeric | Average glucose level |\n| **stroke** | Binary | Outcome (0=No, 1=Yes) |\n\n**Addressing Class Imbalance**\n\nOur dataset is highly unbalanced:\n\n* **Yes (Stroke):** ~5%\n* **No (No Stroke):** ~95%\n\nThis imbalance makes model evaluation tricky. A model could simply guess \"No Stroke\" for everyone and still achieve 95% accuracy, despite being useless for medical diagnosis. To avoid this trap, we look beyond simple accuracy and focus on metrics like sensitivity, specificity, ROC curves, AUC, and Youden’s J statistic.\n\n**Dataset Preparation**\n\nTo ensure our model is valid and to prevent \"data leakage\" (where the model accidentally sees data it shouldn't), we applied several preprocessing steps [@wang2014]:\n\n* **Removed Identifiers:** We dropped columns like Patient ID since they don't predict medical risk.\n* **Cleaned Labels:** We removed rows with vague labels (e.g., \"Unknown\") and standardized rare categories.\n* **Numeric Conversion:** We converted age, BMI, and glucose levels into standard numeric formats and turned categorical variables (like gender) into dummy variables.\n* **Consistency Checks:** We verified that all values fell within realistic ranges.\n\n**Model Validation**\n\nFinally, we split the data into training and testing sets. For the machine-learning comparison, we used **stratified sampling** (via `caret::createDataPartition`). This ensures that the ratio of stroke to non-stroke patients remains consistent in both the training and testing data, preventing the model from learning from a skewed sample [@chen2020modeling].\n\n**Logistic regression model **\n\nLet $Y_i$ denote the stroke status for patient $i$, where\n\n- $Y_i = 1$ if patient $i$ experienced a stroke  \n- $Y_i = 0$ otherwise.\n\nLet the predictor vector for patient $i$ be\n\n$$\n\\mathbf{x}_i = (x_{i1}, x_{i2}, \\ldots, x_{ip})^\\top,\n$$\n\nwhere the $p$ predictors such as age, hypertension, heart disease, average glucose level, BMI, and smoking status. \n\nThe logistic regression model specifies the conditional probability of stroke as\n\n$$\nP(Y_i = 1 \\mid \\mathbf{x}_i)\n= \\pi(\\mathbf{x}_i)\n= \\frac{\\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}\n       {1 + \\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}.\n$$\n\nEquivalently, the logit (log-odds) of stroke is modeled as a linear combination of the predictors:\n\n$$\n\\log\\left(\\frac{\\pi(\\mathbf{x}_i)}{1 - \\pi(\\mathbf{x}_i)}\\right)\n  = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}.\n$$\n\nHere, $\\beta_0$ is the intercept, $\\beta_j$ is the change in log-odds of stroke for a one-unit increase in predictor \n $x_j$, holding other variables constant.\n\nExponentiating $\\beta_j$ gives the odds ratio (OR):\n$$\n\\text{OR}_j = e^{\\beta_j},\n$$\n\nwhich represents the multiplicative change in the odds of stroke for a one-unit increase in $x_j$.\n\n**Model Estimation**\n\nLet $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^\\top$ denote the vector of\nregression coefficients. For independent observations, the likelihood of the data is\n$$\nL(\\boldsymbol{\\beta})\n= \\prod_{i=1}^{n}\n  \\pi(\\mathbf{x}_i)^{\\,y_i}\n  \\left[1 - \\pi(\\mathbf{x}_i)\\right]^{\\,1-y_i},\n$$\n\nwhere $\\pi(\\mathbf{x}_i) = P(Y_i = 1 \\mid \\mathbf{x}_i)$.\n\nThe **log-likelihood** is\n\n$$\n\\ell(\\boldsymbol{\\beta})\n= \\sum_{i=1}^{n}\n\\left[\n  y_i \\log\\big(\\pi(\\mathbf{x}_i)\\big)\n  +\n  (1 - y_i)\\log\\big(1 - \\pi(\\mathbf{x}_i)\\big)\n\\right].\n$$\n\nThe maximum likelihood estimate $\\hat{\\boldsymbol{\\beta}}$ is the value of\n$\\boldsymbol{\\beta}$ that maximizes $\\ell(\\boldsymbol{\\beta})$. In R, this optimization\nis carried out automatically using `glm(..., family = binomial)`\n\n**Machine Learning Models and Evaluation**\n\nTo see if advanced technology could outperform standard methods, we built six different supervised learning models using the `caret` framework. We wanted to determine if sophisticated algorithms could improve our ability to classify stroke risk compared to the baseline.\n\nThe six models were:\n\n* **Logistic Regression (LR)** – Our baseline.\n* **Decision Tree (rpart)** – A simple rule-based model.\n* **Random Forest (RF)** – An ensemble of many decision trees.\n* **Gradient Boosted Machine (GBM)** – A powerful, iterative learning model.\n* **k-Nearest Neighbours (k-NN)** – Classification based on similarity to other patients.\n* **Support Vector Machine (SVM-Radial)** – A model that finds complex boundaries between groups.\n\nTo guarantee a fair fight, every model was treated exactly the same. We used the same 70% training / 30% testing split and applied a consistent cross-validation procedure across the board.Once the model was fitted, we calculated the Odds Ratios and 95% Confidence Intervals to interpret the effect of each predictor.\n\n**Data Splitting and Model Fitting in R**\n\nWe began with our processed dataset, `strokeclean`. As a reminder, our target outcome is `stroke` (0 = No, 1 = Yes), and we are using predictors such as `age`, `hypertension`, `heart_disease`, `avg_glucose_level`, and `bmi`.\n\nFirst, we randomly split the data to create a training set (70%) for building the models and a hold-out test set (30%) to evaluate how well they perform on new data.\n\n\n**Data Splitting and Model Fitting in R**\n\nThe cleaned dataset is stored in the object `strokeclean`, where the outcome variable is\n`stroke` (0 = No stroke, 1 = Stroke), and predictors include `age`, `hypertension`,\n`heart_disease`, `avg_glucose_level`, `bmi`, `smoking_status`, and others.\n\nFirst, the dataset is randomly divided into a training set (70%) and a test set (30%) to\nevaluate out-of-sample performance, logistic regression model is then fitted on the training data:\n\n\nFrom this model, estimated odds ratios and 95% confidence intervals are computed as:\n\n\n\n**Model Predictions and Performance Measures**\n\nPredicted probabilities on the test set are obtained as:\n\n\nUsing a classification threshold $c = 0.5$, the predicted class for patient $i$ is\n\n$$\n\\hat{y}_i =\n\\begin{cases}\n1, & \\text{if } \\hat{\\pi}_i \\ge c, \\\\\\\\\n0, & \\text{if } \\hat{\\pi}_i < c.\n\\end{cases}\n$$\n\nwhere $\\hat{\\pi}_i$ is the predicted probability of stroke for patient $i$.\n\n\n**Evaluation Metrics**\n\nModels were evaluated using standard clinical classification metrics:\n\n- Accuracy\n\n- Sensitivity (Recall)\n\n- Specificity\n\n- Precision\n\n- F1-Score\n\n- Receiver Operating Characteristic (ROC) curve\n\n- Area Under the Curve (AUC)\n\nYouden’s J Statistic, Used to determine optimal classification threshold:\n\n$J = \\text{Sensitivity} + \\text{Specificity} - 1$\n\n\nThese metrics are widely used in stroke-risk modeling literature and as per article it is often used to find optimial classidfication threshhold. [@chen2020modeling].\n\n\n\n# Analysis\n\nBefore starting to generate predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\n\n\n**Distribution of Key Continuous Variables**\n\nHistograms were used to assess the spread of the primary numeric predictors (Age, BMI, and Average Glucose Level). These variables demonstrate clinically expected right-skewness, particularly glucose and BMI, consistent with published literature on metabolic and cardiovascular risk distributions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ncont_long <- strokeclean %>% \n  select(\n    Age = age,\n    BMI = bmi,\n    `Average Glucose` = avg_glucose_level\n  ) %>% \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\")\n\nggplot(cont_long, aes(Value, fill = Variable, colour = Variable)) +\n  geom_density(alpha = 0.25, linewidth = 1) +\n  facet_wrap(~ Variable, scales = \"free\", nrow = 1) +\n  labs(x = NULL, y = \"Density\") +\n  #palette = \"Dark2\") +\n  scale_colour_brewer(palette = \"Dark2\") +\n  theme_minimal(base_size = 12) +\n  theme(\n    strip.text = element_text(face = \"bold\"),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n**Interpretation of Key Continuous Predictors**\n\nWe examined the distributions of our three main numeric variables to identify patterns and potential risk factors.\n\n* **Age**\n  The age distribution is smooth, starting from late adolescence. The majority of individuals fall between **40 and 70 years old**, which corresponds to the population at highest risk for stroke. Since there are no extreme clusters or gaps, Age serves as an excellent continuous predictor.\n\n* **Average Glucose Level**\nThis variable shows a clear **right-skew**, meaning most people have normal levels, but there is a long \"tail\" of data extending above **200 mg/dL**. This highlights a specific subgroup of patients with poor metabolic health (likely indicating diabetes), which is a critical driver for heart disease and stroke risk.\n\n* **BMI**\nBMI values are tightly grouped between **22 and 35**, with relatively few outliers. Because there is less variation here compared to Age or Glucose, it may play a slightly weaker role in distinguishing between stroke and non-stroke cases. This observation aligns with our regression results, where BMI showed a smaller contribution than vascular predictors.\n\n\n**Distribution of Key Categorical Variables**\n\nBar charts help visualize population composition. The dataset shows more females than males, a balanced rural–urban distribution, and substantial variation in work type and smoking behavior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ncat_df = strokeclean %>%\nmutate(\ngender = factor(gender, levels = c(1, 2),\nlabels = c(\"Male\", \"Female\")),\nResidence_type = factor(Residence_type, levels = c(1, 2),\nlabels = c(\"Urban\", \"Rural\")),\nsmoking_status = factor(smoking_status,\nlevels = c(1, 2, 3),\nlabels = c(\"Never\", \"Former\", \"Current\"))\n) %>%\nselect(\nGender    = gender,\nResidence = Residence_type,\nSmoking   = smoking_status\n) %>%\npivot_longer(\neverything(),\nnames_to  = \"Variable\",\nvalues_to = \"Category\"\n) %>%\nfilter(!is.na(Category)) %>%\ncount(Variable, Category) %>%\ngroup_by(Variable) %>%\nmutate(prop = n / sum(n))\n\nggplot(cat_df, aes(x = Category, y = prop, fill = Category)) +\ngeom_col(width = 0.7, colour = \"white\") +\ngeom_text(aes(label = percent(prop, accuracy = 1)),\nvjust = -0.3, size = 3) +\nfacet_wrap(~ Variable, scales = \"free_x\") +\nscale_y_continuous(\nlabels = percent_format(accuracy = 1),\nexpand = expansion(mult = c(0, 0.10))\n) +\nlabs(x = NULL, y = \"Percentage of patients\") +\ntheme_minimal(base_size = 12) +\ntheme(\nlegend.position  = \"none\",\nstrip.text       = element_text(face = \"bold\"),\npanel.grid.minor = element_blank()\n)\n```\n\n::: {.cell-output-display}\n![Sample composition by gender, residence type, and smoking status.](index_files/figure-html/fig-cat-distribution-1.png){#fig-cat-distribution width=864}\n:::\n:::\n\n\n**Interpreatation**\n\n- **Gender**:The dataset has more female patients (61%) than males (39%).\nThis imbalance should be noted because gender-related model effects may partly reflect sample composition.\n\n- **Residence Type**:\nThe population is nearly evenly split between urban (51%) and rural (49%) residents.\nThis indicates no geographic bias and good representation of both environments.\n\n- **Smoking Status**:\nMost participants never smoked (54%), while 25% are former smokers and 22% are current smokers.\nThis provides enough variation to meaningfully examine smoking as a behavioral risk factor for stroke.\n\n**Stroke Risk for Clinical and  Behavioral Predictors **\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(scales)\n\nstopifnot(exists(\"strokeclean\"))\n\n\nstrokeclean_plot = strokeclean %>%\n  mutate(\n    stroke = factor(stroke, levels = c(\"No\", \"Yes\")),\n\n    hypertension = factor(\n      as.numeric(as.character(hypertension)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    heart_disease = factor(\n      as.numeric(as.character(heart_disease)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    smoking_status = factor(\n      as.numeric(as.character(smoking_status)),\n      levels = c(1, 2, 3),\n      labels = c(\"Never\", \"Former\", \"Current\")\n    )\n  )\n\n# 2. Helper: stroke proportion + 95% CI\nprop_ci = function(data, group) {\n  data %>%\n    group_by({{ group }}) %>%\n    summarise(\n      stroke_rate = mean(stroke == \"Yes\"),\n      n = n(),\n      se = sqrt(stroke_rate * (1 - stroke_rate) / n),\n      lower = pmax(0, stroke_rate - 1.96 * se),\n      upper = pmin(1, stroke_rate + 1.96 * se),\n      .groups = \"drop\"\n    )\n}\n\n\ndf_hyp   = prop_ci(strokeclean_plot, hypertension)\ndf_hd    = prop_ci(strokeclean_plot, heart_disease)\ndf_smoke = prop_ci(strokeclean_plot, smoking_status)\n\n\ntheme_stroke =\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 13, hjust = 0.5),\n    axis.title.x = element_blank()\n  )\n\n\ncols_hyp   = c(\"No\" = \"#FDE725FF\", \"Yes\" = \"#440154FF\")      \ncols_hd    = c(\"No\" = \"#20A387FF\", \"Yes\" = \"#F98400FF\")     \ncols_smoke = c(\"Never\" = \"#1F78B4\", \"Former\" = \"#33A02C\", \"Current\" = \"#E31A1C\")  \n\n\np1 =\n  ggplot(df_hyp, aes(x = hypertension, y = stroke_rate, fill = hypertension)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hyp) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Hypertension\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np2 =\n  ggplot(df_hd, aes(x = heart_disease, y = stroke_rate, fill = heart_disease)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hd) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Heart Disease\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np3 =\n  ggplot(df_smoke, aes(x = smoking_status, y = stroke_rate, fill = smoking_status)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_smoke) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Smoking Status\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\n\nggarrange(p1, p2, p3, ncol = 3, align = \"hv\")\n```\n\n::: {.cell-output-display}\n![Stroke percentages (95% CI) by hypertension, heart disease, and smoking status.](index_files/figure-html/fig-stroke-binary-risk-1.png){#fig-stroke-binary-risk width=1152}\n:::\n:::\n\n\n**Interpretation**\n\nThe figure summarises how stroke *risk* varies across key categorical predictors:\n\n- **Hypertension**\n  - Stroke risk is clearly higher among hypertensive patients.\n  - Confidence intervals show a noticeable separation, supporting a strong association.\n\n- **Heart Disease**\n  - Patients with heart disease show higher stroke percentages than those without.\n  - The pattern is consistent with cardiovascular disease being a major clinical risk factor.\n\n- **Smoking Status**\n  - Former and current smokers have higher stroke percentages than never-smokers.\n  - This reflects the long-term vascular effects of tobacco exposure.\n\nOverall, these categorical predictors show patterns aligned with clinical expectations:  \nvascular risks (hypertension, heart disease) and behavioural risks (smoking) are all associated with elevated stroke likelihood.\n\n**Correlation among key numeric prediators**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggcorrplot)\nlibrary(RColorBrewer)\n\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\nggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   \n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at <https://github.com/kassambara/ggcorrplot/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\n\n- Correlation Heatmap of Key Numeric Predictors, all correlations are weak to moderate (0.00–0.26) = no multicollinearity concerns.\n\n- Age shows small but meaningful positive correlations with:\n\n- glucose (0.24)\n\n- hypertension (0.26)\n\n- heart disease (0.26)\n= consistent with known aging-related cardiovascular risk patterns.\n\n- BMI has very weak correlations with all other predictors (0.04–0.16) = behaves independently in this dataset.\n\n- Avg glucose moderately correlates with:\n\n- hypertension (0.17)\n\n- heart disease (0.14)\n= aligns with metabolic/vascular relationships.\n\n- Hypertension and heart disease are weakly correlated (0.11) = related but not redundant.\n\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\n\n**Logistic Regression Model & its Coefficients**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n#| label: logit_fit\n#| echo: true\n#| warning: false\n#| message: false\n\nset.seed(123)\n\nn <- nrow(strokeclean)\ntrain_index <- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train <- strokeclean[train_index, ]\nstroke_test  <- strokeclean[-train_index, ]\n\nfit_glm <- glm(\n  stroke ~ age + hypertension + heart_disease +\n    avg_glucose_level + bmi + smoking_status +\n    gender + ever_married,\n  data   = stroke_train,\n  family = binomial(link = \"logit\")\n)\n\nsummary(fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   <2e-16 ***\nage                0.072637   0.008089   8.979   <2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n:::\n\n\n\n**Interpretation — Logistic Regression Coefficients**\n\n- Age is a strong and highly significant predictor (p < 0.001).\nHigher age is associated with a substantial increase in the odds of stroke.\n\n- Hypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\n\n- Average glucose level is also a important predictor (p = 0.0267).\nHigher glucose values modestly increase stroke risk.\n\n- Heart disease shows a positive association but is only borderline significant (p = 0.0718).\nThis suggests a potential effect, but not statistically explainable in this model.\n\n- Smoking has likewise borderline significant (p = 0.0714), indicating a  increased risk among smokers, but the evidence is not too much strong.\n\n- BMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p > 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\n\n- Model fit improved substantially from the null model\n(deviance reduced from 953.4 to 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\n\n**Odds ratios and confidence intervals**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef_est <- coef(fit_glm)\nOR       <- exp(coef_est)\n\nconf_int <- exp(confint(fit_glm))  \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nodds_table <- cbind(OR, conf_int)\ncolnames(odds_table) <- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013\n```\n\n\n:::\n:::\n\n\n**Interpretation**\n\nThe logistic regression results give us a clear picture of how each predictor influences the likelihood of having a stroke, assuming all other factors stay the same.\n\n* **Age (OR = 1.075, CI: 1.059–1.093)**\n  Age is by far the strongest continuous predictor. For every additional year of age, the odds of having a stroke increase by about **7.5%**. The confidence interval is tight and stays well above 1, confirming that this is a highly significant risk factor.\n\n* **Hypertension (OR = 1.577, CI: 0.996–2.450)**\n  Individuals with a history of hypertension have roughly **58% higher odds** of stroke compared to those without it. However, the confidence interval dips just below 1, meaning the effect is on the borderline of statistical significance. Despite this uncertainty, the large increase in odds suggests it is still clinically important.\n\n* **Heart Disease (OR = 1.628, CI: 0.942–2.733)**\n  Similar to hypertension, heart disease raises stroke odds by about **63%**. While the link is positive, the wide confidence interval (which crosses 1) indicates that the statistical evidence in this specific dataset is not definitive.\n\n* **Average Glucose Level (OR = 1.004, CI: 1.000–1.007)**\n  Higher glucose levels are linked to a slightly increased risk. Although the per-unit effect looks small, the confidence interval suggests marginal significance, which aligns with the known medical link between metabolic health and stroke.\n\n* **BMI (OR = 1.007, CI: 0.975–1.037)**\n  Interestingly, BMI showed almost no meaningful effect on stroke risk in our model. The confidence interval overlaps 1, suggesting that once we account for other factors (like age and glucose), BMI itself is not a significant driver here.\n\n* **Smoking Status**\n  * **Former Smokers (OR = 1.263):** Show 26% higher odds, though the evidence is statistically weak.\n  * **Current Smokers (OR = 1.598):** Face nearly **60% higher odds** of stroke. While the confidence interval still overlaps 1 (likely due to sample size), the trend clearly points to increased risk for active smokers.\n\n* **Gender & Marital Status**\n  Females showed slightly higher odds (**OR = 1.259**), and Marital Status (**OR = 1.126**) showed a small positive association, but neither factor was statistically significant in this analysis.\n\n**Model predictions and performance on the test set**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\nstroke_test$pred_prob <- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\nstroke_test$stroke <- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\nstroke_test$pred_class <- ifelse(stroke_test$pred_prob >= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class <- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\ncm <- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc > NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes            \n                                         \n```\n\n\n:::\n:::\n\n\nFrom the confusion matrix, the following performance metrics are defined:\n\n**Accuracy**\n$$\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n$$\n**Sensitivity (Recall / True Positive Rate)**\n\n$$\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n$$\n**Specificity (True Negative Rate)**\n\n$$\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n$$\n\n**Positive Predictive Value (Precision)**\n$$\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n$$\n**Negative Predictive Value (NPV)**\n\n$$\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n$$\n\n**Interpretation of Logistic Regression Performance (Test Set)**\n\n- Accuracy = 94.25%\nThe model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\n\n- Sensitivity (True Positive Rate) = 0.017\nThe model correctly identified only 1 out of 59 actual stroke cases (≈1.7%).\n= This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\n\n- Specificity (True Negative Rate) = 1.00\nThe model correctly classified all non-stroke cases.\n= It is extremely good at predicting “No stroke,” which dominates the dataset.\n\n- Positive Predictive Value (Precision) = 1.00\nWhen the model predicts “Yes,” it is always correct — but it predicted “Yes” only once.\nHigh precision is misleading because the model rarely predicts a positive case.\n\n- Negative Predictive Value = 0.942\nMost “No” predictions are correct, matching the overall class imbalance.\n\n- Kappa = 0.031\nKappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\n\n- Balanced Accuracy = 0.508\nWhen weighting sensitivity and specificity equally, the model performs at chance level (~50%).\n= Confirms that stroke detection is weak.\n\n- McNemar’s Test p < 0.0001\nStrong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity.\nIt performs well for the majority class (non-stroke), but fails for the minority class (stroke).\n\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\n\n**ROC curve and AUC for the logistic model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Compute ROC\nroc_glm <- roc(\n  response  = stroke_test$stroke,\n  predictor = stroke_test$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"<\"\n)\n\nauc_val <- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df <- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\n\n**Interpretation of ROC Curve and AUC (Test Set)**\n\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\n\nThe AUC = 0.815, which indicates good discriminative performance.\n\nAUC = 0.5 is  no discrimination (random guessing)\n\nAUC = 0.7–0.8 is acceptable\n\nAUC = 0.8–0.9 is good\n\nAUC > 0.9 is excellent\n\n- Even though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\n\n- The strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\n- threshold tuning,\n\n- cost-sensitive training,\n\n- resampling techniques (SMOTE / oversampling).\n\n\n**Machine-learning model comparison**\n\n**Data Splitting and prepration**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_df <- strokeclean\nmodel_df <- na.omit(model_df)\nmodel_df$stroke <- factor(model_df$stroke)\nlevels(model_df$stroke) <- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  No  Yes \n3177  180 \n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(123)\nindex <- createDataPartition(model_df$stroke, p = 0.70, list = FALSE)\ntrain_data <- model_df[index, ]\ntest_data  <- model_df[-index, ]\n\ntrain_data$stroke <- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  <- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n```\n:::\n\n\n**Train control settings**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)   # <- add this line to be safe\n\nctrl <- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary,\n  verboseIter = FALSE\n)\n```\n:::\n\n\n\n**Logistic Regression (caret)**\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_lr <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n**Decision Tree**\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_tree <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n```\n:::\n\n\n**Random Forest**\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rf <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n```\n:::\n\n\n**Gradient Boosted Machine (GBM)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_gbm <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n```\n:::\n\n\n**k-Nearest Neighbours (k-NN)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_knn <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n**Support Vector Machine (Radial)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_svm <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n**Model evaluation on the test set**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)   \nlibrary(caret)\nmodels_list <- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults <- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl <- models_list[[m]]\n\npreds_prob  <- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\npreds_class <- predict(mdl, test_data)\n\nroc_obj <- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"<\")\nauc_val <- auc(roc_obj)\n\ncm_m <- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults <- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534\n```\n\n\n:::\n:::\n\n\n**Interpretation**\n\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\n\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\n\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\n\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\n\n\n**ROC curve comparison across models**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\nroc_list <- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\")\n)\n\nauc_vals <- sapply(roc_list, auc)\n\nroc_df <- do.call(rbind, lapply(names(roc_list), function(m) {\n  r <- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\nroc_df$model <- factor(roc_df$model, levels = names(roc_list))\n\nlabel_map <- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) <- names(auc_vals)\n\nmodel_cols <- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\nggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\n\nInterpretation of ROC Comparison Across Models\n\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\n\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\n\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\n\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\n\nAll models perform above 0.5, meaning they all do better than random chance — but with large differences in quality.\n\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\n\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\n\n**Odds ratios and risk stratification**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\nglm_lr <- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\nlr_coef <- summary(glm_lr)$coefficients           \nci_raw  <- suppressMessages(confint(glm_lr))      \n\nor_df <- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(>|z|)\"]\n) %>% \nfilter(Predictor != \"(Intercept)\") %>%\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n\nSig = ifelse(p_value < 0.05, \"p < 0.05\", \"NS\")\n) %>%\narrange(OR) %>%\nmutate(Label = factor(Label, levels = Label))\n\nggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p < 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\n\n- Hypertension (Yes vs No)\n\nThis is the strongest predictor. Its OR is clearly > 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\n\n- Age (per year)\n\nThe OR is slightly above 1 with a narrow CI fully above 1 (orange).\n\nEach additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\n\n- Average glucose level\n\nOR is just above 1 with a tight CI above 1 (orange).\n\nHigher glucose is associated with a modest but statistically reliable increase in stroke risk, consistent with metabolic / diabetes-related vascular risk.\n\n- Ever married, heart disease, smoking status, gender, BMI, residence, work type\n\nTheir confidence intervals all cross 1 (grey points), so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.Some (e.g., heart disease, smoking) still have ORs above 1, suggesting possible elevated risk, but the evidence is weaker in this dataset.\n\nOverall message:\nThe forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\n\n**Threshold tuning to 0.2 from 0.5**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_threshold <- 0.2\n\nstroke_test$pred_class_02 <- ifelse(stroke_test$pred_prob >= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 <- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\ncm_02 <- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm_02\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes             \n                                          \n```\n\n\n:::\n:::\n\n\n**Interpretation (threshold = 0.2)**\n\n- With a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\n\n- Specificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as \"no stroke\" (903 out of 949).\n\n- While overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives.\n\n\n# Conclusion\n\nIn this study, we set out to determine if standard demographic, behavioral, and clinical records could effectively predict stroke risk. We compared a traditional Logistic Regression model against several machine learning algorithms using a cleaned dataset of 3,357 individuals. Because strokes were rare in our sample (occurring in only about 5% of cases), we faced a classic \"class imbalance\" challenge, which made identifying high-risk patients particularly difficult.\n\n- **Key Risk Factors**\n\nOur baseline Logistic Regression model confirmed what we know from clinical literature: **Age, hypertension, heart disease, and high glucose levels** are the strongest predictors of stroke. Smoking also stood out as a substantial risk factor. The model produced odds ratios significantly greater than 1 for these variables (with confidence intervals that did not cross 1), confirming them as statistically significant drivers of risk. This validates Logistic Regression as a transparent tool for explaining *why* a specific patient is at risk.\n\n- **Model Performance and the \"Imbalance\" Challenge**\n\nWhen we first ran the Logistic Regression model using the standard decision threshold of **0.5**, the results were mixed. While the model performed better than random guessing (based on AUC scores), it struggled to actually find the stroke cases. Specifically, the **sensitivity was extremely low (around 2%)**, meaning the model missed almost every true stroke case because it was biased toward the majority \"No Stroke\" class.\n\nTo fix this, we adjusted the decision threshold down to **0.2**. This simple change had a dramatic effect:\n* **Sensitivity** jumped from ~2% to **~22%**.\n* **Specificity** remained high at around **95%**.\n* **Overall Accuracy** dipped slightly to **91%**, but the **Balanced Accuracy** improved.\n\nThis experiment illustrates a critical lesson for medical screening: when dealing with dangerous but rare events like stroke, it is often better to accept a few false alarms (lower precision) in exchange for catching more true cases (higher sensitivity).\n\n- **Logistic Regression vs. Machine Learning**\n\nWhen we pitted Logistic Regression against advanced models like **Random Forest** and **Gradient Boosted Machines**, the advanced models did achieve slightly higher AUC scores. They were better at discriminating between groups across various thresholds.\n\nHowever, this extra power came at a cost. The machine learning models are \"black boxes\"—harder to interpret and explain to a patient. In contrast, Logistic Regression provides precise odds ratios that doctors can easily translate into clinical advice.\n\n- **Future Directions**\n\nOverall, our findings show that even simple models using routine health data can meaningfully distinguish stroke risk. While tree-based models offer a slight performance edge, Logistic Regression remains a robust, interpretable baseline.\n\nFuture work should focus on:\n1.  **External Validation:** Testing these models on data from different hospitals or regions.\n2.  **Calibration:** Ensuring the predicted probabilities match real-world risk levels.\n3.  **Data Enrichment:** Incorporating longitudinal data (health changes over time) to move this from a theoretical exercise to a practical clinical tool.\n\n\n# References\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}