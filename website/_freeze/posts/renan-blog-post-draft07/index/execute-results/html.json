{
  "hash": "f42699f55adb6850b864ba2b3c836283",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Draft v07 --- Predicting stroke risk from common health indicators: a binary logistic regression analysis\"\ndescription: \"Shree sent back draft with changes\"\nauthor:\n  - name: Renan Monteiro Barbosa\n    url: https://github.com/renanmb\n    affiliation: Master of Data Science Program @ The University of West Florida (UWF)\n  - name: \"Shree Krishna M.S Basnet\"\n  - name: \"Supervisor: Dr. Cohen\"\n# date: 10-24-2022\ncategories: [draft, renan, shree]\n# citation:\n#   url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/\nimage: images/spongebob-imagination.jpg\ndraft: false\nbibliography: references.bib\nlink-citations: true\n---\n\n\n\n\n# Introduction\n\nStroke affects people all around the world, resulting in numerous deaths and disabilities.  [@WHO2025]. If we are able to detection stroke early for those at increased risk is will be amazing for prevention and prompt intervention because stroke frequently happens quickly and can cause long-term neurological disability.  Clinicians and public health experts can measure individual-level risk and target high-risk populations for clinical management and lifestyle counseling by using data-driven risk prediction models.\n\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease is present in human or not  [@sperandei2014understanding]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia [@asmare2024determinants], road traffic safety [@rahman2021identification; @chen2024binary; @chen2020modeling], health-care utilisation and clinical admission decisions [@hutchinson2023predictors], and fraud detection [@samara2024using]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\n\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\n\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset.\n\n# Methodology\n\nThis part explains about our stoke dataset, variables, preprocessing steps, logistic regression formulation, and the machine-learning modelling framework used to compare classifiers.\n\nOur datset contains 5,110 observations and 11 predictors commonly associated with cerebrovascular risk. After cleaning missing and inconsistent entries (e.g., ‚ÄúUnknown‚Äù, ‚ÄúN/A‚Äù, or rare textual categories such as ‚Äúchildren‚Äù and ‚Äúother‚Äù), a final dataset of 3,357 individuals remained for analysis. The cleaned dataset is stored in the object **strokeclean**.\n\nRespose we get is in binary so logestic regression is the best approach to observe whether the patient has had **stroke=1** or not **stroke=0** [@hosmer2013applied; @james2021isl]\n\n**Variables**\n\nThe key predictors are listed below.\n\n| Variable              | Type                           | Description                   |\n| --------------------- | ------------------------------ | ----------------------------- |\n| **age**               | Numeric                        | Age of the individual (years) |\n| **gender**            | Categorical (1=Male, 2=Female) | Biological sex                |\n| **hypertension**      | Binary (0/1)                   | Prior hypertension diagnosis  |\n| **heart_disease**     | Binary (0/1)                   | Presence of heart disease     |\n| **ever_married**      | Binary                         | Marital status                |\n| **work_type**         | Categorical (1‚Äì4)              | Employment category           |\n| **Residence_type**    | Binary (1=Urban, 2=Rural)      | Place of residence            |\n| **smoking_status**    | Categorical                    | Never/Former/Smokes           |\n| **bmi**               | Numeric                        | Body Mass Index               |\n| **avg_glucose_level** | Numeric                        | Average glucose level         |\n| **stroke**            | Binary outcome (0=No, 1=Yes)   | Stroke occurrence             |\n\nStroke is a highly unbalanced outcome variable:\n- Yes (stroke): about 5%\n- No (no stroke): around 95%\n\nBecause it is possible to achieve high overall accuracy by merely forecasting the majority class, this class imbalance directly affects model evaluation. Because of this, in addition to accuracy, we also concentrate on sensitivity, specificity, ROC curves, AUC, and Youden's J statistic.\n\n**Dataset Prepration**\n\nTo guarantee model validity and stop data leakage, data preprocessing is performed. [@wang2014].\n\nAmong the steps were:\n\n- Elimination of non-predictive identifiers (patient ID)\n\n- Transforming categorical variables into dummy numerical representations\n\n- Managing uncommon or irregular categories (e.g., \"Other\" gender values handled as absent)\n\n- BMI, glucose, and age conversion to numerical\n\n- Rows with unintelligible labels (\"Unknown,\" \"N/A\") are removed.\n\n- Valid range and consistency verification\n\n- After recoding, missing values might be imputed or removed.\n\n- During splitting, stratified sampling is used to maintain the stroke/no-stroke ratio [@chen2020modeling].\n\n- The outcome stroke was defined as a factor with levels \"No\" and \"Yes\" in the cleaned dataset strokeclean.\n\nTo check sample performance, the data were split into training and test sets. For the baseline logistic regression model, a simple random 70/30 split was used. For the full machine-learning comparison, a stratified partition (via caret::createDataPartition) was applied to preserve the stroke/no-stroke ratio in both sets.\n\n**Logistic regression model**\n\nLet $Y_i$ denote the stroke status for patient $i$, where\n\n- $Y_i = 1$ if patient $i$ experienced a stroke  \n- $Y_i = 0$ otherwise.\n\nLet the predictor vector for patient $i$ be\n\n$$\n\\mathbf{x}_i = (x_{i1}, x_{i2}, \\ldots, x_{ip})^\\top,\n$$\n\nwhere the $p$ predictors such as age, hypertension, heart disease, average glucose level, BMI, and smoking status. \n\nThe logistic regression model specifies the conditional probability of stroke as\n\n$$\nP(Y_i = 1 \\mid \\mathbf{x}_i)\n= \\pi(\\mathbf{x}_i)\n= \\frac{\\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}\n       {1 + \\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}.\n$$\n\nEquivalently, the logit (log-odds) of stroke is modeled as a linear combination of the predictors:\n\n$$\n\\log\\left(\\frac{\\pi(\\mathbf{x}_i)}{1 - \\pi(\\mathbf{x}_i)}\\right)\n  = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}.\n$$\n\nHere, $\\beta_0$ is the intercept, $\\beta_j$ is the change in log-odds of stroke for a one-unit increase in predictor \n $x_j$, holding other variables constant.\n\nExponentiating $\\beta_j$ gives the odds ratio (OR):\n$$\n\\text{OR}_j = e^{\\beta_j},\n$$\n\n\nwhich represents the multiplicative change in the odds of stroke for a one-unit increase in $x_j$.\n\n**Model Estimation**\n\nLet $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^\\top$ denote the vector of\nregression coefficients. For independent observations, the likelihood of the data is\n$$\nL(\\boldsymbol{\\beta})\n= \\prod_{i=1}^{n}\n  \\pi(\\mathbf{x}_i)^{\\,y_i}\n  \\left[1 - \\pi(\\mathbf{x}_i)\\right]^{\\,1-y_i},\n$$\n\nwhere $\\pi(\\mathbf{x}_i) = P(Y_i = 1 \\mid \\mathbf{x}_i)$.\n\nThe **log-likelihood**   is\n\n$$\n\\ell(\\boldsymbol{\\beta})\n= \\sum_{i=1}^{n}\n\\left[\n  y_i \\log\\big(\\pi(\\mathbf{x}_i)\\big)\n  +\n  (1 - y_i)\\log\\big(1 - \\pi(\\mathbf{x}_i)\\big)\n\\right].\n$$\n\nThe maximum likelihood estimate $\\hat{\\boldsymbol{\\beta}}$ is the value of\n$\\boldsymbol{\\beta}$ that maximizes $\\ell(\\boldsymbol{\\beta})$. In R, this optimization\nis carried out automatically using `glm(..., family = binomial)`\n\n\n\n**Machine learning models and evaluation**\n\nSix supervised models were fitted using the caret framework in order to determine whether more sophisticated methods may significantly enhance stroke classification:\n\n- Logistic Regression (LR)\n\n- Decision Tree (rpart)\n\n- Random Forest (RF)\n\n- Gradient Boosted Machine (GBM)\n\n- k-Nearest Neighbours (k-NN)\n\n- Support Vector Machine with radial kernel (SVM-Radial)\n\nAll models used the same 70% training / 30% test split and a consistent cross-validation procedure to ensure fair comparison.\nTo guarantee a fair comparison, all models employed the same cross-validation process and a 70% training/30% test split.\n\n\n**Data Splitting and Model Fitting in R**\n\nThe cleaned dataset is stored in the object `strokeclean`, where the outcome variable is\n`stroke` (0 = No stroke, 1 = Stroke), and predictors include `age`, `hypertension`,\n`heart_disease`, `avg_glucose_level`, `bmi`, `smoking_status`, and others.\n\nFirst, the dataset is randomly divided into a training set (70%) and a test set (30%) to\nevaluate out-of-sample performance, logistic regression model is then fitted on the training data:\n\n\nFrom this model, estimated odds ratios and 95% confidence intervals are computed as:\n\n\n\n**Model Predictions and Performance Measures**\n\nPredicted probabilities on the test set are obtained as:\n\n\nUsing a classification threshold $c = 0.5$, the predicted class for patient $i$ is\n\n$$\n\\hat{y}_i =\n\\begin{cases}\n1, & \\text{if } \\hat{\\pi}_i \\ge c, \\\\\\\\\n0, & \\text{if } \\hat{\\pi}_i < c.\n\\end{cases}\n$$\n\nwhere $\\hat{\\pi}_i$ is the predicted probability of stroke for patient $i$.\n\n\n**Evaluation Metrics**\n\nModels were evaluated using standard clinical classification metrics:\n\n- Accuracy\n\n- Sensitivity (Recall)\n\n- Specificity\n\n- Precision\n\n- F1-Score\n\n- Receiver Operating Characteristic (ROC) curve\n\n- Area Under the Curve (AUC)\n\nYouden‚Äôs J Statistic, Used to determine optimal classification threshold:\n\n$J = \\text{Sensitivity} + \\text{Specificity} - 1$\n\n\nThese metrics are widely used in stroke-risk modeling literature and as per article it is often used to find optimial classidfication threshhold. [@chen2020modeling].\n\n# Analysis\n\nBefore starting to generate predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\n\n\n**Distribution of Key Continuous Variables**\n\nHistograms were used to assess the spread of the primary numeric predictors (Age, BMI, and Average Glucose Level). These variables demonstrate clinically expected right-skewness, particularly glucose and BMI, consistent with published literature on metabolic and cardiovascular risk distributions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ncont_long <- strokeclean %>% \n  select(\n    Age = age,\n    BMI = bmi,\n    `Average Glucose` = avg_glucose_level\n  ) %>% \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\")\n\nggplot(cont_long, aes(Value, fill = Variable, colour = Variable)) +\n  geom_density(alpha = 0.25, linewidth = 1) +\n  facet_wrap(~ Variable, scales = \"free\", nrow = 1) +\n  labs(x = NULL, y = \"Density\") +\n  #palette = \"Dark2\") +\n  scale_colour_brewer(palette = \"Dark2\") +\n  theme_minimal(base_size = 12) +\n  theme(\n    strip.text = element_text(face = \"bold\"),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Interpretation of Key Continuous Predictors\n\n- **Age**\n  - Smooth distribution from late teen.\n  - Majority between **40‚Äì70**, is at high-risk .\n  - No extreme clusters ‚Üí good continuous predictor.\n\n- **Average Glucose Level**\n  - Clear **right-skew** with a long tail above **200 mg/dL**.\n  - Indicates a small group with poor metabolic problem (likely diabetic).\n  - Highly relevant for heart and stroke-related risk.\n\n- **BMI**\n  - Compact distribution (~22‚Äì35) with few outliers.\n  - Less variation ‚Üí weaker contribution compared to vascular predictors.\n  - Pattern aligns with medical proven BMI as influence in our regression results.\n\n\n**Distribution of Key Categorical Variables**\n\nBar charts help visualize population composition. The dataset shows more females than males, a balanced rural‚Äìurban distribution, and substantial variation in work type and smoking behavior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ncat_df = strokeclean %>%\nmutate(\ngender = factor(gender, levels = c(1, 2),\nlabels = c(\"Male\", \"Female\")),\nResidence_type = factor(Residence_type, levels = c(1, 2),\nlabels = c(\"Urban\", \"Rural\")),\nsmoking_status = factor(smoking_status,\nlevels = c(1, 2, 3),\nlabels = c(\"Never\", \"Former\", \"Current\"))\n) %>%\nselect(\nGender    = gender,\nResidence = Residence_type,\nSmoking   = smoking_status\n) %>%\npivot_longer(\neverything(),\nnames_to  = \"Variable\",\nvalues_to = \"Category\"\n) %>%\nfilter(!is.na(Category)) %>%\ncount(Variable, Category) %>%\ngroup_by(Variable) %>%\nmutate(prop = n / sum(n))\n\nggplot(cat_df, aes(x = Category, y = prop, fill = Category)) +\ngeom_col(width = 0.7, colour = \"white\") +\ngeom_text(aes(label = percent(prop, accuracy = 1)),\nvjust = -0.3, size = 3) +\nfacet_wrap(~ Variable, scales = \"free_x\") +\nscale_y_continuous(\nlabels = percent_format(accuracy = 1),\nexpand = expansion(mult = c(0, 0.10))\n) +\nlabs(x = NULL, y = \"Percentage of patients\") +\ntheme_minimal(base_size = 12) +\ntheme(\nlegend.position  = \"none\",\nstrip.text       = element_text(face = \"bold\"),\npanel.grid.minor = element_blank()\n)\n```\n\n::: {.cell-output-display}\n![Sample composition by gender, residence type, and smoking status.](index_files/figure-html/fig-cat-distribution-1.png){#fig-cat-distribution width=864}\n:::\n:::\n\n\n**Interpreatation**\nGender:\nThe dataset has more female patients (61%) than males (39%).\nThis imbalance should be noted because gender-related model effects may partly reflect sample composition.\n\nResidence Type:\nThe population is nearly evenly split between urban (51%) and rural (49%) residents.\nThis indicates no geographic bias and good representation of both environments.\n\nSmoking Status:\nMost participants never smoked (54%), while 25% are former smokers and 22% are current smokers.\nThis provides enough variation to meaningfully examine smoking as a behavioral risk factor for stroke.\n\n**Stroke Risk for Clinical and  Behavioral Predictors **\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(scales)\n\nstopifnot(exists(\"strokeclean\"))\n\n# 1. Prepare a plotting data copy\nstrokeclean_plot = strokeclean %>%\n  mutate(\n    stroke = factor(stroke, levels = c(\"No\", \"Yes\")),\n\n    hypertension = factor(\n      as.numeric(as.character(hypertension)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    heart_disease = factor(\n      as.numeric(as.character(heart_disease)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    smoking_status = factor(\n      as.numeric(as.character(smoking_status)),\n      levels = c(1, 2, 3),\n      labels = c(\"Never\", \"Former\", \"Current\")\n    )\n  )\n\n# 2. Helper: stroke proportion + 95% CI\nprop_ci = function(data, group) {\n  data %>%\n    group_by({{ group }}) %>%\n    summarise(\n      stroke_rate = mean(stroke == \"Yes\"),\n      n = n(),\n      se = sqrt(stroke_rate * (1 - stroke_rate) / n),\n      lower = pmax(0, stroke_rate - 1.96 * se),\n      upper = pmin(1, stroke_rate + 1.96 * se),\n      .groups = \"drop\"\n    )\n}\n\n# 3. Summary tables\ndf_hyp   = prop_ci(strokeclean_plot, hypertension)\ndf_hd    = prop_ci(strokeclean_plot, heart_disease)\ndf_smoke = prop_ci(strokeclean_plot, smoking_status)\n\n# 4. Professional theme\ntheme_stroke =\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 13, hjust = 0.5),\n    axis.title.x = element_blank()\n  )\n\n# 5. Distinct colors for internal comparisons\ncols_hyp   = c(\"No\" = \"#FDE725FF\", \"Yes\" = \"#440154FF\")      # yellow‚Äìpurple\ncols_hd    = c(\"No\" = \"#20A387FF\", \"Yes\" = \"#F98400FF\")      # teal‚Äìorange\ncols_smoke = c(\"Never\" = \"#1F78B4\", \"Former\" = \"#33A02C\", \"Current\" = \"#E31A1C\")  # blue‚Äìgreen‚Äìred\n\n# 6. Individual panels\np1 =\n  ggplot(df_hyp, aes(x = hypertension, y = stroke_rate, fill = hypertension)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hyp) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Hypertension\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np2 =\n  ggplot(df_hd, aes(x = heart_disease, y = stroke_rate, fill = heart_disease)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hd) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Heart Disease\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np3 =\n  ggplot(df_smoke, aes(x = smoking_status, y = stroke_rate, fill = smoking_status)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_smoke) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Smoking Status\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\n# 7. Final combined figure\nggarrange(p1, p2, p3, ncol = 3, align = \"hv\")\n```\n\n::: {.cell-output-display}\n![Stroke percentages (95% CI) by hypertension, heart disease, and smoking status.](index_files/figure-html/fig-stroke-binary-risk-1.png){#fig-stroke-binary-risk width=1152}\n:::\n:::\n\n\n**Interpretation**\n\nThe figure summarises how stroke *risk* varies across key categorical predictors:\n\n- **Hypertension**\n  - Stroke risk is clearly higher among hypertensive patients.\n  - Confidence intervals show a noticeable separation, supporting a strong association.\n\n- **Heart Disease**\n  - Patients with heart disease show higher stroke percentages than those without.\n  - The pattern is consistent with cardiovascular disease being a major clinical risk factor.\n\n- **Smoking Status**\n  - Former and current smokers have higher stroke percentages than never-smokers.\n  - This reflects the long-term vascular effects of tobacco exposure.\n\nOverall, these categorical predictors show patterns aligned with clinical expectations:  \nvascular risks (hypertension, heart disease) and behavioural risks (smoking) are all associated with elevated stroke likelihood.\n\n\n\n**Correlation among key numeric prediators**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggcorrplot)\nlibrary(RColorBrewer)\n\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\nggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   # üî• high contrast red‚Üíwhite‚Üíblue\n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\n‚Ñπ Please use tidy evaluation idioms with `aes()`.\n‚Ñπ See also `vignette(\"ggplot2-in-packages\")` for more information.\n‚Ñπ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at <https://github.com/kassambara/ggcorrplot/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\nCorrelation Heatmap of Key Numeric Predictors\n\nAll correlations are weak to moderate (0.00‚Äì0.26) ‚Üí no multicollinearity concerns.\n\nAge shows small but meaningful positive correlations with:\n\nglucose (0.24)\n\nhypertension (0.26)\n\nheart disease (0.26)\n‚Üí consistent with known aging-related cardiovascular risk patterns.\n\nBMI has very weak correlations with all other predictors (0.04‚Äì0.16) ‚Üí behaves independently in this dataset.\n\nAvg glucose moderately correlates with:\n\nhypertension (0.17)\n\nheart disease (0.14)\n‚Üí aligns with metabolic/vascular relationships.\n\nHypertension and heart disease are weakly correlated (0.11) ‚Üí related but not redundant.\n\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\n\n**Logistic Regression Model & its Coefficients**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n#| label: logit_fit\n#| echo: true\n#| warning: false\n#| message: false\n\nset.seed(123)\n\nn <- nrow(strokeclean)\ntrain_index <- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train <- strokeclean[train_index, ]\nstroke_test  <- strokeclean[-train_index, ]\n\nfit_glm <- glm(\n  stroke ~ age + hypertension + heart_disease + avg_glucose_level + bmi + smoking_status + gender + ever_married,\n  data   = stroke_train,\n  family = binomial(link = \"logit\")\n)\n\nsummary(fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   <2e-16 ***\nage                0.072637   0.008089   8.979   <2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n:::\n\n\n\n**Interpretation ‚Äî Logistic Regression Coefficients**\n\n- Age is a strong and highly significant predictor (p < 0.001).\nHigher age is associated with a substantial increase in the odds of stroke.\n\n- Hypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\n\n- Average glucose level is also a important predictor (p = 0.0267).\nHigher glucose values modestly increase stroke risk.\n\n- Heart disease shows a positive association but is only borderline significant (p = 0.0718).\nThis suggests a potential effect, but not statistically explainable in this model.\n\n- Smoking has likewise borderline significant (p = 0.0714), indicating a  increased risk among smokers, but the evidence is not too much strong.\n\n- BMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p > 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\n\n- Model fit improved substantially from the null model\n(deviance reduced from 953.4 ‚Üí 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\n\n**Odds ratios and confidence intervals**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Odds ratios and 95% confidence intervals\n\ncoef_est <- coef(fit_glm)\nOR       <- exp(coef_est)\n\nconf_int <- exp(confint(fit_glm))  # confidence intervals on OR scale\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nodds_table <- cbind(OR, conf_int)\ncolnames(odds_table) <- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013\n```\n\n\n:::\n:::\n\n\n**Interpretation**\n\nThe logistic regression findings demonstrate how each predictor impacts the likelihood of having a stroke, while keeping other variables constant:\n\n- Age (OR = 1.075, CI: 1.059‚Äì1.093)\nAge is the strongest continuous predictor. Each additional year of age increases the odds of stroke by about 7.5%, and the confidence interval does not include 1, indicating strong statistical significance.\n\n- Hypertension (OR = 1.577, CI: 0.996‚Äì2.450)\nIndividuals with hypertension have roughly 58% higher odds of stroke compared to those without hypertension, although the lower CI bound is just below 1. This suggests a borderline significant effect, but clinically important.\n\n- Heart disease (OR = 1.628, CI: 0.942‚Äì2.733)\nHeart disease increases stroke odds by about 63%, but the CI includes 1, implying the association is positive but not statistically strong in this dataset.\n\n- Average glucose level (OR = 1.004, CI: 1.000‚Äì1.007)\nHigher glucose levels are associated with slightly increased stroke risk. Though the effect is small, the CI indicates marginal significance, aligning with known metabolic risk patterns.\n\n- BMI (OR = 1.007, CI: 0.975‚Äì1.037)\nBMI shows almost no meaningful effect on stroke risk, and the CI overlaps 1. This predictor does not significantly influence stroke likelihood in this dataset.\n\n- Smoking (Fsmoked OR = 1.263; Smokes OR = 1.598)\n\n- Former smokers have 26% higher odds, but CI crosses 1 ‚Üí weak evidence.\n\n- Current smokers have ~60% higher odds, but CI still overlaps 1 ‚Üí suggests increased risk but not statistically conclusive here.\n\n- Gender (Female) (OR = 1.259; CI: 0.842‚Äì1.903)\nFemales show slightly higher odds, but this effect is not statistically significant.\n\n- Ever married (OR = 1.126; CI: 0.590‚Äì2.013)\nMarital status has no clear effect on stroke odds in this sample.\n\n\n**Model predictions and performance on the test set**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# 1) Predicted probabilities from logistic regression\nstroke_test$pred_prob <- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\nstroke_test$stroke <- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\nstroke_test$pred_class <- ifelse(stroke_test$pred_prob >= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class <- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm <- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc > NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes            \n                                         \n```\n\n\n:::\n:::\n\n\nFrom the confusion matrix, the following performance metrics are defined:\n\n**Accuracy**\n$$\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n$$\n**Sensitivity (Recall / True Positive Rate)**\n\n$$\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n$$\n**Specificity (True Negative Rate)**\n\n$$\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n$$\n\n**Positive Predictive Value (Precision)**\n$$\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n$$\n**Negative Predictive Value (NPV)**\n\n$$\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n$$\n\n**Interpretation of Logistic Regression Performance (Test Set)**\n\n- Accuracy = 94.25%\nThe model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\n\n- Sensitivity (True Positive Rate) = 0.017\nThe model correctly identified only 1 out of 59 actual stroke cases (‚âà1.7%).\n‚Üí This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\n\n- Specificity (True Negative Rate) = 1.00\nThe model correctly classified all non-stroke cases.\n‚Üí It is extremely good at predicting ‚ÄúNo stroke,‚Äù which dominates the dataset.\n\n- Positive Predictive Value (Precision) = 1.00\nWhen the model predicts ‚ÄúYes,‚Äù it is always correct ‚Äî but it predicted ‚ÄúYes‚Äù only once.\nHigh precision is misleading because the model rarely predicts a positive case.\n\n- Negative Predictive Value = 0.942\nMost ‚ÄúNo‚Äù predictions are correct, matching the overall class imbalance.\n\n- Kappa = 0.031\nKappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\n\n- Balanced Accuracy = 0.508\nWhen weighting sensitivity and specificity equally, the model performs at chance level (~50%).\n‚Üí Confirms that stroke detection is weak.\n\n- McNemar‚Äôs Test p < 0.0001\nStrong evidence that the model‚Äôs errors are systematically skewed‚Äîit overwhelmingly predicts ‚ÄúNo stroke.‚Äù\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity.\nIt performs well for the majority class (non-stroke), but fails for the minority class (stroke).\n\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\n\n**ROC curve and AUC for the logistic model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Compute ROC\nroc_glm <- roc(\n  response  = stroke_test$stroke,\n  predictor = stroke_test$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"<\"\n)\n\nauc_val <- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df <- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 ‚Äì Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\n\n**Interpretation of ROC Curve and AUC (Test Set)**\n\nThe ROC curve evaluates the model‚Äôs ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\n\nThe AUC = 0.815, which indicates good discriminative performance.\n\nAUC = 0.5 is  no discrimination (random guessing)\n\nAUC = 0.7‚Äì0.8 is acceptable\n\nAUC = 0.8‚Äì0.9 is good\n\nAUC > 0.9 is excellent\n\n- Even though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\n\n- The strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\n- threshold tuning,\n\n- cost-sensitive training,\n\n- resampling techniques (SMOTE / oversampling).\n\n\n**Machine-learning model comparison**\n\n**Data Splitting and prepration**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_df <- strokeclean\nmodel_df <- na.omit(model_df)\nmodel_df$stroke <- factor(model_df$stroke)\nlevels(model_df$stroke) <- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  No  Yes \n3177  180 \n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(123)\nindex <- createDataPartition(model_df$stroke, p = 0.70, list = FALSE)\ntrain_data <- model_df[index, ]\ntest_data  <- model_df[-index, ]\n\ntrain_data$stroke <- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  <- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n```\n:::\n\n\n**Train control settings**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)   # <- add this line to be safe\n\nctrl <- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary,\n  verboseIter = FALSE\n)\n```\n:::\n\n\n\n**Logistic Regression (caret)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_lr <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n\n**Decision Tree**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_tree <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n```\n:::\n\n\n**Random Forest**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rf <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n```\n:::\n\n\n**Gradient Boosted Machine (GBM)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_gbm <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n```\n:::\n\n\n**k-Nearest Neighbours (k-NN)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_knn <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n**Support Vector Machine (Radial)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_svm <- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n```\n:::\n\n\n**Model evaluation on the test set**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)   \nlibrary(caret)\nmodels_list <- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults <- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl <- models_list[[m]]\n\n# Probabilities for the \"Yes\" class\n\npreds_prob  <- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\n# Class predictions\n\npreds_class <- predict(mdl, test_data)\n\n# ROC & AUC\n\nroc_obj <- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"<\")\nauc_val <- auc(roc_obj)\n\n# Confusion matrix ‚Äì positive = \"Yes\"\n\ncm_m <- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults <- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534\n```\n\n\n:::\n:::\n\n\n**Interpretation**\n\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\n\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\n\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1‚Äì2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\n\nAll models appear to perform well based on accuracy and specificity, but this is misleading‚Äîthey are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\n\n\n**ROC curve comparison across models**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\n# 1. Create ROC objects for each model\nroc_list <- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"<\")\n)\n\n# 2. AUC values\nauc_vals <- sapply(roc_list, auc)\n\n# 3. Long data frame of ROC coordinates\nroc_df <- do.call(rbind, lapply(names(roc_list), function(m) {\n  r <- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\n# Treat model as factor in a consistent order\nroc_df$model <- factor(roc_df$model, levels = names(roc_list))\n\n# 4. Legend labels with AUC\nlabel_map <- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) <- names(auc_vals)\n\n# 5. Color palette by short model name\nmodel_cols <- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\n# 6. Plot\nggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 ‚Äì Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\n\nInterpretation of ROC Comparison Across Models\n\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\n\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\n\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\n\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\n\nAll models perform above 0.5, meaning they all do better than random chance ‚Äî but with large differences in quality.\n\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\n\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\n\n**Odds ratios and risk stratification**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Fit logistic regression on the same train_data used in the ML comparison\n\nglm_lr <- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\n# Coefficients, CIs, p-values\n\nlr_coef <- summary(glm_lr)$coefficients           # estimates + p-values\nci_raw  <- suppressMessages(confint(glm_lr))      # CI on log-odds scale\n\nor_df <- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(>|z|)\"]\n) %>%\n\n# remove intercept\n\nfilter(Predictor != \"(Intercept)\") %>%\n\n# nicer labels for the plot\n\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n# significance flag for colour\nSig = ifelse(p_value < 0.05, \"p < 0.05\", \"NS\")\n) %>%\n\n# order from lower to higher OR so the plot reads nicely\n\narrange(OR) %>%\nmutate(Label = factor(Label, levels = Label))\n\n# Forest plot\n\nggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p < 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**\n\nHypertension (Yes vs No)\n\nThis is the strongest predictor. Its OR is clearly > 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\n\nAge (per year)\n\nThe OR is slightly above 1 with a narrow CI fully above 1 (orange).\n\nEach additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\n\nAverage glucose level\n\nOR is just above 1 with a tight CI above 1 (orange).\n\nHigher glucose is associated with a modest but statistically reliable increase in stroke risk, consistent with metabolic / diabetes-related vascular risk.\n\nEver married, heart disease, smoking status, gender, BMI, residence, work type\n\nTheir confidence intervals all cross 1 (grey points), so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.\n\nSome (e.g., heart disease, smoking) still have ORs above 1, suggesting possible elevated risk, but the evidence is weaker in this dataset.\n\nOverall message:\nThe forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\n\n**Threshold tuning to 0.2 from 0.5**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Threshold tuning: use 0.2 instead of 0.5\nnew_threshold <- 0.2\n\nstroke_test$pred_class_02 <- ifelse(stroke_test$pred_prob >= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 <- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\n# Confusion matrix for threshold = 0.2\ncm_02 <- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm_02\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes             \n                                          \n```\n\n\n:::\n:::\n\n\n**Interpretation (threshold = 0.2)**\n\n- With a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\n\n- Specificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as \"no stroke\" (903 out of 949).\n\n- While overall accuracy declines from 94% to 91%, balanced accuracy improves (from ‚âà0.51 to ‚âà0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives.\n\n\n# conclusion\n\nThis experiment compared a conventional logistic regression model with several machine-learning algorithms and examined whether common demographic, behavioral, and clinical characteristics may be used to predict stroke risk using a stroke dataset. Stroke was a rare outcome (about 5% of cases) in the final sample of 3,357 people that was analyzed after the data was cleaned and inconsistent or missing values were eliminated. In addition to reflecting actual epidemiology, this significant class disparity complicates classification, particularly when it comes to identifying the minority (stroke) class.\n\nAge, hypertension, cardiac disease, and raised average glucose levels are among the best predictors of stroke, according to the baseline logistic regression model. Smoking status substantially increased risk.  These variables were identified as significant risk factors by odds ratios significantly greater than 1 and confidence intervals that did not cross 1.  These results support the use of logistic regression as an interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness.\n\nThe logistic regression model performed reasonably well overall in terms of prediction; however, sensitivity for stroke cases was more constrained at the default 0.5 probability threshold, as would be expected with an imbalanced outcome.  The model clearly outperformed random guessing, according to the ROC curve and AUC values, but there was still space for improvement in terms of differentiating between stroke and non-stroke patients.  Youden's J statistic offers a method for selecting a different categorization threshold that enhances the ratio of sensitivity to specificity, which may be crucial in a screening setting when it is expensive to miss actual stroke cases.\n\nMore sophisticated models, such Random Forest and Gradient Boosted Machine, were able to attain somewhat higher AUC values than logistic regression in the machine-learning comparison, showing superior discrimination across a range of thresholds.  However, these increases in AUC came at the expense of decreased interpretability and were not always accompanied by significant increases in sensitivity at fixed cut-offs.  Logistic regression, on the other hand, offers precise odds ratios and confidence intervals that are simpler for public health professionals and doctors to understand when discussing risk and developing interventions.\n\nBecause of the severe class imbalance, sensitivity for stroke cases was extremely low (around 2%), meaning that the model almost never predicted ‚Äústroke = Yes‚Äù and therefore missed most true stroke cases.\n\nTo address this, the decision threshold was lowered from 0.5 to 0.2. At this cut-off, sensitivity increased from roughly 2% to about 22%, while specificity remained high at around 95%. Overall accuracy dropped slightly to about 91%, but balanced accuracy improved, indicating a more reasonable trade-off between detecting stroke cases and avoiding false positives. This threshold experiment illustrates a key practical point: for rare but serious outcomes such as stroke, it can be preferable to sacrifice some overall accuracy in order to reduce the number of missed high-risk individuals. In this setting, the logistic model is more appropriately viewed as a screening or risk-flagging tool rather than a definitive diagnostic rule.\n\nOverall, the findings show that relatively simple models built from routinely collected health indicators can meaningfully distinguish between individuals with and without stroke, even in the presence of substantial class imbalance. Logistic regression emerges as a strong, interpretable baseline, while tree-based ensemble methods provide incremental performance improvements at the cost of transparency. Future work could focus on external validation, calibration assessment, more sophisticated imbalance-handling techniques, and the inclusion of additional clinical or longitudinal information. These extensions would help move from proof-of-concept modelling toward robust, clinically usable tools for stroke risk stratification and targeted prevention.\n\n\n# References\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}