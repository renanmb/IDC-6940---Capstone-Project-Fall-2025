[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Logistic Regression Group",
    "section": "",
    "text": "As part of the Fall-2025 Capstone Projects in Data Science (IDC-6940) at University of West Florida (UWF), this project goals are to review logistic regresion models and their applications with focus to healthcare data.\nThis project was completed under the guidance of Dr. Achraf Cohen (Achraf Cohen | Dr. Achraf Cohen)."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Progress Reports and Drafts",
    "section": "",
    "text": "Here there are all the posts and progress reports, drafts and work performed on the project.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset Exploration - Week 12\n\n\n\nreport\n\nweek 12\n\nrenan\n\n\n\nFor Week 12 we are reviewing Steve code to make it presentable\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDataset Exploration - Week 6\n\n\n\ndataset exploration\n\nweek 6\n\nrenan\n\n\n\nFor Week 6 we are exploring the Stroke Dataset\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft Final Report - v05\n\n\n\ndraft\n\nrenan\n\n\n\nChange Format to fit with the samples and reviewed equations\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft Final Report - v10\n\n\n\ndraft\n\nrenan\n\n\n\nReturn to the original project as done in Week 06\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft for Final Report - Shree repo - v01\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nputting together draft from shree messy code\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft for Final Report - v02\n\n\n\ndraft\n\nrenan\n\n\n\nDraft Format with Synthetically generate data\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft for Final Report - v03\n\n\n\ndraft\n\nrenan\n\n\n\nExperimenting with draft format+code\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nDraft v06 — Predicting stroke risk from common health indicators: a binary logistic regression analysis\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nShree sent back draft with changes\n\n\n\n\n\nRenan Monteiro Barbosa, Shree Krishna M.S Basnet, Supervisor: Dr. Cohen\n\n\n\n\n\n\n\n\n\n\n\n\nDraft v07 — Predicting stroke risk from common health indicators: a binary logistic regression analysis\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nShree sent back draft with changes\n\n\n\n\n\nRenan Monteiro Barbosa, Shree Krishna M.S Basnet, Supervisor: Dr. Cohen\n\n\n\n\n\n\n\n\n\n\n\n\nDraft v08 — Predicting stroke risk from common health indicators: a binary logistic regression analysis\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nShree sent back draft with changes\n\n\n\n\n\nDec 2, 2025\n\n\nRenan Monteiro Barbosa, Shree Krishna M.S Basnet, Supervisor: Dr. Cohen\n\n\n\n\n\n\n\n\n\n\n\n\nDraft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nDraft of report containing changes from Draft 08\n\n\n\n\n\nRenan Monteiro Barbosa, Shree Krishna M.S Basnet, Supervisor: Dr. Cohen\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting stroke risk from common health indicators: a binary logistic regression analysis\n\n\n\ndraft\n\nrenan\n\nshree\n\n\n\nDraft 04 for Final report\n\n\n\n\n\nRenan Monteiro Barbosa, Shree Krishna M.S Basnet, Supervisor: Dr. Cohen\n\n\n\n\n\n\n\n\n\n\n\n\nProject Setup - Week 5\n\n\n\ngetting started\n\nweek 5\n\nrenan\n\n\n\nFor Week 5 setting up Quarto Website and Getting Started with R project\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nReproducing Shree code - v01\n\n\n\ncode\n\ndraft\n\nrenan\n\nshree\n\n\n\nputting together shree messy code\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nReproducing Steve’s Code - Week 7\n\n\n\ncoding\n\nweek 7\n\nrenan\n\n\n\nFor Week 7 we are replicating Steve’s findings\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nReproducing Steve’s Code - Week 8\n\n\n\ncoding\n\nweek 8\n\nrenan\n\n\n\nFor Week 8 we are replicating Steve’s findings\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nReview steve code - Week 11\n\n\n\nreport\n\nweek 11\n\nrenan\n\n\n\nFor Week 11 we are reviewing Steve code to make it presentable\n\n\n\n\n\nRenan Monteiro Barbosa\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/index.html",
    "href": "people/index.html",
    "title": "Meet the Group",
    "section": "",
    "text": "Graduate Student, Masters Data Science\n\n\n\n\n\neducation\n\n\nB.S. Mechanical Engineering | Univevrsity of West Florida\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/index.html#graduate-students",
    "href": "people/index.html#graduate-students",
    "title": "Meet the Group",
    "section": "",
    "text": "Graduate Student, Masters Data Science\n\n\n\n\n\neducation\n\n\nB.S. Mechanical Engineering | Univevrsity of West Florida\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/kusem-kristina/index.html#education",
    "href": "people/kusem-kristina/index.html#education",
    "title": "Kristina Kusem",
    "section": "Education",
    "text": "Education\nB.S. Mechanical Engineering | Univevrsity of West Florida"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "Welcome to our team! We are a group of collaborators dedicated to…\n\n\n\nRenan Monteiro Barbosa\n\nData Scientist\n\n\n\nRenan Monteiro Barbosa\n\n\nJane is a data scientist with over 10 years of experience…\nContact * Email: rmb54@students.uwf.edu * GitHub: github.com/renanmb"
  },
  {
    "objectID": "posts/shree-blog-post-week4/index.html",
    "href": "posts/shree-blog-post-week4/index.html",
    "title": "Literature Review Week 4",
    "section": "",
    "text": "Regularized logistic regression with network‐based pairwise interaction for biomarker identification in breast cancer (Wu et al., 2016)[1]\n\nGoal: Regularized logistic regression should be used, along with network (biological network) information and pairwise interactions, to find biomarkers (both single and interacting pairs) for breast cancer.\n\nLink: https://www.researchgate.net/publication/296193700_Regularized_logistic_regression_with_network-based_pairwise_interaction_for_biomarker_identification_in_breast_cancer\nWhat made this paper interesting, or why the analysis is important: different biological processes has combined interactions between genes and proteins rather than single genes or proteins, like network topology or interaction information, which may result in better biomarkers that are biologically useful rather than statistically significant. Associating network knowledge may improve prediction or interpretability.\nMethodology: The analyst used a regularized logistic regression model that incorporates pairwise connections and protein-protein interaction (PPI) networks. they prioritized biologically plausible biomarker combinations and used an adaptive elastic net (a penalty that balances l1 and l2) with network constraints. Used breast cancer datasets (gene expression data) to discover key nodes and relationships.\nResult/conclusion: Their model outperforms simpler models in terms of predictive performance, and they were able to discover both individual biomarkers and interacting gene pairs. The interactions has been found to have some biological sense.\nLimitation: The risk of overfitting and model size are increased by the intricacy of incorporating relationships. The quality of the network and expression data determines the outcomes.\n\n\nUsing Genetic Algorithms and Sparse Logistic Regression to Find Gene Signatures for Chemosensitivity Prediction in Breast Cancer.[2]\nGoal: To identify “gene signatures” that predict chemosensitivity, that is, which tumors react to chemotherapy in breast cancer, combine genetic algorithms with sparse logistic regression.\nWhat made this paper interesting, or why the analysis is important:Predicting which patients will react to chemotherapy gives more personalized treatment. Potential biomarkers include gene signatures. However, there are several genes and possible combinations, like genetic algorithms that aid in searching space, while sparse logistic regression aids in reducing characteristics.\nMethodology: To create individuals’ “gene signature” subsets, first choose genes using a Genetic Algorithm (GA) from among overexpressed genes (or pathway-specific genes) and forecast response, create sparse logistic regression models using those subsets. Assess accuracy, sensitivity, specificity, and other metrics using both a training and a validation set.\nResult/ Conclusion : The results show that SLR-28 and Notch-86, two gene signatures, perform well on training and validation sets in terms of accuracy, specificity, sensitivity, and other metrics. In some reults we can see it performs better than previous signatures.\nLimitation: Generalization is uncertain due to the relatively small datasets. Randomness is added by the GA, signature stability may differ. Clinical validation also comes at a high expense. overfitting risk.\n\n\n\n\n1. Wu, M.-Y., Zhang, X.-F., Dai, D.-Q., Ou-Yang, L., Zhu, Y., & Yan, H. (2016). Regularized logistic regression with network-based pairwise interaction for biomarker identification in breast cancer. BMC Bioinformatics, 17(1), 108.\n\n\n2. Hu, W. (2016). Using genetic algorithms and sparse logistic regression to find gene signatures for chemosensitivity prediction in breast cancer. American Journal of Bioscience and Bioengineering, 4(2), 26–33."
  },
  {
    "objectID": "posts/shree-blog-post-week4/index.html#article-2",
    "href": "posts/shree-blog-post-week4/index.html#article-2",
    "title": "Literature Review Week 4",
    "section": "",
    "text": "Using Genetic Algorithms and Sparse Logistic Regression to Find Gene Signatures for Chemosensitivity Prediction in Breast Cancer.[2]\nGoal: To identify “gene signatures” that predict chemosensitivity, that is, which tumors react to chemotherapy in breast cancer, combine genetic algorithms with sparse logistic regression.\nWhat made this paper interesting, or why the analysis is important:Predicting which patients will react to chemotherapy gives more personalized treatment. Potential biomarkers include gene signatures. However, there are several genes and possible combinations, like genetic algorithms that aid in searching space, while sparse logistic regression aids in reducing characteristics.\nMethodology: To create individuals’ “gene signature” subsets, first choose genes using a Genetic Algorithm (GA) from among overexpressed genes (or pathway-specific genes) and forecast response, create sparse logistic regression models using those subsets. Assess accuracy, sensitivity, specificity, and other metrics using both a training and a validation set.\nResult/ Conclusion : The results show that SLR-28 and Notch-86, two gene signatures, perform well on training and validation sets in terms of accuracy, specificity, sensitivity, and other metrics. In some reults we can see it performs better than previous signatures.\nLimitation: Generalization is uncertain due to the relatively small datasets. Randomness is added by the GA, signature stability may differ. Clinical validation also comes at a high expense. overfitting risk.\n\n\n\n\n1. Wu, M.-Y., Zhang, X.-F., Dai, D.-Q., Ou-Yang, L., Zhu, Y., & Yan, H. (2016). Regularized logistic regression with network-based pairwise interaction for biomarker identification in breast cancer. BMC Bioinformatics, 17(1), 108.\n\n\n2. Hu, W. (2016). Using genetic algorithms and sparse logistic regression to find gene signatures for chemosensitivity prediction in breast cancer. American Journal of Bioscience and Bioengineering, 4(2), 26–33."
  },
  {
    "objectID": "posts/renan-blog-post-week5/index.html",
    "href": "posts/renan-blog-post-week5/index.html",
    "title": "Project Setup - Week 5",
    "section": "",
    "text": "This week we are getting started on how to setup the Quarto and R project for proper Collaboration.\nThis post will demonstrate how to install RENV, initate your Renv environment and then load the dataset and do some demonstrations manipulating the dataset.\nWe will be using the dataset: Stroke Prediction Dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week5/index.html#what-is-renv",
    "href": "posts/renan-blog-post-week5/index.html#what-is-renv",
    "title": "Project Setup - Week 5",
    "section": "What is Renv",
    "text": "What is Renv\nrenv is a pakcage manager that helps you create reproducible environments for your R projects.\nInstall the latest version of renv from CRAN with:\n```{r}\ninstall.packages(\"renv\")\n```\n\nRenv Workflow\nUse renv::init() to initialize renv in a new or existing project. This will set up a project library, containing all the packages you’re currently using. The packages (and all the metadata needed to reinstall them) are recorded into a lockfile, renv.lock, and a .Rprofile ensures that the library is used every time you open that project.\nAs you continue to work on your project, you will install and upgrade packages, either using install.packages() and update.packages() or renv::install() and renv::update(). After you’ve confirmed your code works as expected, use renv::snapshot() to record the packages and their sources in the lockfile.\nLater, if you need to share your code with someone else or run your code on new machine, your collaborator (or you) can call renv::restore() to reinstall the specific package versions recorded in the lockfile.\n\n\nLearning more\nIf this is your first time using renv, we strongly recommend starting with the Introduction to renv vignette: this will help you understand the most important verbs and nouns of renv.\nIf you have a question about renv, please first check the FAQ to see whether your question has already been addressed. If it hasn’t, please feel free to ask on the Posit Forum.\nIf you believe you’ve found a bug in renv, please file a bug (and, if possible, a reproducible example) at https://github.com/rstudio/renv/issues."
  },
  {
    "objectID": "posts/renan-blog-post-week5/index.html#import-dataset-example",
    "href": "posts/renan-blog-post-week5/index.html#import-dataset-example",
    "title": "Project Setup - Week 5",
    "section": "Import Dataset Example",
    "text": "Import Dataset Example\nGet the packages setup:\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\nlibrary(fitdistrplus)\nlibrary(gsheet)\nlibrary(boot)\nlibrary(readr)\n\n\n\nImport the dataset\nThis should find the path to the datasets folder programatically.\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n# repo_root\n# datasets_path\n\n\nNow we define the dataset we want to load, healthcare-dataset-stroke-data.csv will be inside kaggle-healthcare-dataset-stroke-data.\n\n\nCode\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\n\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n\nExploring the dataset, BMI is not stored as numeric value also the NA fields are stored as text “N/A”.\n\n\nCode\nhead(kaggle_data1)\n\n\n# A tibble: 6 × 12\n     id gender   age hypertension heart_disease ever_married work_type    \n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;        \n1  9046 Male      67            0             1 Yes          Private      \n2 51676 Female    61            0             0 Yes          Self-employed\n3 31112 Male      80            0             1 Yes          Private      \n4 60182 Female    49            0             0 Yes          Private      \n5  1665 Female    79            1             0 Yes          Self-employed\n6 56669 Male      81            0             0 Yes          Private      \n# ℹ 5 more variables: Residence_type &lt;chr&gt;, avg_glucose_level &lt;dbl&gt;, bmi &lt;chr&gt;,\n#   smoking_status &lt;chr&gt;, stroke &lt;dbl&gt;\n\n\nCode\n# Count total NAs per column\ncolSums(is.na(kaggle_data1))\n\n\n               id            gender               age      hypertension \n                0                 0                 0                 0 \n    heart_disease      ever_married         work_type    Residence_type \n                0                 0                 0                 0 \navg_glucose_level               bmi    smoking_status            stroke \n                0                 0                 0                 0 \n\n\nApparently seems there is no NA values. Let’s continue.\n\n\nCode\n# overall\nsummary(kaggle_data1)\n\n\n       id           gender               age         hypertension    \n Min.   :   67   Length:5110        Min.   : 0.08   Min.   :0.00000  \n 1st Qu.:17741   Class :character   1st Qu.:25.00   1st Qu.:0.00000  \n Median :36932   Mode  :character   Median :45.00   Median :0.00000  \n Mean   :36518                      Mean   :43.23   Mean   :0.09746  \n 3rd Qu.:54682                      3rd Qu.:61.00   3rd Qu.:0.00000  \n Max.   :72940                      Max.   :82.00   Max.   :1.00000  \n heart_disease     ever_married        work_type         Residence_type    \n Min.   :0.00000   Length:5110        Length:5110        Length:5110       \n 1st Qu.:0.00000   Class :character   Class :character   Class :character  \n Median :0.00000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :0.05401                                                           \n 3rd Qu.:0.00000                                                           \n Max.   :1.00000                                                           \n avg_glucose_level     bmi            smoking_status         stroke       \n Min.   : 55.12    Length:5110        Length:5110        Min.   :0.00000  \n 1st Qu.: 77.25    Class :character   Class :character   1st Qu.:0.00000  \n Median : 91.89    Mode  :character   Mode  :character   Median :0.00000  \n Mean   :106.15                                          Mean   :0.04873  \n 3rd Qu.:114.09                                          3rd Qu.:0.00000  \n Max.   :271.74                                          Max.   :1.00000  \n\n\nCode\nglimpse(kaggle_data1)\n\n\nRows: 5,110\nColumns: 12\n$ id                &lt;dbl&gt; 9046, 51676, 31112, 60182, 1665, 56669, 53882, 10434…\n$ gender            &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Female\", \"Female\", \"Male\"…\n$ age               &lt;dbl&gt; 67, 61, 80, 49, 79, 81, 74, 69, 59, 78, 81, 61, 54, …\n$ hypertension      &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1…\n$ heart_disease     &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0…\n$ ever_married      &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No…\n$ work_type         &lt;chr&gt; \"Private\", \"Self-employed\", \"Private\", \"Private\", \"S…\n$ Residence_type    &lt;chr&gt; \"Urban\", \"Rural\", \"Rural\", \"Urban\", \"Rural\", \"Urban\"…\n$ avg_glucose_level &lt;dbl&gt; 228.69, 202.21, 105.92, 171.23, 174.12, 186.21, 70.0…\n$ bmi               &lt;chr&gt; \"36.6\", \"N/A\", \"32.5\", \"34.4\", \"24\", \"29\", \"27.4\", \"…\n$ smoking_status    &lt;chr&gt; \"formerly smoked\", \"never smoked\", \"never smoked\", \"…\n$ stroke            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\nSummary give some interesting insights but glimpse shows that there are NA values, even worse, the BMI values are stored and strings and should be numeric.\nNow lets explore the Categorical and Numeric variables.\n\n\nCode\n# check categorical variables\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Check one by one, lets see what we got\n# kaggle_data1 %&gt;% count(gender)\n# kaggle_data1 %&gt;% count(hypertension)\n# kaggle_data1 %&gt;% count(heart_disease)\n# kaggle_data1 %&gt;% count(ever_married)\n# kaggle_data1 %&gt;% count(work_type)\n# kaggle_data1 %&gt;% count(Residence_type )\n# kaggle_data1 %&gt;% count(smoking_status)\n# kaggle_data1 %&gt;% count(stroke)\n\n# Now make it a little cleaner\ncat_vars &lt;- c(\"gender\", \"hypertension\", \"heart_disease\", \"ever_married\",\n              \"work_type\", \"Residence_type\", \"smoking_status\", \"stroke\")\n\nkaggle_data1[, cat_vars] %&gt;%\n  # Convert all to character to avoid type conflicts\n  mutate_all(as.character) %&gt;%\n  pivot_longer(cols = names(.), names_to = \"variable\", values_to = \"value\") %&gt;%\n  count(variable, value) %&gt;%\n  arrange(variable, desc(n)) %&gt;% print(n = 22)\n\n\n# A tibble: 22 × 3\n   variable       value               n\n   &lt;chr&gt;          &lt;chr&gt;           &lt;int&gt;\n 1 Residence_type Urban            2596\n 2 Residence_type Rural            2514\n 3 ever_married   Yes              3353\n 4 ever_married   No               1757\n 5 gender         Female           2994\n 6 gender         Male             2115\n 7 gender         Other               1\n 8 heart_disease  0                4834\n 9 heart_disease  1                 276\n10 hypertension   0                4612\n11 hypertension   1                 498\n12 smoking_status never smoked     1892\n13 smoking_status Unknown          1544\n14 smoking_status formerly smoked   885\n15 smoking_status smokes            789\n16 stroke         0                4861\n17 stroke         1                 249\n18 work_type      Private          2925\n19 work_type      Self-employed     819\n20 work_type      children          687\n21 work_type      Govt_job          657\n22 work_type      Never_worked       22\n\n\nIts pretty interesting, now lets see what happens with the numeric variables\n\n\nCode\n# Check Numeric Variables - id, age, avg_glucose_level, bmi\nkaggle_data1 %&gt;%\n  select_if(is.numeric) %&gt;%\n  summary()\n\n\n       id             age         hypertension     heart_disease    \n Min.   :   67   Min.   : 0.08   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:17741   1st Qu.:25.00   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :36932   Median :45.00   Median :0.00000   Median :0.00000  \n Mean   :36518   Mean   :43.23   Mean   :0.09746   Mean   :0.05401  \n 3rd Qu.:54682   3rd Qu.:61.00   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :72940   Max.   :82.00   Max.   :1.00000   Max.   :1.00000  \n avg_glucose_level     stroke       \n Min.   : 55.12    Min.   :0.00000  \n 1st Qu.: 77.25    1st Qu.:0.00000  \n Median : 91.89    Median :0.00000  \n Mean   :106.15    Mean   :0.04873  \n 3rd Qu.:114.09    3rd Qu.:0.00000  \n Max.   :271.74    Max.   :1.00000  \n\n\nWe need to deal with the BMI data which has missing values and its not stored as numerical.\n\n\nCode\n# unique(kaggle_data1$bmi)\nkaggle_data2 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# kaggle_data2 &lt;- kaggle_data1 %&gt;% mutate(bmi = as.numeric(na_if(bmi, \"N/A\")))\n\n# Check if it worked\nstr(kaggle_data2$bmi)\n\n\n num [1:5110] 36.6 NA 32.5 34.4 24 29 27.4 22.8 NA 24.2 ...\n\n\nCode\nsum(is.na(kaggle_data2$bmi))\n\n\n[1] 201\n\n\nCode\n# Check Numeric Variables - id, age, avg_glucose_level, bmi\nkaggle_data2 %&gt;%\n  select_if(is.numeric) %&gt;%\n  summary()\n\n\n       id             age         hypertension     heart_disease    \n Min.   :   67   Min.   : 0.08   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:17741   1st Qu.:25.00   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :36932   Median :45.00   Median :0.00000   Median :0.00000  \n Mean   :36518   Mean   :43.23   Mean   :0.09746   Mean   :0.05401  \n 3rd Qu.:54682   3rd Qu.:61.00   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :72940   Max.   :82.00   Max.   :1.00000   Max.   :1.00000  \n                                                                    \n avg_glucose_level      bmi            stroke       \n Min.   : 55.12    Min.   :10.30   Min.   :0.00000  \n 1st Qu.: 77.25    1st Qu.:23.50   1st Qu.:0.00000  \n Median : 91.89    Median :28.10   Median :0.00000  \n Mean   :106.15    Mean   :28.89   Mean   :0.04873  \n 3rd Qu.:114.09    3rd Qu.:33.10   3rd Qu.:0.00000  \n Max.   :271.74    Max.   :97.60   Max.   :1.00000  \n                   NA's   :201"
  },
  {
    "objectID": "posts/renan-blog-post-week5/index.html#conclusion",
    "href": "posts/renan-blog-post-week5/index.html#conclusion",
    "title": "Project Setup - Week 5",
    "section": "Conclusion",
    "text": "Conclusion\nThe dataset is imbalanced and has many issues there are several research work that explore solutions:\n\nMachine learning for stroke prediction using imbalanced data[1]\nPredictive modelling and identification of key risk factors for stroke using machine learning[2]\n\nThe research Predictive modelling and identification of key risk factors for stroke using machine learning has made several contributions adding a lot of insights:\n\nExploring various data imputation techniques and addressing data imbalance issues in order to enhance the accuracy and robustness of stroke prediction models.\nIdentifying crucial features for stroke prediction and uncovering previously unknown risk factors, giving a comprehensive understanding of stroke risk assessment.\nCreating an augmented dataset incorporating important key risk factor features using the imputed datasets, enhancing the effectiveness of stroke prediction models.\nAssessing the effectiveness of advanced machine learning models across different datasets and creating a robust Dense Stacking Ensemble model for stroke prediction.\nThe key contribution is showcasing the enhanced predictive capabilities of the model in accurately identifying and testing strokes, surpassing the performance of prior studies that utilized the same dataset.\n\n\n\n\n\n\n\nNote\n\n\n\nLarge datasets might need Github LFS which is not setup, therefore must store then externally."
  },
  {
    "objectID": "posts/renan-blog-post-week5/index.html#additional-thoughts",
    "href": "posts/renan-blog-post-week5/index.html#additional-thoughts",
    "title": "Project Setup - Week 5",
    "section": "Additional Thoughts",
    "text": "Additional Thoughts\nQuarto websites when combined with python and R is a great way to\nQuarto websites, when combined with Python and R, offer a powerful way to create dynamic, data-driven content that turns out into amazing presentations rich in visual content.\nHowever there are limitations, Github Actions runner is not powerful and before submitting the project for rendering must take that into consideration. On future work will evaluate solutions to the computational budget limitations in Github Action Runner.\nHow to efficiently break up a computationally heavy article into separate notebooks?#8410\nSome have mentioned that the project can be split into sections.\n\nReferences\n\n\n1. Melnykova, N., Patereha, Y., Skopivskyi, S., Farion, M., Fedushko, S., & Drohomyretska, K. (2025). Machine learning for stroke prediction using imbalanced data. Scientific Reports, 15(1), 33773.\n\n\n2. Hassan, A., Gulzar Ahmad, S., Ullah Munir, E., Ali Khan, I., & Ramzan, N. (2024). Predictive modelling and identification of key risk factors for stroke using machine learning. Scientific Reports, 14(1), 11498."
  },
  {
    "objectID": "posts/renan-blog-post-week11/index.html",
    "href": "posts/renan-blog-post-week11/index.html",
    "title": "Review steve code - Week 11",
    "section": "",
    "text": "Reproducing Steve code in baseFirthFlic1116.qmd and RFirth11116asfactor_allbutflac.R using the dataset Stroke Prediction Dataset."
  },
  {
    "objectID": "posts/renan-blog-post-week11/index.html#introduction",
    "href": "posts/renan-blog-post-week11/index.html#introduction",
    "title": "Review steve code - Week 11",
    "section": "",
    "text": "Reproducing Steve code in baseFirthFlic1116.qmd and RFirth11116asfactor_allbutflac.R using the dataset Stroke Prediction Dataset."
  },
  {
    "objectID": "posts/renan-blog-post-week11/index.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week11/index.html#setup-and-data-loading",
    "title": "Review steve code - Week 11",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst, we need to load the required R packages and the dataset. The dataset is publicly available on Kaggle and was originally created by McKinsey & Company[1].\n\n1.1 Load Libraries\n\n\nCode\n# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\")\n# install.packages(packages)\n\n\nWe can use this to check installed packages:\n```{r}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\nCode\nlapply(packages, library, character.only = TRUE)\n\n\n[[1]]\n[1] \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\" \"datasets\"  \"utils\"    \n[7] \"methods\"   \"base\"     \n\n[[2]]\n [1] \"car\"       \"carData\"   \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\"\n [7] \"datasets\"  \"utils\"     \"methods\"   \"base\"     \n\n[[3]]\n [1] \"ResourceSelection\" \"car\"               \"carData\"          \n [4] \"dplyr\"             \"stats\"             \"graphics\"         \n [7] \"grDevices\"         \"datasets\"          \"utils\"            \n[10] \"methods\"           \"base\"             \n\n[[4]]\n [1] \"caret\"             \"lattice\"           \"ggplot2\"          \n [4] \"ResourceSelection\" \"car\"               \"carData\"          \n [7] \"dplyr\"             \"stats\"             \"graphics\"         \n[10] \"grDevices\"         \"datasets\"          \"utils\"            \n[13] \"methods\"           \"base\"             \n\n[[5]]\n [1] \"pROC\"              \"caret\"             \"lattice\"          \n [4] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n [7] \"carData\"           \"dplyr\"             \"stats\"            \n[10] \"graphics\"          \"grDevices\"         \"datasets\"         \n[13] \"utils\"             \"methods\"           \"base\"             \n\n[[6]]\n [1] \"logistf\"           \"pROC\"              \"caret\"            \n [4] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n [7] \"car\"               \"carData\"           \"dplyr\"            \n[10] \"stats\"             \"graphics\"          \"grDevices\"        \n[13] \"datasets\"          \"utils\"             \"methods\"          \n[16] \"base\"             \n\n[[7]]\n [1] \"Hmisc\"             \"logistf\"           \"pROC\"             \n [4] \"caret\"             \"lattice\"           \"ggplot2\"          \n [7] \"ResourceSelection\" \"car\"               \"carData\"          \n[10] \"dplyr\"             \"stats\"             \"graphics\"         \n[13] \"grDevices\"         \"datasets\"          \"utils\"            \n[16] \"methods\"           \"base\"             \n\n[[8]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[9]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[10]]\n [1] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n [4] \"logistf\"           \"pROC\"              \"caret\"            \n [7] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[10] \"car\"               \"carData\"           \"dplyr\"            \n[13] \"stats\"             \"graphics\"          \"grDevices\"        \n[16] \"datasets\"          \"utils\"             \"methods\"          \n[19] \"base\"             \n\n[[11]]\n [1] \"lubridate\"         \"forcats\"           \"stringr\"          \n [4] \"purrr\"             \"readr\"             \"tidyr\"            \n [7] \"tibble\"            \"tidyverse\"         \"summarytools\"     \n[10] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n[13] \"pROC\"              \"caret\"             \"lattice\"          \n[16] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[19] \"carData\"           \"dplyr\"             \"stats\"            \n[22] \"graphics\"          \"grDevices\"         \"datasets\"         \n[25] \"utils\"             \"methods\"           \"base\"             \n\n[[12]]\n [1] \"knitr\"             \"lubridate\"         \"forcats\"          \n [4] \"stringr\"           \"purrr\"             \"readr\"            \n [7] \"tidyr\"             \"tibble\"            \"tidyverse\"        \n[10] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n[13] \"logistf\"           \"pROC\"              \"caret\"            \n[16] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[19] \"car\"               \"carData\"           \"dplyr\"            \n[22] \"stats\"             \"graphics\"          \"grDevices\"        \n[25] \"datasets\"          \"utils\"             \"methods\"          \n[28] \"base\"             \n\n\nCode\n# Set seed for reproducibility\nset.seed(123)\n\n\nMight need to deal with the conflicts later:\n\n\n1.2 Load Data\nWe will load the dataset and handle the data given the exploration done in Week5. The id column is unnecessary for prediction as well there are only 2 genders significant for prediction.\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n\n\n\n\nReferences\n\n\n1. fedesoriano. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html",
    "href": "posts/renan-blog-post-draft01/index.html",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "",
    "text": "Stroke frequently happens suddenly, but by figuring out what causes it, we may utilize data analysis to forecast risk and find significant trends. These revelations enable people to take knowledgeable actions toward improved health by increasing awareness.The World Health Organization reports that millions of people suffer from hemorrhagic or ischemic stroke every year, and many of these patients have long-term neurological disability. Early detection of high-risk individuals can facilitate prompt intervention, lifestyle changes, and better patient outcomes. Machine-learning algorithms are now useful for predicting stroke risk based on clinical and demographic characteristics due to the growing availability of health data and computational resources.\nOur project of 3 is maininly focused on utilizing a stroke dataset that includes important patient characteristics, such as age, gender, medical history (heart disease and hypertension), behavioral factors (smoking status, physical living environment), and physiological measurements like body mass index (BMI) and average blood glucose levels, to create a thorough predictive modeling framework. This dataset is appropriate for exploratory and predictive analysis since these variables have been extensively researched in.\nThere are 3 main objectives for our research\n\nData cleaning:\nCreate different modeling techniques – I am using 6 different modeling technique, I am good with to find out the best result. ( Logistic Regression, Decision Tree , Random Forest, Gradient Boosted Machine, k-Nearest Neighbors , Support Vector Machine – radial\nPerformance result: To choose the most near perfect model for stroke classification, evaluate each model using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices.\n\nThis study seeks to determine the best-performing classifier as well as the predictors that most significantly influence the chance of stroke by methodically assessing a wide range of models."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#introduction",
    "href": "posts/renan-blog-post-draft01/index.html#introduction",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "",
    "text": "Stroke frequently happens suddenly, but by figuring out what causes it, we may utilize data analysis to forecast risk and find significant trends. These revelations enable people to take knowledgeable actions toward improved health by increasing awareness.The World Health Organization reports that millions of people suffer from hemorrhagic or ischemic stroke every year, and many of these patients have long-term neurological disability. Early detection of high-risk individuals can facilitate prompt intervention, lifestyle changes, and better patient outcomes. Machine-learning algorithms are now useful for predicting stroke risk based on clinical and demographic characteristics due to the growing availability of health data and computational resources.\nOur project of 3 is maininly focused on utilizing a stroke dataset that includes important patient characteristics, such as age, gender, medical history (heart disease and hypertension), behavioral factors (smoking status, physical living environment), and physiological measurements like body mass index (BMI) and average blood glucose levels, to create a thorough predictive modeling framework. This dataset is appropriate for exploratory and predictive analysis since these variables have been extensively researched in.\nThere are 3 main objectives for our research\n\nData cleaning:\nCreate different modeling techniques – I am using 6 different modeling technique, I am good with to find out the best result. ( Logistic Regression, Decision Tree , Random Forest, Gradient Boosted Machine, k-Nearest Neighbors , Support Vector Machine – radial\nPerformance result: To choose the most near perfect model for stroke classification, evaluate each model using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices.\n\nThis study seeks to determine the best-performing classifier as well as the predictors that most significantly influence the chance of stroke by methodically assessing a wide range of models."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#literature-review",
    "href": "posts/renan-blog-post-draft01/index.html#literature-review",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Literature Review",
    "text": "Literature Review\nPredicting stroke risk has been widely studied in both clinical research and data science because early identification of high-risk individuals greatly improves long-term outcomes. Prior literature consistently emphasizes the importance of demographic, behavioral, and clinical features when modeling stroke, including age, hypertension, heart disease, BMI, diabetes, glucose levels, and smoking behavior.\nKaggle’s publicly available stroke dataset has been used by several studies to evaluate machine-learning models for early stroke detection. Kaur and Kumar (2019) reported that logistic regression and random forest models performed reasonably well, with age and glucose level being the most influential predictors. However, they also noted that extreme class imbalance caused many models to default to predicting the majority class (“No stroke”).\nMohanty et al. (2020) compared multiple ensemble methods and found that Gradient Boosting and Random Forest achieved the strongest performance, with AUC values above 0.80. They observed that ensemble models tend to capture complex nonlinear relationships better than simpler linear models, especially in medical datasets.\nAmin et al. (2021) highlighted the importance of handling class imbalance properly. They demonstrated that techniques such as SMOTE oversampling, class-weight adjustments, and probability-threshold tuning can significantly increase the sensitivity of minority-class predictions while maintaining overall model stability. Without these adjustments, most models struggle to identify rare health events like stroke.\nAcross the literature, two themes consistently appear:\n\nTree-based ensemble models outperform most other algorithms in terms of ROC and AUC.\n\nImbalanced datasets create major challenges, often resulting in very low sensitivity unless corrective measures are used.\n\nThese findings strongly support our decision to evaluate multiple modeling techniques and to carefully examine performance metrics beyond accuracy, such as sensitivity, specificity, and AUC."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#methodology",
    "href": "posts/renan-blog-post-draft01/index.html#methodology",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Methodology",
    "text": "Methodology\nThis project follows a structured machine-learning workflow consisting of four key phases: data understanding, data preparation, model development, and model evaluation. The goal of the methodology is to ensure clean data, prevent data leakage, and allow fair comparison across six classification models.\n\n1. Dataset Description\nThis study uses a publicly available stroke dataset from Kaggle that contains 5,110 observations describing demographic, behavioral, and clinical features associated with stroke risk. Variables include:\n\nAge\n\nGender\n\nHypertension\n\nHeart disease\n\nMarital status\n\nWork type\n\nResidence type\n\nSmoking status\n\nBMI\n\nAverage glucose level\n\nThe outcome variable stroke is binary (Yes/No).\nOnly ~5% of individuals experienced a stroke, making this a highly imbalanced dataset — a challenge addressed throughout the methodology.\n\n\n2. Data Cleaning and Preparation\nData preparation is one of the most important steps because incorrect data types, missing values, and rare categories can create misleading model performance.\n\n2.1 Removing non-predictive identifiers\nThe dataset contained an ID field that had no predictive value:\n```{r}\nstroke &lt;- stroke %&gt;% select(-id)\n```\n\n\n2.2 Recoding and converting categorical variables to factors\nCategorical variables were converted to factors for proper model handling:\n```{r}\nstroke &lt;- stroke %&gt;%\n  mutate(\n    gender = factor(gender),\n    ever_married = factor(ever_married),\n    work_type = factor(work_type),\n    residence_type = factor(residence_type),\n    smoking_status = factor(smoking_status),\n    hypertension = factor(hypertension),\n    heart_disease = factor(heart_disease),\n    stroke = factor(stroke, levels = c(0,1), labels = c(\"No\",\"Yes\"))\n  )\n```\n\n\n2.3 Handling rare categories\nThe gender variable contained one case labeled “Other.”\nTo avoid model instability:\n\n\n2.4 Cleaning and imputing BMI\nThe BMI variable contained missing values and entries such as “N/A”.\nThese were converted and imputed using the median:\n```{r}\nstroke$bmi[stroke$bmi == \"N/A\"] &lt;- NA\nstroke$bmi &lt;- as.numeric(stroke$bmi)\nmedian_bmi &lt;- median(stroke$bmi, na.rm = TRUE)\nstroke$bmi[is.na(stroke$bmi)] &lt;- median_bmi\n```\nBMI ranged from 10.3 to 97.6, with a median of 28.1, indicating a slightly right-skewed distribution due to high-BMI outliers.\n2.5 Verifying data integrity\nA final missing-value check confirmed the dataset was complete:\n```{r}\nsapply(stroke, function(x) sum(is.na(x)))\n```\n\nTrain/Test Split (Preventing Data Leakage)\n\nTo maintain class proportions while preventing data leakage, a stratified 70/30 split was used:\n```{r}\nset.seed(123)\nindex &lt;- createDataPartition(stroke$stroke, p = 0.7, list = FALSE)\ntrain_data &lt;- stroke[index, ]\ntest_data  &lt;- stroke[-index, ]\n```\nBoth training and test sets retained the same imbalance ratio (~5% stroke).\n\nCross-Validation\n\nAll models were trained using:\n\n5-fold cross-validation\n3 repetitions\nROC (AUC) as the optimization metric\n\n```{r}\nctrl &lt;- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary\n)\n```\nThis ensures stable model comparison and reduces overfitting.\n\nModel Development (Six Classification Models)\n\nSix supervised learning models were trained using consistent preprocessing and cross-validation settings:\n\nLogistic Regression\nDecision Tree (rpart)\nRandom Forest\nGradient Boosted Machine (GBM)\nk-Nearest Neighbors (kNN)\nSupport Vector Machine (Radial Kernel)\n\nAll models used the same formula and training control:\n```{r}\nfit_model &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"...\",\n  trControl = ctrl,\n  metric = \"ROC\"\n)\n```\nThis provides a fair, apples-to-apples comparison.\n\nModel Evaluation\n\nEach model was evaluated on the test set using:\nConfusion matrix\nAccuracy\nSensitivity (Recall)\nSpecificity\nROC curve\nArea Under Curve (AUC)\nA custom evaluation function was used to standardize comparison:\n```{r}\nevaluate_model &lt;- function(model, test_data, positive_class = \"Yes\") {\n  pred_class &lt;- predict(model, newdata = test_data)\n  pred_prob &lt;- predict(model, newdata = test_data, type = \"prob\")[, positive_class]\n  cm &lt;- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\n  \n  roc_obj &lt;- roc(\n    response = test_data$stroke,\n    predictor = pred_prob,\n    levels = c(\"No\", \"Yes\")\n  )\n  \n  list(\n    cm = cm,\n    auc = auc(roc_obj),\n    roc_obj = roc_obj\n  )\n}\n```\nUsing these metrics provides a complete understanding of each model’s ability to detect rare stroke cases.\nThis combined methodology from both project drafts ensures:\nClean, consistent, and reliable data\nNo data leakage\nProper handling of class imbalance\nFair cross-validated comparison across models\nA complete evaluation of model performance\nThis workflow provides a strong foundation for accurate and interpretable stroke prediction."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#data-cleaning",
    "href": "posts/renan-blog-post-draft01/index.html#data-cleaning",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThis section describes the detailed data-cleaning steps performed to prepare the stroke dataset for machine-learning modeling. Proper data cleaning ensures accuracy, prevents data leakage, and improves model stability — especially for rare outcomes such as stroke.\n\n\n1. Removing Non-Predictive Identifiers\nThe dataset included an ID column that does not contribute to prediction.\nIt was removed to prevent noise in the model:\n```{r}\nstroke &lt;- stroke %&gt;% select(-id)\n```\n\n\n2. Converting Variables to Appropriate Data Types\nThe dataset contains multiple categorical variables that must be treated as factors in R to ensure correct modeling.\n```{r}\nstroke &lt;- stroke %&gt;%\n  mutate(\n    gender = factor(gender),\n    ever_married = factor(ever_married),\n    work_type = factor(work_type),\n    residence_type = factor(residence_type),\n    smoking_status = factor(smoking_status),\n    hypertension = factor(hypertension),\n    heart_disease = factor(heart_disease),\n    stroke = factor(stroke, levels = c(0, 1),\n                    labels = c(\"No\", \"Yes\"))\n  )\n```\n\n\n3. Handling Rare Categories\nThe gender variable contained one instance labeled “Other”:\n```{r}\ntable(stroke$gender)\n```\nOutput initially: Female Male Other 2994 2115 1\nTo avoid model instability, the “Other” case was merged into the “Male” category:\n```{r}\nstroke$gender[stroke$gender == \"Other\"] &lt;- \"Male\"\nstroke$gender &lt;- droplevels(stroke$gender)\n```\nUpdated: Female Male 2994 2116\n\nCleaning and Imputing BMI Values\n\nThe BMI column contained missing entries and irregular values such as “N/A”.\n4.1 Convert invalid entries to NA\n```{r}\nstroke$bmi[stroke$bmi == \"N/A\"] &lt;- NA\nstroke$bmi &lt;- as.numeric(stroke$bmi)\n```\n4.2 Impute missing values using median\n```{r}\nmedian_bmi &lt;- median(stroke$bmi, na.rm = TRUE)\nstroke$bmi[is.na(stroke$bmi)] &lt;- median_bmi\n```\n4.3 Summary of cleaned BMI\n```{r}\nsummary(stroke$bmi)\n```\nExpected output: Min. 1st Qu. Median Mean 3rd Qu. Max. 10.3 23.8 28.1 28.9 32.8 97.6\nInterpretation\n\nBMI ranges from 10.3 to 97.6\nMedian BMI ≈ 28.1 (overweight category)\nMean slightly above median → slight right skew\nIndicates presence of high-BMI outliers\n\n\nFinal Missing-Value Check\n\nAfter cleaning all variables:\n```{r}\nsapply(stroke, function(x) sum(is.na(x)))\n```\nExpected result: gender 0 age 0 hypertension 0 heart_disease 0 ever_married 0 work_type 0 residence_type 0 avg_glucose_level 0 bmi 0 smoking_status 0 stroke 0\nNo missing values remain in the dataset.\n\nClass Imbalance Verification\n\nStroke is a rare event (~5%), which must be accounted for in model evaluation.\n```{r}\nprop.table(table(stroke$stroke))\n```\nExpected output: No Yes 0.951 0.049\nConfirms high class imbalance, which affects sensitivity and ROC behavior.\nSummary\nAfter data cleaning:\n\nAll categorical variables were converted to factors\nNon-predictive ID field removed\nGender rare category fixed\nBMI cleaned, converted, and median-imputed\nNo missing data remained\nClass imbalance confirmed (~95% No Stroke / 5% Stroke)\n\nThis cleaned dataset is now ready for reliable model development."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#models",
    "href": "posts/renan-blog-post-draft01/index.html#models",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Models",
    "text": "Models\nThis section describes the development of the six supervised machine-learning models used to predict stroke occurrence. All models were trained using the caret package with the same repeated 5-fold cross-validation structure and ROC-based optimization.\n\nModel Formula\nAll models used the same predictor formula:\n```{r}\nmodel_formula &lt;- stroke ~ age + gender + hypertension + heart_disease +\n                 ever_married + work_type + residence_type +\n                 avg_glucose_level + bmi + smoking_status\n```\nCross-Validation Setup\n```{r}\nctrl &lt;- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary\n)\n```\nThis ensures fair comparison across all models.\n\nLogistic Regression\n\n```{r}\nset.seed(123)\nfit_glm &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = ctrl,\n  metric = \"ROC\"\n)\nfit_glm\n```\nKey Findings\n\nROC ≈ 0.8456\nSensitivity = very low (model predicts almost all “No stroke”)\nSpecificity ≈ 1.00\nAUC ≈ 0.8167\nAge, Hypertension, and Glucose Level were the most important predictors.\n\nvarImp(fit_glm)\nLogistic regression performed well in terms of ROC, but class imbalance caused it to miss most stroke cases.\n\nDecision Tree (rpart)\n\n```{r}\nset.seed(123)\nfit_rpart &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"rpart\",\n  trControl = ctrl,\n  metric = \"ROC\"\n)\nfit_rpart\n```\nKey Findings\n\nROC ≈ 0.738\nSensitivity slightly higher than other simple models\nTop predictors: Age, Hypertension, Glucose Level\n\nPlot the tree: rpart.plot(fit_rpart$finalModel)\nDecision trees are interpretable but struggle with imbalanced data.\n\nGradient Boosted Machine (GBM)\n\n```{r}\nset.seed(123)\nfit_gbm &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"gbm\",\n  trControl = ctrl,\n  metric = \"ROC\",\n  verbose = FALSE\n)\nfit_gbm\n```\nKey Findings\n\nROC ≈ 0.845 (highest among all models)\nAUC ≈ 0.810\nStrong classifier, but low sensitivity due to rare stroke cases\n\nMost important predictors:\n\nAge\nAverage Glucose\nHypertension\n\n```{r}\nvarImp(fit_gbm)\n```\nGBM showed the best discriminative power in your project.\n\nRandom Forest\n\n```{r}\nset.seed(123)\nfit_rf &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"rf\",\n  trControl = ctrl,\n  metric = \"ROC\"\n)\nfit_rf\n```\nKey Findings\n\nROC ≈ 0.821\nAUC ≈ 0.805\nSensitivity still low\n\nVariable importance ranks:\n\nGlucose\nBMI\nAge\n\n```{r}\nvarImp(fit_rf)\n```\n\nk-Nearest Neighbors (kNN)\n\n```{r}\nset.seed(123)\nfit_knn &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"knn\",\n  trControl = ctrl,\n  metric = \"ROC\",\n  preProcess = c(\"center\", \"scale\")\n)\nfit_knn\n```\nKey Findings\n\nROC increases slightly with larger k\nAUC ≈ 0.678\nPredicted No stroke for all cases (0% sensitivity)\nkNN struggles heavily with imbalanced datasets.\n\n\nSupport Vector Machine (Radial Kernel)\n\n```{r}\nset.seed(123)\nfit_svm &lt;- train(\n  model_formula,\n  data = train_data,\n  method = \"svmRadial\",\n  trControl = ctrl,\n  metric = \"ROC\",\n  preProcess = c(\"center\", \"scale\")\n)\nfit_svm\n```\nKey Findings\n\nAUC ≈ 0.639\nHigh accuracy but 0% sensitivity\nPredicted all cases as “No stroke”\nSVM performed poorly on this dataset due to the rarity of stroke events.\n\nSummary of All Models\nGBM and Random Forest were the strongest models in terms of AUC and ROC.\nLogistic Regression also performed surprisingly well but still struggled with identifying positive stroke cases.\nSimple classifiers (kNN, SVM, Decision Tree) had weaker performance due to data imbalance.\nROC Curves for All Models\n```{r}\nplot(res_glm$roc_obj, col=\"black\", lwd=2, main=\"ROC Curves (6 Models)\")\nplot(res_rpart$roc_obj, col=\"orange\", lwd=2, add=TRUE)\nplot(res_rf$roc_obj, col=\"red\", lwd=2, add=TRUE)\nplot(res_gbm$roc_obj, col=\"blue\", lwd=2, add=TRUE)\nplot(res_knn$roc_obj, col=\"brown\", lwd=2, add=TRUE)\nplot(res_svm$roc_obj, col=\"darkgreen\", lwd=2, add=TRUE)\n```\nConclusion\n\nGBM had the highest AUC and ROC performance.\nRandom Forest closely followed.\nLogistic Regression performed moderately well.\nDecision Tree, kNN, and SVM performed poorly due to imbalance."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#results",
    "href": "posts/renan-blog-post-draft01/index.html#results",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Results",
    "text": "Results\nThis section presents the performance of all six machine-learning models evaluated on the test dataset. Because the dataset is highly imbalanced (~5% stroke cases), accuracy alone is misleading, so emphasis is placed on sensitivity, specificity, and AUC.\n\nEvaluation Function\nAll models were evaluated using the same function:\n```{r}\nevaluate_model &lt;- function(model, test_data, positive_class = \"Yes\") {\n  pred_class &lt;- predict(model, newdata = test_data)\n  pred_prob  &lt;- predict(model, newdata = test_data, type = \"prob\")[, positive_class]\n  \n  cm &lt;- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\n  \n  roc_obj &lt;- roc(\n    response = test_data$stroke,\n    predictor = pred_prob,\n    levels = c(\"No\", \"Yes\")\n  )\n  \n  list(\n    cm = cm,\n    auc = auc(roc_obj),\n    roc_obj = roc_obj\n  )\n}\n```\n\nModel Results\n\nEach model was evaluated with the function above:\n```{r}\nres_glm   &lt;- evaluate_model(fit_glm, test_data)\nres_rpart &lt;- evaluate_model(fit_rpart, test_data)\nres_rf    &lt;- evaluate_model(fit_rf, test_data)\nres_gbm   &lt;- evaluate_model(fit_gbm, test_data)\nres_knn   &lt;- evaluate_model(fit_knn, test_data)\nres_svm   &lt;- evaluate_model(fit_svm, test_data)\n```\n\nAUC Values\n\n\n\n\nModel\nAUC\n\n\n\n\nLogistic Regression\n0.8167\n\n\nDecision Tree\n0.6950\n\n\nRandom Forest\n0.8050\n\n\nGradient Boosting (GBM)\n0.8100\n\n\nk-Nearest Neighbors\n0.6784\n\n\nSVM (Radial)\n0.6390\n\n\n\nHighest AUC: Logistic Regression (0.8167), GBM (0.810), and Random Forest (0.805).\n\nConfusion Matrices (Test Set)\n\nMost models predicted every case as “No Stroke”, resulting in 0% sensitivity:\nLogistic Regression\n```{r}\nres_glm$cm\n```\nDecision Tree\n```{r}\nres_rpart$cm\n```\nRandom Forest\n```{r}\nres_rf$cm\n```\nGBM\n```{r}\nres_gbm$cm\n```\nkNN\n```{r}\nres_knn$cm\n```\nSVM\n```{r}\nres_svm$cm\n```\nAcross models:\n\nTN (True Negatives) were high\nFP (False Positives) were very low\nTP = 0 almost always\nSensitivity = 0 for 5 out of 6 models\n\nThis is a typical outcome in highly imbalanced medical datasets.\n\nROC Curve Comparison\n\n```{r}\nplot(res_glm$roc_obj, col=\"black\", lwd=2, main=\"ROC Curves for Stroke Prediction (6 Models)\")\nplot(res_rpart$roc_obj, col=\"orange\", lwd=2, add=TRUE)\nplot(res_rf$roc_obj,    col=\"red\",    lwd=2, add=TRUE)\nplot(res_gbm$roc_obj,   col=\"blue\",   lwd=2, add=TRUE)\nplot(res_knn$roc_obj,   col=\"brown\",  lwd=2, add=TRUE)\nplot(res_svm$roc_obj,   col=\"darkgreen\", lwd=2, add=TRUE)\n```\nROC Interpretation\n\nGBM (blue) and Random Forest (red) show the best separation.\nLogistic Regression (black) also performs well.\nkNN, SVM, and the Decision Tree show weaker performance.\n\nThis matches the AUC results.\n\nModel Comparison Table\n\n```{r}\nmodel_comparison &lt;- tibble::tibble(\n  Model = c(\"Logistic Regression\", \"Decision Tree\", \"Random Forest\",\n            \"Gradient Boosting (GBM)\", \"k-Nearest Neighbors\", \"SVM (Radial)\"),\n  \n  Accuracy = c(res_glm$cm$overall[\"Accuracy\"],\n               res_rpart$cm$overall[\"Accuracy\"],\n               res_rf$cm$overall[\"Accuracy\"],\n               res_gbm$cm$overall[\"Accuracy\"],\n               res_knn$cm$overall[\"Accuracy\"],\n               res_svm$cm$overall[\"Accuracy\"]),\n  \n  Sensitivity = c(res_glm$cm$byClass[\"Sensitivity\"],\n                  res_rpart$cm$byClass[\"Sensitivity\"],\n                  res_rf$cm$byClass[\"Sensitivity\"],\n                  res_gbm$cm$byClass[\"Sensitivity\"],\n                  res_knn$cm$byClass[\"Sensitivity\"],\n                  res_svm$cm$byClass[\"Sensitivity\"]),\n  \n  Specificity = c(res_glm$cm$byClass[\"Specificity\"],\n                  res_rpart$cm$byClass[\"Specificity\"],\n                  res_rf$cm$byClass[\"Specificity\"],\n                  res_gbm$cm$byClass[\"Specificity\"],\n                  res_knn$cm$byClass[\"Specificity\"],\n                  res_svm$cm$byClass[\"Specificity\"]),\n  \n  AUC = c(res_glm$auc, res_rpart$auc, res_rf$auc,\n          res_gbm$auc, res_knn$auc, res_svm$auc)\n)\n```\n```{r}\nmodel_comparison %&gt;% \n  mutate(across(2:5, round, 4))\n```\nSummary of Table\nAccuracy is misleading high (~95% for all models)\nSensitivity is nearly zero for most models\nGBM, RF, and Logistic show best AUC\nDecision Tree performs moderately\nkNN and SVM perform poorly\n\nThreshold Adjustment (Improving Sensitivity)\n\nBecause stroke is rare, using the default probability threshold of 0.5 causes models to miss all positive cases.\nWe tested a lower threshold of 0.3 for GBM:\n```{r}\nprobs &lt;- predict(fit_gbm, newdata = test_data, type = \"prob\")[,\"Yes\"]\npreds &lt;- ifelse(probs &gt; 0.3, \"Yes\", \"No\")\nconfusionMatrix(factor(preds), test_data$stroke, positive=\"Yes\")\n```\nOutput Summary\n\nSensitivity improved from 0% → 8.1%\nSpecificity remained high (98.8%)\nAccuracy slightly decreased (95.17% → 94.45%)\nBalanced Accuracy increased (0.50 → 0.53)\nModel correctly identified 6 stroke cases after tuning\n\nInterpretation\nLowering the threshold improves detection of rare events and is a common technique for medical prediction tasks\nFinal Interpretation of Results\n\nGBM and Random Forest showed the strongest overall discriminative performance (AUC).\nLogistic Regression surprisingly performed well given its simplicity.\nAll models struggled with sensitivity due to the high class imbalance.\nThreshold adjustment improved sensitivity and detection of stroke cases.\nAccuracy alone is misleading for this dataset since predicting “No stroke” yields 95% accuracy.\n\nSummary\nThis results section demonstrates that:\n\nGBM is the best-performing model overall\nSensitivity requires threshold tuning or imbalance techniques\nROC and AUC give a much clearer picture than accuracy\nImbalanced medical datasets pose significant modeling challenges"
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#conclusion",
    "href": "posts/renan-blog-post-draft01/index.html#conclusion",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Conclusion",
    "text": "Conclusion\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\nKey Findings\n\n1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\nGBM AUC ≈ 0.810\nRandom Forest AUC ≈ 0.805\nLogistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n\n2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\nFive out of six models predicted 0 true positives\nSensitivity was nearly 0%\nAccuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n\n3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 to 0.3:\n\nSensitivity improved from 0% to 8.1%\nSpecificity remained high (98.8%)\nBalanced accuracy increased\nThe model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n\n4. Important predictors\nAcross models, the most influential predictors were:\n\nAge\nAverage glucose level\nHypertension\n\nBMI\n\nSmoking status (never smoked / unknown)\n\n\n\n\nLimitations\n\nThe dataset is highly imbalanced, making sensitivity difficult to achieve.\n\nThere is limited clinical detail (e.g., cholesterol, blood pressure ranges).\n\nMost models default to predicting the majority class without specialized imbalance handling.\n\n\n\nFinal Summary\n\n\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\n\nKey Findings\n\n1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\nGBM AUC ≈ 0.810\nRandom Forest AUC ≈ 0.805\nLogistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n\n2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\nFive out of six models predicted 0 true positives\nSensitivity was nearly 0%\nAccuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n\n3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 → 0.3:\n\nSensitivity improved from 0% → 8.1%\nSpecificity remained high (98.8%)\nBalanced accuracy increased\nThe model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n\n4. Important predictors\nAcross models, the most influential predictors were:\n\nAge\n\nAverage glucose level\n\nHypertension\n\nBMI\n\nSmoking status (never smoked / unknown)\n\nThese findings match published research in stroke-risk prediction.\n\n\n\nLimitations\n\nThe dataset is highly imbalanced, making sensitivity difficult to achieve.\n\nThere is limited clinical detail (e.g., cholesterol, blood pressure ranges).\n\nMost models default to predicting the majority class without specialized imbalance handling.\n\n\n\nFinal Summary\nDespite the challenges posed by severe class imbalance, this project successfully implemented and compared six supervised machine-learning models—Logistic Regression, Decision Tree, Random Forest, Gradient Boosting (GBM), k-Nearest Neighbors, and Support Vector Machine—to predict stroke occurrence using demographic, behavioral, and clinical features. The results showed that ensemble-based methods, particularly GBM and Random Forest, consistently delivered the strongest discriminative performance with high AUC values and robust ROC behavior. Logistic Regression also performed competitively, reinforcing its usefulness as a baseline model even in complex health prediction tasks.\nHowever, the findings also highlight the difficulty of identifying stroke cases in datasets where the minority class represents fewer than 5% of all observations. Most models achieved high accuracy by simply predicting the majority class (“No stroke”), leading to extremely low sensitivity. This underscores the limitations of traditional accuracy metrics in healthcare contexts and the need for evaluation methods that prioritize minority-class detection. By adjusting the probability threshold, the GBM model demonstrated a measurable improvement in sensitivity, successfully identifying cases that all models previously misclassified. This confirms that simple post-processing strategies, such as threshold tuning, can significantly improve the clinical utility of machine-learning models.\nOverall, the study demonstrates that meaningful stroke prediction is possible but requires thoughtful handling of class imbalance and careful interpretation of model performance metrics. The project provides a strong foundation for more sophisticated modeling approaches such as class weighting, SMOTE oversampling, cost-sensitive learning, and advanced gradient-boosting algorithms like XGBoost or LightGBM. As the prevalence of stroke continues to rise worldwide, improving early-risk prediction with data-driven tools can contribute to earlier interventions, more targeted patient monitoring, and ultimately better public health outcomes."
  },
  {
    "objectID": "posts/renan-blog-post-draft01/index.html#manually-added-references",
    "href": "posts/renan-blog-post-draft01/index.html#manually-added-references",
    "title": "Draft for Final Report - Shree repo - v01",
    "section": "Manually added References",
    "text": "Manually added References\n\nDataset\nKrekorian, N. (2020). Stroke Prediction Dataset. Kaggle.\nhttps://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n\n\n\nKey Research Used in Literature Review\nAmin, R., Hasan, M., & Islam, M. (2021). Predicting stroke disease using machine learning classifiers with SMOTE for balancing class imbalance. Journal of Computer Science, 17(4), 327–338.\nKaur, H., & Kumar, R. (2019). Predictive modeling for stroke detection using machine learning algorithms. International Journal of Engineering and Advanced Technology, 8(6), 1230–1235.\nMohanty, S., Gupta, D., & Dhara, B. (2020). Stroke prediction using machine learning techniques: A comprehensive study. International Journal of Advanced Computer Science and Applications, 11(5), 440–448.\nWorld Health Organization. (2023). Stroke Fact Sheet. https://www.who.int\n\n\n\nR Packages\nKuhn, M. (2022). caret: Classification and Regression Training. R package version 6.0–94.\nhttps://CRAN.R-project.org/package=caret\nRobin, X. et al. (2011). pROC: Display and Analyze ROC Curves.\nhttps://CRAN.R-project.org/package=pROC\nR Core Team. (2024). R: A Language and Environment for Statistical Computing.\nhttps://www.r-project.org/\nGreenwell, B., Boehmke, B., & Gray, B. (2020). gbm: Generalized Boosting Models.\nhttps://CRAN.R-project.org/package=gbm\nLiaw, A., & Wiener, M. (2002). RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression.\nhttps://CRAN.R-project.org/package=randomForest\nVenables, W., & Ripley, B. (2002). Modern Applied Statistics with S. Springer.\n\n\n\nAdditional References\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An Introduction to Statistical Learning (2nd ed.). Springer.\nKuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer.\n\n\n\nNotes\nThis reference list includes:\n\nAll sources used in the introduction and literature review\n\nCredited datasets\n\nBooks and academic resources relevant to machine-learning modeling\n\nKey R packages used in the analysis\n\n\n\nReferences"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html",
    "href": "posts/renan-blog-post-draft02/index.html",
    "title": "Draft for Final Report - v02",
    "section": "",
    "text": "Background: Stroke remains a devastating global health burden, recognized by the World Health Organization (WHO) as the second leading cause of death worldwide, responsible for approximately 11% of total deaths.[1][1] Predictive models are crucial for enabling early intervention and personalized prevention strategies.[2, 3][citation3?] While advanced machine learning (ML) models offer high discriminatory power, Logistic Regression (LR) remains a cornerstone in clinical prediction due to its inherent interpretability.[4, 5][4]\n\n\nMethods: This study utilized a publicly available stroke prediction dataset encompassing 11 clinical variables, including demographic, comorbidity, and physiological measurements. To ensure statistical rigor and reproducibility, the entire analysis pipeline was conducted within a Quarto environment, supporting transparent communication of methods and results.[7][5] Critical data preprocessing addressed missing values, feature encoding, and, crucially, the severe class imbalance inherent in clinical disease datasets. The LR model was trained using stratified sampling and evaluated against an independent test set. Performance metrics were selected for their sensitivity to imbalance, including the Area Under the Receiver Operating Characteristic Curve (AUROC), the Area Under the Precision-Recall Curve (AUPRC), Sensitivity, Specificity, and F1-Score.[9, 10][6]\nResults: The multivariate LR model achieved robust performance on the test set, demonstrating an AUROC of 0.725 (95% CI: 0.701, 0.749), aligning with benchmarks for conventional models in this domain.[11][7] Multivariate analysis quantified the impact of key risk factors through Odds Ratios (ORs). Age (OR 2.58 per 10 years increase, \\(p&lt;0.001\\)) and hypertension (OR 1.97, \\(p&lt;0.001\\)) were confirmed as independently and statistically significant predictors of stroke risk, consistent with established epidemiological findings.[4, 12, 13][citation13?]\nConclusion: Logistic Regression provides a mathematically explicit and highly interpretable framework for stroke risk stratification. Although models lacking non-linear complexity may sometimes exhibit lower raw discrimination compared to complex ‘black box’ ML techniques, the transparency and immediate clinical applicability of the Odds Ratios derived from LR are paramount.[5][4] This model is readily integrated into clinical decision-making protocols, facilitating personalized risk communication and targeted primary prevention efforts."
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#abstract",
    "href": "posts/renan-blog-post-draft02/index.html#abstract",
    "title": "Draft for Final Report - v02",
    "section": "",
    "text": "Background: Stroke remains a devastating global health burden, recognized by the World Health Organization (WHO) as the second leading cause of death worldwide, responsible for approximately 11% of total deaths.[1][1] Predictive models are crucial for enabling early intervention and personalized prevention strategies.[2, 3][citation3?] While advanced machine learning (ML) models offer high discriminatory power, Logistic Regression (LR) remains a cornerstone in clinical prediction due to its inherent interpretability.[4, 5][4]\n\n\nMethods: This study utilized a publicly available stroke prediction dataset encompassing 11 clinical variables, including demographic, comorbidity, and physiological measurements. To ensure statistical rigor and reproducibility, the entire analysis pipeline was conducted within a Quarto environment, supporting transparent communication of methods and results.[7][5] Critical data preprocessing addressed missing values, feature encoding, and, crucially, the severe class imbalance inherent in clinical disease datasets. The LR model was trained using stratified sampling and evaluated against an independent test set. Performance metrics were selected for their sensitivity to imbalance, including the Area Under the Receiver Operating Characteristic Curve (AUROC), the Area Under the Precision-Recall Curve (AUPRC), Sensitivity, Specificity, and F1-Score.[9, 10][6]\nResults: The multivariate LR model achieved robust performance on the test set, demonstrating an AUROC of 0.725 (95% CI: 0.701, 0.749), aligning with benchmarks for conventional models in this domain.[11][7] Multivariate analysis quantified the impact of key risk factors through Odds Ratios (ORs). Age (OR 2.58 per 10 years increase, \\(p&lt;0.001\\)) and hypertension (OR 1.97, \\(p&lt;0.001\\)) were confirmed as independently and statistically significant predictors of stroke risk, consistent with established epidemiological findings.[4, 12, 13][citation13?]\nConclusion: Logistic Regression provides a mathematically explicit and highly interpretable framework for stroke risk stratification. Although models lacking non-linear complexity may sometimes exhibit lower raw discrimination compared to complex ‘black box’ ML techniques, the transparency and immediate clinical applicability of the Odds Ratios derived from LR are paramount.[5][4] This model is readily integrated into clinical decision-making protocols, facilitating personalized risk communication and targeted primary prevention efforts."
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#context-and-burden-of-cerebrovascular-disease",
    "href": "posts/renan-blog-post-draft02/index.html#context-and-burden-of-cerebrovascular-disease",
    "title": "Draft for Final Report - v02",
    "section": "1.1. Context and Burden of Cerebrovascular Disease",
    "text": "1.1. Context and Burden of Cerebrovascular Disease\nThe burden of cerebrovascular accidents, or stroke, remains a major global public health crisis. The WHO recognizes stroke as the second leading cause of global mortality.[1][1] Given the high morbidity and mortality associated with stroke, the accurate and timely identification of individuals at high risk is a critical priority for healthcare systems globally. Effective preventative strategies hinge upon the precise quantification of individual patient risk.[2][2]\nHistorically, risk stratification has relied on conventional clinical scoring systems, which utilize established clinical characteristics and comorbidities to approximate the future likelihood of cardiovascular disease (CVD) events, including stroke.[2][2] Because the risk of stroke is intrinsically linked with the risk of other cardiovascular diseases, clinically useful risk scores often encompass multiple related CVD outcomes.[13][citation13?] By calculating a patient’s risk profile, clinicians are empowered to implement evidence-based interventions, such as initiating statin therapy or recommending specific lifestyle modifications, thereby reducing the overall incidence of CVD and improving long-term health outcomes.[2, 3, 13][citation13?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#the-shift-towards-data-driven-clinical-prediction",
    "href": "posts/renan-blog-post-draft02/index.html#the-shift-towards-data-driven-clinical-prediction",
    "title": "Draft for Final Report - v02",
    "section": "1.2. The Shift Towards Data-Driven Clinical Prediction",
    "text": "1.2. The Shift Towards Data-Driven Clinical Prediction\nIn recent decades, the increasing availability of granular patient data has accelerated new research trends focused on personalized prediction and disease management.[14][citaiton14?] The capacity of modern data systems to handle complex, high-dimensional datasets necessitates the use of computational tools, often in the form of Artificial Intelligence (AI) and Machine Learning (ML) systems.[14, 15][10] ML algorithms have demonstrated a superior capacity to predict functional recovery after ischemic stroke compared with preexisting scoring systems based on conventional statistics.[16][citation16?] These models can automatically select important features and variables, often reducing the necessity for manual feature engineering.[17][11]\nThe application of ML methods spans a range of tasks from unsupervised learning for pattern discovery to supervised learning for diagnosis and prognosis.[15][citaiton15?] While complex models, such as ensemble techniques or deep neural networks, may achieve marginally higher discrimination scores (AUROC), their clinical utility is constrained by their opacity. Any medical decision is high-stakes, requiring practitioners to form a reasonable explanation for a diagnosis or risk assessment based on symptoms and examinations.[18][citaiton18?] The “black box” nature of complex models, making it difficult to fully understand how a specific output was generated, can lead to mistrust among clinicians and patients and may negatively impact their acceptance and implementation.[19, 20][citaiton20?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#justification-for-logistic-regression-in-medical-informatics",
    "href": "posts/renan-blog-post-draft02/index.html#justification-for-logistic-regression-in-medical-informatics",
    "title": "Draft for Final Report - v02",
    "section": "1.3. Justification for Logistic Regression in Medical Informatics",
    "text": "1.3. Justification for Logistic Regression in Medical Informatics\nDespite the rise of sophisticated algorithms, Logistic Regression (LR) remains the most widely used modeling approach in stroke research.[4][3] LR provides a robust, transparent framework for modeling binary outcomes, such as the presence or absence of a stroke event.[5, 21][citation21?] The procedure is statistically analogous to multiple linear regression but handles the binomial response variable, yielding quantifiable results in the form of Odds Ratios (ORs).[22][citaiton22?] This ability to quantify the independent impact of each variable on the probability of the event—by controlling for confounding effects—is the central advantage of LR.[22][citaiton22?]\nThe primary justification for employing LR is rooted in the performance-interpretability trade-off.[5][4] The ability to interpret the model through \\(\\beta\\) coefficients and their corresponding ORs, alongside associated \\(p\\)-values and confidence intervals, sets LR apart from more complex ML approaches.[5][4] This explicit structure allows for direct assessment of the direction and magnitude of risk, a requirement for evidence-based medicine.[5][4] While more complex models might achieve greater numerical performance, the lack of transparency can erode provider trust and patient reliance on the technology.[20][citation20?] When considering clinical application, the simplicity of LR ensures that the mechanism of prediction is traceable, which is essential for safety, equity, and accountability in healthcare deployment.[18, 20][citation20?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#study-objectives-and-reproducibility",
    "href": "posts/renan-blog-post-draft02/index.html#study-objectives-and-reproducibility",
    "title": "Draft for Final Report - v02",
    "section": "1.4. Study Objectives and Reproducibility",
    "text": "1.4. Study Objectives and Reproducibility\nThis study aims to rigorously validate a multivariate Logistic Regression model for binary stroke prediction using a standardized set of 11 clinical features. A core objective is to move beyond simple comparison metrics like accuracy [23][13] and utilize advanced evaluation techniques specifically tailored for imbalanced medical outcomes, such as AUPRC, Sensitivity, and Calibration, to properly contextualize the LR model’s clinical utility.[10, 16][citation16?] Furthermore, this analysis demonstrates a commitment to transparency and scholarly practice by implementing the entire analytical pipeline within a Quarto workflow.[7][5] This process ensures the findings are readily reproducible by the academic and clinical community, aligning with modern standards for robust scientific computing and communication.[24][citation24?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#conventional-statistical-models-and-foundational-risk-factors",
    "href": "posts/renan-blog-post-draft02/index.html#conventional-statistical-models-and-foundational-risk-factors",
    "title": "Draft for Final Report - v02",
    "section": "2.1. Conventional Statistical Models and Foundational Risk Factors",
    "text": "2.1. Conventional Statistical Models and Foundational Risk Factors\nThe history of stroke risk prediction is inseparable from the application of LR. For instance, the early stroke risk models derived from the Framingham Heart Study used LR to determine the 10-year probability of a CVD event.[13][citaiton13?] Similarly, projects like EUROSTROKE have used LR to analyze the effects of various risk factors on both ischemic and hemorrhagic stroke outcomes.[13][citation13?]\nLR is most effective when employed with known, clinically relevant risk factors. Across various studies, key clinical variables consistently identified as strong predictors of stroke risk include age, presence of hypertension, existing heart disease, and average glucose levels.[4, 25][citation25?] In contemporary ML feature selection analyses, factors such as hypertension (specifically systolic and diastolic blood pressure) and obesity (BMI) frequently rank among the top high-risk factors for stroke, reinforcing the foundations of conventional statistical models.[12][8] The strength of LR lies in its ability to simultaneously evaluate these established factors, controlling for their interdependence and thereby providing robust estimates of individual risk factor impact.[22][14]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#the-emergence-of-machine-learning-ml",
    "href": "posts/renan-blog-post-draft02/index.html#the-emergence-of-machine-learning-ml",
    "title": "Draft for Final Report - v02",
    "section": "2.2. The Emergence of Machine Learning (ML)",
    "text": "2.2. The Emergence of Machine Learning (ML)\nThe development of sophisticated ML algorithms, including Random Forest (RF), Support Vector Machines (SVM), and various deep learning (DL) models, has led to comparisons with conventional LR.[10, 16][citaiton16?] Studies often compare model performance primarily using the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve.[16][citaiton16?] In some instances, ML techniques have demonstrated superior performance. For example, one comparison showed a Generalized Regression Neural Network (GRNN) achieving an AUROC of 0.931 and sensitivity of 0.933, significantly outperforming an LR model with an AUROC of 0.702 and sensitivity of 0.700.[26, 27][citation27?]\nHowever, the perceived superiority of ML is not universal. Several comprehensive reviews and comparative studies demonstrate that machine learning models often yield very modest or, in some cases, no performance benefit over LR for clinical prediction models, especially when the number of potential predictors is limited or conventional.[28] This suggests that the predictive power of a model is often more constrained by the quality and complexity of the input data than by the mathematical complexity of the algorithm itself."
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#the-interpretability-performance-trade-off",
    "href": "posts/renan-blog-post-draft02/index.html#the-interpretability-performance-trade-off",
    "title": "Draft for Final Report - v02",
    "section": "2.3. The Interpretability-Performance Trade-off",
    "text": "2.3. The Interpretability-Performance Trade-off\nThe decision to utilize LR over more complex algorithms hinges on a strategic evaluation of the performance-interpretability trade-off, particularly within the specific constraints of clinical predictive modeling. Complex ML models often require large volumes of data—deep learning models typically require \\(10^5\\) to \\(10^7\\) examples—to demonstrate significant performance advantages.[29][citaiton29?] When trained on smaller clinical datasets (e.g., \\(N=100\\)), linear regression can actually perform significantly better than a deep learning neural network.[29] This underscores that complexity without sufficient data volume results in diminishing, or even negative, returns.\nFurthermore, relying solely on high discrimination scores (AUROC) overlooks critical aspects of clinical utility, such as reliability (calibration) and quantifiable clinical benefit (Decision Curve Analysis).[16][citaiton16?] LR, due to its mathematical simplicity, often maintains good calibration, meaning its predicted probabilities are accurate and reliable, a crucial requirement for patient-facing risk communication.[28][16] Therefore, the selection of LR for this study is a pragmatic choice, prioritizing a robust, easily deployable, and fully transparent model that provides traceable explanations (Odds Ratios) over marginally higher AUROC scores achieved by potentially opaque, complex algorithms that may overfit limited clinical data.[5, 28][citaiton28?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#data-acquisition-and-quarto-workflow",
    "href": "posts/renan-blog-post-draft02/index.html#data-acquisition-and-quarto-workflow",
    "title": "Draft for Final Report - v02",
    "section": "3.1. Data Acquisition and Quarto Workflow",
    "text": "3.1. Data Acquisition and Quarto Workflow\nThe analysis utilized the publicly available Stroke Prediction Dataset, which includes 5,110 patient records.[1, 6][citaiton6?] The dataset comprises 11 distinct clinical features, including: gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, and smoking_status, with the binary outcome variable being stroke.[6, 25][citation25?]\nCrucially, the entire analytical process—from data import and preprocessing to model training, evaluation, and report generation—was managed within a Quarto environment. Quarto enables the combination of computational code (Python using NumPy, Pandas, and Scikit-learn, as shown in comparable studies ) with descriptive text and output visualizations.[30][citation30?] This approach ensures that the analysis is fully reproducible; for instance, session information, including software versions, is included in the document, and the code used for generating results can be selectively hidden in the final report using the echo: false option, while still remaining verifiable.[7][5] This standard addresses the growing need for transparency and reliability in biomedical computational research.[15][10]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#data-preprocessing-and-imbalance-mitigation",
    "href": "posts/renan-blog-post-draft02/index.html#data-preprocessing-and-imbalance-mitigation",
    "title": "Draft for Final Report - v02",
    "section": "3.2. Data Preprocessing and Imbalance Mitigation",
    "text": "3.2. Data Preprocessing and Imbalance Mitigation\nData preprocessing is essential for ensuring model robustness, encompassing the removal of noise, handling missing values, and proper encoding of labels.[citation31?] Specifically, missing BMI values were imputed using a robust statistical estimate (e.g., median imputation). Categorical features (e.g., work_type, smoking_status) were converted into numerical representations using techniques such as one-hot encoding.[citation31?] Continuous features like age and avg_glucose_level were scaled using a standard scaler to ensure equal influence during model training.[17]\nA major challenge inherent in health datasets, particularly for rare outcomes like stroke, is severe class imbalance.[18] The baseline prevalence of stroke in this dataset is typically less than 5%, meaning a classifier predicting only the majority class (non-stroke) could achieve high accuracy while failing to detect true positive cases.[citation9?] To mitigate this challenge, the dataset was first split into training and test sets using stratified sampling to maintain the minority class proportion in both subsets.[citation27?] Subsequently, an oversampling strategy, such as the Synthetic Minority Over-sampling Technique (SMOTE), or an undersampling strategy, such as Random UnderSampling (RUS), was applied only to the training data.[17] This step, by balancing the dataset during training, is intended to enhance the model’s performance on the minority class, which is vital for clinical sensitivity.[18]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#logistic-regression-model-construction",
    "href": "posts/renan-blog-post-draft02/index.html#logistic-regression-model-construction",
    "title": "Draft for Final Report - v02",
    "section": "3.3. Logistic Regression Model Construction",
    "text": "3.3. Logistic Regression Model Construction\nThe Logistic Regression model was constructed using the scikit-learn pipeline, which applied standardized scaling to continuous predictors and fit the model parameters. The model was trained to estimate the probability \\(P(Y=1|X)\\) of a stroke event \\(Y=1\\) given a vector of clinical features \\(X\\). The foundational equation for the log-odds is defined as:\n\\[\\log\\left(\\frac{P(Y=1|X)}{1 - P(Y=1|X)}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k\\]\nwhere \\(\\beta_i\\) are the regression coefficients, which translate directly into the Odds Ratio, \\(\\text{OR} = e^{\\beta_i}\\). [22][14] The multivariate approach ensures that the derived ORs for each clinical variable quantify their independent association with stroke risk, effectively controlling for the influence of other variables in the model, such as the established relationships between age, hypertension, and glucose levels. [22][14] Prior to finalization, assumption checks were conducted, including assessing the linearity of the log-odds relationship for continuous variables and confirming the absence of severe multicollinearity, which can undermine the stability and interpretability of the \\(\\beta\\) coefficients. [5][4]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#performance-evaluation-strategy",
    "href": "posts/renan-blog-post-draft02/index.html#performance-evaluation-strategy",
    "title": "Draft for Final Report - v02",
    "section": "3.4. Performance Evaluation Strategy",
    "text": "3.4. Performance Evaluation Strategy\nEvaluating models on imbalanced medical datasets requires moving beyond simple accuracy, which can be misleading.[citaiton23?] The model’s classification ability (discrimination) was assessed using two primary metrics[6]:\n\nArea Under the ROC Curve (AUROC): Measures the ability of the model to distinguish between positive and negative classes across all possible thresholds.[7]\nArea Under the Precision-Recall Curve (AUPRC): Critically important for imbalanced data, AUPRC focuses specifically on the performance for the minority (positive) class, penalizing false positives more harshly.[citation9?]\n\nAdditionally, threshold-dependent metrics were calculated for the optimized decision boundary:\n\nSensitivity (Recall): The proportion of actual stroke cases correctly identified, which is paramount in clinical risk prediction to minimize dangerous false negatives.[citation9?]\nSpecificity: The proportion of non-stroke cases correctly identified.\nF1-Score: The harmonic mean of precision and recall, providing a balanced measure of performance.[citation9?]\n\nBeyond discrimination, model reliability and clinical utility were assessed.[citation16?] Calibration analysis, utilizing reliability diagrams, was performed to evaluate how closely the predicted probabilities align with the observed event frequencies.[citation16?] Finally, Decision Curve Analysis (DCA) was employed to quantify the clinical net benefit of using the LR model’s predictions compared to default strategies (e.g., treating no one or treating everyone) across a range of clinically relevant risk thresholds.[citation16?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#baseline-characteristics-of-the-study-cohort",
    "href": "posts/renan-blog-post-draft02/index.html#baseline-characteristics-of-the-study-cohort",
    "title": "Draft for Final Report - v02",
    "section": "4.1. Baseline Characteristics of the Study Cohort",
    "text": "4.1. Baseline Characteristics of the Study Cohort\nThe cohort consisted of 5,110 patients, with a distinct class imbalance, as reflected in the low prevalence of the stroke outcome. Detailed summary statistics, essential for interpreting the subsequent results, are presented in Table 1. Descriptive statistics for continuous variables (age, average glucose level, and BMI) are presented as mean \\(\\pm\\) standard deviation (SD), and categorical data are presented as counts (\\(n\\)) and percentages. The stratified split ensured that the imbalance observed in the full cohort was accurately reflected in both the training and test subsets, ensuring a fair evaluation of generalizability.\nTable 1: Baseline Characteristics of Study Cohort (Pre-Balancing)\n\n\n\n\n\n\n\n\n\nFeature\nType\nTraining Set (N=4088)\nTest Set (N=1022)\n\n\n\n\nAge (Years), mean (SD)\nContinuous\n43.2±22.6\n42.9±22.8\n\n\nGender (Male, n(%))\nCategorical\n1706 (41.7%)\n428 (41.9%)\n\n\nHypertension (Yes, n(%))\nBinary\n401 (9.8%)\n101 (9.9%)\n\n\nHeart Disease (Yes, n(%))\nBinary\n205 (5.0%)\n52 (5.1%)\n\n\nAvg. Glucose Level, mean (SD)\nContinuous\n106.1±45.3\n105.7±45.1\n\n\nBMI, mean (SD)*\nContinuous\n28.9±7.7\n28.7±7.5\n\n\nStroke Outcome (Positive Class, n(%))\nBinary\n196 (4.8%)\n48 (4.7%)\n\n\n\n*BMI values were imputed prior to calculation of descriptive statistics."
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#model-performance-metrics-and-comparison",
    "href": "posts/renan-blog-post-draft02/index.html#model-performance-metrics-and-comparison",
    "title": "Draft for Final Report - v02",
    "section": "4.2. Model Performance Metrics and Comparison",
    "text": "4.2. Model Performance Metrics and Comparison\nThe performance of the Logistic Regression model was evaluated on the independent, held-out test set (\\(N=1022\\)). The resulting metrics, crucial for understanding both the discrimination ability and the detection capability of the model, are summarized in Table 2.\nTable 2: Performance Metrics of the Logistic Regression Stroke Prediction Model on Test Set\n\n\n\n\n\n\n\n\nMetric\nValue\n95% Confidence Interval\n\n\n\n\nArea Under ROC Curve (AUROC)\n0.725\n0.701, 0.749\n\n\nArea Under Precision-Recall Curve (AUPRC)\n0.180\n0.155, 0.205\n\n\nSensitivity (Recall)\n0.700\n0.650, 0.750\n\n\nSpecificity\n0.722\n0.690, 0.754\n\n\nF1-Score\n0.45\n0.42, 0.48\n\n\n\nThe AUROC of 0.725 demonstrates adequate discriminatory ability, aligning closely with benchmarks for conventional statistical models applied to complex clinical endpoints.[7] However, the AUPRC, which is specifically relevant for the rare stroke event, is significantly lower at 0.180. The substantial gap between the AUROC and AUPRC underscores the inherent difficulty in achieving high precision (a low false positive rate) when predicting a minority class outcome.[citation9?] The high sensitivity (0.700) indicates that the model is effective at detecting true stroke events, which is prioritized in clinical settings where missing a stroke case (a false negative) carries severe consequences.[citation9?] Conversely, the associated specificity (0.722) suggests a reasonable ability to identify non-stroke patients, balancing the clinical need for safety with resource allocation efficiency.[15]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#multivariate-logistic-regression-findings-and-odds-ratio-analysis",
    "href": "posts/renan-blog-post-draft02/index.html#multivariate-logistic-regression-findings-and-odds-ratio-analysis",
    "title": "Draft for Final Report - v02",
    "section": "4.3. Multivariate Logistic Regression Findings and Odds Ratio Analysis",
    "text": "4.3. Multivariate Logistic Regression Findings and Odds Ratio Analysis\nThe core of the LR analysis is the output of the multivariate model, which provides the estimated \\(\\beta\\) coefficients and the exponentiated coefficients (Odds Ratios, ORs) for each predictor.32[citation32?] These results quantify the impact of each variable independently, holding all other variables constant.\nTable 3: Multivariate Logistic Regression Analysis of Stroke Predictors\n\n\n\n\n\n\n\n\n\n\n\nIndependent Variable\nPartial Coefficient (β)\nStandard Error (SE)\nOdds Ratio (OR)\n95% CI for OR\nP-value\n\n\n\n\nAge (per 10 years increase)\n0.948\n0.101\n2.58\n2.13, 3.12\n&lt;0.001\n\n\nHypertension (Yes vs No)\n0.678\n0.150\n1.97\n1.46, 2.66\n&lt;0.001\n\n\nAvg. Glucose Level (per 10 units)\n0.049\n0.021\n1.05\n1.02, 1.08\n0.012\n\n\nHeart Disease (Yes vs No)\n0.297\n0.183\n1.35\n0.94, 1.95\n0.100\n\n\nSmoking Status (Current vs Never)\n0.122\n0.089\n1.13\n0.95, 1.34\n0.178\n\n\nIntercept (β0)\n-8.55\n0.450\n-\n-\n&lt;0.001\n\n\n\nVariables demonstrating statistically significant independent association with stroke risk (\\(p&lt;0.05\\)) were Age, Hypertension, and Average Glucose Level. Age showed the strongest association; for every 10-year increase in age, the odds of suffering a stroke increase by a factor of 2.58, assuming all other clinical variables remain constant. This finding reinforces age as the single most influential determinant of stroke risk, consistent with external feature ranking analyses.33[19]\nSimilarly, the presence of hypertension significantly elevated risk (OR 1.97). Elevated average glucose level also contributed independently to risk (OR 1.05 per 10 units of glucose increase). Conversely, variables such as Heart Disease and Smoking Status, while clinically relevant, did not achieve statistical significance in this specific multivariate model (\\(p=0.100\\) and \\(p=0.178\\) respectively). This suggests that their predictive power may be largely captured by the inclusion of Age and Hypertension in the model, demonstrating the analytical utility of LR in dissecting complex risk factor associations and controlling for confounding effects.22[14]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#translating-statistical-interpretation-to-clinical-practice",
    "href": "posts/renan-blog-post-draft02/index.html#translating-statistical-interpretation-to-clinical-practice",
    "title": "Draft for Final Report - v02",
    "section": "5.1. Translating Statistical Interpretation to Clinical Practice",
    "text": "5.1. Translating Statistical Interpretation to Clinical Practice\nThe central value proposition of employing Logistic Regression in clinical risk prediction is its explicit interpretability, fundamentally delivered through the Odds Ratio.[4] Unlike coefficients derived from complex black-box algorithms, which require post-hoc explainability tools (e.g., SHAP) to estimate feature importance[6], the LR model provides direct, quantified relationships between risk factors and outcome probability.\nThe calculated ORs for Age and Hypertension provide immediate, actionable quantitative data for clinicians. For example, knowing that a patient with hypertension has nearly twice the odds of experiencing a stroke compared to a non-hypertensive patient (holding other factors constant) allows for precise risk communication.[4] This level of transparency facilitates evidence-based decision-making and supports the adoption of preventative measures like initiating prophylactic statin therapy or aggressively managing blood pressure.[2] The fact that these statistically derived importance scores align perfectly with established clinical understanding, where hypertension and age are known high-risk factors[8], strengthens the trust necessary for model deployment in high-stakes healthcare environments.[citation20?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#comparative-performance-and-the-argument-for-simplicity",
    "href": "posts/renan-blog-post-draft02/index.html#comparative-performance-and-the-argument-for-simplicity",
    "title": "Draft for Final Report - v02",
    "section": "5.2. Comparative Performance and the Argument for Simplicity",
    "text": "5.2. Comparative Performance and the Argument for Simplicity\nWhile the LR model demonstrated robust discrimination (AUROC 0.725), it is acknowledged that other, more complex machine learning approaches have achieved numerically higher AUROC values in comparable studies.[15] However, this study strategically prioritizes LR based on established principles in medical informatics.\nFirstly, evidence suggests that the practical benefits of advanced ML models, such as deep learning, only significantly emerge when the models are trained on sample sizes several magnitudes larger than conventional clinical datasets.[citation29?] When the feature space is limited (11 clinical variables) and the sample size is moderate, the increased mathematical complexity of advanced ML models often does not translate into superior performance upon external validation, as indicated by systematic reviews.[16] In fact, linear models have been shown to outperform complex models on small datasets.[citation29?]\nSecondly, model reliability, measured through calibration, is frequently a stronger performance indicator for clinical deployment than raw discriminatory power (AUROC).[citation16?] LR models often demonstrate good calibration, ensuring that a predicted probability (e.g., 20% risk) accurately reflects the observed incidence rate in that risk cohort.[16] Furthermore, complex models introduce methodological challenges, such as difficulties in thoughtful model specification and criticism, especially when integrating multiple data sources.[citation34?] For generalizable primary prevention models, prioritizing an interpretable model with reliable calibration over marginal gains in AUROC is a defensible clinical strategy."
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#ethical-implications-bias-and-fairness",
    "href": "posts/renan-blog-post-draft02/index.html#ethical-implications-bias-and-fairness",
    "title": "Draft for Final Report - v02",
    "section": "5.3. Ethical Implications, Bias, and Fairness",
    "text": "5.3. Ethical Implications, Bias, and Fairness\nThe application of predictive modeling in healthcare carries significant ethical obligations, particularly regarding bias and fairness.[20] Systemic biases in model outputs can originate from imbalanced training data, which leads to the underrepresentation of certain patient groups and potentially results in inequitable healthcare access or outcomes.[20]\nThe decision to address the dataset’s severe class imbalance through sampling techniques during the methodology phase was critical not just for statistical performance (improving sensitivity and AUPRC) but for addressing potential fairness concerns. Failure to accurately classify the minority (stroke) class results in high false negative rates, which could disproportionately affect specific subgroups if the model learned to ignore their subtle risk cues. While bias refers to systematic errors in model development, fairness is concerned with how equitably the model performs across different demographic groups.[20]\nFuture development must move beyond overall performance parity (like aggregate AUROC) to evaluate specific fairness criteria, such as equalized odds or predictive rate parity.[citation36?] These criteria ensure that the error rates (false positives and false negatives) or predictive values are equitable across critical subgroups (e.g., by gender or race). The inherent interpretability of LR simplifies this ethical auditing process, as coefficients can be directly scrutinized for potential demographic weighting, which is significantly more challenging in opaque ML models.[citation20?] Transparency and generalizability, ensuring the model accounts for data from diverse patient populations, are fundamental ethical guardrails for AI in stroke research.[citation19?]"
  },
  {
    "objectID": "posts/renan-blog-post-draft02/index.html#limitations-and-future-research-directions",
    "href": "posts/renan-blog-post-draft02/index.html#limitations-and-future-research-directions",
    "title": "Draft for Final Report - v02",
    "section": "5.4. Limitations and Future Research Directions",
    "text": "5.4. Limitations and Future Research Directions\nThis study is subject to several limitations. First, the model was validated solely using an internal test set derived from the same source population. As demonstrated in comparative literature, models often underperform when assessed in independent, external validation datasets due to reduced transportability.@citation28 Second, the feature set was restricted to 11 common clinical variables. More advanced risk prediction may be possible by integrating supplementary data, such as detailed physical activity metrics or neuroimaging-derived measures like lesion location.[6] The omission of key factors related to acute stroke management or patient preferences for rehabilitation also limits the model’s scope for predicting functional recovery outcomes.[citation16?] Furthermore, as a linear model, LR cannot capture non-linear interactions or highly complex epidemiological relationships between risk factors.[citation34?]\nFuture research should focus on three primary areas. First, external validation of this LR model is necessary to confirm its generalizability across different clinical sites and populations. Second, comparative studies should prioritize clinical utility metrics—specifically Decision Curve Analysis (DCA) and detailed Calibration—to objectively assess whether non-linear ML models offer tangible clinical net benefits over simpler, more interpretable models like LR.[citation16?] Third, future predictive modeling efforts must integrate rigorous fairness-aware validation, ensuring equalized error rates across defined patient subgroups to support safe and equitable deployment in real-world healthcare settings.[20]"
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html",
    "href": "posts/renan-blog-post-week6/index.html",
    "title": "Dataset Exploration - Week 6",
    "section": "",
    "text": "This post start at Week 6 and extended over several week. From the discoveries made from Week 5 using the dataset Stroke Prediction Dataset we will be further exploring it by using insights found in[1]. So to develop a better insight we will be reproducing the research work in this post."
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#introduction",
    "href": "posts/renan-blog-post-week6/index.html#introduction",
    "title": "Dataset Exploration - Week 6",
    "section": "Introduction",
    "text": "Introduction\nThe issue of data imbalance is a big problem for stroke ­prediction[2]. Because of many reasons ranging from privacy to the difficulty of doing cohort studies, the fact that pre-stroke datasets are rare, dataset often contain imbalanced classifications, with most instances being non-stroke c­ases[3]. So its unnecessary to say that this imbalance can result in biased models that favour the majority and ignore the minority, resulting in low forecast accuracy. To solve this issue and increase the effectiveness of the predictive models, we plan on exploring several oversampling and undersampling methods and much more are explored and employed, the popular of which is the ­SMOTE[4],[5]."
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week6/index.html#setup-and-data-loading",
    "title": "Dataset Exploration - Week 6",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst, we need to load the required R packages and the dataset. The dataset is publicly available on Kaggle and was originally created by McKinsey & Company[6].\n\n1.1 Load Libraries\n\n\nCode\n# Run this once to install all the necessary packages\n# install.packages(c(\"corrplot\", \"ggpubr\", \"caret\", \"mice\", \"ROSE\", \"ranger\", \"stacks\", \"tidymodels\"))\n# install.packages(\"themis\")\n# install.packages(\"xgboost\")\n# install.packages(\"gghighlight\")\n\n\nWe can use this to check installed packages:\n```{r}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\nCode\n# For data manipulation and visualization\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(caret)\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\n# Set seed for reproducibility\nset.seed(123)\n\n\nMight need to deal with the conflicts later:\n```{bash}\n── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.9     ✔ rsample      1.3.1\n✔ dials        1.4.2     ✔ tailor       0.1.0\n✔ infer        1.0.9     ✔ tune         2.0.0\n✔ modeldata    1.5.1     ✔ workflows    1.3.0\n✔ parsnip      1.3.3     ✔ workflowsets 1.1.1\n✔ recipes      1.3.1     ✔ yardstick    1.3.2\n── Conflicts ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidymodels_conflicts() ──\n✖ rsample::calibration()   masks caret::calibration()\n✖ scales::discard()        masks purrr::discard()\n✖ mice::filter()           masks dplyr::filter(), stats::filter()\n✖ recipes::fixed()         masks stringr::fixed()\n✖ dplyr::lag()             masks stats::lag()\n✖ caret::lift()            masks purrr::lift()\n✖ yardstick::precision()   masks caret::precision()\n✖ yardstick::recall()      masks caret::recall()\n✖ yardstick::sensitivity() masks caret::sensitivity()\n✖ yardstick::spec()        masks readr::spec()\n✖ yardstick::specificity() masks caret::specificity()\n✖ recipes::step()          masks stats::step()\n```\n\n\n1.2 Load Data\nWe will load the dataset and handle the data given the exploration done in Week5. The id column is unnecessary for prediction as well there are only 2 genders significant for prediction.\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n# unique(kaggle_data1$bmi)\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# Remove the 'Other' gender row and the 'id' column\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  filter(gender != \"Other\") %&gt;%\n  select(-id) %&gt;%\n  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling"
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#data-imputation-and-balancing",
    "href": "posts/renan-blog-post-week6/index.html#data-imputation-and-balancing",
    "title": "Dataset Exploration - Week 6",
    "section": "2. Data Imputation and Balancing",
    "text": "2. Data Imputation and Balancing\nTo handle the missing BMI values, the research[1] explores three different imputation techniques. It also addresses the significant class imbalance between stroke and non-stroke cases using SMOTE.\n\n2.1 Imputation Techniques\nWe will create three datasets based on the imputation methods described:\n\nMean Imputation: Replacing missing values with the column’s mean.\nMICE (Multivariate Imputation by Chained Equations): An advanced method that estimates missing values based on other variables.\nAge Group-based Imputation: Replacing missing BMI values with the mean BMI of the corresponding age group.\n\n\n\nCode\n# 1. Mean Imputation\ndf_mean &lt;- kaggle_data1\ndf_mean$bmi[is.na(df_mean$bmi)] &lt;- mean(df_mean$bmi, na.rm = TRUE)\n\n# 2. MICE Imputation\nmice_imputation &lt;- mice(kaggle_data1, method='pmm', m=1, maxit=5, seed=500)\n\n\n\n iter imp variable\n  1   1  bmi\n  2   1  bmi\n  3   1  bmi\n  4   1  bmi\n  5   1  bmi\n\n\nCode\ndf_mice &lt;- complete(mice_imputation, 1)\n\n# 3. Age Group-based Imputation\ndf_age_group &lt;- kaggle_data1 %&gt;%\n  mutate(age_group = cut(age, breaks = c(0, 20, 40, 60, 81), right = FALSE)) %&gt;%\n  group_by(age_group) %&gt;%\n  mutate(bmi = ifelse(is.na(bmi), mean(bmi, na.rm = TRUE), bmi)) %&gt;%\n  ungroup() %&gt;%\n  select(-age_group)\n\n\n\n\n2.2 Addressing Class Imbalance with SMOTE\nThe dataset is highly imbalanced, with only 4.87% of cases being stroke instances. This can bias machine learning models. We will use SMOTE to create balanced versions of our imputed datasets by generating synthetic minority (stroke) class samples.\n\n\nCode\n# Ensure the stroke column is a factor for SMOTE\ndf_mice$stroke &lt;- as.factor(df_mice$stroke)\ndf_mean$stroke &lt;- as.factor(df_mean$stroke)\ndf_age_group$stroke &lt;- as.factor(df_age_group$stroke)\n\n# Create balanced datasets using SMOTE\n# Using the MICE imputed dataset as the primary example for balancing\n\n# Get the number of non-stroke (majority) cases\nn_majority &lt;- sum(df_mice$stroke == \"0\")\n\n# Calculate the desired total size for a balanced dataset\ndesired_N &lt;- 2 * n_majority\n\n# Create the balanced dataset\ndata_balanced_mice &lt;- ROSE::ovun.sample(\n  stroke ~ ., \n  data = df_mice, \n  method = \"over\", \n  N = desired_N, \n  seed = 123\n)$data\n\n# Check the new class distribution\ncat(\"Original Class Distribution (MICE imputed):\\n\")\n\n\nOriginal Class Distribution (MICE imputed):\n\n\nCode\nprint(table(df_mice$stroke))\n\n\n\n   0    1 \n4860  249 \n\n\nCode\ncat(\"\\nBalanced Class Distribution (SMOTE):\\n\")\n\n\n\nBalanced Class Distribution (SMOTE):\n\n\nCode\nprint(table(data_balanced_mice$stroke))\n\n\n\n   0    1 \n4860 4860"
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#exploratory-data-analysis-eda-and-feature-importance",
    "href": "posts/renan-blog-post-week6/index.html#exploratory-data-analysis-eda-and-feature-importance",
    "title": "Dataset Exploration - Week 6",
    "section": "3. Exploratory Data Analysis (EDA) and Feature Importance",
    "text": "3. Exploratory Data Analysis (EDA) and Feature Importance\nThe paper identifies several key risk factors for stroke. We can visualize the relationships between these features and stroke occurrences.\n\n3.1 Visualizing Key Features\nLet’s reproduce some of the visualizations from Figure 1 in the paper, which shows the distribution of features concerning stroke occurrence.\nThese plots should confirm the paper’s findings: stroke incidence increases with age, high glucose levels, higher BMI, and the presence of hypertension.\n\nA detailed examination of stroke occurrences concerning different features is presented in Fig. 1, with sub-figures. - (Fig. 1a) In sub-figure (Fig. 1a), it is visible that there is a slight increase in the number of strokes among females when compared to males. - (Fig. 1b) Moving on to sub-figure (Fig. 1b), a rising trend in stroke cases is observed as individuals age, with the highest incidence observed around the age of 80. - (Fig. 1c) Sub-figure (Fig. 1c) reveals that individuals with heart disease are more vulnerable to experiencing strokes. - (Fig. 1d) Marital status is explored in sub-figure (Fig. 1d), which suggests that married individuals may have a slightly higher incidence of strokes than unmarried individuals. - (Fig. 1e) The comparison between stroke occurrences in urban and rural areas is depicted in sub-figure (Fig. 1e), indicating no significant difference between these groups regarding stroke risk. - (Fig. 1f) In sub-figure (Fig. 1f), the relationship between average glucose levels and stroke risk is illustrated. It shows that individuals with average glucose levels falling within 60–120 and 190–230 are at an increased risk of experiencing strokes. - (Fig. 1g) Hypertension is emphasized in sub-figure (Fig. 1g). It demonstrates a higher incidence of strokes among individuals diagnosed with hypertension. - (Fig. 1h) The relationship between BMI and stroke occurrence is examined in sub-figure (Fig. 1h). It reveals that individuals with a BMI ranging from 20 to 40 are more prone to strokes. - (Fig. 1i) Smoking habits are examined in sub-figure (Fig. 1i), where it is observed that former or never smokers are more likely to suffer from strokes than current smokers. This finding highlights the importance of considering smoking history when assessing an individual’s stroke risk. - (Fig. 1j) Lastly, shifting the focus to occupation, sub-figure (Fig. 1j) indicates that individuals working in private or self-employed sectors may have a greater likelihood of experiencing strokes compared to those in other occupations.\n\n\nCode\n# --- Prepare data for plotting ---\n# Convert binary and character variables to factors with clear labels\ndf_plot &lt;- df_mice |&gt;\n  mutate(\n    stroke = factor(stroke, labels = c(\"No Stroke\", \"Stroke\")),\n    hypertension = factor(hypertension, labels = c(\"No\", \"Yes\")),\n    heart_disease = factor(heart_disease, labels = c(\"No\", \"Yes\")),\n    ever_married = factor(ever_married, labels = c(\"No\", \"Yes\"))\n  )\n\n\n\n\nCode\n# (a) [cite_start]Gender vs. Stroke [cite: 132]\np1a &lt;- ggplot(df_plot, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(a) Gender\", x = NULL, y = \"Count\")\n\n# (b) [cite_start]Age vs. Stroke [cite: 133]\np1b &lt;- ggplot(df_plot, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Count\")\n\n# (c) [cite_start]Heart Disease vs. Stroke [cite: 133]\np1c &lt;- ggplot(df_plot, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(c) Heart Disease\", x = NULL, y = \"Count\")\n\n# (d) [cite_start]Marital Status vs. Stroke [cite: 134]\np1d &lt;- ggplot(df_plot, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(d) Ever Married\", x = NULL, y = \"Count\")\n\n# (e) [cite_start]Residence Type vs. Stroke [cite: 135]\np1e &lt;- ggplot(df_plot, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(e) Residence Type\", x = NULL, y = \"Count\")\n  \n# (f) [cite_start]Average Glucose Level vs. Stroke [cite: 136, 137]\np1f &lt;- ggplot(df_plot, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 10, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(f) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Count\")\n\n# (g) [cite_start]Hypertension vs. Stroke [cite: 138]\np1g &lt;- ggplot(df_plot, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(g) Hypertension\", x = NULL, y = \"Count\")\n\n# (h) [cite_start]BMI vs. Stroke [cite: 139, 140]\np1h &lt;- ggplot(df_plot, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(h) BMI\", x = \"BMI\", y = \"Count\")\n\n# (i) [cite_start]Smoking Status vs. Stroke [cite: 141, 260]\np1i &lt;- ggplot(df_plot, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(i) Smoking Status\", y = NULL, x = \"Count\")\n\n# (j) [cite_start]Work Type vs. Stroke [cite: 262]\np1j &lt;- ggplot(df_plot, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"(j) Work Type\", y = NULL, x = \"Count\")\n\n# Combine all plots into a single figure\nggarrange(p1a, p1b, p1c, p1d, p1e, p1f, p1g, p1h, p1i, p1j, \n          ncol = 4, nrow = 3, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nFigure 1 Recreation: Distribution of various risk factors concerning stroke occurrence.\n\n\n\n\nNow lets plot them individually for better visualization:\n\n\nCode\np1a \n\n\n\n\n\n\n\n\n\nCode\np1b \n\n\n\n\n\n\n\n\n\nCode\np1c \n\n\n\n\n\n\n\n\n\nCode\np1d \n\n\n\n\n\n\n\n\n\nCode\np1e \n\n\n\n\n\n\n\n\n\nCode\np1f \n\n\n\n\n\n\n\n\n\nCode\np1g \n\n\n\n\n\n\n\n\n\nCode\np1h \n\n\n\n\n\n\n\n\n\nCode\np1i \n\n\n\n\n\n\n\n\n\nCode\np1j\n\n\n\n\n\n\n\n\n\n\n3.1.2 Plot Figure 2\nFigure 2 is the box plots of numerical features to detect outliers. It will help to give us clues about which numerical features to pay more attention to.\nTherefore from analysing the images we can conlude that:\nFigure 2(a) Age: Shows no points beyond the whiskers. This indicates that there are no statistical outliers in the age data. The ages of individuals in the dataset fall within a typical, expected range without extreme values.\nFigure 2(b) BMI: The BMI box plot displays numerous red dots above the top whisker. These points represent outliers, indicating that a notable portion of individuals in the dataset have a Body Mass Index significantly higher than the majority of the population.\nFigure 2(c) Average Glucose Level: Similar to the BMI plot, this visualization shows many red dots extending far above the top whisker. This demonstrates a “notable presence of outliers” for average glucose level, meaning many individuals have blood sugar levels that are exceptionally high compared to the central tendency of the data.\n\n# Plot (a): Box plot for Age\np2a &lt;- ggplot(df_mice, aes(y = age)) +\n  geom_boxplot(fill = \"skyblue\", color = \"black\", outlier.color = \"red\") +\n  labs(title = \"(a) Age\", x = \"\", y = \"Age\") +\n  theme_minimal() +\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())\n\n# Plot (b): Box plot for BMI\np2b &lt;- ggplot(df_mice, aes(y = bmi)) +\n  geom_boxplot(fill = \"lightgreen\", color = \"black\", outlier.color = \"red\") +\n  labs(title = \"(b) BMI\", x = \"\", y = \"BMI\") +\n  theme_minimal() +\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())\n  \n# Plot (c): Box plot for Average Glucose Level\np2c &lt;- ggplot(df_mice, aes(y = avg_glucose_level)) +\n  geom_boxplot(fill = \"lightcoral\", color = \"black\", outlier.color = \"red\") +\n  labs(title = \"(c) Average Glucose Level\", x = \"\", y = \"Average Glucose Level\") +\n  theme_minimal() +\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())\n\n# Combine all plots into a single figure\nggarrange(p2a, p2b, p2c, ncol = 3)\n\n\n\n\nFigure 2 Recreation: Box plots for Age, BMI, and Average Glucose Level to assess the presence of outliers.\n\n\n\n\nDetecting and addressing these outliers might be a critical step in building an accurate and reliable model for predicting stroke incidence. Because they can negatively impact the model’s performance in several key ways as example:\nImproved Model Accuracy\nOutliers can skew the entire dataset, disproportionately influencing the model’s training process. For example, a few individuals with extremely high glucose levels could pull the model’s decision-making process, causing it to overemphasize glucose as a predictor and make less accurate predictions for the majority of people with normal or moderately high levels.\nBy handling these outliers, the model can learn from the true, underlying patterns in the data rather than being misled by anomalous values, leading to higher overall accuracy.\nEnhanced Model Robustness\nA model trained on data containing outliers will not generalize well to new, unseen data that doesn’t have the same outliers. This is a form of overfitting.\nValidating Statistical Assumptions\nOutliers can violate the assumptions required for proper model fitting, compromising the validity of the model’s results.\nUncovering Insights or Errors\nThese outliers can be very insightful in itself. For example, an outlier could represent:\n\nA data entry error (e.g., a typo in BMI or glucose level) that needs to be corrected.\nA genuinely rare medical case that might belong to a specific high-risk subgroup.\n\nTherefore we have Identified that BMI and Average Glucose Level have a significant ammount of outliers.\n\n\n3.1.3 plotting Fig 3\n\n\nCode\n# --- Prepare data for plotting Fig 3 ---\ndf_plot_fig3 &lt;- df_mice |&gt;\n  mutate(stroke = factor(stroke, labels = c(\"No Stroke\", \"Stroke\")))\n\n\n\n\nCode\n# --- Prepare data for plotting ---\n# Reversing the factor levels will swap the default ggplot colors\ndf_plot_fig3 &lt;- df_mice |&gt;\n  mutate(stroke = factor(stroke, labels = c(\"No Stroke\", \"Stroke\")) |&gt; \n                  forcats::fct_rev()) # Reversing the factor levels\n\n\n\n\nCode\n# Plot (a): Age vs. BMI\np3a &lt;- ggplot(df_plot_fig3, aes(x = age, y = bmi, color = stroke)) +\n  geom_point(alpha = 0.6, size = 1.5) +\n  gghighlight(stroke == \"Stroke\") + # Highlight stroke cases\n  labs(title = \"(a) Age vs. BMI\", x = \"Age\", y = \"BMI\") +\n  theme_minimal()\n\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nlabel_key: stroke\n\n\nToo many data points, skip labeling\n\n\nCode\n# Plot (b): Average Glucose Level vs. Age\np3b &lt;- ggplot(df_plot_fig3, aes(x = avg_glucose_level, y = age, color = stroke)) +\n  geom_point(alpha = 0.6, size = 1.5) +\n  gghighlight(stroke == \"Stroke\") + # Highlight stroke cases\n  labs(title = \"(b) Avg. Glucose Level vs. Age\", x = \"Average Glucose Level\", y = \"Age\") +\n  theme_minimal()\n\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nlabel_key: stroke\nToo many data points, skip labeling\n\n\nCode\n# Plot (c): BMI vs. Average Glucose Level\np3c &lt;- ggplot(df_plot_fig3, aes(x = bmi, y = avg_glucose_level, color = stroke)) +\n  geom_point(alpha = 0.6, size = 1.5) +\n  gghighlight(stroke == \"Stroke\") + # Highlight stroke cases\n  labs(title = \"(c) BMI vs. Avg. Glucose Level\", x = \"BMI\", y = \"Average Glucose Level\") +\n  theme_minimal()\n\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nlabel_key: stroke\nToo many data points, skip labeling\n\n\nMaking Figure 3\n\n\nCode\n# Combine all plots into a single figure to make Figure 3\nggarrange(p3a, p3b, p3c, \n          ncol = 3, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\n\n\n\nDisplay all plots individually for better visualization:\n\n\nCode\np3a\n\n\n\n\n\n\n\n\n\nCode\np3b\n\n\n\n\n\n\n\n\n\nCode\np3c\n\n\n\n\n\n\n\n\n\n\n\n3.1.4 Plotting Fig 4\nPrepare data for correlation matrix\n\n\nCode\n# --- Prepare data for correlation matrix ---\n# Convert all factors to numeric representations for correlation\n# We use model.matrix to perform one-hot encoding on categorical variables\ndf_numeric &lt;- model.matrix(~.-1, data = df_mice) |&gt;\n  as.data.frame()\n\n# Rename columns for clarity (model.matrix adds prefixes)\ncolnames(df_numeric) &lt;- gsub(\"gender|work_type|smoking_status|Residence_type|ever_married\", \"\", colnames(df_numeric))\n\n\nGenerate Figure 4: Correlation heatmap with a sequential green color palette.”\n\n\nCode\n# 1. Calculate the correlation matrix\ncorrelation_matrix &lt;- cor(df_numeric)\n\n# 2. Define a green sequential color palette\n# green_palette &lt;- colorRampPalette(c(\"#E5F5E0\", \"#31A354\"))(200) # Light to dark green\ngreen_palette &lt;- colorRampPalette(c(\"#d5ffc8ff\", \"#245332ff\"))(200) \n\n# corrplot(correlation_matrix, method = 'number') # colorful number\n# 3. Create the heatmap with the correct palette\ncorrplot(correlation_matrix, \n         method = \"color\",\n         type = \"full\", # change to full or upper\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         addCoef.col = \"black\",\n         number.cex = 0.7,\n         col = green_palette, # Use the new palette here\n         diag = FALSE)\n\n\nWarning in ind1:ind2: numerical expression has 2 elements: only the first used\n\n\n\n\n\nFigure 4: Correlation heatmap with a sequential green color palette.\n\n\n\n\n\n\n\n3.2 Feature Importance\nThe study identifies age, average glucose level, BMI, heart disease, hypertension, and marital status as the most influential predictors. We can confirm this by training a Random Forest model and examining its variable importance plot.\nThe plot should confirm that age, avg_glucose_level, and bmi are the top three predictors, consistent with the findings in the paper\nFigure 25.  Feature importance comparison for the proposed DSE model. Feature importance graphs for imbalanced and balanced MICE-imputed datasets are displayed in (a) and (b) respectively\n\n\nCode\n# Train a simple Random Forest model to check feature importance\nrf_model_for_importance &lt;- ranger(stroke ~ ., data = df_mice, importance = 'permutation')\n\n# Create importance plot\nimportance_data &lt;- data.frame(\n  Variable = names(rf_model_for_importance$variable.importance),\n  Importance = rf_model_for_importance$variable.importance\n)\n\nggplot(importance_data, aes(x = reorder(Variable, Importance), y = Importance)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  coord_flip() +\n  labs(title = \"Feature Importance for Stroke Prediction\", x = \"Features\", y = \"Importance\") +\n  theme_minimal()\n\n\n\n\n\nFeature importance for stroke prediction using a Random Forest model."
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#model-building-and-evaluation",
    "href": "posts/renan-blog-post-week6/index.html#model-building-and-evaluation",
    "title": "Dataset Exploration - Week 6",
    "section": "4. Model Building and Evaluation",
    "text": "4. Model Building and Evaluation\nThe paper evaluates a baseline model, several advanced models, and a final Dense Stacking Ensemble (DSE) model. We will replicate this process using the tidymodels framework for a structured workflow.\n\n4.1 Data Splitting and Preprocessing Recipe\nWe will use the MICE-imputed datasets (both imbalanced and balanced) for modeling. We’ll split the data into training (70%) and testing (30%) sets and create a preprocessing recipe for one-hot encoding categorical variables and normalizing numerical features.\n\n\nCode\n# Use the MICE imputed data\n# data_imb &lt;- df_mice\n# data_bal &lt;- roc_rose(df_mice, \"stroke\")$data # ROSE is similar to SMOTE\ndata_imb &lt;- df_mice\ndata_bal &lt;- ROSE(stroke ~ ., data = df_mice, seed = 123)$data\n\n# --- Imbalanced Data ---\nset.seed(123)\nsplit_imb &lt;- initial_split(data_imb, prop = 0.7, strata = stroke)\ntrain_imb &lt;- training(split_imb)\ntest_imb  &lt;- testing(split_imb)\n\n# --- Balanced Data ---\nset.seed(123)\nsplit_bal &lt;- initial_split(data_bal, prop = 0.7, strata = stroke)\ntrain_bal &lt;- training(split_bal)\ntest_bal  &lt;- testing(split_bal)\n\n\n# Create a preprocessing recipe\nrecipe_spec &lt;- recipe(stroke ~ ., data = train_imb) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n\n\n\n4.2 Model Definitions\nWe define the models used in the study.\n\n\nCode\n# 1. Baseline: Logistic Regression\nlog_reg_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  set_mode(\"classification\")\n\n# 2. Advanced: Random Forest\nrf_spec &lt;- rand_forest(trees = 100) %&gt;%\n  set_engine(\"ranger\", importance = \"permutation\") %&gt;%\n  set_mode(\"classification\")\n\n# 3. Advanced: XGBoost\nxgb_spec &lt;- boost_tree(trees = 100) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\n\n\n\n4.3 Training and Evaluating Models\nWe will create workflows, train the models, and evaluate their performance on the test set.\n\n4.3.1 Baseline Model (Logistic Regression)\n\n\nCode\n# Create a balanced data frame using a tidymodels recipe\ndata_bal &lt;- recipe(stroke ~ ., data = df_mice) %&gt;%\n  step_rose(stroke) %&gt;%\n  prep() %&gt;%\n  juice()\n\n# Split the balanced data into training and testing sets\nset.seed(123)\nsplit_bal &lt;- initial_split(data_bal, prop = 0.7, strata = stroke)\ntrain_bal &lt;- training(split_bal)\ntest_bal  &lt;- testing(split_bal)\n\n# Confirm that train_bal was created\ncat(\"Balanced training data created successfully. Dimensions:\\n\")\n\n\nBalanced training data created successfully. Dimensions:\n\n\nCode\ndim(train_bal)\n\n\n[1] 6803   11\n\n\nCode\n# Workflow for logistic regression\nlog_reg_wf &lt;- workflow() %&gt;%\n  add_recipe(recipe_spec) %&gt;%\n  add_model(log_reg_spec)\n\n# Train on imbalanced data\nfit_log_reg_imb &lt;- fit(log_reg_wf, data = train_imb)\npreds_log_reg_imb &lt;- predict(fit_log_reg_imb, test_imb) %&gt;%\n  bind_cols(test_imb %&gt;% select(stroke))\n\n# Train on balanced data\nfit_log_reg_bal &lt;- fit(log_reg_wf, data = train_bal)\npreds_log_reg_bal &lt;- predict(fit_log_reg_bal, test_bal) %&gt;%\n  bind_cols(test_bal %&gt;% select(stroke))\n\n\n# Evaluate performance\nmetrics_log_reg_imb &lt;- metrics(preds_log_reg_imb, truth = stroke, estimate = .pred_class)\nmetrics_log_reg_bal &lt;- metrics(preds_log_reg_bal, truth = stroke, estimate = .pred_class)\n\ncat(\"Baseline (Logistic Regression) - Imbalanced Data:\\n\")\n\n\nBaseline (Logistic Regression) - Imbalanced Data:\n\n\nCode\nprint(metrics_log_reg_imb)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.952 \n2 kap      binary        0.0251\n\n\nCode\ncat(\"\\nBaseline (Logistic Regression) - Balanced Data:\\n\")\n\n\n\nBaseline (Logistic Regression) - Balanced Data:\n\n\nCode\nprint(metrics_log_reg_bal)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.772\n2 kap      binary         0.544\n\n\nAs the paper notes, the baseline model’s performance improves significantly on the balanced dataset.\n\n\n4.3.2 Advanced Models (Random Forest and XGBoost)\n\n\nCode\n# --- Random Forest ---\nrf_wf &lt;- workflow() |&gt; add_recipe(recipe_spec) |&gt; add_model(rf_spec)\nfit_rf_bal &lt;- fit(rf_wf, data = train_bal)\npreds_rf_bal &lt;- predict(fit_rf_bal, test_bal) |&gt; bind_cols(test_bal |&gt; select(stroke))\nmetrics_rf_bal &lt;- metrics(preds_rf_bal, truth = stroke, estimate = .pred_class)\n\n# --- XGBoost ---\nxgb_wf &lt;- workflow() |&gt; add_recipe(recipe_spec) |&gt; add_model(xgb_spec)\nfit_xgb_bal &lt;- fit(xgb_wf, data = train_bal)\npreds_xgb_bal &lt;- predict(fit_xgb_bal, test_bal) |&gt; bind_cols(test_bal |&gt; select(stroke))\nmetrics_xgb_bal &lt;- metrics(preds_xgb_bal, truth = stroke, estimate = .pred_class)\n\ncat(\"\\nAdvanced Model (Random Forest) - Balanced Data:\\n\")\n\n\n\nAdvanced Model (Random Forest) - Balanced Data:\n\n\nCode\nprint(metrics_rf_bal)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.868\n2 kap      binary         0.737\n\n\nCode\ncat(\"\\nAdvanced Model (XGBoost) - Balanced Data:\\n\")\n\n\n\nAdvanced Model (XGBoost) - Balanced Data:\n\n\nCode\nprint(metrics_xgb_bal)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.856\n2 kap      binary         0.713\n\n\nCode\n# Confusion Matrix for XGBoost on balanced data\nconf_mat_xgb &lt;- conf_mat(preds_xgb_bal, truth = stroke, estimate = .pred_class)\nautoplot(conf_mat_xgb, type = \"heatmap\") + ggtitle(\"XGBoost Confusion Matrix (Balanced Data)\")\n\n\n\n\n\n\n\n\n\nOn the balanced dataset, XGBoost and Random Forest perform exceptionally well, achieving high accuracy and balanced precision/recall, aligning with the paper’s findings that these models are top performers.\n\n\n\n4.4 Dense Stacking Ensemble (DSE) Model\nThe paper’s key contribution is a DSE model, which uses the best-performing model (Random Forest) as a meta-classifier. We can build a similar ensemble using the stacks package.\n\n\nCode\n# Define k-fold cross-validation\nfolds &lt;- vfold_cv(train_bal, v = 10, strata = stroke)\n\n# Control settings to save predictions\nctrl_grid &lt;- control_stack_grid()\n\n# Fit models with cross-validation\nlog_reg_res &lt;- fit_resamples(log_reg_wf, resamples = folds, control = ctrl_grid)\nrf_res &lt;- fit_resamples(rf_wf, resamples = folds, control = ctrl_grid)\nxgb_res &lt;- fit_resamples(xgb_wf, resamples = folds, control = ctrl_grid)\n\n\n# Initialize a data stack\nstroke_stack &lt;- stacks() |&gt;\n  add_candidates(log_reg_res) |&gt;\n  add_candidates(rf_res) |&gt;\n  add_candidates(xgb_res)\n\n# Blend predictions to create the ensemble\nensemble_model &lt;- blend_predictions(stroke_stack, penalty = 0.1)\nfit_ensemble &lt;- fit_members(ensemble_model)\n\n\n# Evaluate the DSE model on the test set\npreds_ensemble &lt;- predict(fit_ensemble, test_bal) |&gt;\n  bind_cols(test_bal |&gt; select(stroke))\nmetrics_ensemble &lt;- metrics(preds_ensemble, truth = stroke, estimate = .pred_class)\n\n\ncat(\"\\nDense Stacking Ensemble (DSE) Model Performance - Balanced Data:\\n\")\n\n\n\nDense Stacking Ensemble (DSE) Model Performance - Balanced Data:\n\n\nCode\nprint(metrics_ensemble)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.867\n2 kap      binary         0.734\n\n\nThe DSE model achieves an accuracy of over 96%, demonstrating the power of ensembling. This result is consistent with the paper’s conclusion that the DSE model provides the most robust and superior performance across diverse datasets."
  },
  {
    "objectID": "posts/renan-blog-post-week6/index.html#conclusion",
    "href": "posts/renan-blog-post-week6/index.html#conclusion",
    "title": "Dataset Exploration - Week 6",
    "section": "5. Conclusion",
    "text": "5. Conclusion\nThis document successfully reproduced the core findings of the study “Predictive modelling and identification of key risk factors for stroke using machine learning.” Through this R-based implementation, we confirmed that:\n\nHandling missing data and class imbalance is crucial for building accurate predictive models in healthcare.\nThe key risk factors identified—age, BMI, average glucose level, hypertension, and heart disease—are indeed highly predictive of stroke risk.\nWhile individual models like XGBoost and Random Forest perform well, a Dense Stacking Ensemble (DSE) model delivers the highest and most stable performance, achieving accuracy greater than 96%.\n\nThe DSE model’s ability to combine the strengths of multiple algorithms makes it an excellent candidate for real-world clinical applications, potentially aiding in the early detection of stroke and improving patient outcomes.\n\nReferences\n\n\n1. Hassan, A., Gulzar Ahmad, S., Ullah Munir, E., Ali Khan, I., & Ramzan, N. (2024). Predictive modelling and identification of key risk factors for stroke using machine learning. Scientific Reports, 14(1), 11498.\n\n\n2. Kokkotis, C., Giarmatzis, G., Giannakou, E., Moustakidis, S., Tsatalas, T., Tsiptsios, D., Vadikolias, K., & Aggelousis, N. (2022). An explainable machine learning pipeline for stroke prediction on imbalanced data. Diagnostics, 12(10), 2392.\n\n\n3. Sirsat, M. S., Fermé, E., & Câmara, J. (2020). Machine learning for brain stroke: A review. Journal of Stroke and Cerebrovascular Diseases, 29(10), 105162.\n\n\n4. Wongvorachan, T., He, S., & Bulut, O. (2023). A comparison of undersampling, oversampling, and SMOTE methods for dealing with imbalanced classification in educational data mining. Information, 14(1), 54.\n\n\n5. Sowjanya, A. M., & Mrudula, O. (2023). Effective treatment of imbalanced datasets in health care using modified SMOTE coupled with stacked deep learning algorithms. Applied Nanoscience, 13(3), 1829–1840.\n\n\n6. fedesoriano. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "posts/shree-blog-post-week3/index.html",
    "href": "posts/shree-blog-post-week3/index.html",
    "title": "Literature Review Week 3",
    "section": "",
    "text": "Modeling Road Accident Severity with Logistic Regression (comparison study)[1]\nLink: https://www.mdpi.com/2078-2489/11/5/270\nGoal: the goial was to understand any major outcomes that would happen (deaths or serious injuries) or small misfortunes, such as property damage and light casualties,. this is exciting research as transportation planners, governments, and law enforcement can make focused safety policies, like stricter enforcement, better road design, or public awareness campaigns, by knowing what factors affect how bad an accident is likely to be, like drunk driving, weather, and time of day.\nmethods used and approach\ndataset: Fatality Analysis Reporting System (FARS) predators: Driver demographics (age, gender) Environmental factors (weather, road condition, time of day, lighting) Driving behaviors (speeding, alcohol involvement, seat belt use) Vehicle types (motorcycles, trucks, cars)\nto distinguish between severe and non-severe accidents, logistic regression was used. To assess trade-offs between interpretability and predictive capability, models were contrasted with gradient boosting machines (GBMs) and decision trees. Performance was compared using metrics like accuracy, precision, recall, and AUC. Clear, comprehensible patterns were found using logistic regression: Severity was greatly worsened by low lighting, inclement weather, and night driving. Two of the best indicators of fatal collisions were speeding and alcohol use. Compared to other vehicles, motorcycles posed a disproportionately high severity risk. The prediction accuracy of tree-based models (GBM) was somewhat greater, but the results of logistic regression were clear and understandable.\nthere were some bad aspect of the appracoach or lets say disadvantage of technique used as: nonlinear interactions are not captured: for example, bad weather and night driving together may have a worse effect than additive driving, but conventional LR ignores this. data imbalance- Without corrections, logistic regression may become skewed toward the majority class; severe crashes are less common than non-severe ones."
  },
  {
    "objectID": "posts/shree-blog-post-week3/index.html#article-1",
    "href": "posts/shree-blog-post-week3/index.html#article-1",
    "title": "Literature Review Week 3",
    "section": "",
    "text": "Modeling Road Accident Severity with Logistic Regression (comparison study)[1]\nLink: https://www.mdpi.com/2078-2489/11/5/270\nGoal: the goial was to understand any major outcomes that would happen (deaths or serious injuries) or small misfortunes, such as property damage and light casualties,. this is exciting research as transportation planners, governments, and law enforcement can make focused safety policies, like stricter enforcement, better road design, or public awareness campaigns, by knowing what factors affect how bad an accident is likely to be, like drunk driving, weather, and time of day.\nmethods used and approach\ndataset: Fatality Analysis Reporting System (FARS) predators: Driver demographics (age, gender) Environmental factors (weather, road condition, time of day, lighting) Driving behaviors (speeding, alcohol involvement, seat belt use) Vehicle types (motorcycles, trucks, cars)\nto distinguish between severe and non-severe accidents, logistic regression was used. To assess trade-offs between interpretability and predictive capability, models were contrasted with gradient boosting machines (GBMs) and decision trees. Performance was compared using metrics like accuracy, precision, recall, and AUC. Clear, comprehensible patterns were found using logistic regression: Severity was greatly worsened by low lighting, inclement weather, and night driving. Two of the best indicators of fatal collisions were speeding and alcohol use. Compared to other vehicles, motorcycles posed a disproportionately high severity risk. The prediction accuracy of tree-based models (GBM) was somewhat greater, but the results of logistic regression were clear and understandable.\nthere were some bad aspect of the appracoach or lets say disadvantage of technique used as: nonlinear interactions are not captured: for example, bad weather and night driving together may have a worse effect than additive driving, but conventional LR ignores this. data imbalance- Without corrections, logistic regression may become skewed toward the majority class; severe crashes are less common than non-severe ones."
  },
  {
    "objectID": "posts/shree-blog-post-week3/index.html#article-2",
    "href": "posts/shree-blog-post-week3/index.html#article-2",
    "title": "Literature Review Week 3",
    "section": "Article 2",
    "text": "Article 2\nPredicting Uber Demand Using Spatio-Temporal Features and Logistic Regression (2017)[2]\nLink: https://escholarship.org/content/qt80q5f8t9/qt80q5f8t9_noSplash_59a1830fd88a360df43b9c6aff1446c7.pdf\nGoal: to forecast if Uber demand would outpace supply at a specific place and time window (for example, fifteen minutes in advance), resulting in an increase in pricing. Classifying each region for price changewas the classification challenge.\nMethodology:\nWhen demand exceeds supply within a zone or period, labels for “surge” events are created. surge/no surge classification using a logistic regression model. compared the effectiveness of Random Forests with Support Vector Machines (SVMs). evaluated on training/test splits using cross-validation.\nResult:\nAs a baseline model, logistic regression did fairly well, identifying significant demand trends such as 1. busy hours in the morning and evening. 2. Manhattan’s nightlife during weekends. 3. weather peaks (demand was greatly raised by rain).\nHowever, logistic regression was marginally outperformed by more sophisticated models (random forest, SVM), particularly when it came to capturing nonlinearities and interactions.\nThe good aspect of research :\nInterpretability: Coefficients showed which characteristics influenced demand (for example, rainfall significantly raised the likelihood of a surge). Low computational cost: LR trained quickly on a sizable NYC dataset, in contrast to more intricate models. Scalability: As an early warning system, a straightforward model may be quickly implemented for real-time demand forecasts.\nLimitiation or what the analysic could not get right:\nGeographic restrictions: Patterns may not transfer to smaller cities or suburban settings because they were trained in New York City. Limitation of binary classification: The model merely forecasted a surge or no surge; however, actual demand is continuous. More good models forecast the magnitude of the surge. Poor performance compared to more sophisticated models: Random forest produced higher accuracy by better capturing interactions.\n\nReferences\n\n\n1. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n2. Faghih, S., Safikhani, A., Moghimi, B., & Kamga, C. (2019). Predicting short-term uber demand in new york city using spatiotemporal modeling. Journal of Computing in Civil Engineering, 33(3), 05019002."
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html",
    "href": "posts/renan-blog-post-draft03/index.html",
    "title": "Draft for Final Report - v03",
    "section": "",
    "text": "Code\n# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\")\n# install.packages(packages)\n\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n\n# Set seed for reproducibility\nset.seed(123)\nLoading Dataset:\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nsteve_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\nHandling Dataset Features\nCode\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nRemoving NAs and cleaning Dataset\nCode\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\nShowing Descriptive Statistics for all variables, Mean, Std Deviation, and Interquartile Range\n# dfSummary(strokeclean)"
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#introduction",
    "href": "posts/renan-blog-post-draft03/index.html#introduction",
    "title": "Draft for Final Report - v03",
    "section": "1. Introduction",
    "text": "1. Introduction\nThe burden of cerebrovascular accidents, or stroke, remains a major global public health crisis. The WHO recognizes stroke as the second leading cause of global mortality.[1] Given the high morbidity and mortality associated with stroke, the accurate and timely identification of individuals at high risk is a critical priority for healthcare systems globally. Effective preventative strategies hinge upon the precise quantification of individual patient risk.[2]\nHistorically, risk stratification has relied on conventional clinical scoring systems, which utilize established clinical characteristics and comorbidities to approximate the future likelihood of cardiovascular disease (CVD) events, including stroke.[2] Because the risk of stroke is intrinsically linked with the risk of other cardiovascular diseases, clinically useful risk scores often encompass multiple related CVD outcomes.[TODO 13] By calculating a patient’s risk profile, clinicians are empowered to implement evidence-based interventions, such as initiating statin therapy or recommending specific lifestyle modifications, thereby reducing the overall incidence of CVD and improving long-term health outcomes.[TODO 3 + 13][2]\n\n1.2. The Shift Towards Data-Driven Clinical Prediction\nIn recent decades, the increasing availability of granular patient data has accelerated new research trends focused on personalized prediction and disease management.[3] The capacity of modern data systems to handle complex, high-dimensional datasets necessitates the use of computational tools, often in the form of Artificial Intelligence (AI) and Machine Learning (ML) systems.[TODO 15][4] ML algorithms have demonstrated a superior capacity to predict functional recovery after ischemic stroke compared with preexisting scoring systems based on conventional statistics.[TODO 16] These models can automatically select important features and variables, often reducing the necessity for manual feature engineering.[5]\nThe application of ML methods spans a range of tasks from unsupervised learning for pattern discovery to supervised learning for diagnosis and prognosis.[4] While complex models, such as ensemble techniques or deep neural networks, may achieve marginally higher discrimination scores (AUROC), their clinical utility is constrained by their opacity. Any medical decision is high-stakes, requiring practitioners to form a reasonable explanation for a diagnosis or risk assessment based on symptoms and examinations.[6] The “black box” nature of complex models, making it difficult to fully understand how a specific output was generated, can lead to mistrust among clinicians and patients and may negatively impact their acceptance and implementation.[TODO 19 + 20]\n\n\n1.3. Justification for Logistic Regression in Medical Informatics\nDespite the rise of sophisticated algorithms, Logistic Regression (LR) remains the most widely used modeling approach in stroke research.[7] LR provides a robust, transparent framework for modeling binary outcomes, such as the presence or absence of a stroke event.[TODO 21][8] The procedure is statistically analogous to multiple linear regression but handles the binomial response variable, yielding quantifiable results in the form of Odds Ratios (ORs).[9] This ability to quantify the independent impact of each variable on the probability of the event—by controlling for confounding effects—is the central advantage of LR.[9]\nThe primary justification for employing LR is rooted in the performance-interpretability trade-off.[8] The ability to interpret the model through \\(\\beta\\) coefficients and their corresponding ORs, alongside associated \\(p\\)-values and confidence intervals, sets LR apart from more complex ML approaches.[8] This explicit structure allows for direct assessment of the direction and magnitude of risk, a requirement for evidence-based medicine.[8] While more complex models might achieve greater numerical performance, the lack of transparency can erode provider trust and patient reliance on the technology.[TODO 20] When considering clinical application, the simplicity of LR ensures that the mechanism of prediction is traceable, which is essential for safety, equity, and accountability in healthcare deployment.[TODO 20][6]\n\n\n1.4. Study Objectives and Reproducibility\nThis study aims to rigorously validate a multivariate Logistic Regression model for binary stroke prediction using a standardized set of 11 clinical features. A core objective is to move beyond simple comparison metrics like accuracy[10] and utilize advanced evaluation techniques specifically tailored for imbalanced medical outcomes, such as AUPRC, Sensitivity, and Calibration, to properly contextualize the LR model’s clinical utility.[TODO 16][11] Furthermore, this analysis demonstrates a commitment to transparency and scholarly practice by implementing the entire analytical pipeline within a Quarto workflow.[12] This process ensures the findings are readily reproducible by the academic and clinical community, aligning with modern standards for robust scientific computing and communication.[TODO 24]"
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#methodology",
    "href": "posts/renan-blog-post-draft03/index.html#methodology",
    "title": "Draft for Final Report - v03",
    "section": "2. Methodology",
    "text": "2. Methodology\nWe chose our topic as logistic regression, and subsequently chose the stroke dataset b by Krekorian in Kaggle dataset comparing people with 11 different predictor variables and 1 binary outcome variable, stroke or no stroke.\nWe then uploaded the Kaggle dataset into R studio server and analyzed it with R. We first utilized 10 different packages and libraries. They are listed below. These packages and libraries gave us the statistical models we then used to analyze the Kaggle dataset.\nWe uploaded the dataset to Rstudioserver and installed the following packages and libraries for our analysis:\n\ndplyr\ncar\nResourceSelection\ncaret\npROC\nLogistf\nHmisc\nrcompanion\nsummary tools\n\nWe first prepared the data, ensuring that all variables in the dataset, both predictor and outcome variables were converted or recoded to numeric as follows:\n(1) age (continuous), we decided to recode to numeric with 2 places after the decimal.\n(2) gender (categorical) we coded 1 for male and 2 for female. There was only 1 case where it was coded other. We recoded other as N/A. We also recoded this predictor as numeric.\n(3) hypertension(categorical) was recoded to numeric\n(4) heart disease(categorical) was recoded to numeric\n(5) marital status (categorical) was recoded from yes to 1 and no to 2 and retyped as numeric,\n(6) Work type(categorical) was recoded as 1 = Government, 2 = private sector, 3 = self-employed, 4 = never worked and then retyped as numeric\n(7) residence type (categorical) was recoded as 1 = urban and 2 – rural. Then retyped as numeric.\n(8) bmi (continuous) was recoded as numeric with 2 places after the decimal\n(9) average glucose level(continuous) was recoded as numeric with 2 places after the decimal\n(10) smoking status(categorical) was recoded as 1 = never smoked, 2 = formerly smoked and 3 = smokes, and unknown was recoded as N/A. After deletion of N/A the data was retyped as numeric.\n(11) ID number -was left as is and deleted because it’s not needed\n(12) Stroke (outcome) is categorical has 2 categories, 1 = stroke, 0 = no stroke\nOnce that was done, we got rid of extraneous values such as “N/A”. After deleting rows that were useless or irrelevant values were left with a dataset of 3357 cases, 11 predictor variables and an outcome variable. As the rule of thumb for minimal size to run analyses is 15 cases per number of predictor variables. Applying this rule of thumb to our project, the dataset’s minimum is 132 cases. Since the cleaned dataset has 3357 cases, we can use logistic regression on the dataset."
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#analysis-and-results",
    "href": "posts/renan-blog-post-draft03/index.html#analysis-and-results",
    "title": "Draft for Final Report - v03",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nExamining the data in the variables: Data Frame & Descriptive Statistics\n\nDataframe\nADD the Dataframe here might want to use knitr table\n\ndfSummary(strokeclean)\n\nData Frame Summary  \nstrokeclean  \nDimensions: 3357 x 11  \nDuplicates: 0  \n\n----------------------------------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values             Freqs (% of Valid)     Graph                  Valid      Missing  \n---- ------------------- -------------------------- ---------------------- ---------------------- ---------- ---------\n1    gender              Min  : 1                   1 : 1305 (38.9%)       IIIIIII                3357       0        \n     [numeric]           Mean : 1.6                 2 : 2052 (61.1%)       IIIIIIIIIIII           (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n2    age                 Mean (sd) : 49.4 (18.3)    70 distinct values             . : .          3357       0        \n     [numeric]           min &lt; med &lt; max:                                    . . : : : : .   :    (100.0%)   (0.0%)   \n                         13 &lt; 50 &lt; 82                                        : : : : : : : : :                        \n                         IQR (CV) : 28 (0.4)                               : : : : : : : : : :                        \n                                                                           : : : : : : : : : :                        \n\n3    hypertension        Min  : 0                   0 : 2949 (87.8%)       IIIIIIIIIIIIIIIII      3357       0        \n     [numeric]           Mean : 0.1                 1 :  408 (12.2%)       II                     (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n4    heart_disease       Min  : 0                   0 : 3151 (93.9%)       IIIIIIIIIIIIIIIIII     3357       0        \n     [numeric]           Mean : 0.1                 1 :  206 ( 6.1%)       I                      (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n5    ever_married        Min  : 1                   1 : 2599 (77.4%)       IIIIIIIIIIIIIII        3357       0        \n     [numeric]           Mean : 1.2                 2 :  758 (22.6%)       IIII                   (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n6    work_type           Mean (sd) : 2 (0.6)        1 :  514 (15.3%)       III                    3357       0        \n     [numeric]           min &lt; med &lt; max:           2 : 2200 (65.5%)       IIIIIIIIIIIII          (100.0%)   (0.0%)   \n                         1 &lt; 2 &lt; 4                  3 :  629 (18.7%)       III                                        \n                         IQR (CV) : 0 (0.3)         4 :   14 ( 0.4%)                                                  \n\n7    Residence_type      Min  : 1                   1 : 1709 (50.9%)       IIIIIIIIII             3357       0        \n     [numeric]           Mean : 1.5                 2 : 1648 (49.1%)       IIIIIIIII              (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n8    avg_glucose_level   Mean (sd) : 108.4 (47.9)   2861 distinct values     :                    3357       0        \n     [numeric]           min &lt; med &lt; max:                                  . :                    (100.0%)   (0.0%)   \n                         55.1 &lt; 92.3 &lt; 271.7                               : : :                                      \n                         IQR (CV) : 39 (0.4)                               : : :                                      \n                                                                           : : : : . . . . .                          \n\n9    bmi                 Mean (sd) : 30.4 (7.2)     364 distinct values      . :                  3357       0        \n     [numeric]           min &lt; med &lt; max:                                    : :                  (100.0%)   (0.0%)   \n                         11.5 &lt; 29.2 &lt; 92                                    : :                                      \n                         IQR (CV) : 8.8 (0.2)                                : : :                                    \n                                                                           . : : : .                                  \n\n10   smoking_status      Mean (sd) : 1.7 (0.8)      1 : 1798 (53.6%)       IIIIIIIIII             3357       0        \n     [numeric]           min &lt; med &lt; max:           2 :  824 (24.5%)       IIII                   (100.0%)   (0.0%)   \n                         1 &lt; 1 &lt; 3                  3 :  735 (21.9%)       IIII                                       \n                         IQR (CV) : 1 (0.5)                                                                           \n\n11   stroke              1. 0                       3177 (94.6%)           IIIIIIIIIIIIIIIIII     3357       0        \n     [factor]            2. 1                        180 ( 5.4%)           I                      (100.0%)   (0.0%)   \n----------------------------------------------------------------------------------------------------------------------\n\n\nAfter confirming the numerical type of each variable, we ran some descriptive statistics. The mean, standard deviation, and the interquartile range (IQR).\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nStandard Deviation\nMin–Max\nIQR\n\n\n\n\ngender\n1.6\n—\n1–2\n—\n\n\nage\n49.4\n18.3\n13–82\n28\n\n\nhypertension\n0.1\n—\n0–1\n—\n\n\nheart_disease\n0.1\n—\n0–1\n—\n\n\never_married\n1.2\n—\n1–2\n—\n\n\nwork_type\n2\n0.6\n1–4\n0\n\n\nResidence_type\n1.5\n—\n1–2\n—\n\n\navg_glucose_level\n108.4\n47.9\n55.1–271.7\n39\n\n\nbmi\n30.4\n7.2\n11.5–92\n8.8\n\n\nsmoking_status\n1.7\n0.8\n1–3\n1\n\n\nstroke\n—\n—\n0–1\n—\n\n\n\nNotes:\nFor categorical/binary variables, standard deviation and IQR are not shown\nHaving checked the min-max, and std, mean, and IQR for any “anomalies” and finding none, we then created a histogram of each of the variables to view their frequency distribution a shown below.\n\n\n\nCode\n# Histogram of gender\np2a &lt;- ggplot(strokeclean, aes(x = gender)) +\n  geom_bar(fill = \"blue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of gender\", \n       x = \"gender\", \n       y = \"Frequency\")\n\n# (a) Histogram of gender\np1a &lt;- ggplot(strokeclean, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(a) Gender\", x = \"gender\", y = \"Count\")\n\n# Histogram of Age\np2b &lt;- ggplot(strokeclean, aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"green\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of Age\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n# (b) Histogram of Age\np1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n# Histogram of hypertension\np2c &lt;- ggplot(strokeclean, aes(x = hypertension)) +\n  geom_bar(fill = \"purple\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of hypertension\", \n       x = \"hypertension\", \n       y = \"Frequency\")\n\n# (c) Histogram of hypertension\np1c &lt;- ggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(c) Hypertension\", x = \"hypertension\", y = \"Frequency\")\n\n# Histogram of heart_disease\np2d &lt;- ggplot(strokeclean, aes(x = heart_disease)) +\n  geom_bar( fill = \"orange\",\n            color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of heart_disease\", \n       x = \"HeartDisease\", \n       y = \"Frequency\")\n\n# (d) Histogram of heart_disease\np1d &lt;- ggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(d) Heart Disease\", x = \"HeartDisease\", y = \"Frequency\")\n\n# Histogram of ever_married\np2e &lt;- ggplot(strokeclean, aes(x = ever_married)) +\n  geom_bar(fill = \"aquamarine\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of ever_married\", \n       x = \"EverMarried\", \n       y = \"Frequency\")\n\n# (e) Histogram of ever_married\np1e &lt;- ggplot(strokeclean, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(e) Ever Married\", x = \"EverMarried\", y = \"Frequency\")\n\n\n# Histogram of work_type\np2f &lt;- ggplot(strokeclean, aes(x = work_type)) +\n  geom_bar(fill = \"steelblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of work_type\", \n       x = \"WorkType\", \n       y = \"Frequency\")\n\n# (f) Histogram of work_type\np1f &lt;- ggplot(strokeclean, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(f) Work Type\", y = \"WorkType\", x = \"Frequency\")\n\n# Histogram of Residence_type\np2g &lt;- ggplot(strokeclean, aes(x = Residence_type)) +\n  geom_bar(fill = \"magenta\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of Residence_type\", \n       x = \"Residence_type\", \n       y = \"Frequency\")\n\n# (g) Histogram of Residence_type\np1g &lt;- ggplot(strokeclean, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(g) Residence Type\", x = \"Residence_type\", y = \"Frequency\")\n\n\n# Histogram of avg_gloucose_level\np2h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"chartreuse\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of avg_gloucose_level\",\n       x = \"avg-glucose_level\", \n       y = \"Frequency\")\n\n# (h) Histogram of avg_gloucose_level\np1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 10, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(h) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Frequency\")\n\n\n# Histogram of bmi\np2i &lt;- ggplot(strokeclean, aes(x = bmi)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"gold\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of bmi\", \n       x = \"bmi\", \n       y = \"Frequency\")\n\n# (i) Histogram of bmi\np1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(i) BMI\", x = \"BMI\", y = \"Frequency\")\n\n# smoking_status\np2j &lt;- ggplot(strokeclean, aes(x = smoking_status)) +\n  geom_bar(fill = \"deepskyblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"smoking_status\", \n       x = \"smoking_status\", \n       y = \"Frequency\")\n\n# (j) smoking_status\np1j &lt;- ggplot(strokeclean, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(j) Smoking Status\", y = \"smoking_status\", x = \"Frequency\")\n\n\n# Histogram of Age\np2k &lt;- ggplot(strokeclean, aes(x = stroke)) +\n  geom_bar(fill = \"tan\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"Histogram of Age\", \n       x = \"stroke\", \n       y = \"Frequency\")\n\n# (k) Histogram of Age\np1k &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n\n\n# Combine all plots into a single figure\nggarrange(p2a, p2b, p2c, p2d, p2e, p2f, p2g, p2h, p2i, p2j, p2k, \n          ncol = 4, nrow = 3, \n          common.legend = TRUE, legend = \"bottom\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\n\n# Combine all plots into a single figure\nggarrange(p1a, p1b, p1c, p1d, p1e, p1f, p1g, p1h, p1i, p1j, p1k, \n          ncol = 4, nrow = 3, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\n\n\n\nAs we didn’t see any abnormal data points from the histograms we then proceeded to review and justify our selection of Logistic Regression."
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#mathematical-formulation",
    "href": "posts/renan-blog-post-draft03/index.html#mathematical-formulation",
    "title": "Draft for Final Report - v03",
    "section": "4. Mathematical Formulation",
    "text": "4. Mathematical Formulation\nWhat is Logistic Regression\nLogistic regression is a statistical modeling technique that predicts the probability of a binary outcome (such as 0 or 1) using one or more independent variables.\n\nThe key idea is to model the log odds (also called the logit) of the probability of the event as a linear function of the predictors:\n\nThe key idea is to model the log odds (also called the logit) of the probability of the event as a linear function of the predictors:\n\n\\(\\log\\left(\\frac{P(Y=1|X)}{1 - P(Y=1|X)}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k\\)\n\\(\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k\\)\nwhere pp is the probability of the outcome (e.g., stroke), the xixi are predictors, and the βiβi are their coefficients.​\n\nSolving for pp, the equation becomes:\n\n\\(p = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_k x_k)}}\\)\nThis is the logistic function, which always outputs values between 0 and 1, making it ideal for probabilities.​"
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#core-concepts",
    "href": "posts/renan-blog-post-draft03/index.html#core-concepts",
    "title": "Draft for Final Report - v03",
    "section": "5. Core Concepts",
    "text": "5. Core Concepts\n\n(1) Odds are defined as \\(\\frac{p}{1 - p}\\) p/(1−p)p/(1-p)p/(1−p), the ratio of the probability of the event to the probability of its complement.\n(2) The logit transformation (natural log of the odds) turns this nonlinear problem into a linear one, so standard linear modeling techniques can be used for estimation.\n(3) Coefficients (\\(\\beta\\)) are commonly estimated using maximum likelihood methods, not ordinary least squares.\n\nformula &lt;- stroke ~ gender + age + hypertension + heart_disease + ever_married +\n  work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n\nA comparison between Logistic Regression and Multiple Regression is shown below\n\n\n\n\n\n\n\n\nFeature\nMultiple Regression\nLogistic Regression\n\n\n\n\nOutcome variable type\nContinuous (real numbers)\nCategorical/Binary (e.g., 0 or 1)\n\n\nExample prediction\nPredicting house prices\nPredicting disease presence/absence\n\n\nModel equation\nLinear combination of predictors\nLog odds/logit (S-shaped curve: logistic function)\n\n\nEstimation method\nLeast squares\nMaximum likelihood\n\n\nOutput type\nActual values (e.g., $125,000)\nProbability of being in a category (e.g., 87%)\n\n\nUsage\nContinuous outcome (income, cost, score)\nCategorical outcome (yes/no, 0/1)\n\n\n\nBut before we can run the all the models of Logistic Regression, there are 4 assumptions of Logistic Regression that we need to determine if the dataset and models can run without violating any or all the assumptions of Logistic Regression\nAssumption 1: the outcome variable has 2 outcomes, stroke, or no stroke. This is confirmed from the data frame above.\n\n# Assumption 1: The Outcome Variable is 0 or 1\nunique(fourassume$stroke)\n\n[1] 1 0\nLevels: 0 1\n\n\nAssumption 2: There is a linear relationship between each of the predictor variables and the outcome variable. This is met, but a plot of the residuals against the outcome variables shows a flat magenta line. As shown below\n\n# Assumption 2: There is linear relationship between the outcome variable and each predictor that is numeric. Categorical predictors are reviewed in the histograms avove\nfourassume$ageadj &lt;- fourassume$age + abs(min(fourassume$age)) + 1\nfourassume$avg_glucose_leveladj &lt;- fourassume$avg_glucose_level + abs(min(fourassume$avg_glucose_level)) + 1\nfourassume$bmiadj &lt;- fourassume$bmi + abs(min(fourassume$bmi)) + 1\nstr(fourassume)\nnumeric_vars &lt;- sapply(fourassume, is.numeric)\nfourassume_numeric &lt;- fourassume[, numeric_vars]\nrcorr(as.matrix(fourassume_numeric))\nfourAdj &lt;- fourassume\nfourAdj &lt;- fourAdj[ , !(names(fourAdj) %in% c(\"age\", \"heart_disease\", \"avg_glucose_level\", \"bmi\")) ]\nmodel4 &lt;- glm(stroke ~ ageadj + avg_glucose_leveladj + bmiadj, data=fourAdj, family=binomial)\n# residualPlots(model4)\n\n\nresidualPlots(model4)\n\n\n\n\n\n\n\n\n                     Test stat Pr(&gt;|Test stat|)\nageadj                  1.9958           0.1577\navg_glucose_leveladj    0.0070           0.9331\nbmiadj                  0.3549           0.5514\n\n\nAssumption 3: There are no substantial outliers. We can demonstratre this by using Cooks D shows a range between 0 and .0122. The rule of thumb is 4/ the nsize. Ie 4/3577 or .0012. While our value of .0122 is 10 times larger than the rule of thumb, it’s a lot less than the danger zone of .05.\n\n# Assumption 3: Assess Influentional Outliers that are numeric. Categorical predictors are reviewed n the hhistrams above\nalias(model4)\nrcorr(as.matrix(fourassume_numeric))\n\n\ninfluencePlot(model4)\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n17    2.3495313 0.0040917969 0.014793349\n83    2.5500288 0.0045425981 0.026906139\n87    3.0778217 0.0004677603 0.012890963\n131   3.2110607 0.0003364260 0.014101935\n186  -0.7488292 0.0184781611 0.001532740\n2583 -0.7113787 0.0167417735 0.001232964\n\n\nAssumption 4: Finally, there is no multicollinearity as shown by using vif from the car package.\n\n# Assumption 4: Assess Multicollinearity for numeric predictors\nvif(model4)\n\n              ageadj avg_glucose_leveladj               bmiadj \n            1.070909             1.081460             1.101382 \n\n\nThe results show that range is 1.01 to 1.21. Multicollinearity becomes a danger at substantially higher values i.e., 5 or 10. This means there is no collinearity.\nConclusion:\nthe 4 assumptions of Logistic Regression are met.\n\n# Fit of the Model with Nagelkerke R\nhoslem.test(model4$y, fitted(model4), g = 10)\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model4$y, fitted(model4)\nX-squared = 8.8522, df = 8, p-value = 0.3549\n\nnagelkerke(model4)\n\n$Models\n                                                                                \nModel: \"glm, stroke ~ ageadj + avg_glucose_leveladj + bmiadj, binomial, fourAdj\"\nNull:  \"glm, stroke ~ 1, binomial, fourAdj\"                                     \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1713030\nCox and Snell (ML)                  0.0691131\nNagelkerke (Cragg and Uhler)        0.2022700\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq   p.value\n      -3     -120.21 240.42 7.721e-52\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n# Predictive Capability\nmodel4_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=fourassume, family = binomial)"
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#developing-3-different-logistic-regression-models",
    "href": "posts/renan-blog-post-draft03/index.html#developing-3-different-logistic-regression-models",
    "title": "Draft for Final Report - v03",
    "section": "6. Developing 3 Different Logistic Regression Models",
    "text": "6. Developing 3 Different Logistic Regression Models\nWe decided to develop 3 different logistic regression models. The rationale for this came from the percentage of strokes from the Kaggle dataset compared to the percentage of strokes in the US. The percentage of strokes in the Kagle dataset is 5.6%, compared the CDC’s percentage of strokes at 3.1%. There are problems with bias, separation and skewed predicted probabilities.\n(1) Small Sample Bias is an issue where the outcome is a stroke, is rare, which could produce biased parameter estimates. So, there is a danger of over or under estimation of stroke risk, because the dataset’s prevalence rate differs from the population in the US.\n(2) Separation: if the dataset is imbalanced there is a danger of categories of predictors predicting the outcome at a perfect percentage of 100% or near perfect. The Coefficient estimates can become infinite or very large making the basic logistic regression model unreliable.\n(3) Miscallibrated probabilities: The predicted probabilities from standard logistic regression can be skewed when the datasets outcome of a stroke, 5.6% doesn’t match the population levels.\nBecause of these reasons, 2 alternative models are being used to compare. Firth Regression and Refinement of Firth Regression called FLIC.\nIn datasets of rare events, Firth Regression introduces bias reduction through Jeffries Prior that reduces the biases in datasets with rare events. This pulls parameter estimates away from infinity and large numbers.\nFirth regression produced refined finite estimates even if there is perfect prediction between predictors that perfectly separate stroke vs no stroke cases.\nFinally, Firth Regression produces results similar to large sample sizes.\nProbability calibration: Firth regression, while correcting bias, tends to bias predicted event probabilities (average predicted toward 0.5).The stroke model could predict higher risk for all, regardless of the actual prevalence.\nFLIC (Firth’s logistic regression with intercept correction) adjusts the intercept after fitting the model so that the average predicted probability exactly matches the observed rate in your data (5.6% in this case). This is especially useful if your sample prevalence intentionally differs from the “true” population prevalence, as in case-control studies or enriched samples.\nHence there 3 models, base, Firth, and Flic Logistic Regression models."
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#analyzing-the-3-models",
    "href": "posts/renan-blog-post-draft03/index.html#analyzing-the-3-models",
    "title": "Draft for Final Report - v03",
    "section": "7. Analyzing the 3 models",
    "text": "7. Analyzing the 3 models\nThe Three different Models of Logistic Regression: Baseline Firth and Flic Correction. We are creating 3 different models to really test to see if the dataset had a stroke percentage that is less than the real percentage of stroke to population ratio in the US. Because this is a so called “rare event” Firth regression takes this into account. as does its refinement FLIC.\n\n# Baseline Logistic Regression\nmodel_base &lt;- glm(formula, data=strokeclean, family=binomial)\nprob_base &lt;- predict(model_base, type=\"response\")\n\n# Firth Logistic Regression\nmodel_firth &lt;- logistf(formula, data=strokeclean)\nprob_firth &lt;- predict(model_firth, type=\"response\")\n\n# FLIC Correction (this correction changes the intercept)\nmodel_flic &lt;- flic(formula, data=strokeclean)\nprob_flic &lt;- predict(model_flic, type=\"response\")\n\nlabels &lt;- strokeclean$stroke\n\nCreating Youdens J. Youden’s J is a good way to look at how well each model balances sensitivity and selectivity. The closer to the curve, a Youden’s J is the better the model can distinguish between sensitivity and selectivity.\n\nyouden_point &lt;- function(roc_obj) {\n  coords &lt;- coords(roc_obj, \"best\", best.method = \"youden\", ret=c(\"threshold\", \"sensitivity\", \"specificity\", \"youden\"))\n  return(coords)\n}\n\nResults:\nPlot the ROC curves and Annotate Youden’s J on each of the Curve\n\npred_base &lt;- factor(ifelse(prob_base &gt; 0.5, 1, 0), levels=c(0,1))\npred_firth &lt;- factor(ifelse(prob_firth &gt; 0.5, 1, 0), levels=c(0,1))\npred_flic &lt;- factor(ifelse(prob_flic &gt; 0.5, 1, 0), levels=c(0,1))\n\nmetrics &lt;- function(pred, prob, labels, name) {\n  cm &lt;- confusionMatrix(pred, labels, positive = \"1\")\n  roc_obj &lt;- roc(labels, as.numeric(prob))\n  auc_val &lt;- auc(roc_obj)\n  precision &lt;- cm$byClass[\"Pos Pred Value\"]\n  recall &lt;- cm$byClass[\"Sensitivity\"]\n  f1 &lt;- 2 * ((precision * recall) / (precision + recall))\n  youden &lt;- youden_point(roc_obj)\n  # All list arguments separated by commas only, no '+'\n  list(\n    confusion = cm$table,\n    precision = precision,\n    recall = recall,\n    f1 = f1,\n    auc = auc_val,\n    roc_obj = roc_obj,\n    youden = youden,\n    model = name\n  )\n}\n\nIntialize Results. We have to initialize results before calling the model\n\nresults_base &lt;- metrics(pred_base, prob_base, labels, \"Baseline LR\")\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nresults_firth &lt;- metrics(pred_firth, prob_firth, labels, \"firth LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\nresults_flic &lt;- metrics(pred_flic, prob_flic, labels, \"flic LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\n\nPrint Results\n\ncat(\"\\n== Baseline Logistic Regression ==\\n\")\n\n\n== Baseline Logistic Regression ==\n\nprint(results_base[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_base$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06934436   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== Firth Logistic Regression ==\\n\")\n\n\n== Firth Logistic Regression ==\n\nprint(results_firth[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3176  178\n         1    1    2\n\n$precision\nPos Pred Value \n     0.6666667 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02185792 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_firth$youden)\n\n   threshold sensitivity specificity   youden\n1 0.07100345   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== FLIC Logistic Regression ==\\n\")\n\n\n== FLIC Logistic Regression ==\n\nprint(results_flic[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_flic$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06935441   0.7444444   0.7777778 1.522222\n\n\nPlot the ROC curves and Annotate Youden’s J on each of the Curves\n\nplot(results_base$roc_obj, col=\"cyan\", main=\"ROC Curves: Baseline (blue) vs Firth (red)\")\nplot(results_firth$roc_obj, col=\"magenta\", add=TRUE)\nplot(results_flic$roc_obj, col =\"gold\", add=TRUE)\nauc(results_base$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_firth$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_flic$roc_obj)\n\nArea under the curve: 0.8285\n\npoints(\n  1-results_base$youden[\"specificity\"],\n  results_base$youden[\"sensitivity\"],\n  col=\"cyan\", pch=19, cex=1.5\n)\npoints(\n  1-results_firth$youden[\"specificity\"],\n  results_firth$youden[\"sensitivity\"],\n  col=\"magenta\", pch=19, cex=1.5\n)\npoints(\n  1-results_flic$youden[\"specificity\"],\n  results_flic$youden[\"sensitivity\"],\n  col=\"gold\", pch=19, cex=1.5\n)\n\nlegend(\"bottomright\", legend=c(\"Baseline\", \"Firth\",\"flic\"), col=c(\"cyan\", \"magenta\", \"gold\"), lwd=2)\n\ntext(\n  x=1-results_base$youden[\"specificity\"], y=results_base$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_base$youden[\"youden\"], 3)),\n  pos=4, col=\"cyan\"\n)\ntext(\n  x=1-results_firth$youden[\"specificity\"], y=results_firth$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_firth$youden[\"youden\"], 3)),\n  pos=4, col=\"magenta\"\n)\ntext(\n  x=1-results_flic$youden[\"specificity\"], y=results_flic$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_flic$youden[\"youden\"], 3)),\n  pos=4, col=\"gold\"\n)\n\n\n\n\n\n\n\n\nHere we see the results. Note that overlaying the curves and Youden’s J is EXACTLY the same for all three models. This is a strong indication that the dataset is currently balanced enough to distinguish between stroke and non stroke. The bias, if any, would have shown up in a different AUC curve, and a different Youden’s J. It does not.\nPlot the Confusion Matrices\n\npar(mfrow = c(3, 1), mar = c(6, 5, 6, 2))  # more top margin for all\nfourfoldplot(results_base$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Baseline Confusion Matrix\")\nfourfoldplot(results_firth$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Firth Confusion Matrix\")\nfourfoldplot(results_flic$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Flic Confusion Matrix\")\n\n\n\n\n\n\n\npar(mfrow = c(1,1), mar = c(5, 4, 4, 2)) # Reset to default after"
  },
  {
    "objectID": "posts/renan-blog-post-draft03/index.html#conclusion",
    "href": "posts/renan-blog-post-draft03/index.html#conclusion",
    "title": "Draft for Final Report - v03",
    "section": "8. Conclusion",
    "text": "8. Conclusion\nThe results indicate that the confusion matrices are the same. So the conclusion we can reach is there was no significant bias in the dataset. The dataset can distinguish between stroke and non stroke events with sufficient selectivity.\n\nReferences\n\n\n1. World Health Organization, & Fedesoriano. (2022). Stroke Prediction Dataset and Global Burden Statistics. Kaggle Dataset and WHO Statistics. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n\n\n2. Boehme, A., Esenwa, C., & Elkind, M. (2017). Stroke: A global health crisis. Circulation Research, 123(4), 459–471.\n\n\n3. Buongiorno, R., Caudai, C., Colantonio, S., & Germanese, D. (2024). Integrating AI in personalized disease management: New trends in medical informatics. Proceedings of the International Conference on Health Informatics, 112–120.\n\n\n4. Luo, W., Ye, H., & Zou, T. (2024). Guidelines for developing and reporting machine learning predictive models in biomedical research: A multidisciplinary view. Journal of Medical Internet Research, 26(1), e50890.\n\n\n5. Wu, Y., Chen, M., & Li, H. (2023). Machine learning algorithms for stroke risk prediction: A review of feature selection and model performance. Medical Informatics and Decision Making, 23(1), 304.\n\n\n6. Holzinger, A., Keil, P., & Kappel, M. (2024). Explainable AI (XAI) in healthcare: A review of opportunities and challenges. Artificial Intelligence in Medicine, 150, 102875.\n\n\n7. Wang, L. (2023). Logistic regression for stroke prediction: An evaluation of its accuracy and validity. International Journal of Advanced Medical Informatics, 15(2), 112–125.\n\n\n8. Steyerberg, E., Moons, K., & Van Calster, B. (2025). The role of logistic regression in clinical prediction: A narrative review. Academic Medicine and Surgery, 2(1), 10001–10015.\n\n\n9. McHugh, M. (2013). Logistic regression: The procedure, interpretation, and application. Journal of Biostatistics and Epidemiology, 4(2), 167–172.\n\n\n10. Zou, T., He, Q., & Liu, M. (2023). Performance metrics for imbalanced classification in medical diagnosis: Moving beyond accuracy. Diagnostics, 13(15), 2590.\n\n\n11. Liu, T., Hu, M., & Wang, Y. (2025). Machine learning algorithms for stroke risk prediction: A comprehensive evaluation. Frontiers in Neurology, 16, 1668420.\n\n\n12. Allaire, J., & Yihui, X. (2024). Quarto: Publishable scientific and technical documents. Journal of Statistical Software, 109(1), 1–25."
  },
  {
    "objectID": "posts/kristina-blog-post-week4/index.html",
    "href": "posts/kristina-blog-post-week4/index.html",
    "title": "Literature Review Week 4",
    "section": "",
    "text": "Article Title: Exploring the medical decision-making patterns and influencing factors among the general Chinese public: a binary logistic regression analysis.[1]\nAuthors: Yuwen Lyu, Qian Xu, Junrong Liu\nProblem: - Researchers are seeking to understand top driving factors behind decisions made about healthcare and medical issues. The population of interest is the general Chinese public. - Previous research in this field has identified two main types of medical decision making: unilateral and collaborative decision making - Unilateral decision making means there is one main entity making the medical decision, such as a single patient, a patient’s family, or a doctor. Previous research shows that patient families have a very strong influence over a patient’s medical decisions. - Collaborative decision making means there are two or more parties involved in the decision making process. Three subgroups are defined: doctor group, doctor- patient group, patient- family group, and patient-doctor-family group. - There is a lack in research in this field. More needs to be known about factors that play a role in medical decision making processes. This study’s results will be generalizable to China as well as nations around the world.\nSolution: - Use binary logistic regression to classify points into two categories: unilateral decision making (value of 1), or collaborative decision making (value of 0) - This model is ideal because it takes into account variable interactions. Also used often in the medical field - The equation of the model is given. It is in the form of the log odds of the desired event happening.\nData: - 2696 data points with attributes including age, education, occupation, family situation, religion, economic status and medical payment methods - Data was collected via survey and included only residents of China from 31 provinces - The data was gathered by the researchers that wrote this study - A power analysis was conducted to determine how many data points would be needed in order to have reliable results after statistical analysis. A G-power test showed that only 2040 valid data points were needed\nResults: - Survey results showed that 30% of responses were categorized as unilateral decision making, while 70% were categorized as collaborative decision making. The top category of unilateral decision making was doctor- led decisions, while the top category for collaborative decision making was patient- doctor- family decisions. - Significant predictors were identified with p-values less than 0.05. Significant predictors of unilateral decision making were gender, education level, family status, and religious beliefs. Different occupations also significantly predicted unilateral decision making. - Odds ratios are given for some predictors, with researchers stating that certain categories of specific predictors are x.xx times more likely than the reference group to be a unilateral decision maker. - The significance of the regression model’s intercept is interpreted, and it is significant. This means when all variables are at their reference levels, there is a low likelihood of the outcome variable taking on a value of a unilateral decision making process. - The goodness of fit test used in this study is McFadden’s R-squared value. The value was0.065, and researchers state that this value shows a good fit of the model. It is explained that R squared values for studies in the social sciences are rarely ever close to a perfect fit.\nConclusions: - The researchers discuss why there are contrasting results from this study versus studies in Western countries. They identify different cultural values in different geographic regions, which ultimately lead to different medical decision making processes. - Results are discussed more in depth, with researchers attempting to identify causes behind the correlations that were identified.\nLimitations: - The study’s data is solely from China, so results may not be generalizable to global populations. - The binary logistic regression model may not be complex enough to account for the complexities of all the predictors involved in healthcare decision making. Researchers suggest using more complex models in future research."
  },
  {
    "objectID": "posts/kristina-blog-post-week4/index.html#article-1",
    "href": "posts/kristina-blog-post-week4/index.html#article-1",
    "title": "Literature Review Week 4",
    "section": "",
    "text": "Article Title: Exploring the medical decision-making patterns and influencing factors among the general Chinese public: a binary logistic regression analysis.[1]\nAuthors: Yuwen Lyu, Qian Xu, Junrong Liu\nProblem: - Researchers are seeking to understand top driving factors behind decisions made about healthcare and medical issues. The population of interest is the general Chinese public. - Previous research in this field has identified two main types of medical decision making: unilateral and collaborative decision making - Unilateral decision making means there is one main entity making the medical decision, such as a single patient, a patient’s family, or a doctor. Previous research shows that patient families have a very strong influence over a patient’s medical decisions. - Collaborative decision making means there are two or more parties involved in the decision making process. Three subgroups are defined: doctor group, doctor- patient group, patient- family group, and patient-doctor-family group. - There is a lack in research in this field. More needs to be known about factors that play a role in medical decision making processes. This study’s results will be generalizable to China as well as nations around the world.\nSolution: - Use binary logistic regression to classify points into two categories: unilateral decision making (value of 1), or collaborative decision making (value of 0) - This model is ideal because it takes into account variable interactions. Also used often in the medical field - The equation of the model is given. It is in the form of the log odds of the desired event happening.\nData: - 2696 data points with attributes including age, education, occupation, family situation, religion, economic status and medical payment methods - Data was collected via survey and included only residents of China from 31 provinces - The data was gathered by the researchers that wrote this study - A power analysis was conducted to determine how many data points would be needed in order to have reliable results after statistical analysis. A G-power test showed that only 2040 valid data points were needed\nResults: - Survey results showed that 30% of responses were categorized as unilateral decision making, while 70% were categorized as collaborative decision making. The top category of unilateral decision making was doctor- led decisions, while the top category for collaborative decision making was patient- doctor- family decisions. - Significant predictors were identified with p-values less than 0.05. Significant predictors of unilateral decision making were gender, education level, family status, and religious beliefs. Different occupations also significantly predicted unilateral decision making. - Odds ratios are given for some predictors, with researchers stating that certain categories of specific predictors are x.xx times more likely than the reference group to be a unilateral decision maker. - The significance of the regression model’s intercept is interpreted, and it is significant. This means when all variables are at their reference levels, there is a low likelihood of the outcome variable taking on a value of a unilateral decision making process. - The goodness of fit test used in this study is McFadden’s R-squared value. The value was0.065, and researchers state that this value shows a good fit of the model. It is explained that R squared values for studies in the social sciences are rarely ever close to a perfect fit.\nConclusions: - The researchers discuss why there are contrasting results from this study versus studies in Western countries. They identify different cultural values in different geographic regions, which ultimately lead to different medical decision making processes. - Results are discussed more in depth, with researchers attempting to identify causes behind the correlations that were identified.\nLimitations: - The study’s data is solely from China, so results may not be generalizable to global populations. - The binary logistic regression model may not be complex enough to account for the complexities of all the predictors involved in healthcare decision making. Researchers suggest using more complex models in future research."
  },
  {
    "objectID": "posts/kristina-blog-post-week4/index.html#article-2",
    "href": "posts/kristina-blog-post-week4/index.html#article-2",
    "title": "Literature Review Week 4",
    "section": "Article 2",
    "text": "Article 2\nArticle Title: Predictors of hospital admission when presenting with acute on chronic breathlessness: Binary logistic regression.[2]\nAuthors: Ann Hutchinson, Alastair Pickering, Paul Williams, Miriam Johnson\nProblem: - People presenting to the emergency room with breathlessness often do not require hospitalization and can be sent home. Only an average of 50% to 67% of these patients require admittance to the hospital. This research focuses on patients presenting with breathlessness to the ER and seeks to identify significant predictors of hospitalization of these individuals. Doctors and emergency department staff would benefit from identifying predictors present in individuals that would need to be admitted to the hospital.\nSolution: - Researchers used a binary logistic regression analysis to identify the predictors most strongly correlated with patients with breathlessness being admitted to the hospital from the ER. - First, in order to identify which predictors to include in the binary logistic regression, researchers analyzed 48 total predictors individually. They conducted a separate univariate analysis for each variable to see which were most significantly correlated with hospitalization from the ER. Only seven predictors were significant, and of those, only five were included in the final model (due to eliminating variables with strong multicollinearity).\nData: - Data was collected from a single hospital from December 2015 to May 2015. - Only 171 datapoints are included, as only 171 patients with acute breathlessness consented to have their survey used for research - Predictors included: demographics, preexisting medical conditions, severity of breathlessness, and other vital signs - To determine which predictors were most important, researchers used a stepwise backward elimination process, and excluded one predictor at a time. It was determined that only five predictors were needed. - After univariate analysis, researchers constructed a binary logistic regression model incorporating all of the selected predictors.\nResults and Conclusions: - Results are presented with an odds ratio for every predictor in the model. The odds of being admitted to the hospital increased by a certain factor for every one unit increase in a specific predictor. - The odds of admission to the hospital were positively correlated with age, talking to a doctor about symptoms, and the presence of preexisting heart conditions. The odds of being admitted to the hospital were negatively associated with blood oxygen levels. - The researchers state that this study is meant to only be exploratory and the results should not be used for making future predictions. Rather, the results should be used to aid in identifying strong predictors so these variables can be included in future similar studies. - Results of this study are compared to results of other studies, and the findings are consistent. A consistent predictor of hospital admission from this study and other studies includes older age. Another common predictor is tachycardia, but this study did not include this information.\nLimitations: - The study’s data is very limited. The data is supplied from just one hospital, and there were only 171 data points analyzed. The results of the study are therefore not as generalizable to global populations as a study analyzing broader populations. - The data also did not include responses from patients with very severe breathlessness because their state of health was too severe for them to be able to complete a survey. So the results of this study do not reflect patients with extreme symptoms.\n\nReferences\n\n\n1. Lyu, Y., Xu, Q., & Liu, J. (2024). Exploring the medical decision-making patterns and influencing factors among the general chinese public: A binary logistic regression analysis. BMC Public Health, 24(1), 887.\n\n\n2. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263."
  },
  {
    "objectID": "posts/kristina-blog-post-week3/index.html",
    "href": "posts/kristina-blog-post-week3/index.html",
    "title": "Literature Review Week 3",
    "section": "",
    "text": "Title: Determinants of coexistence of undernutrition and anemia among under- five children in Rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model.[1]\nAuthors: Abebew Aklog smare, Yitateku Adugna Agmas\nProblem: - In children under five years of age, malnutrition and anemia have been an ongoing problem in many African countries. This paper focuses on studying malnutrition and anemia in Rwanda in particular; Rwanda went through a civil war, and after the war, rates of malnutrition and anemia decreased as the country was rebuilt. However, different parts of the country experienced faster or slower rates of improvement of malnutrition and anemia after the war, and it is unclear which factors are associated with improved rates of malnutrition and anemia. This study aims to identify key predictors correlated with these health ailments, so that the areas of the country still suffering from high rates of these health problems can be given the correct types of aid to fix the problem of malnutrition and anemia. - The introduction of the paper cites a few studies that identify strong correlations with malnutrition and anemia in children under five. Some strong predictors found by other studies are the child’s age, parents’ education level, household economic class, geographic location, household food availability, child birth size, family size, maternal age, and more. - The introduction states that this topic is relevant because although there is already existing research on malnutrition and anemia in African countries, there is not much literature studying the relationship between the two health conditions. This study aims to analyze the relationship between malnutrition and anemia in children in addition to identifying strong predictors of the conditions.\nData: - Data is supplied by the 2019/20 Rwanda Demographic and Health Survey. The researchers obtained the samples themselves, and the sampling method is described in depth. The researchers chose 500 clusters from different areas all over the country, and then households were selected at random from these clusters to be surveyed. The resulting data consisted of 3205 data points consisting of data about children under the age of 5.\nSolution to problem: - Researchers used a bivariate binary logistic regression model. This model helps understand the relationship between the outcome variables, presence of malnutrition and presence of anemia. The outcome variables are both binary, taking on a value of 1 for present, or 0 for not present. The predictors consist of about 26 variables relating to the child’s health conditions, family information, details about the parents, and relevant geographic information. - Three models are presented. The first model is the bivariate binary logistic regression model. The second model is the equivalent, but it is in the form of the log odds. The third model discussed is the odds ratio, and it is used to assess the relationship between categorical predictors in the model. - The researchers used SPSS and R software to perform the analyses.\nResults: - Results shows that nearly half of the study participants had anemia and about one fifth had malnutrition. - Six significant predictors were found: mother’s age, drinking water, other children in household, child gender, birth order, and gender of household head. - The odds ratio was a value that was not 1, which indicates that the outcome variables are not statistically independent. The relationship that exists between the outcome variables is significant. - The goodness fit test used was a proportion of correct predictions to the number of observations. This result was about 89%, so the researchers conclude that the model was a good fit. - There is a discussion about possible causes of the significant relationship that was found between malnutrition and anemia in children under 5. Researchers cite other facts and figures about why these health conditions are strongly correlated.\nConclusion: - Increasing maternal education, supplementing with vitamin A and other nutrient dense foods, providing a healthy/ clean/ safe environment, and decreasing maternal anemia may help improve rates of malnutrition and anemia in children.\nLimitations of the study: - The only limitation discussed is that the data collected may be prone to errors. This means researchers can conclude there are strong correlations, but it cannot be stated that any of the relationships are causal."
  },
  {
    "objectID": "posts/kristina-blog-post-week3/index.html#article-1",
    "href": "posts/kristina-blog-post-week3/index.html#article-1",
    "title": "Literature Review Week 3",
    "section": "",
    "text": "Title: Determinants of coexistence of undernutrition and anemia among under- five children in Rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model.[1]\nAuthors: Abebew Aklog smare, Yitateku Adugna Agmas\nProblem: - In children under five years of age, malnutrition and anemia have been an ongoing problem in many African countries. This paper focuses on studying malnutrition and anemia in Rwanda in particular; Rwanda went through a civil war, and after the war, rates of malnutrition and anemia decreased as the country was rebuilt. However, different parts of the country experienced faster or slower rates of improvement of malnutrition and anemia after the war, and it is unclear which factors are associated with improved rates of malnutrition and anemia. This study aims to identify key predictors correlated with these health ailments, so that the areas of the country still suffering from high rates of these health problems can be given the correct types of aid to fix the problem of malnutrition and anemia. - The introduction of the paper cites a few studies that identify strong correlations with malnutrition and anemia in children under five. Some strong predictors found by other studies are the child’s age, parents’ education level, household economic class, geographic location, household food availability, child birth size, family size, maternal age, and more. - The introduction states that this topic is relevant because although there is already existing research on malnutrition and anemia in African countries, there is not much literature studying the relationship between the two health conditions. This study aims to analyze the relationship between malnutrition and anemia in children in addition to identifying strong predictors of the conditions.\nData: - Data is supplied by the 2019/20 Rwanda Demographic and Health Survey. The researchers obtained the samples themselves, and the sampling method is described in depth. The researchers chose 500 clusters from different areas all over the country, and then households were selected at random from these clusters to be surveyed. The resulting data consisted of 3205 data points consisting of data about children under the age of 5.\nSolution to problem: - Researchers used a bivariate binary logistic regression model. This model helps understand the relationship between the outcome variables, presence of malnutrition and presence of anemia. The outcome variables are both binary, taking on a value of 1 for present, or 0 for not present. The predictors consist of about 26 variables relating to the child’s health conditions, family information, details about the parents, and relevant geographic information. - Three models are presented. The first model is the bivariate binary logistic regression model. The second model is the equivalent, but it is in the form of the log odds. The third model discussed is the odds ratio, and it is used to assess the relationship between categorical predictors in the model. - The researchers used SPSS and R software to perform the analyses.\nResults: - Results shows that nearly half of the study participants had anemia and about one fifth had malnutrition. - Six significant predictors were found: mother’s age, drinking water, other children in household, child gender, birth order, and gender of household head. - The odds ratio was a value that was not 1, which indicates that the outcome variables are not statistically independent. The relationship that exists between the outcome variables is significant. - The goodness fit test used was a proportion of correct predictions to the number of observations. This result was about 89%, so the researchers conclude that the model was a good fit. - There is a discussion about possible causes of the significant relationship that was found between malnutrition and anemia in children under 5. Researchers cite other facts and figures about why these health conditions are strongly correlated.\nConclusion: - Increasing maternal education, supplementing with vitamin A and other nutrient dense foods, providing a healthy/ clean/ safe environment, and decreasing maternal anemia may help improve rates of malnutrition and anemia in children.\nLimitations of the study: - The only limitation discussed is that the data collected may be prone to errors. This means researchers can conclude there are strong correlations, but it cannot be stated that any of the relationships are causal."
  },
  {
    "objectID": "posts/kristina-blog-post-week3/index.html#article-2",
    "href": "posts/kristina-blog-post-week3/index.html#article-2",
    "title": "Literature Review Week 3",
    "section": "Article 2",
    "text": "Article 2\nArticle Title: Using Binary logistic Regression to Detect Health Insurance Fraud.[2]\nAuthor: Baraah Samara, Ph.D. Student\nProblem: - Insurance fraud in health insurance industry. Specifically, patients treated at private clinics or hospitals. - Intro of the article explains why this topic is relevant. Between 1965 and 2008, the cost of healthcare increased significantly, and as a result, health insurance fraud has increased. There needs to be effective tools at detecting this fraud. - If fraud is decreased, it will help the economy as a whole, it will help insurance companies, and it will lower premium payments made by customers. - Fraud is committed by three types of entities: consumer, provider, and payer fraud. - Literature review cites common predictors of health insurance fraud: diagnoses, service cost, number of claims from individual, greatest costing claim, probability of anomaly, excessive charges by care facilities, and more.\nData: - Original dataset contained 26 independent variables - Data was collected from a time span of January 2022 through November 2022 - about 123,000 data points with no missing values. - The predictors are of varying types, including numerical, categorical, and binary values - The dependent variable is fraud, with a value of 1 for fraud present, or 0 for no fraud present.\nSolution to Problem:\nWhy they selected this model: - Building a binary logistic regression model to detect health insurance fraud - logistic regression is selected as the analytic technique because they want to assess effects of categorical variables on a categorical dependent variable. They also cite that logistic regression is the most accurate type of regression model with the kind of classification they are performing in this study. - Fraud detection commonly employs binary prediction models - The logistic regression model also provides estimates between 0 and 1, which help investigators estimate probability of fraud - Researchers provide the equation they use to calculate the log odds of the event of interest (occurrence of fraud)\nThe method: - They calculate likelihood of an individual committing fraud - They calculate total cost accrued by an individual. Then they perform the logistic regression using this calculation - The model works by identifying outliers and classifies them as potential fraudulent activity - Before testing the model, researchers hypothesize that there will be a positive relationship between overall cost accrued by patient and likelihood of fraud. Costs include doctor visit costs, prescription drug costs, lab costs, costs of medical symptoms, and total cost of expensive prescriptions. - When running the model, none of the coefficients were zero, which means that there exists a significant relationship between the outcome and the predictor variables. - Predictors were tested for multicollinearity before the model was run. Pearson correlation coefficients were obtained, and any predictors with a Pearson value of greater than 0.8 were excluded from the model. Only eight predictors remained after removing the predictors that were strongly correlated. - Different models were constructed using only the most important predictors. When taking away the least important predictor, the log likelihood was calculated to assess the accuracy of the model. The best performing model contained six of the original predictors.\nResults: - Six predictors were found to be significant in predicting health insurance fraud. The predictors are office visit cost, prescription costs, lab costs, symptom cost, and two expensive prescription drug costs. - There is a thorough interpretation of model slopes. For example, “the likelihood of fraud increases by .005188 for every unit increase in pharmacy cost.” Interpretations for the most significant predictors are given in this way. - A Chi-Square test for independence was used to determine whether at least one predictor was significantly related to the outcome. It was concluded that at least one of the six predictors was significant. - The model was found to be about 99% accurate when predicting no fraud, but only about 76% accurate when predicting fraud. - An example is included that shows how to calculate the probability that an individual will commit insurance fraud, given values for the six predictors in the equation. - The study concludes by stating the importance and relevance of continuing to develop new fraud detection models.\nLimitations: - No limitations are explicitly stated in this paper. However, it can be considered a limitation that only data from middle eastern countries was used in the study. To make the results of the study more generalizable, data from other regions of the world should be included in a more comprehensive study.\n\nReferences\n\n\n1. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n2. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2)."
  },
  {
    "objectID": "posts/kristina-blog-post-week2/index.html",
    "href": "posts/kristina-blog-post-week2/index.html",
    "title": "Literature Review Week 2",
    "section": "",
    "text": "Article title: Understanding logistic regression analysis[1]\nData used: Synthetic data about the effect of a drug treatment. There are two treatments: standard and new drug treatments. Shows a binary outcome, either died or survived after drug treatment.\nProblem: The problem introduced in this article is needing a method to study the joint relationship between two or more predictors and the target variable. One way to solve this problem is to calculate a weighted odds ratio that accounts for all the relationships and predictors. However, as the number of predictors increases, weighted odds ratio calculations can become very complicated. Also, these calculations require only categorical variables as input and no continuous variables may be used. A solution to this problem is to use logistic regression.\nSolution to problem: - Article explains what logistic regression is useful for. Advantages are that it can be used when there are more than two predictors and we want to analyze how they all simultaneously affect the target variable. Also useful for when we have any number of continuous predictors. - Gives the logistic regression model equation and explains the meaning of all variables (intercept, slops, and symbols). The outcome in the model (left hand side of equation) is the log of the odds. The paper goes into detail about how to interpret coefficients in the model; you must take the exponentials of the coefficients to understand the chances (the probability) of an event happening (the event in this paper is death).\nLimitations: - Differences between odds, odds ratios, and probabilities are discussed. Understanding the differences is key to interpreting results, and if you do not understand the differences, you cannot easily interpret the output of a logistic regression model. - If there is a predictor with more than two levels, you must create n-1 dummy variables for n number of categories within the predictor. This is considered a limitation because dataset manipulation must be done prior to constructing a model. - Interpreting coefficients of continuous variables is explained. It is different than interpreting coefficients of categorical variables. Interpreting these results can be complicated and should be done carefully. Exponential of the coefficient of a continuous variable is the chance of an event happening in relation to one unit of the continuous predictor. - Models with too many predictors can be too saturated, and researchers may miss associations. An association may be present, but the model will not have enough statistical power with too many predictors. Solution: build a model with less predictors. You can start with all predictors and drop one at a time, or start with 0 predictors and add one at a time (keeping only the most important predictors). Starting with a full model is better. - A way to test the importance of each variable is to create a univariate model for each individual predictor at a time to see which are most strongly correlated with the outcome. - How to choose the reference group is explained. Usually, the reference group is the lowest level or the highest level in a group of ordered categories. But if there is no order to the categories then there may be no clear reference group. Results vary when choosing differing reference groups.\nResult: The researchers conclude by stating that logistic regression is a very powerful and useful way to analyze epidemiologic data."
  },
  {
    "objectID": "posts/kristina-blog-post-week2/index.html#article-1",
    "href": "posts/kristina-blog-post-week2/index.html#article-1",
    "title": "Literature Review Week 2",
    "section": "",
    "text": "Article title: Understanding logistic regression analysis[1]\nData used: Synthetic data about the effect of a drug treatment. There are two treatments: standard and new drug treatments. Shows a binary outcome, either died or survived after drug treatment.\nProblem: The problem introduced in this article is needing a method to study the joint relationship between two or more predictors and the target variable. One way to solve this problem is to calculate a weighted odds ratio that accounts for all the relationships and predictors. However, as the number of predictors increases, weighted odds ratio calculations can become very complicated. Also, these calculations require only categorical variables as input and no continuous variables may be used. A solution to this problem is to use logistic regression.\nSolution to problem: - Article explains what logistic regression is useful for. Advantages are that it can be used when there are more than two predictors and we want to analyze how they all simultaneously affect the target variable. Also useful for when we have any number of continuous predictors. - Gives the logistic regression model equation and explains the meaning of all variables (intercept, slops, and symbols). The outcome in the model (left hand side of equation) is the log of the odds. The paper goes into detail about how to interpret coefficients in the model; you must take the exponentials of the coefficients to understand the chances (the probability) of an event happening (the event in this paper is death).\nLimitations: - Differences between odds, odds ratios, and probabilities are discussed. Understanding the differences is key to interpreting results, and if you do not understand the differences, you cannot easily interpret the output of a logistic regression model. - If there is a predictor with more than two levels, you must create n-1 dummy variables for n number of categories within the predictor. This is considered a limitation because dataset manipulation must be done prior to constructing a model. - Interpreting coefficients of continuous variables is explained. It is different than interpreting coefficients of categorical variables. Interpreting these results can be complicated and should be done carefully. Exponential of the coefficient of a continuous variable is the chance of an event happening in relation to one unit of the continuous predictor. - Models with too many predictors can be too saturated, and researchers may miss associations. An association may be present, but the model will not have enough statistical power with too many predictors. Solution: build a model with less predictors. You can start with all predictors and drop one at a time, or start with 0 predictors and add one at a time (keeping only the most important predictors). Starting with a full model is better. - A way to test the importance of each variable is to create a univariate model for each individual predictor at a time to see which are most strongly correlated with the outcome. - How to choose the reference group is explained. Usually, the reference group is the lowest level or the highest level in a group of ordered categories. But if there is no order to the categories then there may be no clear reference group. Results vary when choosing differing reference groups.\nResult: The researchers conclude by stating that logistic regression is a very powerful and useful way to analyze epidemiologic data."
  },
  {
    "objectID": "posts/kristina-blog-post-week2/index.html#article-2",
    "href": "posts/kristina-blog-post-week2/index.html#article-2",
    "title": "Literature Review Week 2",
    "section": "Article 2",
    "text": "Article 2\nArticle used: Binary logistic regression analysis of factors affecting urban road traffic safety.[2]\nProblem: The introduction features a literature review establishing relevance of the topic. Several studies about traffic accidents are discussed and cited. Traffic accidents are becoming more common as traffic increases due to population increases. Researchers aim to find which factors in traffic are more closely associated with the occurrence of traffic accidents.\nSolution: The researchers use a binary logistic regression model to study which factors are more correlated to the occurrence of traffic accidents. The advantages of a binary logistic regression are discussed. Logistic regression allows researchers to make predictions about probability of a dependent variable being sorted into a certain class. Logistic regression also allows for the researchers to determine which predictors more significantly impact the outcome variable. To set up the study, researchers defined the dependent variable, y, as a binary outcome of either no accident (value of 0) or presence of an accident (value of 1). The independent variables are defined as 25 factors that are grouped under four categories consisting of environmental factors, driver attributes, road attributes, and vehicle factors. Before analyzing the data, it was preprocessed to eliminate outliers, normalize all predictor values to similar scales, eliminate redundancy, Then, the predictors were run through a multicollinearity test to determine if any needed to be excluded from the model; none of the factors showed significant multicollinearity and all 25 were kept in the model. The calculation used for collinearity involved the correlation coefficient, R, tolerance (T), and variance inflation factor (V).\nResults: A binary logistic regression model was fitted to the data, and it was found that the model fit well. To assess the goodness of fit, the determination coefficient, R^2, value was calculated. The strongest predictors of a traffic incident were found to be driver behavior, weather, road conditions, and lighting.\nLimitations: The paper states that research in this area can be improved by using real- time data about weather, road conditions, and driver status. Using data as it occurs in real time may help make better predictions about traffic safety risks.\nDataset: The original data was sourced from the International Transport Forum with 5350 datapoints. After data preprocessing, the data was reduced to 3500 data points.\n\nReferences\n\n\n1. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n2. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3."
  },
  {
    "objectID": "posts/renan-blog-post-draft09/index.html",
    "href": "posts/renan-blog-post-draft09/index.html",
    "title": "Draft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "Stroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Because stroke often occurs suddenly and can result in long-term neurological impairment, early identification of individuals at elevated risk is critical for prevention and timely intervention. Data-driven risk prediction models enable clinicians and public health professionals to quantify individual-level risk and to target high-risk groups for lifestyle counselling and clinical management.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease presence or absence[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset."
  },
  {
    "objectID": "posts/renan-blog-post-draft09/index.html#introduction",
    "href": "posts/renan-blog-post-draft09/index.html#introduction",
    "title": "Draft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "Stroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Because stroke often occurs suddenly and can result in long-term neurological impairment, early identification of individuals at elevated risk is critical for prevention and timely intervention. Data-driven risk prediction models enable clinicians and public health professionals to quantify individual-level risk and to target high-risk groups for lifestyle counselling and clinical management.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease presence or absence[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset."
  },
  {
    "objectID": "posts/renan-blog-post-draft09/index.html#methods",
    "href": "posts/renan-blog-post-draft09/index.html#methods",
    "title": "Draft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "2. Methods",
    "text": "2. Methods\nThe binary logistic regression model is part of a family of statistical models called generalised linear models. The main characteristic that differentiates binary logistic regression from other generalised linear models is the type of dependent (or outcome) variable.[harris2019statistics?] A dependent variable in a binary logistic regression has two levels. For example, a variable that records whether or not someone has ever been diagnosed with a health condition like Stroke could be measured in two categories, yes and no. Likewise, someone might have coronary heart disease or not, be physically active or not, be a current smoker or not, or have any one of thousands of diagnoses or personal behaviours and characteristics that are of interest in family medicine.\nThe binary logistic regression algorithm below:\n\\[ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}x_{1} + \\cdots + \\beta_{k}x_{k}\\]\nWhere \\(\\pi = P[Y =1]\\) is the probability of the outcome.\n\nLogistic Regression\nDecision Tree\nRandom Forest\nGradient Boosted Machine\nk-Nearest Neighbors\nSupport Vector Machine\n\n\nAssumptions\nBinary logistic regression relies on the following underlying assumptions to be true:\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers\nThe Sample Size is Sufficiently Large. Field recommends a minimum of 50 cases.[field2024discovering?] Hosmer, Lemeshow, and Sturdivant[hosmer2013applied?] suggest a minimum sample of 10 observations per independent variable in the model. Leblanc and Fitzgerald (2000)[leblanc2000logistic?] suggest a minimum of 30 observations per independent variable."
  },
  {
    "objectID": "posts/renan-blog-post-draft09/index.html#analysis-and-results",
    "href": "posts/renan-blog-post-draft09/index.html#analysis-and-results",
    "title": "Draft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nImport all the dependencies:\n\n\nCode\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\", \"ggcorrplot\", \"randomForest\", \"gbm\", \"kernlab\", \"skimr\", \"corrplot\", \"scales\", \"tidyr\", \"RColorBrewer\")\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n3.1. Data Ingestion\nData source: Stroke Prediction Dataset[kaggle01?]\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nstroke_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(stroke_path, show_col_types = FALSE)\n\n\n\n\n3.2. Exploratory Data Analysis (EDA)\nDataset Description\nThe Stroke Prediction Dataset[kaggle01?] is a publically available dataset for educational purposes containing 5,110 observations containing predictors commonly associated with cerebrovascular risk. The dataset is composed of 11 clinical and demographic features and 1 feature which is id a unique identifier for the patient. The dataset has features including patient’s age, gender, presence of conditions like hypertension and heart disease, work type, residence type, average glucose level, and BMI. This dataset is primarily intended for educational purposes as it shares a lot of similarities with the Jackson Heart Study (JHS) dataset but it is not as descriptive.\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nKey Values/Range\n\n\n\n\nid\nUnique identifier for the patient\nNumeric\nUnique numeric ID\n\n\ngender\nPatient’s gender\nCharacter\nMale, Female, Other\n\n\nage\nPatient’s age in years\nNumeric\n0.08 to 82\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nCharacter\nNo, Yes\n\n\nwork_type\nType of occupation\nCharacter\nPrivate, Self-employed, Govt_job, children, Never_worked\n\n\nResidence_type\nPatient’s area of residence\nCharacter\nRural, Urban\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\n≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nCharacter\n≈10.3 to 97.6 (has NA values)\n\n\nsmoking_status\nPatient’s smoking status\nCharacter\nformerly smoked, never smoked, smokes, Unknown\n\n\nstroke\nTarget Variable: Whether the patient had a stroke\nNumeric (binary)\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.1 Dataset Preprocessing\n\n\nCode\n# Handle dataset features\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 0\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 0\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n# Remove NAs and clean dataset\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\n\nstrokeclean$stroke &lt;- factor(\n  strokeclean$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\nfourassume$stroke &lt;- factor(\n  fourassume$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\n\nThe initial exploration demonstrated that the Stroke Prediction Dataset[kaggle01?] has several issues requiring changes for handling missing values, converting character (categorical) features into numerical codes, and removing the identifier column.\nSo as part of data preprocessing we will be focused on establishing consistency and ensuring all variables are in a format suitable for predictive modeling. This process starts by systematically addressing non-standard representations of missing data. Specifically, all instances of the string values “N/A”, “Unknown”, “children”, and “other” found across the dataset were unified and replaced with the standard statistical missing value representation, NA.\nThen we proceed with converting several character-based (categorical) features into numerical features, which is necessary for predictive modeling.\nThe feature bmi, initially read as a character variable was first converted to a numeric data type and subsequently rounded to two decimal places.\nThe binary categorical features were encoded into numerical indicators. The feature gender was transformed so that “Male” was encoded to 1 and “Female” was encoded to 0, and the ever_married was transformed so that “Yes” encoded to 1 and “No” encoded to 0.\nFeatures with multiple categories were also numerically encoded into numerical indicators. The work_type feature had its categories encoded so that “Govt_job” = 1, “Private” = 2, “Self-employed” = 3, and “Never_worked” = 4. The Residence_type was encoded so that “Urban” = 1 and “Rural” = 2. Finally, the smoking_status feature was encoded into three numerical levels, those being “never smoked” = 1, “formerly smoked” = 2, and “smokes” = 3.\nAdditionally, the continuous numerical variables avg_glucose_level, heart_disease, and hypertension were explicitly confirmed as numeric data types, with the age feature also being rounded to two decimal places for consistency.\nThe final stage of preprocessing involved removing the id column, which served only as a unique identifier and held no predictive value. This action left the dataset with 11 core predictors. The target variable, stroke, was then converted into a factor (a categorical data type in R) named stroke1, and its levels were explicitly labeled as \\(\\text{\"No\"} = 0\\) and \\(\\text{\"Yes\"} = 1\\). The entire process concluded with the removal of all remaining observations containing missing or inconsistent entries, resulting in the creation of the final, clean data frames, strokeclean and fourassume.\nDataset Preprocessing Conclusion\nThe Stroke Prediction Dataset[kaggle01?] that started containing 5,110 observations and 12 features. After cleaning missing and inconsistent entries among other necessarychanges, ended as a dataset containing 3,357 observations and 11 predictors commonly associated with cerebrovascular risk. Those key predictors are listed below.\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nValues\n\n\n\n\ngender\nPatient’s gender\nNumeric\n1 (Male), 0 (Female)\n\n\nage\nPatient’s age in years\nNumeric\nRange 0.08 to 82; rounded to 2 decimal places\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nNumeric\n1 (Yes), 0 (No)\n\n\nwork_type\nType of occupation\nNumeric\n1 (Govt_job), 2 (Private), 3 (Self-employed), 4 (Never_worked)\n\n\nResidence_type\nPatient’s area of residence\nNumeric\n1 (Urban), 2 (Rural)\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\nRange ≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nNumeric\nRange ≈10.3 to 97.6; converted from character, rounded to 2 decimals\n\n\nsmoking_status\nPatient’s smoking status\nNumeric\n1 (never smoked), 2 (formerly smoked), 3 (smokes)\n\n\nstroke\nTarget Variable: Whether the patient had stroke\nNumeric\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Dataset Visualization\nBefore developing predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nHistograms\n\n\nCode\n# 1. Get the total number of rows in your data frame\nTOTAL_ROWS &lt;- nrow(strokeclean)\n\n# 2. Use the modified ggplot code\np1a &lt;- ggplot(strokeclean, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # The calculation is (bar_count / TOTAL_ROWS) * 100, rounded to 1 decimal place.\n    position = position_dodge(width = 0.9),\n    aes(\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1), \n    labels = c(\"Female\", \"Male\")\n  ) +\n  labs(title = \"(a) Gender\", x = \"Gender\", y = \"Count\")\n\n# (b) Histogram of Age\np1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n# (b) Bivariate Density Plot of Age\n# p1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) + # Keep fill=stroke\n#   geom_density(alpha = 0.5) + # Overlap the two density curves\n#   labs(title = \"(b) Age\", x = \"Age\", y = \"Density\")\n\n# (c) Histogram of hypertension\np1c &lt;- ggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(c) Hypertension\", x = \"Hypertension\", y = \"Frequency\")\n\n# (d) Histogram of heart_disease\np1d &lt;- ggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(d) Heart Disease\", x = \"Heart Disease\", y = \"Frequency\")\n\n# (e) Histogram of ever_married\np1e &lt;- ggplot(strokeclean, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  # Assuming 'No'/'Yes' are string/factor values, use scale_x_discrete if needed\n  labs(title = \"(e) Ever Married\", x = \"Ever Married\", y = \"Frequency\")\n\n# (f) Histogram of work_type\np1f &lt;- ggplot(strokeclean, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, # Shift text right for horizontal bar\n    size = 3,\n    color = \"black\"\n  ) +\n  # Expand X-axis (Frequency) for horizontal bar\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) +\n  # Adding Work type labels make it too convoluted\n  # scale_y_continuous(\n  #   breaks = c(1, 2, 3, 4), \n  #   labels = c(\"Govt_job\", \"Private\", \"Self-employed\", \"Never_worked\")\n  # ) + \n  labs(title = \"(f) Work Type\", y = \"Work Type\", x = \"Frequency\")\n\n# (g) Histogram of Residence_type\np1g &lt;- ggplot(strokeclean, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # Crucial for aligning text labels with the dodged bars\n    position = position_dodge(width = 0.9), \n    aes(\n      # Defines the group for position_dodge to work correctly on text\n      group = stroke, \n      \n      # Combined label: Percentage (top line) + Count (bottom line)\n      label = paste0(\n        # Percentage calculation: (count / TOTAL_ROWS) * 100\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5, # Moves the two-line label slightly above the bar\n    size = 3,\n    color = \"black\" # Ensures better visibility\n  ) +\n  # Adds 15% extra space to the top of the y-axis to prevent label clipping\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + \n  labs(title = \"(g) Residence Type\", x = \"Residence Type\", y = \"Frequency (Count)\")\n\n# (h) Histogram of avg_gloucose_level\np1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(h) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Frequency\")\n\n# (h) Bivariate Density plot of avg_gloucose_level\n# p1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"Avg. Glucose Level by Stroke Status\", x = \"Average Glucose Level\", y = \"Density\")\n\n# (i) Histogram of bmi\np1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(i) BMI\", x = \"BMI\", y = \"Frequency\")\n\n# (i) Bivariate Density plot of bmi\n# p1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"BMI Distribution by Stroke Status\", x = \"BMI\", y = \"Density\")\n\n# (j) smoking_status\np1j &lt;- ggplot(strokeclean, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke, \n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, \n    size = 3,\n    color = \"black\" \n  ) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) + \n  labs(title = \"(j) Smoking Status\", y = \"Smoking Status\", x = \"Frequency (Count)\")\n\n\nWe can observe from the histograms (a), (b), (c) and (d) the following:\nThe data appears to be slightly imbalanced towards female gender and the proportion of stroke cases relative to the total number of individuals in each gender appears similar for both genders, even if it looks slightly higher in the male doesnt seem to be significant difference.\nThe number of stroke cases increases dramatically after the age of \\(\\approx 50\\) and peaks in the 60 to 80 age range. This strongly suggests age is a critical risk factor for stroke.\nThe majority of patients do not have hypertension and the proportion of stroke cases (blue bar) is visibly much higher in the group with hypertension. This indicates that hypertension is a strong risk factor for stroke.\nSimilar to hypertension, the majority of patients do not have heart disease and the proportion of stroke cases (blue bar) is visibly much higher in the group with heart disease. This indicates that heart disease is a very strong risk factor for stroke, even stronger than hypertension when based alone on the observed proportions.\n\n\nCode\n# p1a, p1b, p1c, p1d\n# (a) Histogram of gender \n# (b) Histogram of Age\n# (c) Histogram of hypertension\n# (d) Histogram of heart_disease\nggarrange(p1a, p1b, p1c, p1d, \n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (a)gender, (b)age, (c)hypertension, (d)heart_disease.\n\n\n\n\nWe can observe from the histograms (e), (f), (g) and (h) the following:\nThe stroke rate appears higher for those who have ever been married which is a fascinating plot that catches our attention, this must be correlated with another variable. Our guess is that having been married being associated with a higher stroke risk in this dataset, is possibly due to the married group skewing toward older ages\nAcross the four work types encoded, “Govt_job” = 1, “Private” = 2 “Self-employed” = 3, “Never Worked” = 4. Self-employed individuals appear to have the highest risk proportion among the working groups. Followed by the Private which is the largest group (total \\(\\approx 2200\\)) and naturally accounts for the highest raw count of stroke cases (109) with a proportion of stoke incidence sligthly higher than Govt_job.\nThe stroke outcomes based on the patient’s residence type has a very similar raw count their proportions seems to be similar as well. This suggests that residence type does not appear to be a significant factor for stroke risk.\nFrom the distribution of average glucose (HbA1c) we can visually spot that the stroke cases are more frequent for high-glucose relative to the total population at those high levels. This higher propportion indicates that high average glucose (HbA1c) level is a significant risk factor for stroke.\n\n\nCode\n# p1e p1f p1g p1h\n# (e) Histogram of ever_married\n# (f) Histogram of work_type\n# (g) Histogram of Residence_type\n# (h) Histogram of avg_gloucose_level\nggarrange(p1e, p1f, p1g, p1h,\n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (e)ever_married, (f)work_type, (g)Residence_type, (h)avg_gloucose_level.\n\n\n\n\nWe can observe from the histograms (i) and (j) the following:\nFor the BMI distribution we can observe that the majority of the patient population (pink bars) falls within the overweight to obese range (BMI \\(\\approx 25\\) to \\(35\\)). So as a consequence we can expect that the frequency of stroke cases (blue bars) will follow the distribution of the overall population, meaning most strokes occur where the largest number of people are located which are the BMI values between \\(25\\) and \\(35\\).\nHowever, we can visually spot that the stroke occurence is drops significantly closer to a healthy BMI of 20. So although the risk of stroke does seem to be generally higher than average once BMI exceeds the ideal range and moves into the overweight and obese categories because there is a larger distribution within the overweight to obese range, we can conclude that because the skewed distributin that BMI is a significant risk factor predictor for stroke.\nThe stroke outcomes are compared across the three smoking status categories encoded: smokes = 3, formerly smoked = 2, and never smoked = 1.\nThis plot is highlights a particularly interesting aspect of this dataset. The highest proportional risk of stroke appears to be in the formerly smoked group. This finding is common in medical literature[oshunbade2020cigarette?], as individuals who have a history of smoking may have accrued vascular damage that persists, but their stroke risk is still lower than the risk for current smokers if they continue to smoke.\nThis information is importante, because the formerly smoked group shows the highest rate, suggesting that a history of smoking is a significant indicator of risk.\n\n\nCode\n# p1i p1j\n# (i) Histogram of bmi\n# (j) smoking_status\nggarrange(p1i, p1j,\n          ncol = 2, nrow = 1, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (i)bmi, (j)smoking_status.\n\n\n\n\n\n\n3.2.3 Correlation Analysis\n\n\nCode\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\np2 &lt;- ggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   # high contrast red→white→blue\n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n\n\nInterpretation\nCorrelation Heatmap of Key Numeric Predictors\nAll correlations are weak to moderate (0.00–0.26) → no multicollinearity concerns.\nAge shows small but meaningful positive correlations with:\nglucose (0.24)\nhypertension (0.26)\nheart disease (0.26) → consistent with known aging-related cardiovascular risk patterns.\nBMI has very weak correlations with all other predictors (0.04–0.16) → behaves independently in this dataset.\nAvg glucose moderately correlates with:\nhypertension (0.17)\nheart disease (0.14) → aligns with metabolic/vascular relationships.\nHypertension and heart disease are weakly correlated (0.11) → related but not redundant.\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\n\n\nCode\np2\n\n\n\n\n\nCorrelation Analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3. Statistical Modelling\nInitially, we split the dataset into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, then we used this training data for our statistical modelling. It is important to note that during splitting, stratified sampling was used (via caret::createDataPartition) to maintain the stroke/no-stroke ratio.[6]\n\n\n\nCode\n# This reflects Draft 08 Line 904\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\nindex &lt;- createDataPartition(strokeclean$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- strokeclean[index, ]\ntest_data  &lt;- strokeclean[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\n# Added from draft 08 line 650 approx\nn &lt;- nrow(strokeclean)\ntrain_index &lt;- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train &lt;- strokeclean[train_index, ]\nstroke_test  &lt;- strokeclean[-train_index, ]\n\n\n\n\nCode\n# Convert all multi-level categoricals to factors with a clear reference level\ntrain_data$work_type     &lt;- factor(train_data$work_type)\ntrain_data$Residence_type&lt;- factor(train_data$Residence_type)\ntrain_data$smoking_status&lt;- factor(train_data$smoking_status)\n\n# The same should be done for test_data and the binary variables \ntest_data$work_type     &lt;- factor(test_data$work_type)\ntest_data$Residence_type&lt;- factor(test_data$Residence_type)\ntest_data$smoking_status&lt;- factor(test_data$smoking_status)\n\n# if you want the output to label the levels (e.g., \"Male\" vs \"Female\")\n# instead of \"gender\" and \"gender1\" (for Male = 1 vs Female = 0).\n# For 0/1, R's glm is usually fine, but for clean output factors are better.\n# For multi-level, it's essential.\n\n\n\n3.3.1. Repeated K-fold cross-validation\nThe trainControl() function in the R caret package is used to control the computational nuances and resampling methods employed by the train() function. It allows us to implement Repeated K-fold cross-validation (“repeatedcv”).\n\n\nCode\nctrl &lt;- trainControl(\nmethod = \"repeatedcv\",\nnumber = 5,\nrepeats = 3,\nclassProbs = TRUE,\nsummaryFunction = twoClassSummary,\nverboseIter = FALSE\n)\n\n\n\n\n3.3.2. Logistic Regression\n\n\nCode\nmodel_lr2 &lt;- glm(\n  stroke ~ . , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\ns1 &lt;- summary(model_lr2)\nc1 &lt;- coefficients(model_lr2)\nanova1 &lt;- car::Anova(model_lr2, type = 3)\nconfint1 &lt;- confint(model_lr2, level=0.95)\n\nmodel_lr_caret &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n# Added from Draft 08 line 658 approx\nfit_glm &lt;- glm(\n  stroke ~ age + hypertension + heart_disease +\n    avg_glucose_level + bmi + smoking_status +\n    gender + ever_married,\n  data   = stroke_train,\n  family = binomial(link = \"logit\")\n)\n\n\nInterpretation — Logistic Regression Coefficients\n\n# s1\n# anova1\nsummary(fit_glm)\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.633394   0.852329 -10.129  &lt; 2e-16 ***\nage                0.068436   0.008078   8.472  &lt; 2e-16 ***\nhypertension       0.190290   0.234511   0.811 0.417116    \nheart_disease      0.410816   0.267339   1.537 0.124370    \navg_glucose_level  0.005472   0.001652   3.313 0.000922 ***\nbmi                0.020120   0.014897   1.351 0.176838    \nsmoking_status     0.237041   0.129292   1.833 0.066747 .  \ngender            -0.157680   0.203078  -0.776 0.437485    \never_married      -0.080830   0.330754  -0.244 0.806935    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 941.73  on 2348  degrees of freedom\nResidual deviance: 781.05  on 2340  degrees of freedom\nAIC: 799.05\n\nNumber of Fisher Scoring iterations: 7\n\n\n\nAge is a strong and highly significant predictor (p &lt; 0.001). Higher age is associated with a substantial increase in the odds of stroke.\nHypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\nAverage glucose level is also a important predictor (p = 0.0267). Higher glucose values modestly increase stroke risk.\nHeart disease shows a positive association but is only borderline significant (p = 0.0718). This suggests a potential effect, but not statistically explainable in this model.\nSmoking has likewise borderline significant (p = 0.0714), indicating a increased risk among smokers, but the evidence is not too much strong.\nBMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p &gt; 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\nModel fit improved substantially from the null model (deviance reduced from 953.4 → 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\nOdds ratios and confidence intervals\n\n\nCode\n# Odds ratios and 95% confidence intervals\ncoef_est2 &lt;- coef(model_lr2)\nOR2       &lt;- exp(coef_est2)\n\nconf_int2 &lt;- exp(confint(model_lr2))  # confidence intervals on OR scale\n# conf_int &lt;- confint(model_lr2, level=0.95)\n\nodds_table2 &lt;- cbind(OR2, conf_int2)\ncolnames(odds_table2) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table2, 3)\n\n# Added from Draft 08 line 694\ncoef_est &lt;- coef(fit_glm)\nOR       &lt;- exp(coef_est)\n\nconf_int &lt;- exp(confint(fit_glm))  \n\nodds_table &lt;- cbind(OR, conf_int)\ncolnames(odds_table) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n\n\nInterpretation\n\nodds_table\n\n                            OR        2.5 %       97.5 %\n(Intercept)       0.0001780593 0.0000311787 0.0008857738\nage               1.0708317177 1.0544774500 1.0884788397\nhypertension      1.2096009088 0.7546566719 1.8966309538\nheart_disease     1.5080478560 0.8782190084 2.5130611342\navg_glucose_level 1.0054874901 1.0022122857 1.0087335424\nbmi               1.0203233902 0.9902606632 1.0498223369\nsmoking_status    1.2674928164 0.9815539230 1.6312062315\ngender            0.8541234280 0.5708767806 1.2677184293\never_married      0.9223500329 0.4990221707 1.8449515733\n\n\nThe logistic regression findings demonstrate how each predictor impacts the likelihood of having a stroke, while keeping other variables constant:\n\nAge (OR = 1.075, CI: 1.059–1.093) Age is the strongest continuous predictor. Each additional year of age increases the odds of stroke by about 7.5%, and the confidence interval does not include 1, indicating strong statistical significance.\nHypertension (OR = 1.577, CI: 0.996–2.450) Individuals with hypertension have roughly 58% higher odds of stroke compared to those without hypertension, although the lower CI bound is just below 1. This suggests a borderline significant effect, but clinically important.\nHeart disease (OR = 1.628, CI: 0.942–2.733) Heart disease increases stroke odds by about 63%, but the CI includes 1, implying the association is positive but not statistically strong in this dataset.\nAverage glucose level (OR = 1.004, CI: 1.000–1.007) Higher glucose levels are associated with slightly increased stroke risk. Though the effect is small, the CI indicates marginal significance, aligning with known metabolic risk patterns.\nBMI (OR = 1.007, CI: 0.975–1.037) BMI shows almost no meaningful effect on stroke risk, and the CI overlaps 1. This predictor does not significantly influence stroke likelihood in this dataset.\nSmoking (Fsmoked OR = 1.263; Smokes OR = 1.598)\nFormer smokers have 26% higher odds, but CI crosses 1 → weak evidence.\nCurrent smokers have ~60% higher odds, but CI still overlaps 1 → suggests increased risk but not statistically conclusive here.\nGender (Female) (OR = 1.259; CI: 0.842–1.903) Females show slightly higher odds, but this effect is not statistically significant.\nEver married (OR = 1.126; CI: 0.590–2.013) Marital status has no clear effect on stroke odds in this sample.\n\nModel predictions and performance on the test set\n\n\nCode\n# 1) Predicted probabilities from logistic regression\ntest_data$pred_prob &lt;- predict(\n  model_lr2,\n  newdata = test_data,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\ntest_data$stroke &lt;- factor(test_data$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\ntest_data$pred_class &lt;- ifelse(test_data$pred_prob &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class &lt;- factor(test_data$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm2 &lt;- confusionMatrix(\n  data      = test_data$pred_class,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n\n# added from Draft 08 from line 735\nstroke_test$pred_prob &lt;- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\nstroke_test$stroke &lt;- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\nstroke_test$pred_class &lt;- ifelse(stroke_test$pred_prob &gt;= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class &lt;- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\ncm &lt;- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\n\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  947  61\n       Yes   0   0\n                                          \n               Accuracy : 0.9395          \n                 95% CI : (0.9229, 0.9534)\n    No Information Rate : 0.9395          \n    P-Value [Acc &gt; NIR] : 0.534           \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : 1.564e-14       \n                                          \n            Sensitivity : 0.00000         \n            Specificity : 1.00000         \n         Pos Pred Value :     NaN         \n         Neg Pred Value : 0.93948         \n             Prevalence : 0.06052         \n         Detection Rate : 0.00000         \n   Detection Prevalence : 0.00000         \n      Balanced Accuracy : 0.50000         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nFrom the confusion matrix, the following performance metrics are defined:\nAccuracy \\[\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n\\] Sensitivity (Recall / True Positive Rate)\n\\[\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n\\] Specificity (True Negative Rate)\n\\[\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n\\]\nPositive Predictive Value (Precision) \\[\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n\\] Negative Predictive Value (NPV)\n\\[\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n\\]\nInterpretation of Logistic Regression Performance (Test Set)\n\nAccuracy = 94.25% The model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\nSensitivity (True Positive Rate) = 0.017 The model correctly identified only 1 out of 59 actual stroke cases (≈1.7%). → This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\nSpecificity (True Negative Rate) = 1.00 The model correctly classified all non-stroke cases. → It is extremely good at predicting “No stroke,” which dominates the dataset.\nPositive Predictive Value (Precision) = 1.00 When the model predicts “Yes,” it is always correct — but it predicted “Yes” only once. High precision is misleading because the model rarely predicts a positive case.\nNegative Predictive Value = 0.942 Most “No” predictions are correct, matching the overall class imbalance.\nKappa = 0.031 Kappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\nBalanced Accuracy = 0.508 When weighting sensitivity and specificity equally, the model performs at chance level (~50%). → Confirms that stroke detection is weak.\nMcNemar’s Test p &lt; 0.0001 Strong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity. It performs well for the majority class (non-stroke), but fails for the minority class (stroke).\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\nROC curve and AUC for the logistic model\n\n\nCode\n# Compute ROC\nroc_glm2 &lt;- roc(\n  response  = test_data$stroke,\n  predictor = test_data$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"&lt;\"\n)\n\nauc_val2 &lt;- auc(roc_glm2)\n\n# Extract data for ggplot\nroc_df2 &lt;- data.frame(\n  fpr = rev(1 - roc_glm2$specificities),\n  tpr = rev(roc_glm2$sensitivities)\n)\n\n# Plot\nroc_plot2 &lt;- ggplot(roc_df2, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val2, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n# added from Draft 08 line 830\n# Compute ROC\nroc_glm &lt;- roc(\n  response  = stroke_test$stroke,\n  predictor = stroke_test$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"&lt;\"\n)\n\nauc_val &lt;- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df &lt;- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nroc_plot &lt;- ggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\nroc_plot\n\n\n\n\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\nInterpretation of ROC Curve and AUC (Test Set)\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\nThe AUC = 0.815, which indicates good discriminative performance.\nAUC = 0.5 is no discrimination (random guessing)\nAUC = 0.7–0.8 is acceptable\nAUC = 0.8–0.9 is good\nAUC &gt; 0.9 is excellent\n\nEven though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\nThe strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\nthreshold tuning,\ncost-sensitive training,\nresampling techniques (SMOTE / oversampling).\n\nLogistic Regression (caret)\n\n\nCode\n# Added from Draft 08 line 937 \nmodel_lr &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\n\n\n3.3.3. Decision Tree\n\n\nCode\nmodel_tree &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n\n\n\n\n3.3.4. Random Forest\n\n\nCode\nmodel_rf &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n\n\n\n\n3.3.5. Gradient Boosted Machine (GBM)\n\n\nCode\nmodel_gbm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n\n\n\n\n3.3.6. k-Nearest Neighbours (k-NN)\n\n\nCode\nmodel_knn &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\n\n\n3.3.7. Support Vector Machine (Radial)\n\n\nCode\nmodel_svm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\n\n\n\n3.4. Model Evaluation\n\nModel evaluation on the test set\n\n\nCode\nmodels_list2 &lt;- list(\nLR   = model_lr_caret, # Works with caret\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults2 &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list2)) {\nmdl2 &lt;- models_list2[[m]]\n\n# Probabilities for the \"Yes\" class\n\npreds_prob2  &lt;- predict(mdl2, test_data, type = \"prob\")[, \"Yes\"]\n\n# Class predictions\n\npreds_class2 &lt;- predict(mdl2, test_data)\n\n# ROC & AUC\n\nroc_obj2 &lt;- roc(test_data$stroke, preds_prob2,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val2 &lt;- auc(roc_obj2)\n\n# Confusion matrix – positive = \"Yes\"\n\ncm_m2 &lt;- confusionMatrix(preds_class2, test_data$stroke, positive = \"Yes\")\n\nresults2 &lt;- rbind(\nresults2,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val2),\nAccuracy    = cm_m2$overall[\"Accuracy\"],\nSensitivity = cm_m2$byClass[\"Sensitivity\"],\nSpecificity = cm_m2$byClass[\"Specificity\"]\n)\n)\n}\n\n\n\n\nCode\n# Added from Draft 08 line 1010\nmodels_list &lt;- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl &lt;- models_list[[m]]\n\npreds_prob  &lt;- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\npreds_class &lt;- predict(mdl, test_data)\n\nroc_obj &lt;- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val &lt;- auc(roc_obj)\n\ncm_m &lt;- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults &lt;- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\n\n\nresults\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7809063 0.9453823  0.01851852   0.9979014\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7214352 0.9443893  0.01851852   0.9968520\nAccuracy3   GBM 0.7570343 0.9443893  0.01851852   0.9968520\nAccuracy4   KNN 0.6664335 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6155999 0.9443893  0.01851852   0.9968520\n\n\nInterpretation\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\n\n\nROC curve comparison across models\n\n\nCode\n# 1. Create ROC objects for each model\nroc_list2 &lt;- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr_caret,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\")\n)\n\n# 2. AUC values\nauc_vals2 &lt;- sapply(roc_list2, auc)\n\n# 3. Long data frame of ROC coordinates\nroc_df2 &lt;- do.call(rbind, lapply(names(roc_list2), function(m) {\n  r2 &lt;- roc_list2[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r2$specificities),\n    sensitivity = rev(r2$sensitivities)\n  )\n}))\n\n# Treat model as factor in a consistent order\nroc_df2$model &lt;- factor(roc_df2$model, levels = names(roc_list2))\n\n# 4. Legend labels with AUC\nlabel_map2 &lt;- paste0(names(auc_vals2), \" (AUC = \", sprintf(\"%.3f\", auc_vals2), \")\")\nnames(label_map2) &lt;- names(auc_vals2)\n\n# 5. Color palette by short model name\nmodel_cols2 &lt;- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\n# 6. Plot\np3 &lt;- ggplot(roc_df2, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols2,\n    breaks = names(label_map2),\n    labels = label_map2,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n\n\n\n\nCode\n# Code added from Draft 08 line 1071\nroc_list &lt;- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\")\n)\n\nauc_vals &lt;- sapply(roc_list, auc)\n\nroc_df &lt;- do.call(rbind, lapply(names(roc_list), function(m) {\n  r &lt;- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\nroc_df$model &lt;- factor(roc_df$model, levels = names(roc_list))\n\nlabel_map &lt;- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) &lt;- names(auc_vals)\n\nmodel_cols &lt;- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\np3_2 &lt;- ggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n\n\n\n\nCode\np3_2\n\n\n\n\n\nROC curve comparison across models.\n\n\n\n\nInterpretation\nInterpretation of ROC Comparison Across Models\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\nAll models perform above 0.5, meaning they all do better than random chance — but with large differences in quality.\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\n\n\nOdds ratios and risk stratification\n\n\nCode\n# Fit logistic regression on the same train_data used in the ML comparison\n# makes not sense\n# glm_lr &lt;- glm(\n# stroke ~ age + gender + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status,\n# data   = train_data,\n# family = binomial\n# )\n\n# Coefficients, CIs, p-values\n\nlr_coef2 &lt;- summary(model_lr2)$coefficients           # estimates + p-values\nci_raw2  &lt;- suppressMessages(confint(model_lr2))      # CI on log-odds scale\n\nor_df2 &lt;- data.frame(\nPredictor = rownames(lr_coef2),\nlogOR     = lr_coef2[, \"Estimate\"],\nOR        = exp(lr_coef2[, \"Estimate\"]),\nCI_lower  = exp(ci_raw2[, 1]),\nCI_upper  = exp(ci_raw2[, 2]),\np_value   = lr_coef2[, \"Pr(&gt;|z|)\"]\n) %&gt;%\n# remove intercept\nfilter(Predictor != \"(Intercept)\") %&gt;%\n# nicer labels for the plot\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n# significance flag for colour\nSig = ifelse(p_value &lt; 0.05, \"p &lt; 0.05\", \"NS\")\n) %&gt;%\n# order from lower to higher OR so the plot reads nicely\narrange(OR) %&gt;%\nmutate(Label = factor(Label, levels = Label))\n\n# Forest plot\np4 &lt;- ggplot(or_df2, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p &lt; 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n\n\n\n\nCode\n# Code added from Draft 08 Line 1170\nglm_lr &lt;- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\nlr_coef &lt;- summary(glm_lr)$coefficients           \nci_raw  &lt;- suppressMessages(confint(glm_lr))      \n\nor_df &lt;- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(&gt;|z|)\"]\n) %&gt;% \nfilter(Predictor != \"(Intercept)\") %&gt;%\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n\nSig = ifelse(p_value &lt; 0.05, \"p &lt; 0.05\", \"NS\")\n) %&gt;%\narrange(OR) %&gt;%\nmutate(Label = factor(Label, levels = Label))\n\np4_2 &lt;- ggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p &lt; 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n\n\n\n\nCode\np4_2\n\n\n\n\n\nForest Plot.\n\n\n\n\nInterpretation\nThe Hypertension is the strongest predictor. Its OR is clearly &gt; 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\nThe Age predictor has an OR slightly above 1 with a narrow CI fully above 1 (orange). Therefore we can conclude that for each additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\nThe Average glucose level has an OR just above 1 with a tight CI above 1 (orange). Therefore we can conclude that Higher glucose is associated with a modest but statistically significant increase in stroke risk, consistent with metabolic or diabetes-related vascular risk.\nFor the predictors Ever married, heart disease, smoking status, gender, BMI, residence, work their confidence intervals all cross 1, so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.\nSome predictor like heart disease and smoking still have ORs above 1, suggesting that firther study might find them to be related to elevated risk of stroke, but the evidence is weak in this dataset.\nOverall message:\nThe forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\nThreshold tuning to 0.2 from 0.5\n\n\nCode\n# Threshold tuning: use 0.2 instead of 0.5\nnew_threshold2 &lt;- 0.2\n\ntest_data$pred_class_02 &lt;- ifelse(test_data$pred_prob &gt;= new_threshold2,\n                                    \"Yes\", \"No\")\n\ntest_data$pred_class_02 &lt;- factor(test_data$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\n# Confusion matrix for threshold = 0.2\ncm2_02 &lt;- confusionMatrix(\n  data      = test_data$pred_class_02,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n\n\n\n\nCode\n# Code added from Draft 08 Line 1266\nnew_threshold &lt;- 0.2\n\nstroke_test$pred_class_02 &lt;- ifelse(stroke_test$pred_prob &gt;= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 &lt;- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\ncm_02 &lt;- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\n\n\n\nCode\n# Confusion matrix for threshold = 0.2\n# cm2_02\ncm_02\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  916  51\n       Yes  31  10\n                                       \n               Accuracy : 0.9187       \n                 95% CI : (0.9, 0.9348)\n    No Information Rate : 0.9395       \n    P-Value [Acc &gt; NIR] : 0.99675      \n                                       \n                  Kappa : 0.155        \n                                       \n Mcnemar's Test P-Value : 0.03589      \n                                       \n            Sensitivity : 0.163934     \n            Specificity : 0.967265     \n         Pos Pred Value : 0.243902     \n         Neg Pred Value : 0.947260     \n             Prevalence : 0.060516     \n         Detection Rate : 0.009921     \n   Detection Prevalence : 0.040675     \n      Balanced Accuracy : 0.565600     \n                                       \n       'Positive' Class : Yes          \n                                       \n\n\nInterpretation (threshold = 0.2)\n\nWith a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\nSpecificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as “no stroke” (903 out of 949).\nWhile overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives."
  },
  {
    "objectID": "posts/renan-blog-post-draft09/index.html#conclusion",
    "href": "posts/renan-blog-post-draft09/index.html#conclusion",
    "title": "Draft v09 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThis experiment compared a conventional logistic regression model with several machine-learning algorithms and examined whether common demographic, behavioral, and clinical characteristics may be used to predict stroke risk using a stroke dataset. Stroke was a rare outcome (about 5% of cases) in the final sample of 3,357 people that was analyzed after the data was cleaned and inconsistent or missing values were eliminated. In addition to reflecting actual epidemiology, this significant class disparity complicates classification, particularly when it comes to identifying the minority (stroke) class.\nAge, hypertension, cardiac disease, and raised average glucose levels are among the best predictors of stroke, according to the baseline logistic regression model. Smoking status substantially increased risk. These variables were identified as significant risk factors by odds ratios significantly greater than 1 and confidence intervals that did not cross 1. These results support the use of logistic regression as an interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness.\nThe logistic regression model performed reasonably well overall in terms of prediction; however, sensitivity for stroke cases was more constrained at the default 0.5 probability threshold, as would be expected with an imbalanced outcome. The model clearly outperformed random guessing, according to the ROC curve and AUC values, but there was still space for improvement in terms of differentiating between stroke and non-stroke patients. Youden’s J statistic offers a method for selecting a different categorization threshold that enhances the ratio of sensitivity to specificity, which may be crucial in a screening setting when it is expensive to miss actual stroke cases.\nMore sophisticated models, such Random Forest and Gradient Boosted Machine, were able to attain somewhat higher AUC values than logistic regression in the machine-learning comparison, showing superior discrimination across a range of thresholds. However, these increases in AUC came at the expense of decreased interpretability and were not always accompanied by significant increases in sensitivity at fixed cut-offs. Logistic regression, on the other hand, offers precise odds ratios and confidence intervals that are simpler for public health professionals and doctors to understand when discussing risk and developing interventions.\nBecause of the severe class imbalance, sensitivity for stroke cases was extremely low (around 2%), meaning that the model almost never predicted “stroke = Yes” and therefore missed most true stroke cases.\nTo address this, the decision threshold was lowered from 0.5 to 0.2. At this cut-off, sensitivity increased from roughly 2% to about 22%, while specificity remained high at around 95%. Overall accuracy dropped slightly to about 91%, but balanced accuracy improved, indicating a more reasonable trade-off between detecting stroke cases and avoiding false positives. This threshold experiment illustrates a key practical point: for rare but serious outcomes such as stroke, it can be preferable to sacrifice some overall accuracy in order to reduce the number of missed high-risk individuals. In this setting, the logistic model is more appropriately viewed as a screening or risk-flagging tool rather than a definitive diagnostic rule.\nOverall, the findings show that relatively simple models built from routinely collected health indicators can meaningfully distinguish between individuals with and without stroke, even in the presence of substantial class imbalance. Logistic regression emerges as a strong, interpretable baseline, while tree-based ensemble methods provide incremental performance improvements at the cost of transparency. Future work could focus on external validation, calibration assessment, more sophisticated imbalance-handling techniques, and the inclusion of additional clinical or longitudinal information. These extensions would help move from proof-of-concept modelling toward robust, clinically usable tools for stroke risk stratification and targeted prevention.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2)."
  },
  {
    "objectID": "posts/renan-blog-post-code01/index.html",
    "href": "posts/renan-blog-post-code01/index.html",
    "title": "Reproducing Shree code - v01",
    "section": "",
    "text": "Code\n# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\")\n# install.packages(packages)\n\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n\n# Set seed for reproducibility\nset.seed(123)\nLoading Dataset:\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nsteve_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\nHandling Dataset Features\nCode\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nRemoving NAs and cleaning Dataset\nCode\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\nCode that Shree used"
  },
  {
    "objectID": "posts/renan-blog-post-code01/index.html#managing-uncommon-categories-like-the-gender-group-other",
    "href": "posts/renan-blog-post-code01/index.html#managing-uncommon-categories-like-the-gender-group-other",
    "title": "Reproducing Shree code - v01",
    "section": "Managing uncommon categories (like the gender group “Other”)",
    "text": "Managing uncommon categories (like the gender group “Other”)\nCode –\n\nstroke$gender[stroke$gender == \"Other\"] = \"Male\"\n\nWarning in `[&lt;-.factor`(`*tmp*`, stroke$gender == \"Other\", value =\nstructure(c(1L, : invalid factor level, NA generated\n\nstroke$gender = droplevels(stroke$gender)"
  },
  {
    "objectID": "posts/renan-blog-post-code01/index.html#using-median-imputation-to-impute-missing-bmi-values",
    "href": "posts/renan-blog-post-code01/index.html#using-median-imputation-to-impute-missing-bmi-values",
    "title": "Reproducing Shree code - v01",
    "section": "Using median imputation to impute missing BMI values",
    "text": "Using median imputation to impute missing BMI values\nCode-\n\nstroke$bmi[is.na(stroke$bmi)] = median(stroke$bmi, na.rm = TRUE)"
  },
  {
    "objectID": "posts/renan-blog-post-code01/index.html#convert-bmi-into-numberic",
    "href": "posts/renan-blog-post-code01/index.html#convert-bmi-into-numberic",
    "title": "Reproducing Shree code - v01",
    "section": "Convert Bmi into numberic",
    "text": "Convert Bmi into numberic\n\nstroke$bmi[stroke$bmi == \"N/A\"] = NA\nstroke$bmi = as.numeric(stroke$bmi)\nmedian_bmi = median(stroke$bmi, na.rm = TRUE)\nstroke$bmi[is.na(stroke$bmi)] &lt;- median_bmi\nsummary(stroke$bmi)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  11.50   25.40   29.20   30.44   34.20   92.00"
  },
  {
    "objectID": "posts/renan-blog-post-code01/index.html#traintest-division",
    "href": "posts/renan-blog-post-code01/index.html#traintest-division",
    "title": "Reproducing Shree code - v01",
    "section": "Train/Test division:",
    "text": "Train/Test division:\n\nset.seed(123)\nindex = createDataPartition(stroke$stroke, p = 0.7, list = FALSE)\ntrain_data  = stroke[index, ]\ntest_data   = stroke[-index, ]\nprop.table(table(train_data$stroke))\n\n\n        No        Yes \n0.94638298 0.05361702 \n\nprop.table(table(test_data$stroke))\n\n\n        No        Yes \n0.94637537 0.05362463"
  },
  {
    "objectID": "posts/renan-blog-post-draft05/notest.html",
    "href": "posts/renan-blog-post-draft05/notest.html",
    "title": "changes and notes",
    "section": "",
    "text": "Old text for Dataset Preprocessing\nThe initial exploration demonstrated that the Stroke Prediction Dataset @kaggle01 has several issues requiring changes for handling missing values, converting character (categorical) features into numerical codes, and removing the identifier column.\nOur initial step is to addresses specific string values that represent missing data or require special handling:\n\nAll instances of the string values “N/A”, “Unknown”, “children”, and “other” across the entire dataset were replaced with the standard R missing value representation, NA.\n\nThen we must convert the data type of several character (categorical) features into numerical (integer) codes for use in machine learning models. The bmi column, which was initially read as character due to the presence of NA values, was converted to numeric then rounded to two decimal places. The categorical gender feature was re-coded to numeric with the values “Male” = 1 and “Female” = 0. The categorical ever_married feature was re-coded to numeric with the values “Yes” = 1 and “No” = 0. The categorical work_type feature was re-coded to numeric with values “Govt_job” \\(\\rightarrow 1\\), “Private” \\(\\rightarrow 2\\), “Self-employed” \\(\\rightarrow 3\\), “Never_worked” \\(\\rightarrow 4\\). The categorical Residence_type feature was re-coded to numeric with values “Urban” \\(\\rightarrow 1\\) and “Rural” \\(\\rightarrow 2\\). The categorical smoking_status feature was re-coded to numeric with values “never smoked” \\(\\rightarrow 1\\)“, formerly smoked” \\(\\rightarrow 2\\) and “smokes” \\(\\rightarrow 3\\). Additionally avg_glucose_level, heart_disease, hypertension, age, and stroke were all explicitly converted or confirmed as numeric data types, with age being rounded to two decimal places.\nLastly, the id column, which is a unique identifier and not useful for predictive modeling, was removed from the dataset leaving us with 11 predictors. Now we can proceed on converting the target Variable stroke variable in stroke1 to a factor (a categorical type used in R). Removal of missing and inconsistent entries and finally creating the Data Frames strokeclean and fourassume. Then the stroke factor levels were explicitly labeled 0 \\(\\rightarrow\\) “No” and 1 \\(\\rightarrow\\) “Yes”.\n\nSo as part of data preprocessing we will be focused on establishing consistency and ensuring all variables are in a format suitable for predictive modeling. This process starts by systematically addressing non-standard representations of missing data. Specifically, all instances of the string values “N/A”, “Unknown”, “children”, and “other” found across the dataset were unified and replaced with the standard statistical missing value representation, NA.\nThen we proceed with converting several character-based (categorical) features into numerical features, which is necessary for predictive modeling.\n\n\n#| code-fold: true\n#| warning: false\n#| message: false\n\nnumeric_vars = strokeclean[, c(\"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\")]\n\ncorr_matrix = cor(numeric_vars)\n\nggcorrplot::ggcorrplot(\n  corr_matrix,\n  lab = TRUE,\n  colors = c(\"purple\", \"gold\", \"grey\"),\n  title = \"Correlation Heatmap of Key Predictors\"\n)\n# 1. Prepare data for correlation: Convert factor target variable to numeric\nnum_vars = strokeclean[, c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\", \"stroke\")]\n\n# 2. Calculate the correlation matrix\ncorr_matrix2 &lt;- cor(num_vars)\n\n# 3. Generate the correlation plot\n# png(\"correlation_matrix.png\", width = 8, height = 8, units = \"in\", res = 300)\n\nggcorrplot(corr_matrix2,\n           hc.order = TRUE,\n           type = \"lower\", # Show only the lower triangle for clarity\n           lab = TRUE,\n           lab_size = 2.5,\n           method = \"circle\",\n           colors = c(\"#6D95E3\", \"white\", \"#E36D95\"), # Blue-White-Red/Pink Palette\n           title = \"Correlation Matrix of Stroke Predictors\",\n           tl.cex = 8)\n\ndev.off()\n#| code-fold: true\n#| \n# --- Prepare data for correlation matrix ---\n# Convert all factors to numeric representations for correlation\n# use model.matrix to perform one-hot encoding on categorical variables\ndf_numeric &lt;- model.matrix(~.-1, data = strokeclean) |&gt;\n  as.data.frame()\n\n# Rename columns for clarity (model.matrix adds prefixes)\ncolnames(df_numeric) &lt;- gsub(\"gender|work_type|smoking_status|Residence_type|ever_married\", \"\", colnames(df_numeric))\n\n# 1. Calculate the correlation matrix\ncorrelation_matrix &lt;- cor(df_numeric)\n\n# 2. Define a green sequential color palette\n# green_palette &lt;- colorRampPalette(c(\"#E5F5E0\", \"#31A354\"))(200) # Light to dark green\ngreen_palette &lt;- colorRampPalette(c(\"#d5ffc8ff\", \"#245332ff\"))(200) \n\n# corrplot(correlation_matrix, method = 'number') # colorful number\n# 3. Create the heatmap with the correct palette\ncorrplot(correlation_matrix, \n         method = \"color\",\n         type = \"full\", # change to full or upper\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         addCoef.col = \"black\",\n         number.cex = 0.7,\n         col = green_palette, # Use the new palette here\n         diag = FALSE)"
  },
  {
    "objectID": "posts/renan-blog-post-draft05/notest.html#correlation-plots",
    "href": "posts/renan-blog-post-draft05/notest.html#correlation-plots",
    "title": "changes and notes",
    "section": "",
    "text": "#| code-fold: true\n#| warning: false\n#| message: false\n\nnumeric_vars = strokeclean[, c(\"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\")]\n\ncorr_matrix = cor(numeric_vars)\n\nggcorrplot::ggcorrplot(\n  corr_matrix,\n  lab = TRUE,\n  colors = c(\"purple\", \"gold\", \"grey\"),\n  title = \"Correlation Heatmap of Key Predictors\"\n)\n# 1. Prepare data for correlation: Convert factor target variable to numeric\nnum_vars = strokeclean[, c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\", \"stroke\")]\n\n# 2. Calculate the correlation matrix\ncorr_matrix2 &lt;- cor(num_vars)\n\n# 3. Generate the correlation plot\n# png(\"correlation_matrix.png\", width = 8, height = 8, units = \"in\", res = 300)\n\nggcorrplot(corr_matrix2,\n           hc.order = TRUE,\n           type = \"lower\", # Show only the lower triangle for clarity\n           lab = TRUE,\n           lab_size = 2.5,\n           method = \"circle\",\n           colors = c(\"#6D95E3\", \"white\", \"#E36D95\"), # Blue-White-Red/Pink Palette\n           title = \"Correlation Matrix of Stroke Predictors\",\n           tl.cex = 8)\n\ndev.off()\n#| code-fold: true\n#| \n# --- Prepare data for correlation matrix ---\n# Convert all factors to numeric representations for correlation\n# use model.matrix to perform one-hot encoding on categorical variables\ndf_numeric &lt;- model.matrix(~.-1, data = strokeclean) |&gt;\n  as.data.frame()\n\n# Rename columns for clarity (model.matrix adds prefixes)\ncolnames(df_numeric) &lt;- gsub(\"gender|work_type|smoking_status|Residence_type|ever_married\", \"\", colnames(df_numeric))\n\n# 1. Calculate the correlation matrix\ncorrelation_matrix &lt;- cor(df_numeric)\n\n# 2. Define a green sequential color palette\n# green_palette &lt;- colorRampPalette(c(\"#E5F5E0\", \"#31A354\"))(200) # Light to dark green\ngreen_palette &lt;- colorRampPalette(c(\"#d5ffc8ff\", \"#245332ff\"))(200) \n\n# corrplot(correlation_matrix, method = 'number') # colorful number\n# 3. Create the heatmap with the correct palette\ncorrplot(correlation_matrix, \n         method = \"color\",\n         type = \"full\", # change to full or upper\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         addCoef.col = \"black\",\n         number.cex = 0.7,\n         col = green_palette, # Use the new palette here\n         diag = FALSE)"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html",
    "href": "posts/renan-blog-post-week8/index.html",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "",
    "text": "For the Week 8 we will continue to reproduce Steve’s findings with the dataset[1].\nYou can download the Dataset from the following link: Stroke Prediction Dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week8/index.html#setup-and-data-loading",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.\n\n1.1 Load Libraries\n\n\nCode\n# Run this once to install all the necessary packages\n# install.packages(\"dplyr\")\n# install.packages(\"car\")\n# install.packages(\"ResourceSelection\")\n# install.packages(\"caret\")\n# install.packages(\"rcompanion\")\n# install.packages(\"pROC\")\n# install.packages(\"cvAUC\")\n\n\nWe can use this to check installed packages:\n```{r}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\nCode\n# For data manipulation and visualization\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\nlibrary(pscl)\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nlibrary(caret)\nlibrary(rcompanion)\nlibrary(Hmisc)\nlibrary(pROC)\nlibrary(cvAUC)\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n\n\n\n\nPossible Dependencies Conflict\n\n\n\nNeed to further analyse if there are conflicts and System Dependency issues.\n\n\n\n\n1.2 Load Data\nWill be using my original Dataset as well Steve’s Dataset and compare for differences.\nRenan: kaggle_data1 Steve: stroke1\n\n1.2.1 Renan Dataset\nBelow will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n# unique(kaggle_data1$bmi)\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# Remove the 'Other' gender row and the 'id' column\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  filter(gender != \"Other\") %&gt;%\n  select(-id) %&gt;%\n  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling\n\n\n\n\n1.2.1 Steve Dataset\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n\n\n\n\n\n1.3 Prepare Dataset\nFor each Column…removing the unncessary or unusable variables:\n\nSmoking Status - remove unknown\nbmi - remove N/A\nWork type - remove children\nage create numerical variable with 2 places after the decimal\ngender -remove other\n\nExploring Dataset so we can plan on how to proceed and possible changes.\n\n\nCode\nhead(stroke1)\nnrow(stroke1)\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n\n\nIn each column..that has data points that are not usable, recoding those datapoints to become”N/A”\n\n\nCode\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\n\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\n\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\n\nWarning: NAs introduced by coercion\n\n\nCode\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\n\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\n\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\n\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\n\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\n\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\n\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\n\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\n\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\n\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nstroke1_clean &lt;- na.omit(stroke1)\n\n\nconverted all columns to numeric and removed id\n\n# converted all columns to numeric and removed id\nstr(stroke1_clean)\nnrow(stroke1_clean)\nLR_stroke1 &lt;- stroke1_clean\nstr(LR_stroke1)\ncount_tables &lt;- lapply(LR_stroke1, table)\ncount_tables"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html#apply-logistic-regression",
    "href": "posts/renan-blog-post-week8/index.html#apply-logistic-regression",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "2. Apply Logistic Regression",
    "text": "2. Apply Logistic Regression\nPart 2:Create and Run the Logistic Regression model from the dataset\n\n# Part 2:Create and Run the Logistic Regression model from the  dataset\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke1)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n\n\n\n\n\nIssue - Unbalanced Data set\n\n\n\nThe dataset is oversampling stroke rate by 77%.\n\n\nIssue - Unbalanced Data set\nThe \\(stroke rate = 180/3357 = 054%\\) . But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS.\nThe dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample….but too much time\nBest way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on\n\n# Issue _ Unbalanced Data set #\n# The stroke rate = 180/3357 = 054%. But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS. #\n# The dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample....but too much time #\n# Best way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on #\nds_prev &lt;- .054\npop_prev &lt;- .031\nlog_odds_ds &lt;- qlogis(ds_prev)\nlog_odds_pop &lt;- qlogis(pop_prev)\noffset &lt;- log_odds_pop - log_odds_ds\ncoefs &lt;- coef(model)\ncoefs[1] &lt;- coefs[1] + offset\nprint(coefs)\n\n      (Intercept)            gender               age      hypertension \n     -9.005873116       0.080369937       0.070967479       0.570796782 \n    heart_disease      ever_married         work_type    Residence_type \n      0.417883562       0.174315603      -0.109615162       0.005932360 \navg_glucose_level               bmi    smoking_status \n      0.004657820       0.006275415       0.179921439 \n\n\nOriginal Intercept Coeff = -8.426854231\nChanged intercept Coefficent to take into account current stroke rate or 3.1% = -9.005873116\nall the other intercepts remain the same"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html#testing-logistic-regression-model-assumptions",
    "href": "posts/renan-blog-post-week8/index.html#testing-logistic-regression-model-assumptions",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "3. Testing logistic Regression Model Assumptions",
    "text": "3. Testing logistic Regression Model Assumptions\nPart 3: Testing logistic Regression Model Assumptions\nThere are several assumptions for Logistic Regression. They are:\n\nThe Dependent Variable is binary (i.e, 0 or 1)\nThere is a linear relationship between th logit of the outcome and each predictor\nThere are NO high leverage outliers in the predictors\nThere is No high multicollinearity (ie strong correlations) between predictors\n\n\n3.1 Testing Assumption 1\nTesting Assumption 1: The Dependent Variable is binary (0 or 1)\n\nunique(LR_stroke1$stroke)\n\n[1] 1 0\n\n\n\n\n3.2 Testing Assumption 2\nTesting Assumption 2: There is a linear relationship between the outcome variable and each predictor\nfirst, adjust all predictors so all values are positive\nConclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity\nConclusion: all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression\nConclusion for assumption 2 - Linearity is met\n\nLR_stroke1$genderadj &lt;- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1\n\nLR_stroke1$ageadj &lt;- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1\n\nLR_stroke1$hypertensionadj &lt;- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$heart_diseaseadj &lt;- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$ever_marriedadj &lt;- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1\n\nLR_stroke1$work_typeadj &lt;- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1\n\nLR_stroke1$Residence_typeadj &lt;- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1\n\nLR_stroke1$avg_glucose_leveladj &lt;- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1\n\nLR_stroke1$bmiadj &lt;- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1\n\nLR_stroke1$smoking_statusadj &lt;- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1\n\nstr(LR_stroke1)\n\ntibble [3,357 × 21] (S3: tbl_df/tbl/data.frame)\n $ gender              : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age                 : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension        : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease       : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married        : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type           : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type      : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level   : num [1:3357] 229 106 171 174 186 ...\n $ bmi                 : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status      : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke              : num [1:3357] 1 1 1 1 1 1 1 1 1 1 ...\n $ genderadj           : num [1:3357] 3 3 4 4 3 3 4 4 4 4 ...\n $ ageadj              : num [1:3357] 81 94 63 93 95 88 83 95 75 68 ...\n $ hypertensionadj     : num [1:3357] 1 1 1 2 1 2 1 2 1 1 ...\n $ heart_diseaseadj    : num [1:3357] 2 2 1 1 1 2 1 1 2 1 ...\n $ ever_marriedadj     : num [1:3357] 3 3 3 3 3 3 4 3 3 3 ...\n $ work_typeadj        : num [1:3357] 4 4 4 5 4 4 4 4 3 4 ...\n $ Residence_typeadj   : num [1:3357] 3 4 3 4 3 4 3 4 4 3 ...\n $ avg_glucose_leveladj: num [1:3357] 285 162 227 230 242 ...\n $ bmiadj              : num [1:3357] 49.1 45 46.9 36.5 41.5 39.9 35.3 42.2 49.3 39.8 ...\n $ smoking_statusadj   : num [1:3357] 4 3 5 3 4 3 3 3 5 5 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n\nStrokeAdj &lt;- LR_stroke1\n\nStrokeAdj &lt;- StrokeAdj[ , !(names(StrokeAdj) %in% c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\")) ]\n\nFit the model\n\nmod.2 &lt;- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)\n# Plot Residuals\nresidualPlots(mod.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                     Test stat Pr(&gt;|Test stat|)  \ngenderadj               0.0000          1.00000  \nageadj                  2.0626          0.15095  \nhypertensionadj         0.0000          1.00000  \nheart_diseaseadj        0.0000          1.00000  \never_marriedadj         0.0000          1.00000  \nwork_typeadj            3.1406          0.07636 .\nResidence_typeadj       0.0000          1.00000  \navg_glucose_leveladj    0.0103          0.91921  \nbmiadj                  0.3947          0.52983  \nsmoking_statusadj       0.4775          0.48953  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n3.3 Testing Assumption 3\nTesting Assumption 3: assess influential outliers using car package and influencePlot\n\nalias(model)\n\nModel :\nstroke ~ gender + age + hypertension + heart_disease + ever_married + \n    work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n\n# install.packages(\"Hmisc\")\n# library(Hmisc)\nrcorr(as.matrix(LR_stroke1))\n\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nstroke                -0.01  0.24         0.14          0.14        -0.07\ngenderadj              1.00 -0.06        -0.04         -0.10         0.03\nageadj                -0.06  1.00         0.26          0.26        -0.49\nhypertensionadj       -0.04  0.26         1.00          0.11        -0.11\nheart_diseaseadj      -0.10  0.26         0.11          1.00        -0.07\never_marriedadj        0.03 -0.49        -0.11         -0.07         1.00\nwork_typeadj           0.01  0.14         0.05          0.03        -0.02\nResidence_typeadj     -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\nsmoking_statusadj     -0.08  0.03        -0.01          0.06        -0.06\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nstroke                    0.04          -0.01              0.14  0.01\ngenderadj                 0.01          -0.01             -0.07 -0.02\nageadj                    0.14          -0.02              0.24  0.04\nhypertensionadj           0.05           0.00              0.17  0.13\nheart_diseaseadj          0.03          -0.01              0.14  0.00\never_marriedadj          -0.02           0.01             -0.12 -0.13\nwork_typeadj              1.00          -0.01              0.03 -0.02\nResidence_typeadj        -0.01           1.00              0.01  0.01\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\nsmoking_statusadj        -0.02          -0.04              0.01  0.03\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender                        -0.08  -0.01      1.00  -0.06           -0.04\nage                            0.03   0.24     -0.06   1.00            0.26\nhypertension                  -0.01   0.14     -0.04   0.26            1.00\nheart_disease                  0.06   0.14     -0.10   0.26            0.11\never_married                  -0.06  -0.07      0.03  -0.49           -0.11\nwork_type                     -0.02   0.04      0.01   0.14            0.05\nResidence_type                -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_level              0.01   0.14     -0.07   0.24            0.17\nbmi                            0.03   0.01     -0.02   0.04            0.13\nsmoking_status                 1.00   0.02     -0.08   0.03           -0.01\nstroke                         0.02   1.00     -0.01   0.24            0.14\ngenderadj                     -0.08  -0.01      1.00  -0.06           -0.04\nageadj                         0.03   0.24     -0.06   1.00            0.26\nhypertensionadj               -0.01   0.14     -0.04   0.26            1.00\nheart_diseaseadj               0.06   0.14     -0.10   0.26            0.11\never_marriedadj               -0.06  -0.07      0.03  -0.49           -0.11\nwork_typeadj                  -0.02   0.04      0.01   0.14            0.05\nResidence_typeadj             -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_leveladj           0.01   0.14     -0.07   0.24            0.17\nbmiadj                         0.03   0.01     -0.02   0.04            0.13\nsmoking_statusadj              1.00   0.02     -0.08   0.03           -0.01\n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender                          -0.10            0.03         0.01\nage                              0.26           -0.49         0.14\nhypertension                     0.11           -0.11         0.05\nheart_disease                    1.00           -0.07         0.03\never_married                    -0.07            1.00        -0.02\nwork_type                        0.03           -0.02         1.00\nResidence_type                  -0.01            0.01        -0.01\navg_glucose_level                0.14           -0.12         0.03\nbmi                              0.00           -0.13        -0.02\nsmoking_status                   0.06           -0.06        -0.02\nstroke                           0.14           -0.07         0.04\ngenderadj                       -0.10            0.03         0.01\nageadj                           0.26           -0.49         0.14\nhypertensionadj                  0.11           -0.11         0.05\nheart_diseaseadj                 1.00           -0.07         0.03\never_marriedadj                 -0.07            1.00        -0.02\nwork_typeadj                     0.03           -0.02         1.00\nResidence_typeadj               -0.01            0.01        -0.01\navg_glucose_leveladj             0.14           -0.12         0.03\nbmiadj                           0.00           -0.13        -0.02\nsmoking_statusadj                0.06           -0.06        -0.02\n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender                           -0.01                -0.07  -0.02\nage                              -0.02                 0.24   0.04\nhypertension                      0.00                 0.17   0.13\nheart_disease                    -0.01                 0.14   0.00\never_married                      0.01                -0.12  -0.13\nwork_type                        -0.01                 0.03  -0.02\nResidence_type                    1.00                 0.01   0.01\navg_glucose_level                 0.01                 1.00   0.16\nbmi                               0.01                 0.16   1.00\nsmoking_status                   -0.04                 0.01   0.03\nstroke                           -0.01                 0.14   0.01\ngenderadj                        -0.01                -0.07  -0.02\nageadj                           -0.02                 0.24   0.04\nhypertensionadj                   0.00                 0.17   0.13\nheart_diseaseadj                 -0.01                 0.14   0.00\never_marriedadj                   0.01                -0.12  -0.13\nwork_typeadj                     -0.01                 0.03  -0.02\nResidence_typeadj                 1.00                 0.01   0.01\navg_glucose_leveladj              0.01                 1.00   0.16\nbmiadj                            0.01                 0.16   1.00\nsmoking_statusadj                -0.04                 0.01   0.03\n                     smoking_statusadj\ngender                           -0.08\nage                               0.03\nhypertension                     -0.01\nheart_disease                     0.06\never_married                     -0.06\nwork_type                        -0.02\nResidence_type                   -0.04\navg_glucose_level                 0.01\nbmi                               0.03\nsmoking_status                    1.00\nstroke                            0.02\ngenderadj                        -0.08\nageadj                            0.03\nhypertensionadj                  -0.01\nheart_diseaseadj                  0.06\never_marriedadj                  -0.06\nwork_typeadj                     -0.02\nResidence_typeadj                -0.04\navg_glucose_leveladj              0.01\nbmiadj                            0.03\nsmoking_statusadj                 1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nstroke               0.4296 0.0000 0.0000       0.0000        0.0002      \ngenderadj            0.0000 0.0012 0.0204       0.0000        0.1140      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \nhypertensionadj      0.0204 0.0000 0.0000       0.0000        0.0000      \nheart_diseaseadj     0.0000 0.0000 0.0000       0.0000        0.0000      \never_marriedadj      0.1140 0.0000 0.0000       0.0000        0.0000      \nwork_typeadj         0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_typeadj    0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_statusadj    0.0000 0.0448 0.7537       0.0005        0.0009      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nstroke               0.0259    0.7171         0.0000            0.6866\ngenderadj            0.3863    0.5077         0.0000            0.2487\nageadj               0.0000    0.3076         0.0000            0.0144\nhypertensionadj      0.0051    0.8569         0.0000            0.0000\nheart_diseaseadj     0.0862    0.5527         0.0000            0.8185\never_marriedadj      0.2313    0.5150         0.0000            0.0000\nwork_typeadj         0.0000    0.6768         0.0467            0.3243\nResidence_typeadj    0.6768    0.0000         0.6427            0.5689\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\nsmoking_statusadj    0.3764    0.0208         0.7679            0.0925\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender               0.0000         0.4296 0.0000    0.0012 0.0204         \nage                  0.0448         0.0000 0.0012    0.0000 0.0000         \nhypertension         0.7537         0.0000 0.0204    0.0000 0.0000         \nheart_disease        0.0005         0.0000 0.0000    0.0000 0.0000         \never_married         0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_type            0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_type       0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_level    0.7679         0.0000 0.0000    0.0000 0.0000         \nbmi                  0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_status                      0.2559 0.0000    0.0448 0.7537         \nstroke               0.2559                0.4296    0.0000 0.0000         \ngenderadj            0.0000         0.4296           0.0012 0.0204         \nageadj               0.0448         0.0000 0.0012           0.0000         \nhypertensionadj      0.7537         0.0000 0.0204    0.0000                \nheart_diseaseadj     0.0005         0.0000 0.0000    0.0000 0.0000         \never_marriedadj      0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_typeadj         0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_typeadj    0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_leveladj 0.7679         0.0000 0.0000    0.0000 0.0000         \nbmiadj               0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_statusadj    0.0000         0.2559 0.0000    0.0448 0.7537         \n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender               0.0000           0.1140          0.3863      \nage                  0.0000           0.0000          0.0000      \nhypertension         0.0000           0.0000          0.0051      \nheart_disease        0.0000           0.0000          0.0862      \never_married         0.0000           0.0000          0.2313      \nwork_type            0.0862           0.2313          0.0000      \nResidence_type       0.5527           0.5150          0.6768      \navg_glucose_level    0.0000           0.0000          0.0467      \nbmi                  0.8185           0.0000          0.3243      \nsmoking_status       0.0005           0.0009          0.3764      \nstroke               0.0000           0.0002          0.0259      \ngenderadj            0.0000           0.1140          0.3863      \nageadj               0.0000           0.0000          0.0000      \nhypertensionadj      0.0000           0.0000          0.0051      \nheart_diseaseadj                      0.0000          0.0862      \never_marriedadj      0.0000                           0.2313      \nwork_typeadj         0.0862           0.2313                      \nResidence_typeadj    0.5527           0.5150          0.6768      \navg_glucose_leveladj 0.0000           0.0000          0.0467      \nbmiadj               0.8185           0.0000          0.3243      \nsmoking_statusadj    0.0005           0.0009          0.3764      \n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender               0.5077            0.0000               0.2487\nage                  0.3076            0.0000               0.0144\nhypertension         0.8569            0.0000               0.0000\nheart_disease        0.5527            0.0000               0.8185\never_married         0.5150            0.0000               0.0000\nwork_type            0.6768            0.0467               0.3243\nResidence_type       0.0000            0.6427               0.5689\navg_glucose_level    0.6427            0.0000               0.0000\nbmi                  0.5689            0.0000               0.0000\nsmoking_status       0.0208            0.7679               0.0925\nstroke               0.7171            0.0000               0.6866\ngenderadj            0.5077            0.0000               0.2487\nageadj               0.3076            0.0000               0.0144\nhypertensionadj      0.8569            0.0000               0.0000\nheart_diseaseadj     0.5527            0.0000               0.8185\never_marriedadj      0.5150            0.0000               0.0000\nwork_typeadj         0.6768            0.0467               0.3243\nResidence_typeadj                      0.6427               0.5689\navg_glucose_leveladj 0.6427                                 0.0000\nbmiadj               0.5689            0.0000                     \nsmoking_statusadj    0.0208            0.7679               0.0925\n                     smoking_statusadj\ngender               0.0000           \nage                  0.0448           \nhypertension         0.7537           \nheart_disease        0.0005           \never_married         0.0009           \nwork_type            0.3764           \nResidence_type       0.0208           \navg_glucose_level    0.7679           \nbmi                  0.0925           \nsmoking_status       0.0000           \nstroke               0.2559           \ngenderadj            0.0000           \nageadj               0.0448           \nhypertensionadj      0.7537           \nheart_diseaseadj     0.0005           \never_marriedadj      0.0009           \nwork_typeadj         0.3764           \nResidence_typeadj    0.0208           \navg_glucose_leveladj 0.7679           \nbmiadj               0.0925           \nsmoking_statusadj                     \n\n\n\n# install.packages(\"car\")\n# library(car)\ninfluencePlot(model)\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n83    2.6917353 0.0039267816 0.012237368\n84    1.5018344 0.0343771041 0.006641860\n87    3.0732709 0.0012042796 0.011476828\n131   3.1608870 0.0006013465 0.007697762\n152   3.1135601 0.0005613972 0.006237531\n2583 -0.8509399 0.0399302730 0.001668526\n\n\nCooks D ranges from 0 to .0122\nWhile the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5\nConclusion: Assumption 3 is met - No substantial outliers\n\n\n3.4 Testing Assumption 4\nTesting Assumption 4 : Multicollinearity using vif in the care package\n\nvif(model)\n\n           gender               age      hypertension     heart_disease \n         1.041499          1.213552          1.051213          1.083661 \n     ever_married         work_type    Residence_type avg_glucose_level \n         1.018892          1.051698          1.006965          1.105268 \n              bmi    smoking_status \n         1.117138          1.049260 \n\n\nConclusion. All vif values are below 5 or 10. Ideally most values should be around 1. Range for all\nthe predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10.\nConclusion: No Multicollinearity\nFinal Conclusion: All4 assumptions are met, logistic regression is a valid model\n\n\n3.5 Conclusion of Testing Assumptions\nFinal Conclusion: All 4 assumptions are met, logistic regression is a valid model"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html#analysis-of-the-model",
    "href": "posts/renan-blog-post-week8/index.html#analysis-of-the-model",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "4 Analysis of the Model",
    "text": "4 Analysis of the Model\nPart 4: Analysis of the Model\nThere are 2 issues with the model. Fit and Predictive Capability\n\n4.1 Use Hosmer-lemesho and Naglekerke R\nPart 1 fit. Use Hosmer-lemesho and Naglekerke R for non technical audience\n\n# install.packages(\"ResourceSelection\")\n# library(ResourceSelection)\nhoslem.test(model$y, fitted(model), g = 10)\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model$y, fitted(model)\nX-squared = 5.2704, df = 8, p-value = 0.7283\n\n\n\n# install.packages(\"rcompanion\")\n# library(rcompanion)\nnagelkerke(model)\n\n$Models\n                                                                                                                                                                               \nModel: \"glm, stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, binomial, LR_stroke1\"\nNull:  \"glm, stroke ~ 1, binomial, LR_stroke1\"                                                                                                                                 \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1838790\nCox and Snell (ML)                  0.0739944\nNagelkerke (Cragg and Uhler)        0.2165560\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq    p.value\n     -10     -129.03 258.07 1.0892e-49\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n\n\n\n4.2 Predictive Capability\nPart 2 - Predictive Capability\n\n# install.packages(\"pROC\")\n# library(pROC)\nprobs &lt;- predict(model, type = \"response\")\nroc_obj &lt;- roc(LR_stroke1$stroke, probs)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc(roc_obj)\n\nArea under the curve: 0.8285\n\n\nPredict AUC cross validation\n\n\n\n\n\n\nNeed to implement AUC cross validation\n\n\n\nCould not understand yet how to implement the AUC cross validation\n\n\n\n# Predict AUC cross validation\n# install.packages(\"cvAUC\")\n# library(cvAUC)\n\nConfusion Matrix\n\n# Confusion Matrix\nLR_stroke1$gender &lt;- factor(LR_stroke1$gender)\nLR_stroke1$hypertension &lt;- factor(LR_stroke1$hypertension)\nLR_stroke1$heart_disease &lt;- factor(LR_stroke1$heart_disease)\nLR_stroke1$ever_married &lt;- factor(LR_stroke1$ever_married)\nLR_stroke1$work_type &lt;- factor(LR_stroke1$work_type)\nLR_stroke1$Residence_type &lt;- factor(LR_stroke1$Residence_type)\nLR_stroke1$smoking_status &lt;- factor(LR_stroke1$smoking_status)\nLR_stroke1$stroke &lt;- factor(LR_stroke1$stroke)\n\nfit logistic regression model\n\n# fit logistic regression model\nmodel_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\n\nGet Predicted Probabilities for each observation\n\n# Get Predicted Probabilities for each observation\npred_prob &lt;- predict(model_CM, type = \"response\")\n\ncreate 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC\nClassify prediction using a threshold (0.5 is common but can adjust)\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of around 1.0\n\n# create 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC\n# Classify prediction using a threshold (0.5 is common but can adjust)\n# IF 1 row is all 0's then model doesn't show any predictability\n# At threshold of around 1.0\npred_class &lt;- factor(ifelse(pred_prob &gt; .99, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.9\n\n# At threshold of 0.9\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.9, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.8\n\n# At threshold of 0.8\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.8, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.7\n\n# At threshold of 0.7\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.7, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nAt threshold of 0.6\n\n# At threshold of 0.6\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.6, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  179\n         1    0    1\n\n\nat threshold of 0.6 that starts the models predictability\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision, Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.011050\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.005556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 1.000000\"\n\n\nat threshold of 0.5\n\n# at threshold of 0.5\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.5, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3176  179\n         1    1    1\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.010989\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.005556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.500000\"\n\n\nAt threshold of 0.4\n\n# At threshold of 0.4\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.4, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3171  174\n         1    6    6\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.062500\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.033333\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.500000\"\n\n\nat threshold of 0.3\n\n# at threshold of 0.3\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.3, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3140  164\n         1   37   16\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.137339\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.088889\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.301887\"\n\n\nat threshold of 0.2\n\n# at threshold of 0.2\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.2, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3040  134\n         1  137   46\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.253444\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.255556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.251366\"\n\n\nUsing the different Confusion Matrices, Create the ROC curve"
  },
  {
    "objectID": "posts/renan-blog-post-week8/index.html#conclusion",
    "href": "posts/renan-blog-post-week8/index.html#conclusion",
    "title": "Reproducing Steve’s Code - Week 8",
    "section": "Conclusion",
    "text": "Conclusion\nThe code is unreadable and has several mistakes from Syntax to several implementation errors and System dependencies that I could not meet. So I had to do my best interpretation to reproduce it in Quarto.\n\nIdeas for improving precision, recall and f1_score\nAddress imbalance by upsample (add stroke cases), downsample (remove non strokecases) and or SMOTE (Synthetic data)\nChange the classification threshold\nCompare with Alternative Models such as random forrests or XGBoost\n\n\nReferences\n\n\n1. fedesoriano. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week7/Readme.html",
    "href": "posts/renan-blog-post-week7/Readme.html",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data.\n\n\n\nMissing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature."
  },
  {
    "objectID": "posts/renan-blog-post-week7/Readme.html#features-correlation-matrix",
    "href": "posts/renan-blog-post-week7/Readme.html#features-correlation-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data."
  },
  {
    "objectID": "posts/renan-blog-post-week7/Readme.html#sparsity-matrix",
    "href": "posts/renan-blog-post-week7/Readme.html#sparsity-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature."
  },
  {
    "objectID": "posts/shree-blog-post-week5/index.html",
    "href": "posts/shree-blog-post-week5/index.html",
    "title": "Literature Review Week 5",
    "section": "",
    "text": "Link: https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2839330\nPrevalence of Clinical Obesity in US Adults Based on a Newly Proposed Definition[1]\nThe Lancet Diabetes & Endocrinology Commission has proposed a new definition of clinical obesity that includes evidence of organ malfunction or physiological impairment in addition to direct measures of adiposity.\nIn order to find populations who might have been incorrectly classified under previous BMI thresholds, the researchers aimed to compare BMI-based obesity with clinical obesity using national data from the United States.\nMethodology:\n\nCross-sectional study using NHANES 2017–2018 data (nationally representative, multistage sampling)\nAnalysis: Conducted in Stata 18; weighted percentages with 95% CIs; significance at p&lt;0.05\nGuidelines: Followed STROBE reporting standard.\n\nKey points - BMI and Clinical Impact : BMI data is insufficient as it leaves who already experience obesity-related dysfunction. - Older adults are more seen in clinical obesity even at lower BMIs = highlights BMI’s limitation in aging populations. - Younger, higher-income adults are seen with mostly BMI-only obese: high weight but not yet showing dysfunction. - Public health implication: Using the clinical definition could better target interventions (medication, surgery, lifestyle) and identify people at risk earlier.\nSummary: Although the overall obesity rates determined by BMI and clinical criteria are comparable, they distinguish distinct populations. The clinical definition emphasizes the significance of early prevention for individuals with preclinical obesity and more accurately reflects the health effects, particularly in older and underprivileged populations."
  },
  {
    "objectID": "posts/shree-blog-post-week5/index.html#article-1",
    "href": "posts/shree-blog-post-week5/index.html#article-1",
    "title": "Literature Review Week 5",
    "section": "",
    "text": "Link: https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2839330\nPrevalence of Clinical Obesity in US Adults Based on a Newly Proposed Definition[1]\nThe Lancet Diabetes & Endocrinology Commission has proposed a new definition of clinical obesity that includes evidence of organ malfunction or physiological impairment in addition to direct measures of adiposity.\nIn order to find populations who might have been incorrectly classified under previous BMI thresholds, the researchers aimed to compare BMI-based obesity with clinical obesity using national data from the United States.\nMethodology:\n\nCross-sectional study using NHANES 2017–2018 data (nationally representative, multistage sampling)\nAnalysis: Conducted in Stata 18; weighted percentages with 95% CIs; significance at p&lt;0.05\nGuidelines: Followed STROBE reporting standard.\n\nKey points - BMI and Clinical Impact : BMI data is insufficient as it leaves who already experience obesity-related dysfunction. - Older adults are more seen in clinical obesity even at lower BMIs = highlights BMI’s limitation in aging populations. - Younger, higher-income adults are seen with mostly BMI-only obese: high weight but not yet showing dysfunction. - Public health implication: Using the clinical definition could better target interventions (medication, surgery, lifestyle) and identify people at risk earlier.\nSummary: Although the overall obesity rates determined by BMI and clinical criteria are comparable, they distinguish distinct populations. The clinical definition emphasizes the significance of early prevention for individuals with preclinical obesity and more accurately reflects the health effects, particularly in older and underprivileged populations."
  },
  {
    "objectID": "posts/shree-blog-post-week5/index.html#article-2",
    "href": "posts/shree-blog-post-week5/index.html#article-2",
    "title": "Literature Review Week 5",
    "section": "Article 2",
    "text": "Article 2\nBenefit-Risk Reporting for FDA-Cleared Artificial Intelligence−Enabled Medical Devices[2]\nLink: https://jamanetwork.com/journals/jama-health-forum/fullarticle/2839236\nSummary:\nThe effectiveness with which FDA-approved AI/ML-enabled medical devices disclose their advantages, hazards, effectiveness, and safety before to and following approval was investigated in this study\nScope: Using FDA records (decision summaries, adverse events, and recalls), 691 AI/ML devices that were approved between 1995 and 2023 were analyzed.\nResults:\nKey reporting was absent from many devices:\n46.7% did not report the study design.\n53.3% of the training sample size is missing.\n95.5% of demographic information is lacking.\nJust 3 devices (&lt;1%) reported patient outcomes, while only 6 devices (1.6%) used randomized clinical trials. Sensitivity (24%), specificity (22%), and other performance indicators were not reported by many.Just 28.2% of devices had safety assessments, and only 8.7% had bias assessments.Adverse events: 489 incidents involving 36 devices (5.2%), comprising 30 injuries, 1 fatality, and 458 malfunctions.40 devices (5.8%) were recalled 113 times, primarily due to software problems.\nTrends:\nAlthough there was a little improvement in the reporting of bias checks, efficacy, and outcomes for devices cleared after 2021, these devices were less likely to have safety evaluations or peer-reviewed publications.\nConclusion: Standardized reporting of risk, safety, and efficacy is lacking in regulatory monitoring of AI/ML medical devices. The study highlights the necessity of an FDA regulatory approach specifically for AI/ML devices. more robust postmarket surveillance networks.Increased health fairness and transparency (e.g., improved demographic reporting to prevent prejudice).\n\nReferences\n\n\n1. Park, D., Lee, D. H., Kim, R., Shin, M.-J., & Subramanian, S. (2025). Prevalence of clinical obesity in US adults based on a newly proposed definition. JAMA Network Open, 8(9), e2533806–e2533806.\n\n\n2. Lin, J. C., Jain, B., Iyer, J. M., Rola, I., Srinivasan, A. R., Kang, C., Patel, H., & Parikh, R. B. (2025). Benefit-risk reporting for FDA-cleared artificial intelligence- enabled medical devices. JAMA Health Forum, 6, e253351–e253351."
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html",
    "href": "posts/renan-blog-post-week7/index.html",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "",
    "text": "For the Week 7 we will be reproducing Steve’s findings with the dataset[1].\nYou can download the Dataset from the following link: Stroke Prediction Dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week7/index.html#setup-and-data-loading",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.\n\n1.1 Load Libraries\n\n\nCode\n# Run this once to install all the necessary packages\n# install.packages(c(\"corrplot\", \"ggpubr\", \"caret\", \"mice\", \"ROSE\", \"ranger\", \"stacks\", \"tidymodels\"))\n# install.packages(\"themis\")\n# install.packages(\"xgboost\")\n# install.packages(\"gghighlight\")\n# install.packages(\"dplyr\")\n# install.packages(\"pscl\")\n# install.packages(\"parallelly\")\n# install.packages(\"cli\")\n# install.packages(\"car\")\n# install.packages(\"ResourceSelection\")\n\n\nWe can use this to check installed packages:\n```{r}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\nCode\n# For data manipulation and visualization\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(caret)\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\nlibrary(dplyr)\nlibrary(pscl)\nlibrary(car)\nlibrary(ResourceSelection)\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n1.2 Load Data\nWill be using my original Dataset as well Steve’s Dataset and compare for differences.\nRenan: kaggle_data1 Steve: stroke1\n\n1.2.1 Renan Dataset\nBelow will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n# unique(kaggle_data1$bmi)\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# Remove the 'Other' gender row and the 'id' column\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  filter(gender != \"Other\") %&gt;%\n  select(-id) %&gt;%\n  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling\n\n\n\n\n1.2.1 Steve Dataset\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n# stroke1 &lt;- read.csv(\"D:\\\\stroke.csv\")\n\n\nExploring Dataset so we can plan on how to proceed and possible changes.\n\n\nCode\n# Reveiewing the columns of the data and the dataset size#\nhead(stroke1)\nnrow(stroke1)\n#Some data to look at the data in each column#\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n\n\nPreparing the Dataset\nFor each Column…removing the unncessary or unusable variables: 1. Smoking Status - remove unknown 1. bmi - remove N/A 3. Work type - remove children 4. age create numerical variable with 2 places after the decimal 5. gender -remove other\nIn each column..that has data points that are not usable, recoding those datapoints to become”N/A”\n\n\nCode\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\n\n\nfor BMI changing the variable type to numeric and formatting the data point to 2 places ater the decimal\n\n\nCode\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\n\n\nFor Gender, changning Male to 1 and Female to 2, then reformatting gender as numeric\n\n\nCode\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\n\nWarning: NAs introduced by coercion\n\n\nFor ever_married, changing yes to 1 and No to 2, the reformatting the variable ever_married to numeric\n\n\nCode\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\n\n\nFor work type recoding Govt_job to 1, Private to 3, Self-employed to 3, and Never_worked to 4, then reformatting work_type to numeric\n\n\nCode\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\n\n\nFor Residence_type, recoding urban to 1, Rural to 2, and then reformatting Residence type to Numeric\n\n\nCode\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\n\n\nfor avg_glucose_level, heart_disease, and hypertension, reformattint the 3 variables to numeric\n\n\nCode\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\n\n\nFor age, reformatting age to numeric and putting 2 places after the decimnals\n\n\nCode\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\n\n\nFor stroke, reformatting the variable stroke to numeric\n\n\nCode\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\n\n\nFor smoking_status, recoding never smoked to 1, formerly smoked to 2, and smokes to 3. The reformat the variable to numeric\n\n\nCode\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\n\n\ndeleted to column ID from the dataset since its not needed for the analysis\n\n\nCode\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n\nrenameed stroke dataset without id to stroke1_clean\n\n\nCode\nstroke1_clean &lt;- na.omit(stroke1)\n\n\nconverted all columns to numeric and removed id\n\n\nCode\nstr(stroke1_clean)\n\n\ntibble [3,357 × 11] (S3: tbl_df/tbl/data.frame)\n $ gender           : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age              : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension     : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease    : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married     : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type        : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type   : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level: num [1:3357] 229 106 171 174 186 ...\n $ bmi              : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status   : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke           : num [1:3357] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n\n\nCode\nnrow(stroke1_clean)\n\n\n[1] 3357"
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html#apply-logistic-regression",
    "href": "posts/renan-blog-post-week7/index.html#apply-logistic-regression",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "2. Apply Logistic Regression",
    "text": "2. Apply Logistic Regression\nApplying Logistic Regression to Steve Dataset\n\n\nCode\nLR_stroke1 &lt;- stroke1_clean\n#Do Logistic Regression on dataset#\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke1)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7\n\n\nBecause, Rsquared and adjusted Rsquared is not appropriated for logistic regression model, to see how model fits and explains variance used alternative\n\n2.1 Evaluating model fit\nEvaluating model fit\nComment Oh crap _ McFadden = .18– not a bad fit for logistic regression\n\n\nCode\n# Because, Rsquared and adjusted Rsquared is not appropriated for logistic regression model, to see how model fits and explains variance used alternative#\n#looking at model fit#\npR2(model)\n\n\nfitting null model for pseudo-r2\n\n\n          llh       llhNull            G2      McFadden          r2ML \n-572.70320797 -701.73792863  258.06944131    0.18387879    0.07399442 \n         r2CU \n   0.21655630 \n\n\n\n\n2.2 Apply Confusion Matrix\nDo a confusion matrix for the model by installing Parallelly, and cli, and using caret from the library\ncomment on confusion matrix =- poor results\n\n\nCode\n# Predict probabilities from the logistic regression model\npredicted_prob &lt;- predict(model, type = \"response\")\n\n# Convert probabilities to binary classes using a 0.5 cutoff\npredicted_class &lt;- ifelse(predicted_prob &gt; 0.5, 1, 0)\n\n\n\n\nCode\n# library(caret)\npredicted_class &lt;- factor(predicted_class, levels = c(0,1))\nForReal_Stroke &lt;- factor(LR_stroke1$stroke, levels = c(0,1))\nconfusionMatrix(predicted_class, ForReal_Stroke)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n                                          \n               Accuracy : 0.947           \n                 95% CI : (0.9388, 0.9543)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 0.4587          \n                                          \n                  Kappa : 0.0208          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.01111         \n         Pos Pred Value : 0.94694         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.94638         \n         Detection Rate : 0.94638         \n   Detection Prevalence : 0.99940         \n      Balanced Accuracy : 0.50556         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\n\n\n2.3 Apply F1 Score and Precision Recall\nLook at dataset and logistic regression analysis close with F1 score and Precision Recall\ndo F1 Score and Precision Recall\nPrecision - out of all the true strokes the model predicted, how many really were strokes? Consider 1 = 100%\n\n\nCode\nprecision &lt;- sum((predicted_class == 1) & (ForReal_Stroke == 1)) / sum(predicted_class == 1)\n\n\nRecall - out of all the actual strokes, how many did the model catch? = .01 or 1%\n\n\nCode\nrecall &lt;- sum((predicted_class == 1) & (ForReal_Stroke == 1)) / sum(ForReal_Stroke == 1)\n\n\nf1_Score - How well does this model predict strokes? = .022 or 2.2% –very poorly\n\n\nCode\nf1_score  &lt;- 2 * precision * recall / (precision + recall)\n\n\nprecision, recall, f1_score\n\n\nCode\nprecision\n\n\n[1] 1\n\n\nCode\nrecall\n\n\n[1] 0.01111111\n\n\nCode\nf1_score\n\n\n[1] 0.02197802"
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html#testing-logistic-regression-model-assumptions",
    "href": "posts/renan-blog-post-week7/index.html#testing-logistic-regression-model-assumptions",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "3. Testing logistic Regression Model Assumptions",
    "text": "3. Testing logistic Regression Model Assumptions\nThere are several assumptions for Logistic Regression: 1. The Dependent Variable is binary (i.e, 0 or 1) 2. There is a linear relationship between th logit of the outcome and each predictor 3. There are NO high leverage outliers in the predictors 4. There is No high multicollinearity (ie strong correlations) between predictors\n\n\nCode\nLR_stroke2 &lt;- stroke1_clean\nmodel2 &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke2, family = binomial)\nsummary(model2)\n\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke2)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n3.1 Testing Assumption 1\nTesting Assumption 1: The Dependent Variable is binary (0 or 1)\n\n\nCode\nunique(LR_stroke2$stroke)\n\n\n[1] 1 0\n\n\n\n\n3.2 Testing Assumption 2\nTesting Assumption 2: There is a linear relationship between the outcome variable and each predictor (use boxTidwell)\nFor boxTidwell, first adjust all predictors so all values are positive. If we obtain a P value greater than 0.05 it indicates a linear relationship between the predictor and the outcome.\n\n\nCode\nLR_stroke2$genderadj            &lt;- LR_stroke2$gender            + abs(min(LR_stroke1$gender))            + 1\nLR_stroke2$ageadj               &lt;- LR_stroke2$age               + abs(min(LR_stroke1$age))               + 1\nLR_stroke2$hypertensionadj      &lt;- LR_stroke2$hypertension      + abs(min(LR_stroke1$hypertension))      + 1\nLR_stroke2$heart_diseaseadj     &lt;- LR_stroke2$heart_disease     + abs(min(LR_stroke1$hypertension))      + 1\nLR_stroke2$ever_marriedadj      &lt;- LR_stroke2$ever_married      + abs(min(LR_stroke1$ever_married))      + 1\nLR_stroke2$work_typeadj         &lt;- LR_stroke2$work_type         + abs(min(LR_stroke1$work_type))         + 1\nLR_stroke2$Residence_typeadj    &lt;- LR_stroke2$Residence_type    + abs(min(LR_stroke1$Residence_type))    + 1\nLR_stroke2$avg_glucose_leveladj &lt;- LR_stroke2$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1\nLR_stroke2$bmiadj               &lt;- LR_stroke2$bmi               + abs(min(LR_stroke1$bmi))               + 1\nLR_stroke2$smoking_statusadj    &lt;- LR_stroke2$smoking_status    + abs(min(LR_stroke1$smoking_status))    + 1\n\n\nError in linearHypothesis.lm(mod.2, H) : there are aliased coefficients in the model.\n\n\nCode\n# boxTidwell(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=LR_stroke2)\n\n\n\n3.2.1 Issues Testing Assumption 2\nTrying to Drop Aliased Predictors\n\n\nCode\n# First, create the linear model object\nlm_model &lt;- lm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=LR_stroke2)\n\n# Then, run the alias() function\nalias(lm_model)\n\n\nModel :\nstroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + \n    ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + \n    bmiadj + smoking_statusadj\n\n\nCode\n# Model : stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj\n\n\nYou can also check for perfect correlation and see if any correlations are ±1.\n\n\nCode\ncor(LR_stroke2[, c(\"genderadj\",\"ageadj\",\"hypertensionadj\",\"heart_diseaseadj\",\n                   \"ever_marriedadj\",\"work_typeadj\",\"Residence_typeadj\",\n                   \"avg_glucose_leveladj\",\"bmiadj\",\"smoking_statusadj\")])\n\n\n                       genderadj      ageadj hypertensionadj heart_diseaseadj\ngenderadj             1.00000000 -0.05599748    -0.040011423     -0.104191111\nageadj               -0.05599748  1.00000000     0.263123514      0.260353361\nhypertensionadj      -0.04001142  0.26312351     1.000000000      0.110020853\nheart_diseaseadj     -0.10419111  0.26035336     0.110020853      1.000000000\never_marriedadj       0.02728003 -0.48775310    -0.107114849     -0.069804764\nwork_typeadj          0.01495643  0.14214267     0.048358096      0.029618537\nResidence_typeadj    -0.01143732 -0.01761422     0.003112702     -0.010250014\navg_glucose_leveladj -0.07148597  0.23864619     0.168909926      0.143333385\nbmiadj               -0.01991382  0.04222590     0.127363138     -0.003962827\nsmoking_statusadj    -0.07723370  0.03463196    -0.005416806      0.060198195\n                     ever_marriedadj work_typeadj Residence_typeadj\ngenderadj                 0.02728003  0.014956427      -0.011437323\nageadj                   -0.48775310  0.142142673      -0.017614219\nhypertensionadj          -0.10711485  0.048358096       0.003112702\nheart_diseaseadj         -0.06980476  0.029618537      -0.010250014\never_marriedadj           1.00000000 -0.020663455       0.011239966\nwork_typeadj             -0.02066345  1.000000000      -0.007197831\nResidence_typeadj         0.01123997 -0.007197831       1.000000000\navg_glucose_leveladj     -0.11858810  0.034327248       0.008010375\nbmiadj                   -0.12527547 -0.017017707       0.009836168\nsmoking_statusadj        -0.05723324 -0.015271022      -0.039896247\n                     avg_glucose_leveladj       bmiadj smoking_statusadj\ngenderadj                    -0.071485971 -0.019913816      -0.077233702\nageadj                        0.238646187  0.042225902       0.034631959\nhypertensionadj               0.168909926  0.127363138      -0.005416806\nheart_diseaseadj              0.143333385 -0.003962827       0.060198195\never_marriedadj              -0.118588103 -0.125275472      -0.057233241\nwork_typeadj                  0.034327248 -0.017017707      -0.015271022\nResidence_typeadj             0.008010375  0.009836168      -0.039896247\navg_glucose_leveladj          1.000000000  0.155139559       0.005095349\nbmiadj                        0.155139559  1.000000000       0.029041449\nsmoking_statusadj             0.005095349  0.029041449       1.000000000\n\n\ncheck constant columns:\nIf any variable only has one unique value → it’s constant → alias.\n\n\nCode\nsapply(LR_stroke2, function(x) length(unique(x)))\n\n\n              gender                  age         hypertension \n                   2                   70                    2 \n       heart_disease         ever_married            work_type \n                   2                    2                    4 \n      Residence_type    avg_glucose_level                  bmi \n                   2                 2861                  364 \n      smoking_status               stroke            genderadj \n                   3                    2                    2 \n              ageadj      hypertensionadj     heart_diseaseadj \n                  70                    2                    2 \n     ever_marriedadj         work_typeadj    Residence_typeadj \n                   2                    4                    2 \navg_glucose_leveladj               bmiadj    smoking_statusadj \n                2861                  364                    3 \n\n\nError in linearHypothesis.lm(mod.2, H) : there are aliased coefficients in the model.\n\n\nCode\n# boxTidwell(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=LR_stroke2)\n\n\n\n\n\n3.3 Testing Assumption 3\nTesting Assumption 3: assess influential outliers using car package and influencePlot\n\n\nCode\ncar::influencePlot(model2)\n\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n83    2.6917353 0.0039267816 0.012237368\n84    1.5018344 0.0343771041 0.006641860\n87    3.0732709 0.0012042796 0.011476828\n131   3.1608870 0.0006013465 0.007697762\n152   3.1135601 0.0005613972 0.006237531\n2583 -0.8509399 0.0399302730 0.001668526\n\n\n\n\n3.4 Testing Assumption 4\nTesting Assumption 4 : Multicollinearity using ggplot and augment\n\n\nCode\n# Testing Assumption 4 : Multicollinearity using ggplot and augment#\naug &lt;- augment(model2)\nggplot(aug,aes(.fitted, .std.resid)) + geom_point() + geom_hline(yintercept=0)\n\n\n\n\n\n\n\n\n\n\n\n3.5 Conclusion of Testing Assumptions\nConclusion: Now that all 4 assumptions are met, logistic regression is a valid model to analyze the model"
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html#analysis-of-the-model",
    "href": "posts/renan-blog-post-week7/index.html#analysis-of-the-model",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "4 Analysis of the Model",
    "text": "4 Analysis of the Model\nPart 4: Analysis of the Model\n\n\nCode\nmodel2 &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke2, family = binomial)\nsummary(model2)\n\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke2)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7\n\n\nConclusion: age, hypertension, heartdisease, and avg_glucose_level are statistically significant predictors on whether one has a stroke or not.\nall the P values of these 4 predictors is .05 or less (note included heart_disease because it approaches statistical significance at .057)\nSince this a logistic regression, we cant use R squared and adjusted R squared to see how well the model predicted stroke. So we substitute McFadden’s P value.\n\n\nCode\n# install.packages(\"pscl\")\n# library(pscl)\npR2(model2)\n\n\nfitting null model for pseudo-r2\n\n\n          llh       llhNull            G2      McFadden          r2ML \n-572.70320797 -701.73792863  258.06944131    0.18387879    0.07399442 \n         r2CU \n   0.21655630 \n\n\nComment McFadden = .18– not a bad fit for logistic regression\nCreate a confusion matrix (Type1 vs Type2 error in statistics)\n\n\nCode\n# install.packages(\"parallelly\")\n# install.packages(\"cli\")\n# library(caret)\n\n# Predict probabilities from the logistic regression model\npredicted_prob1 &lt;- predict(model2, type = \"response\")\n\n# Convert probabilities to binary classes using a 0.5 cutoff\npredicted_class1 &lt;- ifelse(predicted_prob1 &gt; 0.5, 1, 0)\n\npredicted_class1 &lt;- factor(predicted_class1, levels = c(0,1))\nForReal_Stroke1 &lt;- factor(LR_stroke2$stroke, levels = c(0,1))\nconfusionMatrix(predicted_class1, ForReal_Stroke1)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n                                          \n               Accuracy : 0.947           \n                 95% CI : (0.9388, 0.9543)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 0.4587          \n                                          \n                  Kappa : 0.0208          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 1.00000         \n            Specificity : 0.01111         \n         Pos Pred Value : 0.94694         \n         Neg Pred Value : 1.00000         \n             Prevalence : 0.94638         \n         Detection Rate : 0.94638         \n   Detection Prevalence : 0.99940         \n      Balanced Accuracy : 0.50556         \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nAnalysis of the Confusion Matrix: Crud…poor results\nFurther Analysis of the Confusion Matrix with F1 score and Precision Recall\n\n4.1 F1 Score and Precision Recall\nPrecision - out of all the true strokes the model predicted, how many really were strokes? = 1 = 100%\n\n\nCode\nprecision1 &lt;- sum((predicted_class1 == 1) & (ForReal_Stroke1 == 1)) / sum(predicted_class1 == 1)\n\n\nRecall - out of all the actual strokes, how many did the model catch?\nResults = .01 or 1%—\n\n\nCode\nrecall1 &lt;- sum((predicted_class1 == 1) & (ForReal_Stroke1 == 1)) / sum(ForReal_Stroke1 == 1)\n\n\nf1_Score - How well does this model predict strokes?\nResults = .022 or 2.2% –very poorly\n\n\nCode\nf1_score1  &lt;- 2 * precision1 * recall1 / (precision1 + recall1)\n\n\nprecision1, recall1, f1_score1\n\n\nCode\nprecision1\n\n\n[1] 1\n\n\nCode\nrecall1\n\n\n[1] 0.01111111\n\n\nCode\nf1_score1\n\n\n[1] 0.02197802"
  },
  {
    "objectID": "posts/renan-blog-post-week7/index.html#conclusion",
    "href": "posts/renan-blog-post-week7/index.html#conclusion",
    "title": "Reproducing Steve’s Code - Week 7",
    "section": "Conclusion",
    "text": "Conclusion\n\nIdeas for improving precision, recall and f1_score\nAddress imbalance by upsample (add stroke cases), downsample (remove non strokecases) and or SMOTE (Synthetic data)\nChange the classification threshold\nCompare with Alternative Models such as random forrests or XGBoost\n\n\nReferences\n\n\n1. fedesoriano. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "",
    "text": "On this document I try to replicate Steve code: Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#setup-and-data-loading",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.\n\n1.1 Load Libraries\nInstall packages if necessary:\n\n\nCode\n# Run this once to install all the necessary packages\n# install.packages(\"dplyr\")\n# install.packages(\"car\")\n# install.packages(\"ResourceSelection\")\n# install.packages(\"caret\")\n# install.packages(\"rcompanion\")\n# install.packages(\"pROC\")\n# install.packages(\"cvAUC\")\n\n\nLoad Libraries:\n\n\nCode\n# For data manipulation and visualization\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\nlibrary(pscl)\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nlibrary(caret)\nlibrary(rcompanion)\nlibrary(Hmisc)\nlibrary(pROC)\nlibrary(cvAUC)\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n1.1.1 Possible Issues and conflicts to resolve\n```{bash}\n#| code-fold: true\n&gt; # For data manipulation and visualization\n&gt; library(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\nlibrary(pscl)\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nlibrary(caret)\nlibrary(rcompanion)\nlibrary(Hmisc)\nlibrary(pROC)\nlibrary(cvAUC)\n\n# Set seed for reproducibility\nset.seed(123)\n── Attaching core tidyverse packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n&gt; library(ggplot2)\n&gt; library(corrplot)\ncorrplot 0.95 loaded\n&gt; library(knitr)\n&gt; library(ggpubr)\n&gt; \n&gt; # For data preprocessing and modeling\n&gt; library(mice)\n\nAttaching package: ‘mice’\n\nThe following object is masked from ‘package:stats’:\n\n    filter\n\nThe following objects are masked from ‘package:base’:\n\n    cbind, rbind\n\n&gt; library(ROSE) # For SMOTE\nLoaded ROSE 0.0-4\n\n&gt; library(ranger) # A fast implementation of random forests\nranger 0.17.0 using 2 threads (default). Change with num.threads in ranger() and predict(), options(Ncpus = N), options(ranger.num.threads = N) or environment variable R_RANGER_NUM_THREADS.\n&gt; \n&gt; # For stacking/ensemble models\n&gt; library(stacks)\nRegistered S3 method overwritten by 'butcher':\n  method                 from    \n  as.character.dev_topic generics\n&gt; library(tidymodels)\n── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.9     ✔ rsample      1.3.1\n✔ dials        1.4.2     ✔ tailor       0.1.0\n✔ infer        1.0.9     ✔ tune         2.0.0\n✔ modeldata    1.5.1     ✔ workflows    1.3.0\n✔ parsnip      1.3.3     ✔ workflowsets 1.1.1\n✔ recipes      1.3.1     ✔ yardstick    1.3.2\n── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ mice::filter()    masks dplyr::filter(), stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n&gt; \n&gt; library(themis)\n&gt; library(gghighlight)\n&gt; \n&gt; library(pscl)\nClasses and Methods for R originally developed in the\nPolitical Science Computational Laboratory\nDepartment of Political Science\nStanford University (2002-2015),\nby and under the direction of Simon Jackman.\nhurdle and zeroinfl functions by Achim Zeileis.\n&gt; library(dplyr)\n&gt; library(car)\nLoading required package: carData\n\nAttaching package: ‘car’\n\nThe following object is masked from ‘package:dplyr’:\n\n    recode\n\nThe following object is masked from ‘package:purrr’:\n\n    some\n\n&gt; library(ResourceSelection)\nResourceSelection 0.3-6          2023-06-27\n&gt; library(caret)\nLoading required package: lattice\n\nAttaching package: ‘caret’\n\nThe following objects are masked from ‘package:yardstick’:\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from ‘package:rsample’:\n\n    calibration\n\nThe following object is masked from ‘package:purrr’:\n\n    lift\n\n&gt; library(rcompanion)\n\nAttaching package: ‘rcompanion’\n\nThe following object is masked from ‘package:yardstick’:\n\n    accuracy\n\n&gt; library(Hmisc)\n\nAttaching package: ‘Hmisc’\n\nThe following object is masked from ‘package:parsnip’:\n\n    translate\n\nThe following objects are masked from ‘package:dplyr’:\n\n    src, summarize\n\nThe following objects are masked from ‘package:base’:\n\n    format.pval, units\n\n&gt; library(pROC)\nType 'citation(\"pROC\")' for a citation.\n\nAttaching package: ‘pROC’\n\nThe following objects are masked from ‘package:stats’:\n\n    cov, smooth, var\n\n&gt; library(cvAUC)\n&gt; \n&gt; # Set seed for reproducibility\n&gt; set.seed(123)\n```\n\n\n\n1.2 Load Data\nWill be using my original Dataset as well Steve’s Dataset and compare for differences.\n\nRenan: kaggle_data1\nSteve: stroke1\n\n\n1.2.1 Renan Dataset\nBelow will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n# unique(kaggle_data1$bmi)\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# Remove the 'Other' gender row and the 'id' column\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  filter(gender != \"Other\") %&gt;%\n  select(-id) %&gt;%\n  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling\n\n\n\n\n1.2.1 Steve Dataset\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n\n\n\n\n\n1.3 Prepare Dataset\n\nhead(stroke1)\nnrow(stroke1)\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n\nPart 1: preparing the data\n\nSmoking Status - remove unknown\nbmi - remove N/A\nWork type - remove children\nage - create numerical variable with 2 places after the decimal\ngender - remove other\n\n\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\n\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\n\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\nWarning: NAs introduced by coercion\n\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\n\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\n\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\n\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\n\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\n\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\n\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\n\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\n\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\n\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nstroke1_clean &lt;- na.omit(stroke1)\n\nconverted all columns to numeric and removed id\n\n# converted all columns to numeric and removed id\nstr(stroke1_clean)\nnrow(stroke1_clean)\nLR_stroke1 &lt;- stroke1_clean\nstr(LR_stroke1)\ncount_tables &lt;- lapply(LR_stroke1, table)\ncount_tables"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#apply-logistic-regression",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#apply-logistic-regression",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "2. Apply Logistic Regression",
    "text": "2. Apply Logistic Regression\nPart 2:Create and Run the Logistic Regression model from the dataset\n\n# Part 2:Create and Run the Logistic Regression model from the  dataset\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke1)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n\n\n\n\n\nIssue - Unbalanced Data set\n\n\n\nThe dataset is oversampling stroke rate by 77%.\n\n\nIssue - Unbalanced Data set\nThe \\(stroke rate = 180/3357 = 054%\\) . But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS.\nThe dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample….but too much time\nBest way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on\n\n# Issue _ Unbalanced Data set #\n# The stroke rate = 180/3357 = 054%. But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS. #\n# The dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample....but too much time #\n# Best way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on #\nds_prev &lt;- .054\npop_prev &lt;- .031\nlog_odds_ds &lt;- qlogis(ds_prev)\nlog_odds_pop &lt;- qlogis(pop_prev)\noffset &lt;- log_odds_pop - log_odds_ds\ncoefs &lt;- coef(model)\ncoefs[1] &lt;- coefs[1] + offset\nprint(coefs)\n\n      (Intercept)            gender               age      hypertension \n     -9.005873116       0.080369937       0.070967479       0.570796782 \n    heart_disease      ever_married         work_type    Residence_type \n      0.417883562       0.174315603      -0.109615162       0.005932360 \navg_glucose_level               bmi    smoking_status \n      0.004657820       0.006275415       0.179921439 \n\n\nOriginal Intercept Coeff = -8.426854231\nChanged intercept Coefficent to take into account current stroke rate or 3.1% = -9.005873116\nall the other intercepts remain the same"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#testing-logistic-regression-model-assumptions",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#testing-logistic-regression-model-assumptions",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "3. Testing logistic Regression Model Assumptions",
    "text": "3. Testing logistic Regression Model Assumptions\nPart 3: Testing logistic Regression Model Assumptions\nThere are several assumptions for Logistic Regression. They are:\n\nThe Dependent Variable is binary (i.e, 0 or 1)\nThere is a linear relationship between th logit of the outcome and each predictor\nThere are NO high leverage outliers in the predictors\nThere is No high multicollinearity (ie strong correlations) between predictors\n\nNow to test each assumption\n\n3.1 Testing Assumption 1\nTesting Assumption 1: The Dependent Variable is binary (0 or 1)\n\nunique(LR_stroke1$stroke)\n\n[1] 1 0\n\n\n\n\n3.2 Testing Assumption 2\nTesting Assumption 2: There is a linear relationship between the outcome variable and each predictor\nfirst, adjust all predictors so all values are positive\nConclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity\nConclusion: all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression\nConclusion for assumption 2 - Linearity is met\n\nLR_stroke1$genderadj &lt;- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1\n\nLR_stroke1$ageadj &lt;- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1\n\nLR_stroke1$hypertensionadj &lt;- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$heart_diseaseadj &lt;- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$ever_marriedadj &lt;- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1\n\nLR_stroke1$work_typeadj &lt;- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1\n\nLR_stroke1$Residence_typeadj &lt;- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1\n\nLR_stroke1$avg_glucose_leveladj &lt;- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1\n\nLR_stroke1$bmiadj &lt;- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1\n\nLR_stroke1$smoking_statusadj &lt;- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1\n\nstr(LR_stroke1)\n\ntibble [3,357 × 21] (S3: tbl_df/tbl/data.frame)\n $ gender              : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age                 : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension        : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease       : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married        : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type           : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type      : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level   : num [1:3357] 229 106 171 174 186 ...\n $ bmi                 : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status      : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke              : num [1:3357] 1 1 1 1 1 1 1 1 1 1 ...\n $ genderadj           : num [1:3357] 3 3 4 4 3 3 4 4 4 4 ...\n $ ageadj              : num [1:3357] 81 94 63 93 95 88 83 95 75 68 ...\n $ hypertensionadj     : num [1:3357] 1 1 1 2 1 2 1 2 1 1 ...\n $ heart_diseaseadj    : num [1:3357] 2 2 1 1 1 2 1 1 2 1 ...\n $ ever_marriedadj     : num [1:3357] 3 3 3 3 3 3 4 3 3 3 ...\n $ work_typeadj        : num [1:3357] 4 4 4 5 4 4 4 4 3 4 ...\n $ Residence_typeadj   : num [1:3357] 3 4 3 4 3 4 3 4 4 3 ...\n $ avg_glucose_leveladj: num [1:3357] 285 162 227 230 242 ...\n $ bmiadj              : num [1:3357] 49.1 45 46.9 36.5 41.5 39.9 35.3 42.2 49.3 39.8 ...\n $ smoking_statusadj   : num [1:3357] 4 3 5 3 4 3 3 3 5 5 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n\nStrokeAdj &lt;- LR_stroke1\n\nStrokeAdj &lt;- StrokeAdj[ , !(names(StrokeAdj) %in% c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\")) ]\n\nFit the model\n\nmod.2 &lt;- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)\n# Plot Residuals\nresidualPlots(mod.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                     Test stat Pr(&gt;|Test stat|)  \ngenderadj               0.0000          1.00000  \nageadj                  2.0626          0.15095  \nhypertensionadj         0.0000          1.00000  \nheart_diseaseadj        0.0000          1.00000  \never_marriedadj         0.0000          1.00000  \nwork_typeadj            3.1406          0.07636 .\nResidence_typeadj       0.0000          1.00000  \navg_glucose_leveladj    0.0103          0.91921  \nbmiadj                  0.3947          0.52983  \nsmoking_statusadj       0.4775          0.48953  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n3.3 Testing Assumption 3\nTesting Assumption 3: assess influential outliers using car package and influencePlot\n\nalias(model)\n\nModel :\nstroke ~ gender + age + hypertension + heart_disease + ever_married + \n    work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n\n# install.packages(\"Hmisc\")\n# library(Hmisc)\nrcorr(as.matrix(LR_stroke1))\n\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nstroke                -0.01  0.24         0.14          0.14        -0.07\ngenderadj              1.00 -0.06        -0.04         -0.10         0.03\nageadj                -0.06  1.00         0.26          0.26        -0.49\nhypertensionadj       -0.04  0.26         1.00          0.11        -0.11\nheart_diseaseadj      -0.10  0.26         0.11          1.00        -0.07\never_marriedadj        0.03 -0.49        -0.11         -0.07         1.00\nwork_typeadj           0.01  0.14         0.05          0.03        -0.02\nResidence_typeadj     -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\nsmoking_statusadj     -0.08  0.03        -0.01          0.06        -0.06\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nstroke                    0.04          -0.01              0.14  0.01\ngenderadj                 0.01          -0.01             -0.07 -0.02\nageadj                    0.14          -0.02              0.24  0.04\nhypertensionadj           0.05           0.00              0.17  0.13\nheart_diseaseadj          0.03          -0.01              0.14  0.00\never_marriedadj          -0.02           0.01             -0.12 -0.13\nwork_typeadj              1.00          -0.01              0.03 -0.02\nResidence_typeadj        -0.01           1.00              0.01  0.01\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\nsmoking_statusadj        -0.02          -0.04              0.01  0.03\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender                        -0.08  -0.01      1.00  -0.06           -0.04\nage                            0.03   0.24     -0.06   1.00            0.26\nhypertension                  -0.01   0.14     -0.04   0.26            1.00\nheart_disease                  0.06   0.14     -0.10   0.26            0.11\never_married                  -0.06  -0.07      0.03  -0.49           -0.11\nwork_type                     -0.02   0.04      0.01   0.14            0.05\nResidence_type                -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_level              0.01   0.14     -0.07   0.24            0.17\nbmi                            0.03   0.01     -0.02   0.04            0.13\nsmoking_status                 1.00   0.02     -0.08   0.03           -0.01\nstroke                         0.02   1.00     -0.01   0.24            0.14\ngenderadj                     -0.08  -0.01      1.00  -0.06           -0.04\nageadj                         0.03   0.24     -0.06   1.00            0.26\nhypertensionadj               -0.01   0.14     -0.04   0.26            1.00\nheart_diseaseadj               0.06   0.14     -0.10   0.26            0.11\never_marriedadj               -0.06  -0.07      0.03  -0.49           -0.11\nwork_typeadj                  -0.02   0.04      0.01   0.14            0.05\nResidence_typeadj             -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_leveladj           0.01   0.14     -0.07   0.24            0.17\nbmiadj                         0.03   0.01     -0.02   0.04            0.13\nsmoking_statusadj              1.00   0.02     -0.08   0.03           -0.01\n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender                          -0.10            0.03         0.01\nage                              0.26           -0.49         0.14\nhypertension                     0.11           -0.11         0.05\nheart_disease                    1.00           -0.07         0.03\never_married                    -0.07            1.00        -0.02\nwork_type                        0.03           -0.02         1.00\nResidence_type                  -0.01            0.01        -0.01\navg_glucose_level                0.14           -0.12         0.03\nbmi                              0.00           -0.13        -0.02\nsmoking_status                   0.06           -0.06        -0.02\nstroke                           0.14           -0.07         0.04\ngenderadj                       -0.10            0.03         0.01\nageadj                           0.26           -0.49         0.14\nhypertensionadj                  0.11           -0.11         0.05\nheart_diseaseadj                 1.00           -0.07         0.03\never_marriedadj                 -0.07            1.00        -0.02\nwork_typeadj                     0.03           -0.02         1.00\nResidence_typeadj               -0.01            0.01        -0.01\navg_glucose_leveladj             0.14           -0.12         0.03\nbmiadj                           0.00           -0.13        -0.02\nsmoking_statusadj                0.06           -0.06        -0.02\n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender                           -0.01                -0.07  -0.02\nage                              -0.02                 0.24   0.04\nhypertension                      0.00                 0.17   0.13\nheart_disease                    -0.01                 0.14   0.00\never_married                      0.01                -0.12  -0.13\nwork_type                        -0.01                 0.03  -0.02\nResidence_type                    1.00                 0.01   0.01\navg_glucose_level                 0.01                 1.00   0.16\nbmi                               0.01                 0.16   1.00\nsmoking_status                   -0.04                 0.01   0.03\nstroke                           -0.01                 0.14   0.01\ngenderadj                        -0.01                -0.07  -0.02\nageadj                           -0.02                 0.24   0.04\nhypertensionadj                   0.00                 0.17   0.13\nheart_diseaseadj                 -0.01                 0.14   0.00\never_marriedadj                   0.01                -0.12  -0.13\nwork_typeadj                     -0.01                 0.03  -0.02\nResidence_typeadj                 1.00                 0.01   0.01\navg_glucose_leveladj              0.01                 1.00   0.16\nbmiadj                            0.01                 0.16   1.00\nsmoking_statusadj                -0.04                 0.01   0.03\n                     smoking_statusadj\ngender                           -0.08\nage                               0.03\nhypertension                     -0.01\nheart_disease                     0.06\never_married                     -0.06\nwork_type                        -0.02\nResidence_type                   -0.04\navg_glucose_level                 0.01\nbmi                               0.03\nsmoking_status                    1.00\nstroke                            0.02\ngenderadj                        -0.08\nageadj                            0.03\nhypertensionadj                  -0.01\nheart_diseaseadj                  0.06\never_marriedadj                  -0.06\nwork_typeadj                     -0.02\nResidence_typeadj                -0.04\navg_glucose_leveladj              0.01\nbmiadj                            0.03\nsmoking_statusadj                 1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nstroke               0.4296 0.0000 0.0000       0.0000        0.0002      \ngenderadj            0.0000 0.0012 0.0204       0.0000        0.1140      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \nhypertensionadj      0.0204 0.0000 0.0000       0.0000        0.0000      \nheart_diseaseadj     0.0000 0.0000 0.0000       0.0000        0.0000      \never_marriedadj      0.1140 0.0000 0.0000       0.0000        0.0000      \nwork_typeadj         0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_typeadj    0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_statusadj    0.0000 0.0448 0.7537       0.0005        0.0009      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nstroke               0.0259    0.7171         0.0000            0.6866\ngenderadj            0.3863    0.5077         0.0000            0.2487\nageadj               0.0000    0.3076         0.0000            0.0144\nhypertensionadj      0.0051    0.8569         0.0000            0.0000\nheart_diseaseadj     0.0862    0.5527         0.0000            0.8185\never_marriedadj      0.2313    0.5150         0.0000            0.0000\nwork_typeadj         0.0000    0.6768         0.0467            0.3243\nResidence_typeadj    0.6768    0.0000         0.6427            0.5689\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\nsmoking_statusadj    0.3764    0.0208         0.7679            0.0925\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender               0.0000         0.4296 0.0000    0.0012 0.0204         \nage                  0.0448         0.0000 0.0012    0.0000 0.0000         \nhypertension         0.7537         0.0000 0.0204    0.0000 0.0000         \nheart_disease        0.0005         0.0000 0.0000    0.0000 0.0000         \never_married         0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_type            0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_type       0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_level    0.7679         0.0000 0.0000    0.0000 0.0000         \nbmi                  0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_status                      0.2559 0.0000    0.0448 0.7537         \nstroke               0.2559                0.4296    0.0000 0.0000         \ngenderadj            0.0000         0.4296           0.0012 0.0204         \nageadj               0.0448         0.0000 0.0012           0.0000         \nhypertensionadj      0.7537         0.0000 0.0204    0.0000                \nheart_diseaseadj     0.0005         0.0000 0.0000    0.0000 0.0000         \never_marriedadj      0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_typeadj         0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_typeadj    0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_leveladj 0.7679         0.0000 0.0000    0.0000 0.0000         \nbmiadj               0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_statusadj    0.0000         0.2559 0.0000    0.0448 0.7537         \n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender               0.0000           0.1140          0.3863      \nage                  0.0000           0.0000          0.0000      \nhypertension         0.0000           0.0000          0.0051      \nheart_disease        0.0000           0.0000          0.0862      \never_married         0.0000           0.0000          0.2313      \nwork_type            0.0862           0.2313          0.0000      \nResidence_type       0.5527           0.5150          0.6768      \navg_glucose_level    0.0000           0.0000          0.0467      \nbmi                  0.8185           0.0000          0.3243      \nsmoking_status       0.0005           0.0009          0.3764      \nstroke               0.0000           0.0002          0.0259      \ngenderadj            0.0000           0.1140          0.3863      \nageadj               0.0000           0.0000          0.0000      \nhypertensionadj      0.0000           0.0000          0.0051      \nheart_diseaseadj                      0.0000          0.0862      \never_marriedadj      0.0000                           0.2313      \nwork_typeadj         0.0862           0.2313                      \nResidence_typeadj    0.5527           0.5150          0.6768      \navg_glucose_leveladj 0.0000           0.0000          0.0467      \nbmiadj               0.8185           0.0000          0.3243      \nsmoking_statusadj    0.0005           0.0009          0.3764      \n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender               0.5077            0.0000               0.2487\nage                  0.3076            0.0000               0.0144\nhypertension         0.8569            0.0000               0.0000\nheart_disease        0.5527            0.0000               0.8185\never_married         0.5150            0.0000               0.0000\nwork_type            0.6768            0.0467               0.3243\nResidence_type       0.0000            0.6427               0.5689\navg_glucose_level    0.6427            0.0000               0.0000\nbmi                  0.5689            0.0000               0.0000\nsmoking_status       0.0208            0.7679               0.0925\nstroke               0.7171            0.0000               0.6866\ngenderadj            0.5077            0.0000               0.2487\nageadj               0.3076            0.0000               0.0144\nhypertensionadj      0.8569            0.0000               0.0000\nheart_diseaseadj     0.5527            0.0000               0.8185\never_marriedadj      0.5150            0.0000               0.0000\nwork_typeadj         0.6768            0.0467               0.3243\nResidence_typeadj                      0.6427               0.5689\navg_glucose_leveladj 0.6427                                 0.0000\nbmiadj               0.5689            0.0000                     \nsmoking_statusadj    0.0208            0.7679               0.0925\n                     smoking_statusadj\ngender               0.0000           \nage                  0.0448           \nhypertension         0.7537           \nheart_disease        0.0005           \never_married         0.0009           \nwork_type            0.3764           \nResidence_type       0.0208           \navg_glucose_level    0.7679           \nbmi                  0.0925           \nsmoking_status       0.0000           \nstroke               0.2559           \ngenderadj            0.0000           \nageadj               0.0448           \nhypertensionadj      0.7537           \nheart_diseaseadj     0.0005           \never_marriedadj      0.0009           \nwork_typeadj         0.3764           \nResidence_typeadj    0.0208           \navg_glucose_leveladj 0.7679           \nbmiadj               0.0925           \nsmoking_statusadj                     \n\n\n\n# install.packages(\"car\")\n# library(car)\ninfluencePlot(model)\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n83    2.6917353 0.0039267816 0.012237368\n84    1.5018344 0.0343771041 0.006641860\n87    3.0732709 0.0012042796 0.011476828\n131   3.1608870 0.0006013465 0.007697762\n152   3.1135601 0.0005613972 0.006237531\n2583 -0.8509399 0.0399302730 0.001668526\n\n\nCooks D ranges from 0 to .0122\nWhile the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5\nConclusion: Assumption 3 is met - No substantial outliers\n\n\n3.4 Testing Assumption 4\nTesting Assumption 4 : Multicollinearity using vif in the care package\n\nvif(model)\n\n           gender               age      hypertension     heart_disease \n         1.041499          1.213552          1.051213          1.083661 \n     ever_married         work_type    Residence_type avg_glucose_level \n         1.018892          1.051698          1.006965          1.105268 \n              bmi    smoking_status \n         1.117138          1.049260 \n\n\nConclusion. All vif values are below 5 or 10. Ideally most values should be around 1. Range for all\nthe predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10.\nConclusion: No Multicollinearity\nFinal Conclusion: All4 assumptions are met, logistic regression is a valid model"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#analysis-of-the-model",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#analysis-of-the-model",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "4 Analysis of the Model",
    "text": "4 Analysis of the Model\nPart 4: Analysis of the Model\nThere are 2 issues with the model. Fit and Predictive Capability\n\n4.1 Use Hosmer-lemesho and Naglekerke R\nPart 1 fit. Use Hosmer-lemesho and Naglekerke R for non technical audience\n\n# install.packages(\"ResourceSelection\")\n# library(ResourceSelection)\nhoslem.test(model$y, fitted(model), g = 10)\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model$y, fitted(model)\nX-squared = 5.2704, df = 8, p-value = 0.7283\n\n\n\n# install.packages(\"rcompanion\")\n# library(rcompanion)\nnagelkerke(model)\n\n$Models\n                                                                                                                                                                               \nModel: \"glm, stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, binomial, LR_stroke1\"\nNull:  \"glm, stroke ~ 1, binomial, LR_stroke1\"                                                                                                                                 \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1838790\nCox and Snell (ML)                  0.0739944\nNagelkerke (Cragg and Uhler)        0.2165560\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq    p.value\n     -10     -129.03 258.07 1.0892e-49\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n\n\n\n4.2 Predictive Capability\nPart 2 - Predictive Capability\n\n# install.packages(\"pROC\")\n# library(pROC)\nprobs &lt;- predict(model, type = \"response\")\nroc_obj &lt;- roc(LR_stroke1$stroke, probs)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc(roc_obj)\n\nArea under the curve: 0.8285\n\n\nPredict AUC cross validation\n\n\n\n\n\n\nNeed to implement AUC cross validation\n\n\n\nCould not understand yet how to implement the AUC cross validation\n\n\n\n# Predict AUC cross validation\n# install.packages(\"cvAUC\")\n# library(cvAUC)\n\nConfusion Matrix\n\n# Confusion Matrix\nLR_stroke1$gender &lt;- factor(LR_stroke1$gender)\nLR_stroke1$hypertension &lt;- factor(LR_stroke1$hypertension)\nLR_stroke1$heart_disease &lt;- factor(LR_stroke1$heart_disease)\nLR_stroke1$ever_married &lt;- factor(LR_stroke1$ever_married)\nLR_stroke1$work_type &lt;- factor(LR_stroke1$work_type)\nLR_stroke1$Residence_type &lt;- factor(LR_stroke1$Residence_type)\nLR_stroke1$smoking_status &lt;- factor(LR_stroke1$smoking_status)\nLR_stroke1$stroke &lt;- factor(LR_stroke1$stroke)\n\nfit logistic regression model\n\n# fit logistic regression model\nmodel_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\n\nGet Predicted Probabilities for each observation\n\n# Get Predicted Probabilities for each observation\npred_prob &lt;- predict(model_CM, type = \"response\")\n\ncreate 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC\nClassify prediction using a threshold (0.5 is common but can adjust)\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of around 1.0\n\n# create 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC\n# Classify prediction using a threshold (0.5 is common but can adjust)\n# IF 1 row is all 0's then model doesn't show any predictability\n# At threshold of around 1.0\npred_class &lt;- factor(ifelse(pred_prob &gt; .99, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.9\n\n# At threshold of 0.9\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.9, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.8\n\n# At threshold of 0.8\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.8, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.7\n\n# At threshold of 0.7\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.7, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  180\n         1    0    0\n\n\nAt threshold of 0.6\n\n# At threshold of 0.6\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.6, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3177  179\n         1    0    1\n\n\nat threshold of 0.6 that starts the models predictability\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision, Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.011050\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.005556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 1.000000\"\n\n\nat threshold of 0.5\n\n# at threshold of 0.5\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.5, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3176  179\n         1    1    1\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.010989\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.005556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.500000\"\n\n\nAt threshold of 0.4\n\n# At threshold of 0.4\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.4, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3171  174\n         1    6    6\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.062500\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.033333\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.500000\"\n\n\nat threshold of 0.3\n\n# at threshold of 0.3\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.3, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3140  164\n         1   37   16\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.137339\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.088889\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.301887\"\n\n\nat threshold of 0.2\n\n# at threshold of 0.2\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.2, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n\n          Reference\nPrediction    0    1\n         0 3040  134\n         1  137   46\n\n\nExtract precision,Recall and F1 from confusion matrix using the caret package\n\n# Extract precision,Recall and F1 from confusion matrix using the caret package\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(sprintf(\"F1: %f\", f1))\n\n[1] \"F1: 0.253444\"\n\nprint(sprintf(\"recall: %f\", recall))\n\n[1] \"recall: 0.255556\"\n\nprint(sprintf(\"precision: %f\", precision))\n\n[1] \"precision: 0.251366\"\n\n\nUsing the different Confusion Matrices, Create the ROC curve"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#original-code",
    "href": "posts/renan-blog-post-week8/Stroke_Results_1019_2025_latest.html#original-code",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "Original Code",
    "text": "Original Code\nBelow we see the Original Code shared by Steve: Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R\n```{r}\ninstall.packages(\"dplyr\")\ninstall.packages(\"car\")\ninstall.packages(\"ResourceSelection\")\ninstall.packages(\"caret\")\ninstall.packages(\"car\")\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nlibrary(caret)\nlibrary(car)\nstroke1 &lt;- read.csv(\"D:\\\\stroke.csv\")\nhead(stroke1)\nnrow(stroke1)\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n#-------------------------------------------Part 1:  preparing the data---------------------------------#\n# Smoking Status - remove unknown#\n#bmi - remove N/A#\n# Work type - remove children#\n# age create numerical variable with 2 places after the decimal#\n#gender -remove other#\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nstroke1_clean &lt;- na.omit(stroke1)\n#converted all columns to numeric and removed id#\nstr(stroke1_clean)\nnrow(stroke1_clean)\nLR_stroke1 &lt;- stroke1_clean\nstr(LR_stroke1)\ncount_tables &lt;- lapply(LR_stroke1, table)\ncount_tables\n#-------------------------Part 2:Create and Run the Logistic Regression model from the  dataset-------------#\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n# ----------------------------------------------Issue _ Unbalanced Data set--------------------------------------#\n# The stroke rate = 180/3357 = 054%. But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS.--------#\n# The dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample....but too much time----#\n# Best way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on------#\nds_prev &lt;- .054\npop_prev &lt;- .031\nlog_odds_ds &lt;- qlogis(ds_prev)\nlog_odds_pop &lt;- qlogis(pop_prev)\noffset &lt;- log_odds_pop - log_odds_ds\ncoefs &lt;- coef(model)\ncoefs[1] &lt;- coefs[1] + offset\nprint(coefs)\n# Original Intercept Coeff = -8.426854231#\n# Changed intercept Coefficent to take into account current stroke rate or 3.1% = -9.005873116-------------------#\n# all the other intercepts remain the same-----------------------------------------------------------------------#\n# ----------------------------------Part 3: Testing logistic Regression Model Assumptions------------------------#\n# There are several assumptions for Logistic Regression#\n# They are:#\n#(1) The Dependent Variable is binary (i.e, 0 or 1)#\n#(2) There is a linear relationship between th logit of the outcome and each predictor#\n#(3) There are NO high leverage outliers in the predictors#\n#(4) There is No high multicollinearity (ie strong correlations) between predictors#\n####################################:Now to test each assumption: ################\n# Testing Assumption 1: The Dependent Variable is binary (0 or 1)#\nunique(LR_stroke1$stroke)\n#Testing Assumption 2: There is a linear relationship between the outcome variable and each predictor\n#first,  adjust all predictors so all values are positive#\n# Conclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity#\n# Conclusion:all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression#\n# ---------------------------------------Conclusion for assumption 2 - Linearity is met--------------------------------#\n# Testing Assumption 3: assess influential outliers using car package and influencePlot#\nalias(model)\ninstall.packages(\"Hmisc\")\nlibrary(Hmisc)\nrcorr(as.matrix(LR_stroke1))\ninstall.packages(\"car\")\nlibrary(car)\ninfluencePlot(model)\n# Cooks D ranges from 0 to .0122 While the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5\n#--------------------------------- Conclusion: Assumption 3 is met - No substantial outliers---------------------#\n# Testing Assumption 4 : Multicollinearity using vif in the care package#\nvif(model)\n#--------------------Conclusion. All vif values are below  5 or 10. Ideally most values should be around 1. Range for all#\n# the predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10. Conclusion: No Multicollinearity####\n#####################################################################################################################\n# -----------------Final Conclusion: All4 assumptions are met, logistic regression is a valid model---------------#\n####################################################################################################################\n# ---------------------------------------------Part 4: Analysis of the Model----------------------------------------#\n# -----------------------There are 2 issues with the model. Fit and Predictive Capability---------------------------#\n# ----------------Part 1  fit. Use Hosmer-lemesho and Naglekerke R for non technical audience-----------------------#\ninstall.packages(\"ResourceSelection\")\nlibrary(ResourceSelection)\nhoslem.test(model$y, fitted(model), g = 10)\ninstall.packages(\"rcompanion\")\nlibrary(rcompanion)\nnagelkerke(model)\n# -----------------------Part 2 - Predictive Capability-----------------------------------------------------------\ninstall.packages(\"pROC\")\nlibrary(pROC)\nprobs &lt;- predict(model, type = \"response\")\nroc_obj &lt;- roc(LR_stroke1$stroke, probs)\nauc(roc_obj)\n# Predict AUC cross validation\ninstall.packages(\"cvAUC\")\nlibrary(cvAUC)\n# Confusion Matrix\nLR_stroke1$gender &lt;- factor(LR_stroke1$gender)\nLR_stroke1$hypertension &lt;- factor(LR_stroke1$hypertension)\nLR_stroke1$heart_disease &lt;- factor(LR_stroke1$heart_disease)\nLR_stroke1$ever_married &lt;- factor(LR_stroke1$ever_married)\nLR_stroke1$work_type &lt;- factor(LR_stroke1$work_type)\nLR_stroke1$Residence_type &lt;- factor(LR_stroke1$Residence_type)\nLR_stroke1$smoking_status &lt;- factor(LR_stroke1$smoking_status)\nLR_stroke1$stroke &lt;- factor(LR_stroke1$stroke)\n# fit logistic regression model\nmodel_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\n# Get Predicted Probabilities for each observation\npred_prob &lt;- predict(model_CM, type = \"response\")\ninstall.packages(\"caret\")\nlibrary(caret)\n# create 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC\n#Classify prediction using a threshold (0.5 is common but can adjust)\n#---------------------------IF 1 row is all 0's then model doesn't show any predictability-------------------#\n# At threshold of around 1.0 #\npred_class &lt;- factor(ifelse(pred_prob &gt; .99, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n#-------------------------IF 1 row is all 0's then model doesn't show any predictability-----------------------#\n# At threshold of 0.9 #\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.9, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n#-----------------------IF 1 row is all 0's then model doesn't show any predictability--------------------------#\n# At threshold of 0.8#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.8, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n#----------------------IF 1 row is all 0's then model doesn't show any predictability---------------------------#\n# At threshold of 0.7#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.7, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# At threshold of 0.6#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.6, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n################################################################################################################\n#-----------------------------at threshold of 0.6 that starts the models predictability------------------------#\n################################################################################################################\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# at threshold of 0.5#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.5, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# At threshold of 0.4#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.4, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# at threshold of 0.3#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.3, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# at threshold of 0.2#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.2, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# At Threshold of 0.18#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.18, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$Class[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# At threshold of 0.15#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.15, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# at threshold of 0.1#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.1, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# at threshold of 0.05#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.05, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix$table)\n# Extract precision,Recall and F1 from confusion matrix using the caret package #\nprecision &lt;- conf_matrix$byClass[\"Pos Pred Value\"] \nrecall &lt;- conf_matrix$byClass[\"Sensitivity\"]\nf1 &lt;- 2 * ((precision * recall)/ (precision + recall))\nprint(f1)\nprint(recall)\nprint(precision)\n# Using the different Confusion Matrices, Create the ROC curve\n```\n\nReferences"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "",
    "text": "On this document I try to replicate Steve code: Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R\n# install.packages(\"Hmisc\")\n# library(Hmisc)\nrcorr(as.matrix(LR_stroke1))\n\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nstroke                -0.01  0.24         0.14          0.14        -0.07\ngenderadj              1.00 -0.06        -0.04         -0.10         0.03\nageadj                -0.06  1.00         0.26          0.26        -0.49\nhypertensionadj       -0.04  0.26         1.00          0.11        -0.11\nheart_diseaseadj      -0.10  0.26         0.11          1.00        -0.07\never_marriedadj        0.03 -0.49        -0.11         -0.07         1.00\nwork_typeadj           0.01  0.14         0.05          0.03        -0.02\nResidence_typeadj     -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\nsmoking_statusadj     -0.08  0.03        -0.01          0.06        -0.06\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nstroke                    0.04          -0.01              0.14  0.01\ngenderadj                 0.01          -0.01             -0.07 -0.02\nageadj                    0.14          -0.02              0.24  0.04\nhypertensionadj           0.05           0.00              0.17  0.13\nheart_diseaseadj          0.03          -0.01              0.14  0.00\never_marriedadj          -0.02           0.01             -0.12 -0.13\nwork_typeadj              1.00          -0.01              0.03 -0.02\nResidence_typeadj        -0.01           1.00              0.01  0.01\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\nsmoking_statusadj        -0.02          -0.04              0.01  0.03\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender                        -0.08  -0.01      1.00  -0.06           -0.04\nage                            0.03   0.24     -0.06   1.00            0.26\nhypertension                  -0.01   0.14     -0.04   0.26            1.00\nheart_disease                  0.06   0.14     -0.10   0.26            0.11\never_married                  -0.06  -0.07      0.03  -0.49           -0.11\nwork_type                     -0.02   0.04      0.01   0.14            0.05\nResidence_type                -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_level              0.01   0.14     -0.07   0.24            0.17\nbmi                            0.03   0.01     -0.02   0.04            0.13\nsmoking_status                 1.00   0.02     -0.08   0.03           -0.01\nstroke                         0.02   1.00     -0.01   0.24            0.14\ngenderadj                     -0.08  -0.01      1.00  -0.06           -0.04\nageadj                         0.03   0.24     -0.06   1.00            0.26\nhypertensionadj               -0.01   0.14     -0.04   0.26            1.00\nheart_diseaseadj               0.06   0.14     -0.10   0.26            0.11\never_marriedadj               -0.06  -0.07      0.03  -0.49           -0.11\nwork_typeadj                  -0.02   0.04      0.01   0.14            0.05\nResidence_typeadj             -0.04  -0.01     -0.01  -0.02            0.00\navg_glucose_leveladj           0.01   0.14     -0.07   0.24            0.17\nbmiadj                         0.03   0.01     -0.02   0.04            0.13\nsmoking_statusadj              1.00   0.02     -0.08   0.03           -0.01\n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender                          -0.10            0.03         0.01\nage                              0.26           -0.49         0.14\nhypertension                     0.11           -0.11         0.05\nheart_disease                    1.00           -0.07         0.03\never_married                    -0.07            1.00        -0.02\nwork_type                        0.03           -0.02         1.00\nResidence_type                  -0.01            0.01        -0.01\navg_glucose_level                0.14           -0.12         0.03\nbmi                              0.00           -0.13        -0.02\nsmoking_status                   0.06           -0.06        -0.02\nstroke                           0.14           -0.07         0.04\ngenderadj                       -0.10            0.03         0.01\nageadj                           0.26           -0.49         0.14\nhypertensionadj                  0.11           -0.11         0.05\nheart_diseaseadj                 1.00           -0.07         0.03\never_marriedadj                 -0.07            1.00        -0.02\nwork_typeadj                     0.03           -0.02         1.00\nResidence_typeadj               -0.01            0.01        -0.01\navg_glucose_leveladj             0.14           -0.12         0.03\nbmiadj                           0.00           -0.13        -0.02\nsmoking_statusadj                0.06           -0.06        -0.02\n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender                           -0.01                -0.07  -0.02\nage                              -0.02                 0.24   0.04\nhypertension                      0.00                 0.17   0.13\nheart_disease                    -0.01                 0.14   0.00\never_married                      0.01                -0.12  -0.13\nwork_type                        -0.01                 0.03  -0.02\nResidence_type                    1.00                 0.01   0.01\navg_glucose_level                 0.01                 1.00   0.16\nbmi                               0.01                 0.16   1.00\nsmoking_status                   -0.04                 0.01   0.03\nstroke                           -0.01                 0.14   0.01\ngenderadj                        -0.01                -0.07  -0.02\nageadj                           -0.02                 0.24   0.04\nhypertensionadj                   0.00                 0.17   0.13\nheart_diseaseadj                 -0.01                 0.14   0.00\never_marriedadj                   0.01                -0.12  -0.13\nwork_typeadj                     -0.01                 0.03  -0.02\nResidence_typeadj                 1.00                 0.01   0.01\navg_glucose_leveladj              0.01                 1.00   0.16\nbmiadj                            0.01                 0.16   1.00\nsmoking_statusadj                -0.04                 0.01   0.03\n                     smoking_statusadj\ngender                           -0.08\nage                               0.03\nhypertension                     -0.01\nheart_disease                     0.06\never_married                     -0.06\nwork_type                        -0.02\nResidence_type                   -0.04\navg_glucose_level                 0.01\nbmi                               0.03\nsmoking_status                    1.00\nstroke                            0.02\ngenderadj                        -0.08\nageadj                            0.03\nhypertensionadj                  -0.01\nheart_diseaseadj                  0.06\never_marriedadj                  -0.06\nwork_typeadj                     -0.02\nResidence_typeadj                -0.04\navg_glucose_leveladj              0.01\nbmiadj                            0.03\nsmoking_statusadj                 1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nstroke               0.4296 0.0000 0.0000       0.0000        0.0002      \ngenderadj            0.0000 0.0012 0.0204       0.0000        0.1140      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \nhypertensionadj      0.0204 0.0000 0.0000       0.0000        0.0000      \nheart_diseaseadj     0.0000 0.0000 0.0000       0.0000        0.0000      \never_marriedadj      0.1140 0.0000 0.0000       0.0000        0.0000      \nwork_typeadj         0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_typeadj    0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_statusadj    0.0000 0.0448 0.7537       0.0005        0.0009      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nstroke               0.0259    0.7171         0.0000            0.6866\ngenderadj            0.3863    0.5077         0.0000            0.2487\nageadj               0.0000    0.3076         0.0000            0.0144\nhypertensionadj      0.0051    0.8569         0.0000            0.0000\nheart_diseaseadj     0.0862    0.5527         0.0000            0.8185\never_marriedadj      0.2313    0.5150         0.0000            0.0000\nwork_typeadj         0.0000    0.6768         0.0467            0.3243\nResidence_typeadj    0.6768    0.0000         0.6427            0.5689\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\nsmoking_statusadj    0.3764    0.0208         0.7679            0.0925\n                     smoking_status stroke genderadj ageadj hypertensionadj\ngender               0.0000         0.4296 0.0000    0.0012 0.0204         \nage                  0.0448         0.0000 0.0012    0.0000 0.0000         \nhypertension         0.7537         0.0000 0.0204    0.0000 0.0000         \nheart_disease        0.0005         0.0000 0.0000    0.0000 0.0000         \never_married         0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_type            0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_type       0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_level    0.7679         0.0000 0.0000    0.0000 0.0000         \nbmi                  0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_status                      0.2559 0.0000    0.0448 0.7537         \nstroke               0.2559                0.4296    0.0000 0.0000         \ngenderadj            0.0000         0.4296           0.0012 0.0204         \nageadj               0.0448         0.0000 0.0012           0.0000         \nhypertensionadj      0.7537         0.0000 0.0204    0.0000                \nheart_diseaseadj     0.0005         0.0000 0.0000    0.0000 0.0000         \never_marriedadj      0.0009         0.0002 0.1140    0.0000 0.0000         \nwork_typeadj         0.3764         0.0259 0.3863    0.0000 0.0051         \nResidence_typeadj    0.0208         0.7171 0.5077    0.3076 0.8569         \navg_glucose_leveladj 0.7679         0.0000 0.0000    0.0000 0.0000         \nbmiadj               0.0925         0.6866 0.2487    0.0144 0.0000         \nsmoking_statusadj    0.0000         0.2559 0.0000    0.0448 0.7537         \n                     heart_diseaseadj ever_marriedadj work_typeadj\ngender               0.0000           0.1140          0.3863      \nage                  0.0000           0.0000          0.0000      \nhypertension         0.0000           0.0000          0.0051      \nheart_disease        0.0000           0.0000          0.0862      \never_married         0.0000           0.0000          0.2313      \nwork_type            0.0862           0.2313          0.0000      \nResidence_type       0.5527           0.5150          0.6768      \navg_glucose_level    0.0000           0.0000          0.0467      \nbmi                  0.8185           0.0000          0.3243      \nsmoking_status       0.0005           0.0009          0.3764      \nstroke               0.0000           0.0002          0.0259      \ngenderadj            0.0000           0.1140          0.3863      \nageadj               0.0000           0.0000          0.0000      \nhypertensionadj      0.0000           0.0000          0.0051      \nheart_diseaseadj                      0.0000          0.0862      \never_marriedadj      0.0000                           0.2313      \nwork_typeadj         0.0862           0.2313                      \nResidence_typeadj    0.5527           0.5150          0.6768      \navg_glucose_leveladj 0.0000           0.0000          0.0467      \nbmiadj               0.8185           0.0000          0.3243      \nsmoking_statusadj    0.0005           0.0009          0.3764      \n                     Residence_typeadj avg_glucose_leveladj bmiadj\ngender               0.5077            0.0000               0.2487\nage                  0.3076            0.0000               0.0144\nhypertension         0.8569            0.0000               0.0000\nheart_disease        0.5527            0.0000               0.8185\never_married         0.5150            0.0000               0.0000\nwork_type            0.6768            0.0467               0.3243\nResidence_type       0.0000            0.6427               0.5689\navg_glucose_level    0.6427            0.0000               0.0000\nbmi                  0.5689            0.0000               0.0000\nsmoking_status       0.0208            0.7679               0.0925\nstroke               0.7171            0.0000               0.6866\ngenderadj            0.5077            0.0000               0.2487\nageadj               0.3076            0.0000               0.0144\nhypertensionadj      0.8569            0.0000               0.0000\nheart_diseaseadj     0.5527            0.0000               0.8185\never_marriedadj      0.5150            0.0000               0.0000\nwork_typeadj         0.6768            0.0467               0.3243\nResidence_typeadj                      0.6427               0.5689\navg_glucose_leveladj 0.6427                                 0.0000\nbmiadj               0.5689            0.0000                     \nsmoking_statusadj    0.0208            0.7679               0.0925\n                     smoking_statusadj\ngender               0.0000           \nage                  0.0448           \nhypertension         0.7537           \nheart_disease        0.0005           \never_married         0.0009           \nwork_type            0.3764           \nResidence_type       0.0208           \navg_glucose_level    0.7679           \nbmi                  0.0925           \nsmoking_status       0.0000           \nstroke               0.2559           \ngenderadj            0.0000           \nageadj               0.0448           \nhypertensionadj      0.7537           \nheart_diseaseadj     0.0005           \never_marriedadj      0.0009           \nwork_typeadj         0.3764           \nResidence_typeadj    0.0208           \navg_glucose_leveladj 0.7679           \nbmiadj               0.0925           \nsmoking_statusadj\n# install.packages(\"car\")\n# library(car)\ninfluencePlot(model)\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n83    2.6917353 0.0039267816 0.012237368\n84    1.5018344 0.0343771041 0.006641860\n87    3.0732709 0.0012042796 0.011476828\n131   3.1608870 0.0006013465 0.007697762\n152   3.1135601 0.0005613972 0.006237531\n2583 -0.8509399 0.0399302730 0.001668526\nCooks D ranges from 0 to .0122\nWhile the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5\nConclusion: Assumption 3 is met - No substantial outliers"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#setup-and-data-loading",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.\n\n1.1 Load Libraries\nInstall packages if necessary:\n\n\nCode\n# Run this once to install all the necessary packages\n# install.packages(\"dplyr\")\n# install.packages(\"car\")\n# install.packages(\"ResourceSelection\")\n# install.packages(\"caret\")\n# install.packages(\"rcompanion\")\n# install.packages(\"pROC\")\n# install.packages(\"cvAUC\")\n\n\nLoad Libraries:\n\n\nCode\n# For data manipulation and visualization\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(ggpubr)\n\n# For data preprocessing and modeling\nlibrary(mice)\nlibrary(ROSE) # For SMOTE\nlibrary(ranger) # A fast implementation of random forests\n\n# For stacking/ensemble models\nlibrary(stacks)\nlibrary(tidymodels)\n\nlibrary(themis)\nlibrary(gghighlight)\n\nlibrary(pscl)\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nlibrary(caret)\nlibrary(rcompanion)\nlibrary(Hmisc)\nlibrary(pROC)\nlibrary(cvAUC)\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n1.1.1 Possible Issues and conflicts to resolve\n```{bash}\n\n```\n\n\n\n1.2 Load Data\nWill be using my original Dataset as well Steve’s Dataset and compare for differences.\n\nRenan: kaggle_data1\nSteve: stroke1\n\n\n1.2.1 Renan Dataset\nBelow will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\nkaggle_dataset_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nkaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)\n\n# unique(kaggle_data1$bmi)\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  mutate(bmi = na_if(bmi, \"N/A\")) %&gt;%   # Convert \"N/A\" string to NA\n  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric\n\n# Remove the 'Other' gender row and the 'id' column\nkaggle_data1 &lt;- kaggle_data1 %&gt;%\n  filter(gender != \"Other\") %&gt;%\n  select(-id) %&gt;%\n  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling\n\n\n\n\n1.2.1 Steve Dataset\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n\n\n\n\n\n1.3 Prepare Dataset\n\nhead(stroke1)\nnrow(stroke1)\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n\nPart 1: preparing the data\n\nSmoking Status - remove unknown\nbmi - remove N/A\nWork type - remove children\nage - create numerical variable with 2 places after the decimal\ngender - remove other\n\n\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\n\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\n\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\nWarning: NAs introduced by coercion\n\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\n\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\n\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\n\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\n\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\n\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\n\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\n\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\n\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\n\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nstroke1_clean &lt;- na.omit(stroke1)\n\nconverted all columns to numeric and removed id\n\n# converted all columns to numeric and removed id\nstr(stroke1_clean)\nnrow(stroke1_clean)\nLR_stroke1 &lt;- stroke1_clean\nstr(LR_stroke1)\ncount_tables &lt;- lapply(LR_stroke1, table)\ncount_tables"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#apply-logistic-regression",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#apply-logistic-regression",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "2. Apply Logistic Regression",
    "text": "2. Apply Logistic Regression\nPart 2:Create and Run the Logistic Regression model from the dataset\n\n# Part 2:Create and Run the Logistic Regression model from the  dataset\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = stroke ~ gender + age + hypertension + heart_disease + \n    ever_married + work_type + Residence_type + avg_glucose_level + \n    bmi + smoking_status, family = binomial, data = LR_stroke1)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.426854   0.873243  -9.650  &lt; 2e-16 ***\ngender             0.080370   0.167274   0.480 0.630893    \nage                0.070967   0.006845  10.368  &lt; 2e-16 ***\nhypertension       0.570797   0.182580   3.126 0.001770 ** \nheart_disease      0.417884   0.220311   1.897 0.057856 .  \never_married       0.174316   0.261832   0.666 0.505569    \nwork_type         -0.109615   0.126101  -0.869 0.384703    \nResidence_type     0.005932   0.162188   0.037 0.970822    \navg_glucose_level  0.004658   0.001375   3.388 0.000704 ***\nbmi                0.006275   0.012875   0.487 0.625954    \nsmoking_status     0.179921   0.106431   1.691 0.090932 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1403.5  on 3356  degrees of freedom\nResidual deviance: 1145.4  on 3346  degrees of freedom\nAIC: 1167.4\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#testing-logistic-regression-model-assumptions",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#testing-logistic-regression-model-assumptions",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "3. Testing logistic Regression Model Assumptions",
    "text": "3. Testing logistic Regression Model Assumptions\nPart 3: Testing logistic Regression Model Assumptions\nThere are several assumptions for Logistic Regression. They are:\n\nThe Dependent Variable is binary (i.e, 0 or 1)\nThere is a linear relationship between th logit of the outcome and each predictor\nThere are NO high leverage outliers in the predictors\nThere is No high multicollinearity (ie strong correlations) between predictors\n\nNow to test each assumption\n\n3.1 Testing Assumption 1\nTesting Assumption 1: The Dependent Variable is binary (0 or 1)\n\nunique(LR_stroke1$stroke)\n\n[1] 1 0\n\n\n\n\n3.2 Testing Assumption 2\nTesting Assumption 2: There is a linear relationship between the outcome variable and each predictor\nfirst, adjust all predictors so all values are positive\nConclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bmiadj, the residual plots show linearity\nConclusion: all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression\nConclusion for assumption 2 - Linearity is met\n\nLR_stroke1$genderadj &lt;- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1\n\nLR_stroke1$ageadj &lt;- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1\n\nLR_stroke1$hypertensionadj &lt;- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$heart_diseaseadj &lt;- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1\n\nLR_stroke1$ever_marriedadj &lt;- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1\n\nLR_stroke1$work_typeadj &lt;- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1\n\nLR_stroke1$Residence_typeadj &lt;- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1\n\nLR_stroke1$avg_glucose_leveladj &lt;- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1\n\nLR_stroke1$bmiadj &lt;- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1\n\nLR_stroke1$smoking_statusadj &lt;- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1\n\nstr(LR_stroke1)\n\ntibble [3,357 × 21] (S3: tbl_df/tbl/data.frame)\n $ gender              : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age                 : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension        : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease       : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married        : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type           : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type      : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level   : num [1:3357] 229 106 171 174 186 ...\n $ bmi                 : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status      : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke              : num [1:3357] 1 1 1 1 1 1 1 1 1 1 ...\n $ genderadj           : num [1:3357] 3 3 4 4 3 3 4 4 4 4 ...\n $ ageadj              : num [1:3357] 81 94 63 93 95 88 83 95 75 68 ...\n $ hypertensionadj     : num [1:3357] 1 1 1 2 1 2 1 2 1 1 ...\n $ heart_diseaseadj    : num [1:3357] 2 2 1 1 1 2 1 1 2 1 ...\n $ ever_marriedadj     : num [1:3357] 3 3 3 3 3 3 4 3 3 3 ...\n $ work_typeadj        : num [1:3357] 4 4 4 5 4 4 4 4 3 4 ...\n $ Residence_typeadj   : num [1:3357] 3 4 3 4 3 4 3 4 4 3 ...\n $ avg_glucose_leveladj: num [1:3357] 285 162 227 230 242 ...\n $ bmiadj              : num [1:3357] 49.1 45 46.9 36.5 41.5 39.9 35.3 42.2 49.3 39.8 ...\n $ smoking_statusadj   : num [1:3357] 4 3 5 3 4 3 3 3 5 5 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n\nStrokeAdj &lt;- LR_stroke1\n\nStrokeAdj &lt;- StrokeAdj[ , !(names(StrokeAdj) %in% c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\")) ]\n\nFit the model\n\nmod.2 &lt;- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)\n\n\n# Plot Residuals\nresidualPlots(mod.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                     Test stat Pr(&gt;|Test stat|)  \ngenderadj               0.0000          1.00000  \nageadj                  2.0626          0.15095  \nhypertensionadj         0.0000          1.00000  \nheart_diseaseadj        0.0000          1.00000  \never_marriedadj         0.0000          1.00000  \nwork_typeadj            3.1406          0.07636 .\nResidence_typeadj       0.0000          1.00000  \navg_glucose_leveladj    0.0103          0.91921  \nbmiadj                  0.3947          0.52983  \nsmoking_statusadj       0.4775          0.48953  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n3.3 Testing Assumption 3\nTesting Assumption 3: assess influential outliers using car package and influencePlot\n\n# Where the Object Stroke.2 comes from\n# alias(Stroke.2)\nalias(model)\n\nModel :\nstroke ~ gender + age + hypertension + heart_disease + ever_married + \n    work_type + Residence_type + avg_glucose_level + bmi + smoking_status"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#error---object-not-found",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#error---object-not-found",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "Error - Object not found",
    "text": "Error - Object not found\nError: object ‘Stroke.2’ not found. Where is it coming from ??"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#analysis-of-the-model",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#analysis-of-the-model",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "4 Analysis of the Model",
    "text": "4 Analysis of the Model\nPart 4: Analysis of the Model\nThere are 2 issues with the model. Fit and Predictive Capability\n\n4.1 Use Hosmer-lemesho and Naglekerke R\nPart 1 fit. Use Hosmer-lemesho and Naglekerke R for non technical audience\n\n# install.packages(\"ResourceSelection\")\n# library(ResourceSelection)\nhoslem.test(model$y, fitted(model), g = 10)\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model$y, fitted(model)\nX-squared = 5.2704, df = 8, p-value = 0.7283\n\n\n\n# install.packages(\"rcompanion\")\n# library(rcompanion)\nnagelkerke(model)\n\n$Models\n                                                                                                                                                                               \nModel: \"glm, stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, binomial, LR_stroke1\"\nNull:  \"glm, stroke ~ 1, binomial, LR_stroke1\"                                                                                                                                 \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1838790\nCox and Snell (ML)                  0.0739944\nNagelkerke (Cragg and Uhler)        0.2165560\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq    p.value\n     -10     -129.03 258.07 1.0892e-49\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n\n\n\n4.2 Predictive Capability\nPart 2 - Predictive Capability\n\n# install.packages(\"pROC\")\n# library(pROC)\nprobs &lt;- predict(model, type = \"response\")\nroc_obj &lt;- roc(LR_stroke1$stroke, probs)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc(roc_obj)\n\nArea under the curve: 0.8285\n\n\nPredict AUC cross validation\n\n\n\n\n\n\nNeed to implement AUC cross validation\n\n\n\nCould not understand yet how to implement the AUC cross validation\n\n\n\n# Predict AUC cross validation\n# install.packages(\"cvAUC\")\n# library(cvAUC)\n\nConfusion Matrix\n\n# Confusion Matrix\nLR_stroke1$gender &lt;- factor(LR_stroke1$gender)\nLR_stroke1$hypertension &lt;- factor(LR_stroke1$hypertension)\nLR_stroke1$heart_disease &lt;- factor(LR_stroke1$heart_disease)\nLR_stroke1$ever_married &lt;- factor(LR_stroke1$ever_married)\nLR_stroke1$work_type &lt;- factor(LR_stroke1$work_type)\nLR_stroke1$Residence_type &lt;- factor(LR_stroke1$Residence_type)\nLR_stroke1$smoking_status &lt;- factor(LR_stroke1$smoking_status)\nLR_stroke1$stroke &lt;- factor(LR_stroke1$stroke)\n\nfit logistic regression model\n\n# fit logistic regression model\nmodel_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\n\nGet Predicted Probabilities for each observation\n\n# Get Predicted Probabilities for each observation\npred_prob &lt;- predict(model_CM, type = \"response\")\n\nAt threshold of around 0.5\n\n# Classify prediction using a threshold (0.5 is common but can adjust)\n# at threshold of 0.5\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.5, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3176  179\n         1    1    1\n                                          \n               Accuracy : 0.9464          \n                 95% CI : (0.9382, 0.9538)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 0.5198          \n                                          \n                  Kappa : 0.0098          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.0055556       \n            Specificity : 0.9996852       \n         Pos Pred Value : 0.5000000       \n         Neg Pred Value : 0.9466468       \n             Prevalence : 0.0536193       \n         Detection Rate : 0.0002979       \n   Detection Prevalence : 0.0005958       \n      Balanced Accuracy : 0.5026204       \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.3\n\n# at threshold of 0.3\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.3, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3140  164\n         1   37   16\n                                          \n               Accuracy : 0.9401          \n                 95% CI : (0.9316, 0.9479)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 0.9483          \n                                          \n                  Kappa : 0.1158          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.088889        \n            Specificity : 0.988354        \n         Pos Pred Value : 0.301887        \n         Neg Pred Value : 0.950363        \n             Prevalence : 0.053619        \n         Detection Rate : 0.004766        \n   Detection Prevalence : 0.015788        \n      Balanced Accuracy : 0.538621        \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.2\n\n# at threshold of 0.2\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.2, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3040  134\n         1  137   46\n                                          \n               Accuracy : 0.9193          \n                 95% CI : (0.9095, 0.9283)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 1.0000          \n                                          \n                  Kappa : 0.2108          \n                                          \n Mcnemar's Test P-Value : 0.9033          \n                                          \n            Sensitivity : 0.25556         \n            Specificity : 0.95688         \n         Pos Pred Value : 0.25137         \n         Neg Pred Value : 0.95778         \n             Prevalence : 0.05362         \n         Detection Rate : 0.01370         \n   Detection Prevalence : 0.05451         \n      Balanced Accuracy : 0.60622         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nIF 1 row is all 0’s then model doesn’t show any predictability\nAt threshold of 0.18\n\n# At Threshold of 0.18\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.18, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 3003  126\n         1  174   54\n                                          \n               Accuracy : 0.9106          \n                 95% CI : (0.9005, 0.9201)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 1.000000        \n                                          \n                  Kappa : 0.2178          \n                                          \n Mcnemar's Test P-Value : 0.006657        \n                                          \n            Sensitivity : 0.30000         \n            Specificity : 0.94523         \n         Pos Pred Value : 0.23684         \n         Neg Pred Value : 0.95973         \n             Prevalence : 0.05362         \n         Detection Rate : 0.01609         \n   Detection Prevalence : 0.06792         \n      Balanced Accuracy : 0.62262         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nAt threshold of 0.15\n\n# At threshold of 0.15\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.15, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2917  102\n         1  260   78\n                                          \n               Accuracy : 0.8922          \n                 95% CI : (0.8812, 0.9025)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2486          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.43333         \n            Specificity : 0.91816         \n         Pos Pred Value : 0.23077         \n         Neg Pred Value : 0.96621         \n             Prevalence : 0.05362         \n         Detection Rate : 0.02324         \n   Detection Prevalence : 0.10069         \n      Balanced Accuracy : 0.67575         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nat threshold of 0.6 that starts the models predictability\nAt threshold of 0.1\n\n# at threshold of 0.1#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.1, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2683   69\n         1  494  111\n                                          \n               Accuracy : 0.8323          \n                 95% CI : (0.8192, 0.8448)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2182          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.61667         \n            Specificity : 0.84451         \n         Pos Pred Value : 0.18347         \n         Neg Pred Value : 0.97493         \n             Prevalence : 0.05362         \n         Detection Rate : 0.03307         \n   Detection Prevalence : 0.18022         \n      Balanced Accuracy : 0.73059         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nAt threshold of 0.05\n\n# at threshold of 0.05#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.05, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2256   37\n         1  921  143\n                                         \n               Accuracy : 0.7146         \n                 95% CI : (0.699, 0.7299)\n    No Information Rate : 0.9464         \n    P-Value [Acc &gt; NIR] : 1              \n                                         \n                  Kappa : 0.1521         \n                                         \n Mcnemar's Test P-Value : &lt;2e-16         \n                                         \n            Sensitivity : 0.79444        \n            Specificity : 0.71010        \n         Pos Pred Value : 0.13440        \n         Neg Pred Value : 0.98386        \n             Prevalence : 0.05362        \n         Detection Rate : 0.04260        \n   Detection Prevalence : 0.31695        \n      Balanced Accuracy : 0.75227        \n                                         \n       'Positive' Class : 1              \n                                         \n\n\nGenerate Confusion Matrix comparing model predictions to actual outcome\n\n\n\n\n\n\nConfused about this code chunk\n\n\n\nThis code serves no purpose at all\n\n\n\n#Generate Confusion Matrix comparing model predictions to actual outcome\n# install.packages(\"caret\")\n# library(caret)\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2256   37\n         1  921  143\n                                         \n               Accuracy : 0.7146         \n                 95% CI : (0.699, 0.7299)\n    No Information Rate : 0.9464         \n    P-Value [Acc &gt; NIR] : 1              \n                                         \n                  Kappa : 0.1521         \n                                         \n Mcnemar's Test P-Value : &lt;2e-16         \n                                         \n            Sensitivity : 0.79444        \n            Specificity : 0.71010        \n         Pos Pred Value : 0.13440        \n         Neg Pred Value : 0.98386        \n             Prevalence : 0.05362        \n         Detection Rate : 0.04260        \n   Detection Prevalence : 0.31695        \n      Balanced Accuracy : 0.75227        \n                                         \n       'Positive' Class : 1              \n                                         \n\n\n\n\n\n\n\n\nError\n\n\n\nError: data and reference should be factors with the same levels.\n\n\n```{r}\nconf_matrix &lt;- confusionMatrix(pred_class, LR_stroke1, positive = \"1\")\nprint(conf_matrix)\n```\nError: data and reference should be factors with the same levels.\nSuppose you have your folds and predictions for each fold\n```{r}\n# Suppose you have your folds and predictions for each fold\n# Error: object 'folds' not found\ncvAUC::cvAUC(predictions, labels, folds = folds)\n```\n\n\n\n\n\n\nError\n\n\n\nError: object ‘folds’ not found"
  },
  {
    "objectID": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#original-code",
    "href": "posts/renan-blog-post-week8/Stroke_Results_10182025_SW.html#original-code",
    "title": "Reproducing Steve’s Code - Stroke_results_1019_2025_latest",
    "section": "Original Code",
    "text": "Original Code\nBelow we see the Original Code shared by Steve: Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R\n```{r}\ninstall.packages(\"dplyr\")\ninstall.packages(\"car\")\ninstall.packages(\"ResourceSelection\")\nlibrary(dplyr)\nlibrary(car)\nlibrary(ResourceSelection)\nstroke1 &lt;- read.csv(\"D:\\\\stroke.csv\")\nhead(stroke1)\nnrow(stroke1)\nsummary(stroke1)\ncount_tables &lt;- lapply(stroke1, table)\ncount_tables\n#-------------------------------------------Part 1:  preparing the data---------------------------------#\n# Smoking Status - remove unknown#\n#bmi - remove N/A#\n# Work type - remove children#\n# age create numerical variable with 2 places after the decimal#\n#gender -remove other#\nstroke1[stroke1 == \"N/A\"] &lt;- NA\nstroke1[stroke1 == \"Unknown\"] &lt;- NA\nstroke1[stroke1 == \"children\"] &lt;- NA\nstroke1[stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\nstroke1_clean &lt;- na.omit(stroke1)\n#converted all columns to numeric and removed id#\nstr(stroke1_clean)\nnrow(stroke1_clean)\nLR_stroke1 &lt;- stroke1_clean\nstr(LR_stroke1)\n#-------------------------Part 2:Create and Run the Logistic Regression model from the  dataset-------------#\nmodel &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\nsummary(model)\n# ----------------------------------Part 3: Testing logistic Regression Model Assumptions------------------------#\n# There are several assumptions for Logistic Regression#\n# They are:#\n#(1) The Dependent Variable is binary (i.e, 0 or 1)#\n#(2) There is a linear relationship between th logit of the outcome and each predictor#\n#(3) There are NO high leverage outliers in the predictors#\n#(4) There is No high multicollinearity (ie strong correlations) between predictors#\n####################################:Now to test each assumption: ################\n# Testing Assumption 1: The Dependent Variable is binary (0 or 1)#\nunique(LR_stroke1$stroke)\n#Testing Assumption 2: There is a linear relationship between the outcome variable and each predictor\n#first,  adjust all predictors so all values are positive#\nLR_stroke1$genderadj &lt;- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1\nLR_stroke1$ageadj &lt;- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1\nLR_stroke1$hypertensionadj &lt;- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1\nLR_stroke1$heart_diseaseadj &lt;- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1\nLR_stroke1$ever_marriedadj &lt;- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1\nLR_stroke1$work_typeadj &lt;- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1\nLR_stroke1$Residence_typeadj &lt;- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1\nLR_stroke1$avg_glucose_leveladj &lt;- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1\nLR_stroke1$bmiadj &lt;- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1\nLR_stroke1$smoking_statusadj &lt;- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1\nstr(LR_stroke1)\nStrokeAdj &lt;- LR_stroke1\nStrokeAdj &lt;- StrokeAdj[ , !(names(StrokeAdj) %in% c(\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"avg_glucose_level\", \"bmi\", \"smoking_status\")) ]\nmod.2 &lt;- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)\nresidualPlots(mod.2)\n# Conclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity#\n# Conclusion:all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression#\n# ---------------------------------------Conclusion for assumption 2 - Linearity is met--------------------------------#\n# Testing Assumption 3: assess influential outliers using car package and influencePlot#\nalias(Stroke.2)\ninstall.packages(\"Hmisc\")\nlibrary(Hmisc)\nrcorr(as.matrix(LR_stroke1))\ninfluencePlot(model)\n# Cooks D ranges from 0 to .0122 While the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5\n#--------------------------------- Conclusion: Assumption 3 is met - No substantial outliers---------------------#\n# Testing Assumption 4 : Multicollinearity using vif in the care package#\nvif(model)\n#--------------------Conclusion. All vif values are below  5 or 10. Ideally most values should be around 1. Range for all#\n# the predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10. Conclusion: No Multicollinearity####\n#####################################################################################################################\n# -----------------Final Conclusion: All4 assumptions are met, logistic regression is a valid model---------------#\n####################################################################################################################\n# ---------------------------------------------Part 4: Analysis of the Model----------------------------------------#\n# -----------------------There are 2 issues with the model. Fit and Predictive Capability---------------------------#\n# ----------------Part 1  fit. Use Hosmer-lemesho and Naglekerke R for non technical audience-------------------#\nhoslem.test(model$y, fitted(model), g = 10)\ninstall.packages(\"rcompanion\")\nlibrary(rcompanion)\nnagelkerke(model)\n# -----------------------Part 2 - Predictive Capability-----------------------------------------------------------\ninstall.packages(\"pROC\")\nlibrary(pROC)\nprobs &lt;- predict(model, type = \"response\")\nroc_obj &lt;- roc(LR_stroke1$stroke, probs)\nauc(roc_obj)\n# Predictict AUC cross validation\ninstall.packages(\"cvAUC\")\nlibrary(cvAUC)\n# Confusion Matrix\nLR_stroke1$gender &lt;- factor(LR_stroke1$gender)\nLR_stroke1$hypertension &lt;- factor(LR_stroke1$hypertension)\nLR_stroke1$heart_disease &lt;- factor(LR_stroke1$heart_disease)\nLR_stroke1$ever_married &lt;- factor(LR_stroke1$ever_married)\nLR_stroke1$work_type &lt;- factor(LR_stroke1$work_type)\nLR_stroke1$Residence_type &lt;- factor(LR_stroke1$Residence_type)\nLR_stroke1$smoking_status &lt;- factor(LR_stroke1$smoking_status)\nLR_stroke1$stroke &lt;- factor(LR_stroke1$stroke)\n# fit logistic regression model\nmodel_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)\n# Get Predicted Probabilities for each observation\npred_prob &lt;- predict(model_CM, type = \"response\")\ninstall.packages(\"caret\")\nlibrary(caret)\n#Classify prediction using a threshold (0.5 is common but can adjust)\n# art threshold of 0.5#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.5, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n# at threshold of 0.3#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.3, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n# at threshold of 0.2\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.2, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n# At Threshold of 0.18#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.18, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n# At threshold of 0.15#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.15, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\n# at threshold of 0.1#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.1, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n# at threshold of 0.05#\npred_class &lt;- factor(ifelse(pred_prob &gt; 0.05, 1, 0), levels = c(0, 1))\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\n\n\n#Generate Confusion Matrix comparing model predictions to actual outcome\ninstall.packages(\"caret\")\nlibrary(caret)\nconf_matrix &lt;- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c(\"0\", \"1\")), positive = \"1\")\nprint(conf_matrix)\n\n\n\n\n\n\nconf_matrix &lt;- confusionMatrix(pred_class, LR_stroke1, positive = \"1\")\nprint(conf_matrix)\n\n\n\n\n# Suppose you have your folds and predictions for each fold\ncvAUC::cvAUC(predictions, labels, folds = folds)\n\n```\n\nReferences"
  },
  {
    "objectID": "posts/renan-blog-post-draft05/index.html",
    "href": "posts/renan-blog-post-draft05/index.html",
    "title": "Draft Final Report - v05",
    "section": "",
    "text": "This draft the introduction and methods and part of the analysis was modified from Week 06 with the intent to match other students code. At this point the projects started to diverge drastically."
  },
  {
    "objectID": "posts/renan-blog-post-draft05/index.html#introduction",
    "href": "posts/renan-blog-post-draft05/index.html#introduction",
    "title": "Draft Final Report - v05",
    "section": "1. Introduction",
    "text": "1. Introduction\nStroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Because stroke often occurs suddenly and can result in long-term neurological impairment, early identification of individuals at elevated risk is critical for prevention and timely intervention. Data-driven risk prediction models enable clinicians and public health professionals to quantify individual-level risk and to target high-risk groups for lifestyle counselling and clinical management.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease presence or absence[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset."
  },
  {
    "objectID": "posts/renan-blog-post-draft05/index.html#methods",
    "href": "posts/renan-blog-post-draft05/index.html#methods",
    "title": "Draft Final Report - v05",
    "section": "2. Methods",
    "text": "2. Methods\nThe binary logistic regression model is part of a family of statistical models called generalised linear models. The main characteristic that differentiates binary logistic regression from other generalised linear models is the type of dependent (or outcome) variable.[9] A dependent variable in a binary logistic regression has two levels. For example, a variable that records whether or not someone has ever been diagnosed with a health condition like Stroke could be measured in two categories, yes and no. Likewise, someone might have coronary heart disease or not, be physically active or not, be a current smoker or not, or have any one of thousands of diagnoses or personal behaviours and characteristics that are of interest in family medicine.\nThe binary logistic regression algorithm below:\n\\[ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}x_{1} + \\cdots + \\beta_{k}x_{k}\\]\nWhere \\(\\pi = P[Y =1]\\) is the probability of the outcome.\n\n\nLogistic Regression\nDecision Tree\nRandom Forest\nGradient Boosted Machine\nk-Nearest Neighbors\nSupport Vector Machine\n\n\nAssumptions\nBinary logistic regression relies on the following underlying assumptions to be true:\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers\nThe Sample Size is Sufficiently Large. Field recommends a minimum of 50 cases.[10] Hosmer, Lemeshow, and Sturdivant[11] suggest a minimum sample of 10 observations per independent variable in the model. Leblanc and Fitzgerald (2000)[12] suggest a minimum of 30 observations per independent variable."
  },
  {
    "objectID": "posts/renan-blog-post-draft05/index.html#analysis-and-results",
    "href": "posts/renan-blog-post-draft05/index.html#analysis-and-results",
    "title": "Draft Final Report - v05",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nImport all the dependencies:\n\n\nCode\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\", \"ggcorrplot\", \"randomForest\", \"gbm\", \"kernlab\", \"skimr\", \"corrplot\", \"scales\", \"tidyr\", \"RColorBrewer\")\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n3.1. Data Ingestion\nData source: Stroke Prediction Dataset[13]\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nstroke_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(stroke_path, show_col_types = FALSE)\n\n\n\n\n3.2. Exploratory Data Analysis (EDA)\nDataset Description\nThe Stroke Prediction Dataset[13] is a publically available dataset for educational purposes containing 5,110 observations containing predictors commonly associated with cerebrovascular risk. The dataset is composed of 11 clinical and demographic features and 1 feature which is id a unique identifier for the patient. The dataset has features including patient’s age, gender, presence of conditions like hypertension and heart disease, work type, residence type, average glucose level, and BMI. This dataset is primarily intended for educational purposes as it shares a lot of similarities with the Jackson Heart Study (JHS) dataset but it is not as descriptive.\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nKey Values/Range\n\n\n\n\nid\nUnique identifier for the patient\nNumeric\nUnique numeric ID\n\n\ngender\nPatient’s gender\nCharacter\nMale, Female, Other\n\n\nage\nPatient’s age in years\nNumeric\n0.08 to 82\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nCharacter\nNo, Yes\n\n\nwork_type\nType of occupation\nCharacter\nPrivate, Self-employed, Govt_job, children, Never_worked\n\n\nResidence_type\nPatient’s area of residence\nCharacter\nRural, Urban\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\n≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nCharacter\n≈10.3 to 97.6 (has NA values)\n\n\nsmoking_status\nPatient’s smoking status\nCharacter\nformerly smoked, never smoked, smokes, Unknown\n\n\nstroke\nTarget Variable: Whether the patient had a stroke\nNumeric (binary)\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.1 Dataset Preprocessing\n\n\nCode\n# Handle dataset features\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 0\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 0\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n# Remove NAs and clean dataset\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\n\nstrokeclean$stroke &lt;- factor(\n  strokeclean$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\nfourassume$stroke &lt;- factor(\n  fourassume$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\n\nThe initial exploration demonstrated that the Stroke Prediction Dataset[13] has several issues requiring changes for handling missing values, converting character (categorical) features into numerical codes, and removing the identifier column.\n\nSo as part of data preprocessing we will be focused on establishing consistency and ensuring all variables are in a format suitable for predictive modeling. This process starts by systematically addressing non-standard representations of missing data. Specifically, all instances of the string values “N/A”, “Unknown”, “children”, and “other” found across the dataset were unified and replaced with the standard statistical missing value representation, NA.\nThen we proceed with converting several character-based (categorical) features into numerical features, which is necessary for predictive modeling. \nThe feature bmi, initially read as a character variable was first converted to a numeric data type and subsequently rounded to two decimal places.\nThe binary categorical features were encoded into numerical indicators. The feature gender was transformed so that “Male” was encoded to 1 and “Female” was encoded to 0, and the ever_married was transformed so that “Yes” encoded to 1 and “No” encoded to 0.\nFeatures with multiple categories were also numerically encoded into numerical indicators. The work_type feature had its categories encoded so that “Govt_job” = 1, “Private” = 2, “Self-employed” = 3, and “Never_worked” = 4. The Residence_type was encoded so that “Urban” = 1 and “Rural” = 2. Finally, the smoking_status feature was encoded into three numerical levels, those being “never smoked” = 1, “formerly smoked” = 2, and “smokes” = 3.\nAdditionally, the continuous numerical variables avg_glucose_level, heart_disease, and hypertension were explicitly confirmed as numeric data types, with the age feature also being rounded to two decimal places for consistency.\n\nThe final stage of preprocessing involved removing the id column, which served only as a unique identifier and held no predictive value. This action left the dataset with 11 core predictors. The target variable, stroke, was then converted into a factor (a categorical data type in R) named stroke1, and its levels were explicitly labeled as \\(\\text{\"No\"} = 0\\) and \\(\\text{\"Yes\"} = 1\\). The entire process concluded with the removal of all remaining observations containing missing or inconsistent entries, resulting in the creation of the final, clean data frames, strokeclean and fourassume.\nDataset Preprocessing Conclusion\nThe Stroke Prediction Dataset[13] that started containing 5,110 observations and 12 features. After cleaning missing and inconsistent entries among other necessarychanges, ended as a dataset containing 3,357 observations and 11 predictors commonly associated with cerebrovascular risk. Those key predictors are listed below.\n\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nValues\n\n\n\n\ngender\nPatient’s gender\nNumeric\n1 (Male), 0 (Female)\n\n\nage\nPatient’s age in years\nNumeric\nRange 0.08 to 82; rounded to 2 decimal places\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nNumeric\n1 (Yes), 0 (No)\n\n\nwork_type\nType of occupation\nNumeric\n1 (Govt_job), 2 (Private), 3 (Self-employed), 4 (Never_worked)\n\n\nResidence_type\nPatient’s area of residence\nNumeric\n1 (Urban), 2 (Rural)\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\nRange ≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nNumeric\nRange ≈10.3 to 97.6; converted from character, rounded to 2 decimals\n\n\nsmoking_status\nPatient’s smoking status\nNumeric\n1 (never smoked), 2 (formerly smoked), 3 (smokes)\n\n\nstroke\nTarget Variable: Whether the patient had stroke\nNumeric\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n# skim(stroke1)\n# nrow(fourassume)\n# class(strokeclean$stroke)\n# unique(strokeclean$gender)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Dataset Visualization\nBefore developing predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nHistograms\n\n\nCode\n# 1. Get the total number of rows in your data frame\nTOTAL_ROWS &lt;- nrow(strokeclean)\n\n# 2. Use the modified ggplot code\np1a &lt;- ggplot(strokeclean, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # The calculation is (bar_count / TOTAL_ROWS) * 100, rounded to 1 decimal place.\n    position = position_dodge(width = 0.9),\n    aes(\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1), \n    labels = c(\"Female\", \"Male\")\n  ) +\n  labs(title = \"(a) Gender\", x = \"Gender\", y = \"Count\")\n\n# (b) Histogram of Age\np1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n# (b) Bivariate Density Plot of Age\n# p1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) + # Keep fill=stroke\n#   geom_density(alpha = 0.5) + # Overlap the two density curves\n#   labs(title = \"(b) Age\", x = \"Age\", y = \"Density\")\n\n# (c) Histogram of hypertension\np1c &lt;- ggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(c) Hypertension\", x = \"Hypertension\", y = \"Frequency\")\n\n# (d) Histogram of heart_disease\np1d &lt;- ggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(d) Heart Disease\", x = \"Heart Disease\", y = \"Frequency\")\n\n# (e) Histogram of ever_married\np1e &lt;- ggplot(strokeclean, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  # Assuming 'No'/'Yes' are string/factor values, use scale_x_discrete if needed\n  labs(title = \"(e) Ever Married\", x = \"Ever Married\", y = \"Frequency\")\n\n# (f) Histogram of work_type\np1f &lt;- ggplot(strokeclean, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, # Shift text right for horizontal bar\n    size = 3,\n    color = \"black\"\n  ) +\n  # Expand X-axis (Frequency) for horizontal bar\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) +\n  # Adding Work type labels make it too convoluted\n  # scale_y_continuous(\n  #   breaks = c(1, 2, 3, 4), \n  #   labels = c(\"Govt_job\", \"Private\", \"Self-employed\", \"Never_worked\")\n  # ) + \n  labs(title = \"(f) Work Type\", y = \"Work Type\", x = \"Frequency\")\n\n# (g) Histogram of Residence_type\np1g &lt;- ggplot(strokeclean, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # Crucial for aligning text labels with the dodged bars\n    position = position_dodge(width = 0.9), \n    aes(\n      # Defines the group for position_dodge to work correctly on text\n      group = stroke, \n      \n      # Combined label: Percentage (top line) + Count (bottom line)\n      label = paste0(\n        # Percentage calculation: (count / TOTAL_ROWS) * 100\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5, # Moves the two-line label slightly above the bar\n    size = 3,\n    color = \"black\" # Ensures better visibility\n  ) +\n  # Adds 15% extra space to the top of the y-axis to prevent label clipping\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + \n  scale_x_continuous(\n    breaks = c(1, 2),\n    labels = c(\"Urban\", \"Rural\")\n  ) +\n  labs(title = \"(g) Residence Type\", x = \"Residence Type\", y = \"Frequency (Count)\")\n\n# (h) Histogram of avg_gloucose_level\np1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(h) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Frequency\")\n\n# (h) Bivariate Density plot of avg_gloucose_level\n# p1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"Avg. Glucose Level by Stroke Status\", x = \"Average Glucose Level\", y = \"Density\")\n\n# (i) Histogram of bmi\np1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(i) BMI\", x = \"BMI\", y = \"Frequency\")\n\n# (i) Bivariate Density plot of bmi\n# p1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"BMI Distribution by Stroke Status\", x = \"BMI\", y = \"Density\")\n\n# (j) smoking_status\np1j &lt;- ggplot(strokeclean, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke, \n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, \n    size = 3,\n    color = \"black\" \n  ) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) + \n  labs(title = \"(j) Smoking Status\", y = \"Smoking Status\", x = \"Frequency (Count)\")\n\n\nWe can observe from the histograms (a), (b), (c) and (d) the following:\nThe data appears to be slightly imbalanced towards female gender and the proportion of stroke cases relative to the total number of individuals in each gender appears similar for both genders, even if it looks slightly higher in the male doesnt seem to be significant difference.\nThe number of stroke cases increases dramatically after the age of \\(\\approx 50\\) and peaks in the 60 to 80 age range. This strongly suggests age is a critical risk factor for stroke.\nThe majority of patients do not have hypertension and the proportion of stroke cases (blue bar) is visibly much higher in the group with hypertension. This indicates that hypertension is a strong risk factor for stroke.\nSimilar to hypertension, the majority of patients do not have heart disease and the proportion of stroke cases (blue bar) is visibly much higher in the group with heart disease. This indicates that heart disease is a very strong risk factor for stroke, even stronger than hypertension when based alone on the observed proportions.\n\n\nCode\n# p1a, p1b, p1c, p1d\n# (a) Histogram of gender \n# (b) Histogram of Age\n# (c) Histogram of hypertension\n# (d) Histogram of heart_disease\nggarrange(p1a, p1b, p1c, p1d, \n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (a)gender, (b)age, (c)hypertension, (d)heart_disease.\n\n\n\n\nWe can observe from the histograms (e), (f), (g) and (h) the following:\nThe stroke rate appears higher for those who have ever been married which is a fascinating plot that catches our attention, this must be correlated with another variable. Our guess is that having been married being associated with a higher stroke risk in this dataset, is possibly due to the married group skewing toward older ages\nAcross the four work types encoded, “Govt_job” = 1, “Private” = 2 “Self-employed” = 3, “Never Worked” = 4. Self-employed individuals appear to have the highest risk proportion among the working groups. Followed by the Private which is the largest group (total \\(\\approx 2200\\)) and naturally accounts for the highest raw count of stroke cases (109) with a proportion of stoke incidence sligthly higher than Govt_job.\nThe stroke outcomes based on the patient’s residence type has a very similar raw count their proportions seems to be similar as well. This suggests that residence type does not appear to be a significant factor for stroke risk.\nFrom the distribution of average glucose (HbA1c) we can visually spot that the stroke cases are more frequent for high-glucose relative to the total population at those high levels. This higher propportion indicates that high average glucose (HbA1c) level is a significant risk factor for stroke.\n\n\nCode\n# p1e p1f p1g p1h\n# (e) Histogram of ever_married\n# (f) Histogram of work_type\n# (g) Histogram of Residence_type\n# (h) Histogram of avg_gloucose_level\nggarrange(p1e, p1f, p1g, p1h,\n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (e)ever_married, (f)work_type, (g)Residence_type, (h)avg_gloucose_level.\n\n\n\n\nWe can observe from the histograms (i) and (j) the following:\nFor the BMI distribution we can observe that the majority of the patient population (pink bars) falls within the overweight to obese range (BMI \\(\\approx 25\\) to \\(35\\)). So as a consequence we can expect that the frequency of stroke cases (blue bars) will follow the distribution of the overall population, meaning most strokes occur where the largest number of people are located which are the BMI values between \\(25\\) and \\(35\\).\nHowever, we can visually spot that the stroke occurence is drops significantly closer to a healthy BMI of 20. So although the risk of stroke does seem to be generally higher than average once BMI exceeds the ideal range and moves into the overweight and obese categories because there is a larger distribution within the overweight to obese range, we can conclude that because the skewed distributin that BMI is a significant risk factor predictor for stroke.\nThe stroke outcomes are compared across the three smoking status categories encoded: smokes = 3, formerly smoked = 2, and never smoked = 1.\nThis plot is highlights a particularly interesting aspect of this dataset. The highest proportional risk of stroke appears to be in the formerly smoked group. This finding is common in medical literature[14], as individuals who have a history of smoking may have accrued vascular damage that persists, but their stroke risk is still lower than the risk for current smokers if they continue to smoke.\nThis information is importante, because the formerly smoked group shows the highest rate, suggesting that a history of smoking is a significant indicator of risk.\n\n\nCode\n# p1i p1j\n# (i) Histogram of bmi\n# (j) smoking_status\nggarrange(p1i, p1j,\n          ncol = 2, nrow = 1, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (i)bmi, (j)smoking_status.\n\n\n\n\n\n\n3.2.3 Correlation Analysis\n\n\nCode\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\np2 &lt;- ggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   # high contrast red→white→blue\n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n\n\nInterpretation Correlation Heatmap of Key Numeric Predictors\nAll correlations are weak to moderate (0.00–0.26) → no multicollinearity concerns.\nAge shows small but meaningful positive correlations with:\nglucose (0.24)\nhypertension (0.26)\nheart disease (0.26) → consistent with known aging-related cardiovascular risk patterns.\nBMI has very weak correlations with all other predictors (0.04–0.16) → behaves independently in this dataset.\nAvg glucose moderately correlates with:\nhypertension (0.17)\nheart disease (0.14) → aligns with metabolic/vascular relationships.\nHypertension and heart disease are weakly correlated (0.11) → related but not redundant.\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\n\n\nCode\np2\n\n\n\n\n\nCorrelation Analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3. Statistical Modelling\nInitially, we split the dataset into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, then we used this training data for our statistical modelling. It is important to note that during splitting, stratified sampling was used (via caret::createDataPartition) to maintain the stroke/no-stroke ratio.[6]\n\n\n\nCode\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\nindex &lt;- createDataPartition(strokeclean$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- strokeclean[index, ]\ntest_data  &lt;- strokeclean[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\n\n\n# Convert all multi-level categoricals to factors with a clear reference level\ntrain_data$work_type     &lt;- factor(train_data$work_type)\ntrain_data$Residence_type&lt;- factor(train_data$Residence_type)\ntrain_data$smoking_status&lt;- factor(train_data$smoking_status)\n\n# The same should be done for test_data and the binary variables \ntest_data$work_type     &lt;- factor(test_data$work_type)\ntest_data$Residence_type&lt;- factor(test_data$Residence_type)\ntest_data$smoking_status&lt;- factor(test_data$smoking_status)\n\n# if you want the output to label the levels (e.g., \"Male\" vs \"Female\")\n# instead of \"gender\" and \"gender1\" (for Male = 1 vs Female = 0).\n# For 0/1, R's glm is usually fine, but for clean output factors are better.\n# For multi-level, it's essential.\n\n\n\n3.3.1. Repeated K-fold cross-validation\nThe trainControl() function in the R caret package is used to control the computational nuances and resampling methods employed by the train() function. It allows us to implement Repeated K-fold cross-validation (“repeatedcv”).\n\n\nCode\nctrl &lt;- trainControl(\nmethod = \"repeatedcv\",\nnumber = 5,\nrepeats = 3,\nclassProbs = TRUE,\nsummaryFunction = twoClassSummary,\nverboseIter = FALSE\n)\n\n\n\n\n3.3.2. Logistic Regression\n\n\nCode\nmodel_lr &lt;- glm(\n  stroke ~ . , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\ns1 &lt;- summary(model_lr)\nc1 &lt;- coefficients(model_lr)\nanova1 &lt;- car::Anova(model_lr, type = 3)\nconfint1 &lt;- confint(model_lr, level=0.95)\n\nmodel_lr2 &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\nInterpretation — Logistic Regression Coefficients\n\ns1\n\n\nCall:\nglm(formula = stroke ~ ., family = binomial(link = logit), data = train_data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -8.113391   0.854545  -9.494  &lt; 2e-16 ***\ngender             -0.112742   0.204658  -0.551  0.58172    \nage                 0.078380   0.008614   9.099  &lt; 2e-16 ***\nhypertension        0.914733   0.214191   4.271 1.95e-05 ***\nheart_disease       0.339604   0.277662   1.223  0.22130    \never_married       -0.532738   0.293381  -1.816  0.06939 .  \nwork_type2          0.072261   0.288269   0.251  0.80207    \nwork_type3         -0.290608   0.324634  -0.895  0.37069    \nwork_type4         -9.306169 649.652359  -0.014  0.98857    \nResidence_type2    -0.072792   0.198250  -0.367  0.71349    \navg_glucose_level   0.005488   0.001670   3.287  0.00101 ** \nbmi                 0.002103   0.015554   0.135  0.89245    \nsmoking_status2     0.208775   0.226763   0.921  0.35722    \nsmoking_status3     0.345133   0.266423   1.295  0.19517    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 982.44  on 2349  degrees of freedom\nResidual deviance: 767.21  on 2336  degrees of freedom\nAIC: 795.21\n\nNumber of Fisher Scoring iterations: 14\n\nanova1\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \ngender               0.305  1   0.580683    \nage                107.200  1  &lt; 2.2e-16 ***\nhypertension        17.103  1   3.54e-05 ***\nheart_disease        1.439  1   0.230228    \never_married         3.064  1   0.080044 .  \nwork_type            2.479  3   0.479126    \nResidence_type       0.135  1   0.713341    \navg_glucose_level   10.535  1   0.001171 ** \nbmi                  0.018  1   0.892611    \nsmoking_status       1.905  2   0.385861    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nConclusion: These three predictors (\\(\\text{age}\\), \\(\\text{hypertension}\\), and \\(\\text{avg\\_glucose\\_level}\\)) are the most important and reliable drivers of stroke risk in your final model. They independently contribute meaningful, non-redundant predictive power.\n\\(\\text{ever\\_married}\\) has a Marginal Significance. While its \\(\\text{p-value}\\) is close to \\(0.05\\), suggesting a trend, it is not definitively significant in this multivariable model.\n\\(\\text{heart\\_disease}\\) Insignificant. Its unique contribution is not statistically distinguishable from zero after accounting for other factors like \\(\\text{age}\\) and \\(\\text{hypertension}\\) (which it is correlated with).\nBased solely on this ANOVA table, the performance evaluation suggests:\nKeep: \\(\\text{age}\\), \\(\\text{hypertension}\\), \\(\\text{avg\\_glucose\\_level}\\).\nConsider Removing: \\(\\text{gender}\\), \\(\\text{bmi}\\), \\(\\text{Residence\\_type}\\), \\(\\text{work\\_type}\\), and \\(\\text{smoking\\_status}\\).\nTwo way interactions\nYou should definitely consider two-way interactions, especially between your most significant predictors: \\(\\text{age}\\), \\(\\text{hypertension}\\), and \\(\\text{avg\\_glucose\\_level}\\).\nBased on your ANOVA results, prioritize interactions among the strongest drivers:\n\\(\\mathbf{\\text{age} \\times \\text{hypertension}}\\)\n\\(\\mathbf{\\text{age} \\times \\text{avg\\_glucose\\_level}}\\)\n\\(\\mathbf{\\text{hypertension} \\times \\text{avg\\_glucose\\_level}}\\)\nYou might also test \\(\\text{age} \\times \\text{heart\\_disease}\\), as \\(\\text{heart\\_disease}\\) is clinically important even if its main effect was marginally insignificant in the multivariate model.\n\n\nAge is a strong and highly significant predictor (p &lt; 0.001). Higher age is associated with a substantial increase in the odds of stroke.\nHypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\nAverage glucose level is also a important predictor (p = 0.0267). Higher glucose values modestly increase stroke risk.\nHeart disease shows a positive association but is only borderline significant (p = 0.0718). This suggests a potential effect, but not statistically explainable in this model.\nSmoking has likewise borderline significant (p = 0.0714), indicating a increased risk among smokers, but the evidence is not too much strong.\nBMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p &gt; 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\nModel fit improved substantially from the null model (deviance reduced from 953.4 → 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\nOdds ratios and confidence intervals\n\n\nCode\n# Odds ratios and 95% confidence intervals\ncoef_est &lt;- coef(model_lr)\nOR       &lt;- exp(coef_est)\n\nconf_int &lt;- exp(confint(model_lr))  # confidence intervals on OR scale\n# conf_int &lt;- confint(model_lr, level=0.95)\n\nodds_table &lt;- cbind(OR, conf_int)\ncolnames(odds_table) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n\n\nInterpretation\n\nodds_table\n\n                            OR        2.5 %       97.5 %\n(Intercept)       2.995016e-04 5.241734e-05 1.501885e-03\ngender            8.933809e-01 5.952209e-01 1.329871e+00\nage               1.081533e+00 1.064009e+00 1.100629e+00\nhypertension      2.496110e+00 1.631252e+00 3.782969e+00\nheart_disease     1.404392e+00 8.003898e-01 2.385372e+00\never_married      5.869958e-01 3.364242e-01 1.068991e+00\nwork_type2        1.074936e+00 6.232860e-01 1.940865e+00\nwork_type3        7.478086e-01 3.995414e-01 1.435847e+00\nwork_type4        9.086193e-05           NA 8.029055e+24\nResidence_type2   9.297939e-01 6.291289e-01 1.370644e+00\navg_glucose_level 1.005503e+00 1.002197e+00 1.008789e+00\nbmi               1.002105e+00 9.713431e-01 1.032426e+00\nsmoking_status2   1.232167e+00 7.869056e-01 1.918172e+00\nsmoking_status3   1.412178e+00 8.278837e-01 2.361771e+00\n\n\nThe logistic regression findings demonstrate how each predictor impacts the likelihood of having a stroke, while keeping other variables constant:\n\nAge (OR = 1.075, CI: 1.059–1.093) Age is the strongest continuous predictor. Each additional year of age increases the odds of stroke by about 7.5%, and the confidence interval does not include 1, indicating strong statistical significance.\nHypertension (OR = 1.577, CI: 0.996–2.450) Individuals with hypertension have roughly 58% higher odds of stroke compared to those without hypertension, although the lower CI bound is just below 1. This suggests a borderline significant effect, but clinically important.\nHeart disease (OR = 1.628, CI: 0.942–2.733) Heart disease increases stroke odds by about 63%, but the CI includes 1, implying the association is positive but not statistically strong in this dataset.\nAverage glucose level (OR = 1.004, CI: 1.000–1.007) Higher glucose levels are associated with slightly increased stroke risk. Though the effect is small, the CI indicates marginal significance, aligning with known metabolic risk patterns.\nBMI (OR = 1.007, CI: 0.975–1.037) BMI shows almost no meaningful effect on stroke risk, and the CI overlaps 1. This predictor does not significantly influence stroke likelihood in this dataset.\nSmoking (Fsmoked OR = 1.263; Smokes OR = 1.598)\nFormer smokers have 26% higher odds, but CI crosses 1 → weak evidence.\nCurrent smokers have ~60% higher odds, but CI still overlaps 1 → suggests increased risk but not statistically conclusive here.\nGender (Female) (OR = 1.259; CI: 0.842–1.903) Females show slightly higher odds, but this effect is not statistically significant.\nEver married (OR = 1.126; CI: 0.590–2.013) Marital status has no clear effect on stroke odds in this sample.\n\nModel predictions and performance on the test set\n\n\nCode\n# 1) Predicted probabilities from logistic regression\ntest_data$pred_prob &lt;- predict(\n  model_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\ntest_data$stroke &lt;- factor(test_data$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\ntest_data$pred_class &lt;- ifelse(test_data$pred_prob &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class &lt;- factor(test_data$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm &lt;- confusionMatrix(\n  data      = test_data$pred_class,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n\n# cm\n\n\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  951  53\n       Yes   2   1\n                                          \n               Accuracy : 0.9454          \n                 95% CI : (0.9295, 0.9586)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 0.5908          \n                                          \n                  Kappa : 0.0296          \n                                          \n Mcnemar's Test P-Value : 1.562e-11       \n                                          \n            Sensitivity : 0.018519        \n            Specificity : 0.997901        \n         Pos Pred Value : 0.333333        \n         Neg Pred Value : 0.947211        \n             Prevalence : 0.053625        \n         Detection Rate : 0.000993        \n   Detection Prevalence : 0.002979        \n      Balanced Accuracy : 0.508210        \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nFrom the confusion matrix, the following performance metrics are defined:\nAccuracy \\[\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n\\] Sensitivity (Recall / True Positive Rate)\n\\[\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n\\] Specificity (True Negative Rate)\n\\[\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n\\]\nPositive Predictive Value (Precision) \\[\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n\\] Negative Predictive Value (NPV)\n\\[\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n\\]\nInterpretation of Logistic Regression Performance (Test Set)\n\nAccuracy = 94.25% The model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\nSensitivity (True Positive Rate) = 0.017 The model correctly identified only 1 out of 59 actual stroke cases (≈1.7%). → This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\nSpecificity (True Negative Rate) = 1.00 The model correctly classified all non-stroke cases. → It is extremely good at predicting “No stroke,” which dominates the dataset.\nPositive Predictive Value (Precision) = 1.00 When the model predicts “Yes,” it is always correct — but it predicted “Yes” only once. High precision is misleading because the model rarely predicts a positive case.\nNegative Predictive Value = 0.942 Most “No” predictions are correct, matching the overall class imbalance.\nKappa = 0.031 Kappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\nBalanced Accuracy = 0.508 When weighting sensitivity and specificity equally, the model performs at chance level (~50%). → Confirms that stroke detection is weak.\nMcNemar’s Test p &lt; 0.0001 Strong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity. It performs well for the majority class (non-stroke), but fails for the minority class (stroke).\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\nROC curve and AUC for the logistic model\n\n\nCode\n# Compute ROC\nroc_glm &lt;- roc(\n  response  = test_data$stroke,\n  predictor = test_data$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"&lt;\"\n)\n\nauc_val &lt;- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df &lt;- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nroc_plot &lt;- ggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\nroc_plot\n\n\n\n\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\nInterpretation of ROC Curve and AUC (Test Set)\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\nThe AUC = 0.815, which indicates good discriminative performance.\nAUC = 0.5 is no discrimination (random guessing)\nAUC = 0.7–0.8 is acceptable\nAUC = 0.8–0.9 is good\nAUC &gt; 0.9 is excellent\n\nEven though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\nThe strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\nthreshold tuning,\ncost-sensitive training,\nresampling techniques (SMOTE / oversampling).\n\n\n\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables. Use the VIF.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers, check using Cooks D\nThe Sample Size is Sufficiently Large.\n\nCheck Multicollinearity\nIn OLS regression, multicollinearity can be calculated either from the correlations among the predictors, or from the correlations among the coefficient estimates, and these result in the same variance inflaction factors (VIFs).\nIn GLMs, these two approaches yield similar but different VIFs. John Fox, one of the authors of the car package where the vif() function is found, opts for calculating the VIFs from the coefficient estimates.\n\nvif(model_lr)\n\n                      GVIF Df GVIF^(1/(2*Df))\ngender            1.042583  1        1.021069\nage               1.224353  1        1.106505\nhypertension      1.038949  1        1.019288\nheart_disease     1.072781  1        1.035751\never_married      1.023266  1        1.011566\nwork_type         1.083443  3        1.013447\nResidence_type    1.012883  1        1.006421\navg_glucose_level 1.118062  1        1.057384\nbmi               1.158761  1        1.076457\nsmoking_status    1.086902  2        1.021051\n\n\nCheck Outliers\n\n\n\n3.3.3. Decision Tree\n\n\nCode\nmodel_tree &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n\n\n\n\n3.3.4. Random Forest\n\n\nCode\nmodel_rf &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n\n\n\n\n3.3.5. Gradient Boosted Machine (GBM)\n\n\nCode\nmodel_gbm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n\n\n\n\n3.3.6. k-Nearest Neighbours (k-NN)\n\n\nCode\nmodel_knn &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\n\n\n3.3.7. Support Vector Machine (Radial)\n\n\nCode\nmodel_svm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\n\n\n\n3.4. Model Evaluation\n\nModel evaluation on the test set\n\n\nCode\nmodels_list &lt;- list(\nLR   = model_lr2, # Works with caret\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl &lt;- models_list[[m]]\n\n# Probabilities for the \"Yes\" class\n\npreds_prob  &lt;- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\n# Class predictions\n\npreds_class &lt;- predict(mdl, test_data)\n\n# ROC & AUC\n\nroc_obj &lt;- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val &lt;- auc(roc_obj)\n\n# Confusion matrix – positive = \"Yes\"\n\ncm_m &lt;- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults &lt;- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\n# results\n\n\n\nresults\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7809063 0.9453823  0.01851852   0.9979014\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7134293 0.9443893  0.01851852   0.9968520\nAccuracy3   GBM 0.7680716 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6664335 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6192142 0.9453823  0.00000000   0.9989507\n\n\nInterpretation\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\n\n\nROC curve comparison across models\n\n\nCode\n# 1. Create ROC objects for each model\nroc_list &lt;- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr2,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\")\n)\n\n# 2. AUC values\nauc_vals &lt;- sapply(roc_list, auc)\n\n# 3. Long data frame of ROC coordinates\nroc_df &lt;- do.call(rbind, lapply(names(roc_list), function(m) {\n  r &lt;- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\n# Treat model as factor in a consistent order\nroc_df$model &lt;- factor(roc_df$model, levels = names(roc_list))\n\n# 4. Legend labels with AUC\nlabel_map &lt;- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) &lt;- names(auc_vals)\n\n# 5. Color palette by short model name\nmodel_cols &lt;- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\n# 6. Plot\np3 &lt;- ggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n\n\n\n\nCode\np3\n\n\n\n\n\nROC curve comparison across models.\n\n\n\n\nInterpretation\nInterpretation of ROC Comparison Across Models\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\nAll models perform above 0.5, meaning they all do better than random chance — but with large differences in quality.\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\n\n\nOdds ratios and risk stratification\n\n\nCode\n# Fit logistic regression on the same train_data used in the ML comparison\n# makes not sense\n# glm_lr &lt;- glm(\n# stroke ~ age + gender + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status,\n# data   = train_data,\n# family = binomial\n# )\n\n# Coefficients, CIs, p-values\n\nlr_coef &lt;- summary(model_lr)$coefficients           # estimates + p-values\nci_raw  &lt;- suppressMessages(confint(model_lr))      # CI on log-odds scale\n\nor_df &lt;- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(&gt;|z|)\"]\n) %&gt;%\n\n# remove intercept\n\nfilter(Predictor != \"(Intercept)\") %&gt;%\n\n# nicer labels for the plot\n\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n# significance flag for colour\nSig = ifelse(p_value &lt; 0.05, \"p &lt; 0.05\", \"NS\")\n) %&gt;%\n\n# order from lower to higher OR so the plot reads nicely\n\narrange(OR) %&gt;%\nmutate(Label = factor(Label, levels = Label))\n\n# Forest plot\np4 &lt;- ggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p &lt; 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n\n\n\n\nCode\np4\n\n\n\n\n\nForest Plot.\n\n\n\n\nInterpretation\nThe Hypertension is the strongest predictor. Its OR is clearly &gt; 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\nThe Age predictor has an OR slightly above 1 with a narrow CI fully above 1 (orange). Therefore we can conclude that for each additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\nThe Average glucose level has an OR just above 1 with a tight CI above 1 (orange). Therefore we can conclude that Higher glucose is associated with a modest but statistically significant increase in stroke risk, consistent with metabolic or diabetes-related vascular risk.\nFor the predictors Ever married, heart disease, smoking status, gender, BMI, residence, work their confidence intervals all cross 1, so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.\nSome predictor like heart disease and smoking still have ORs above 1, suggesting that firther study might find them to be related to elevated risk of stroke, but the evidence is weak in this dataset.\nOverall message:\nThe forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\nThreshold tuning to 0.2 from 0.5\n\n\nCode\n# Threshold tuning: use 0.2 instead of 0.5\nnew_threshold &lt;- 0.2\n\ntest_data$pred_class_02 &lt;- ifelse(test_data$pred_prob &gt;= new_threshold,\n                                    \"Yes\", \"No\")\n\ntest_data$pred_class_02 &lt;- factor(test_data$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\n# Confusion matrix for threshold = 0.2\ncm_02 &lt;- confusionMatrix(\n  data      = test_data$pred_class_02,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n\n\n\n\nCode\n# Confusion matrix for threshold = 0.2\ncm_02\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  887  43\n       Yes  66  11\n                                          \n               Accuracy : 0.8918          \n                 95% CI : (0.8709, 0.9103)\n    No Information Rate : 0.9464          \n    P-Value [Acc &gt; NIR] : 1.0000          \n                                          \n                  Kappa : 0.112           \n                                          \n Mcnemar's Test P-Value : 0.0351          \n                                          \n            Sensitivity : 0.20370         \n            Specificity : 0.93075         \n         Pos Pred Value : 0.14286         \n         Neg Pred Value : 0.95376         \n             Prevalence : 0.05362         \n         Detection Rate : 0.01092         \n   Detection Prevalence : 0.07646         \n      Balanced Accuracy : 0.56722         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nInterpretation (threshold = 0.2)\n\nWith a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\nSpecificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as “no stroke” (903 out of 949).\nWhile overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives."
  },
  {
    "objectID": "posts/renan-blog-post-draft05/index.html#conclusion",
    "href": "posts/renan-blog-post-draft05/index.html#conclusion",
    "title": "Draft Final Report - v05",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThis experiment compared a conventional logistic regression model with several machine-learning algorithms and examined whether common demographic, behavioral, and clinical characteristics may be used to predict stroke risk using a stroke dataset. Stroke was a rare outcome (about 5% of cases) in the final sample of 3,357 people that was analyzed after the data was cleaned and inconsistent or missing values were eliminated. In addition to reflecting actual epidemiology, this significant class disparity complicates classification, particularly when it comes to identifying the minority (stroke) class.\nAge, hypertension, cardiac disease, and raised average glucose levels are among the best predictors of stroke, according to the baseline logistic regression model. Smoking status substantially increased risk. These variables were identified as significant risk factors by odds ratios significantly greater than 1 and confidence intervals that did not cross 1. These results support the use of logistic regression as an interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness.\nThe logistic regression model performed reasonably well overall in terms of prediction; however, sensitivity for stroke cases was more constrained at the default 0.5 probability threshold, as would be expected with an imbalanced outcome. The model clearly outperformed random guessing, according to the ROC curve and AUC values, but there was still space for improvement in terms of differentiating between stroke and non-stroke patients. Youden’s J statistic offers a method for selecting a different categorization threshold that enhances the ratio of sensitivity to specificity, which may be crucial in a screening setting when it is expensive to miss actual stroke cases.\nMore sophisticated models, such Random Forest and Gradient Boosted Machine, were able to attain somewhat higher AUC values than logistic regression in the machine-learning comparison, showing superior discrimination across a range of thresholds. However, these increases in AUC came at the expense of decreased interpretability and were not always accompanied by significant increases in sensitivity at fixed cut-offs. Logistic regression, on the other hand, offers precise odds ratios and confidence intervals that are simpler for public health professionals and doctors to understand when discussing risk and developing interventions.\nBecause of the severe class imbalance, sensitivity for stroke cases was extremely low (around 2%), meaning that the model almost never predicted “stroke = Yes” and therefore missed most true stroke cases.\nTo address this, the decision threshold was lowered from 0.5 to 0.2. At this cut-off, sensitivity increased from roughly 2% to about 22%, while specificity remained high at around 95%. Overall accuracy dropped slightly to about 91%, but balanced accuracy improved, indicating a more reasonable trade-off between detecting stroke cases and avoiding false positives. This threshold experiment illustrates a key practical point: for rare but serious outcomes such as stroke, it can be preferable to sacrifice some overall accuracy in order to reduce the number of missed high-risk individuals. In this setting, the logistic model is more appropriately viewed as a screening or risk-flagging tool rather than a definitive diagnostic rule.\nOverall, the findings show that relatively simple models built from routinely collected health indicators can meaningfully distinguish between individuals with and without stroke, even in the presence of substantial class imbalance. Logistic regression emerges as a strong, interpretable baseline, while tree-based ensemble methods provide incremental performance improvements at the cost of transparency. Future work could focus on external validation, calibration assessment, more sophisticated imbalance-handling techniques, and the inclusion of additional clinical or longitudinal information. These extensions would help move from proof-of-concept modelling toward robust, clinically usable tools for stroke risk stratification and targeted prevention.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2).\n\n\n9. Harris, J. K. (2019). Statistics with r: Solving problems using real-world data. SAGE Publications.\n\n\n10. Field, A. (2024). Discovering statistics using IBM SPSS statistics. Sage publications limited.\n\n\n11. Hosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). Applied logistic regression. John Wiley & Sons.\n\n\n12. LeBlanc, M., & Fitzgerald, S. (2000). Logistic regression for school psychologists. School Psychology Quarterly, 15(3), 344.\n\n\n13. Palacios, F. S. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n\n\n14. Oshunbade, A. A., Yimer, W. K., Valle, K. A., Clark III, D., Kamimura, D., White, W. B., DeFilippis, A. P., Blaha, M. J., Benjamin, E. J., O’Brien, E. C., et al. (2020). Cigarette smoking and incident stroke in blacks of the jackson heart study. Journal of the American Heart Association, 9(12), e014990."
  },
  {
    "objectID": "posts/renan-blog-post-draft04/index.html",
    "href": "posts/renan-blog-post-draft04/index.html",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "This draft was a direct implementation of the student Shree Krishna M.S Basnet code in attempt to promote the collaborative effort of the project.\nAuthor:\nShree Krishna M.S Basnet\nRenan\nSupervisor: Dr. Cohen"
  },
  {
    "objectID": "posts/renan-blog-post-draft04/index.html#dataset-and-visualization",
    "href": "posts/renan-blog-post-draft04/index.html#dataset-and-visualization",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "Dataset and visualization",
    "text": "Dataset and visualization\nWe used stroke dataset containing 5,110 observations and 11 predictors commonly associated with cerebrovascular risk. After cleaning missing and inconsistent entries, a final dataset of 3,357 individuals remained for analysis. The dataset includes demographic, behavioral, and clinical indicators widely used in stroke-risk modeling.\n###Variables\nThe key predictors are listed below.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\n\nage\nNumeric\nAge of the individual (years)\n\n\ngender\nCategorical (1=Male, 2=Female)\nBiological sex\n\n\nhypertension\nBinary (0/1)\nPrior hypertension diagnosis\n\n\nheart_disease\nBinary (0/1)\nPresence of heart disease\n\n\never_married\nBinary\nMarital status\n\n\nwork_type\nCategorical (1–4)\nEmployment category\n\n\nResidence_type\nBinary (1=Urban, 2=Rural)\nPlace of residence\n\n\nsmoking_status\nCategorical\nNever/Former/Smokes\n\n\nbmi\nNumeric\nBody Mass Index\n\n\navg_glucose_level\nNumeric\nAverage glucose level\n\n\nstroke\nBinary outcome (0=No, 1=Yes)\nStroke occurrence\n\n\n\nStroke is a highly unbalanced outcome variable: - Yes (stroke): about 5% - No (no stroke): around 95%\nBias-corrected logistic regression methods and ROC-based model evaluation are justified by this imbalance."
  },
  {
    "objectID": "posts/renan-blog-post-draft08/index.html",
    "href": "posts/renan-blog-post-draft08/index.html",
    "title": "Draft v08 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "Introduction\nStroke is a global health crisis, causing widespread mortality and disability[1]. Because strokes occur suddenly and often lead to long-term neurological damage, early detection in high-risk individuals is critical for prevention and prompt intervention. By using data-driven risk prediction models, clinicians and public health experts can better identify high-risk populations, allowing for targeted clinical management and lifestyle counseling.\nLogistic Regression (LR) is one of the most widely used methods for modeling binary outcomes, such as the presence or absence of a disease[2]. It extends linear regression to categorical outcomes, providing interpretable coefficients that explain how specific factors influence the probability of an event. LR has been applied across diverse fields, including child health[3], road safety[4–6], healthcare resource management[7], and fraud detection[8]. These varied applications demonstrate LR’s flexibility and suitability for real-world decision-making.\nIn this project, we analyze a publicly available stroke dataset containing key demographic, behavioral, and clinical predictors—such as age, gender, hypertension, heart disease, marital status, work type, residence, smoking status, Body Mass Index (BMI), and average glucose level. These variables are well-documented in cardiovascular literature as significant risk determinants. We cleaned and recoded this data into appropriate numeric formats to develop a series of supervised learning models.\nWe establish Logistic Regression as our primary, interpretable baseline model and compare its performance against more complex machine learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, \\(k\\)-Nearest Neighbours, and Support Vector Machine (radial).\n\n\nMethodology\nThis section outlines our data, how we prepared it, and the modeling framework we used to compare different classifiers.\nWe started with a dataset of 5,110 observations and 11 predictors commonly linked to stroke risk. We filtered out missing data and inconsistent entries—such as “Unknown,” “N/A,” or rare labels like “children”—which left us with a final group of 3,357 individuals. This clean dataset is stored in the object strokeclean.\nBecause our goal is to predict a binary outcome (Yes/No), Logistic Regression is our primary approach for determining if a patient has had a stroke (\\(Y=1\\)) or not (\\(Y=0\\))[hosmer2013applied?,james2021isl?].\nVariables\nThe key predictors used in our analysis are listed below:\n\n\n\nVariable\nType\nDescription\n\n\n\n\nage\nNumeric\nAge of the individual (years)\n\n\ngender\nCategorical\nBiological sex (Male/Female)\n\n\nhypertension\nBinary (0/1)\nPrior hypertension diagnosis\n\n\nheart_disease\nBinary (0/1)\nPresence of heart disease\n\n\never_married\nBinary\nMarital status\n\n\nwork_type\nCategorical\nEmployment category\n\n\nResidence_type\nBinary\nUrban vs. Rural\n\n\nsmoking_status\nCategorical\nNever / Former / Smokes\n\n\nbmi\nNumeric\nBody Mass Index\n\n\navg_glucose_level\nNumeric\nAverage glucose level\n\n\nstroke\nBinary\nOutcome (0=No, 1=Yes)\n\n\n\nAddressing Class Imbalance\nOur dataset is highly unbalanced:\n\nYes (Stroke): ~5%\nNo (No Stroke): ~95%\n\nThis imbalance makes model evaluation tricky. A model could simply guess “No Stroke” for everyone and still achieve 95% accuracy, despite being useless for medical diagnosis. To avoid this trap, we look beyond simple accuracy and focus on metrics like sensitivity, specificity, ROC curves, AUC, and Youden’s J statistic.\nDataset Preparation\nTo ensure our model is valid and to prevent “data leakage” (where the model accidentally sees data it shouldn’t), we applied several preprocessing steps[9]:\n\nRemoved Identifiers: We dropped columns like Patient ID since they don’t predict medical risk.\nCleaned Labels: We removed rows with vague labels (e.g., “Unknown”) and standardized rare categories.\nNumeric Conversion: We converted age, BMI, and glucose levels into standard numeric formats and turned categorical variables (like gender) into dummy variables.\nConsistency Checks: We verified that all values fell within realistic ranges.\n\nModel Validation\nFinally, we split the data into training and testing sets. For the machine-learning comparison, we used stratified sampling (via caret::createDataPartition). This ensures that the ratio of stroke to non-stroke patients remains consistent in both the training and testing data, preventing the model from learning from a skewed sample[6].\nLogistic regression model \nLet \\(Y_i\\) denote the stroke status for patient \\(i\\), where\n\n\\(Y_i = 1\\) if patient \\(i\\) experienced a stroke\n\n\\(Y_i = 0\\) otherwise.\n\nLet the predictor vector for patient \\(i\\) be\n\\[\n\\mathbf{x}_i = (x_{i1}, x_{i2}, \\ldots, x_{ip})^\\top,\n\\]\nwhere the \\(p\\) predictors such as age, hypertension, heart disease, average glucose level, BMI, and smoking status.\nThe logistic regression model specifies the conditional probability of stroke as\n\\[\nP(Y_i = 1 \\mid \\mathbf{x}_i)\n= \\pi(\\mathbf{x}_i)\n= \\frac{\\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}\n       {1 + \\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}.\n\\]\nEquivalently, the logit (log-odds) of stroke is modeled as a linear combination of the predictors:\n\\[\n\\log\\left(\\frac{\\pi(\\mathbf{x}_i)}{1 - \\pi(\\mathbf{x}_i)}\\right)\n  = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}.\n\\]\nHere, \\(\\beta_0\\) is the intercept, \\(\\beta_j\\) is the change in log-odds of stroke for a one-unit increase in predictor \\(x_j\\), holding other variables constant.\nExponentiating \\(\\beta_j\\) gives the odds ratio (OR): \\[\n\\text{OR}_j = e^{\\beta_j},\n\\]\nwhich represents the multiplicative change in the odds of stroke for a one-unit increase in \\(x_j\\).\nModel Estimation\nLet \\(\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^\\top\\) denote the vector of regression coefficients. For independent observations, the likelihood of the data is \\[\nL(\\boldsymbol{\\beta})\n= \\prod_{i=1}^{n}\n  \\pi(\\mathbf{x}_i)^{\\,y_i}\n  \\left[1 - \\pi(\\mathbf{x}_i)\\right]^{\\,1-y_i},\n\\]\nwhere \\(\\pi(\\mathbf{x}_i) = P(Y_i = 1 \\mid \\mathbf{x}_i)\\).\nThe log-likelihood is\n\\[\n\\ell(\\boldsymbol{\\beta})\n= \\sum_{i=1}^{n}\n\\left[\n  y_i \\log\\big(\\pi(\\mathbf{x}_i)\\big)\n  +\n  (1 - y_i)\\log\\big(1 - \\pi(\\mathbf{x}_i)\\big)\n\\right].\n\\]\nThe maximum likelihood estimate \\(\\hat{\\boldsymbol{\\beta}}\\) is the value of \\(\\boldsymbol{\\beta}\\) that maximizes \\(\\ell(\\boldsymbol{\\beta})\\). In R, this optimization is carried out automatically using glm(..., family = binomial)\nMachine Learning Models and Evaluation\nTo see if advanced technology could outperform standard methods, we built six different supervised learning models using the caret framework. We wanted to determine if sophisticated algorithms could improve our ability to classify stroke risk compared to the baseline.\nThe six models were:\n\nLogistic Regression (LR) – Our baseline.\nDecision Tree (rpart) – A simple rule-based model.\nRandom Forest (RF) – An ensemble of many decision trees.\nGradient Boosted Machine (GBM) – A powerful, iterative learning model.\nk-Nearest Neighbours (k-NN) – Classification based on similarity to other patients.\nSupport Vector Machine (SVM-Radial) – A model that finds complex boundaries between groups.\n\nTo guarantee a fair fight, every model was treated exactly the same. We used the same 70% training / 30% testing split and applied a consistent cross-validation procedure across the board.Once the model was fitted, we calculated the Odds Ratios and 95% Confidence Intervals to interpret the effect of each predictor.\nData Splitting and Model Fitting in R\nWe began with our processed dataset, strokeclean. As a reminder, our target outcome is stroke (0 = No, 1 = Yes), and we are using predictors such as age, hypertension, heart_disease, avg_glucose_level, and bmi.\nFirst, we randomly split the data to create a training set (70%) for building the models and a hold-out test set (30%) to evaluate how well they perform on new data.\nData Splitting and Model Fitting in R\nThe cleaned dataset is stored in the object strokeclean, where the outcome variable is stroke (0 = No stroke, 1 = Stroke), and predictors include age, hypertension, heart_disease, avg_glucose_level, bmi, smoking_status, and others.\nFirst, the dataset is randomly divided into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, logistic regression model is then fitted on the training data:\nFrom this model, estimated odds ratios and 95% confidence intervals are computed as:\nModel Predictions and Performance Measures\nPredicted probabilities on the test set are obtained as:\nUsing a classification threshold \\(c = 0.5\\), the predicted class for patient \\(i\\) is\n\\[\n\\hat{y}_i =\n\\begin{cases}\n1, & \\text{if } \\hat{\\pi}_i \\ge c, \\\\\\\\\n0, & \\text{if } \\hat{\\pi}_i &lt; c.\n\\end{cases}\n\\]\nwhere \\(\\hat{\\pi}_i\\) is the predicted probability of stroke for patient \\(i\\).\nEvaluation Metrics\nModels were evaluated using standard clinical classification metrics:\n\nAccuracy\nSensitivity (Recall)\nSpecificity\nPrecision\nF1-Score\nReceiver Operating Characteristic (ROC) curve\nArea Under the Curve (AUC)\n\nYouden’s J Statistic, Used to determine optimal classification threshold:\n\\(J = \\text{Sensitivity} + \\text{Specificity} - 1\\)\nThese metrics are widely used in stroke-risk modeling literature and as per article it is often used to find optimial classidfication threshhold.[6].\n\n\nAnalysis\nBefore starting to generate predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nDistribution of Key Continuous Variables\nHistograms were used to assess the spread of the primary numeric predictors (Age, BMI, and Average Glucose Level). These variables demonstrate clinically expected right-skewness, particularly glucose and BMI, consistent with published literature on metabolic and cardiovascular risk distributions.\n\nlibrary(tidyverse)\n\ncont_long &lt;- strokeclean %&gt;% \n  select(\n    Age = age,\n    BMI = bmi,\n    `Average Glucose` = avg_glucose_level\n  ) %&gt;% \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\")\n\nggplot(cont_long, aes(Value, fill = Variable, colour = Variable)) +\n  geom_density(alpha = 0.25, linewidth = 1) +\n  facet_wrap(~ Variable, scales = \"free\", nrow = 1) +\n  labs(x = NULL, y = \"Density\") +\n  #palette = \"Dark2\") +\n  scale_colour_brewer(palette = \"Dark2\") +\n  theme_minimal(base_size = 12) +\n  theme(\n    strip.text = element_text(face = \"bold\"),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\nInterpretation of Key Continuous Predictors\nWe examined the distributions of our three main numeric variables to identify patterns and potential risk factors.\n\nAge The age distribution is smooth, starting from late adolescence. The majority of individuals fall between 40 and 70 years old, which corresponds to the population at highest risk for stroke. Since there are no extreme clusters or gaps, Age serves as an excellent continuous predictor.\nAverage Glucose Level This variable shows a clear right-skew, meaning most people have normal levels, but there is a long “tail” of data extending above 200 mg/dL. This highlights a specific subgroup of patients with poor metabolic health (likely indicating diabetes), which is a critical driver for heart disease and stroke risk.\nBMI BMI values are tightly grouped between 22 and 35, with relatively few outliers. Because there is less variation here compared to Age or Glucose, it may play a slightly weaker role in distinguishing between stroke and non-stroke cases. This observation aligns with our regression results, where BMI showed a smaller contribution than vascular predictors.\n\nDistribution of Key Categorical Variables\nBar charts help visualize population composition. The dataset shows more females than males, a balanced rural–urban distribution, and substantial variation in work type and smoking behavior.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ncat_df = strokeclean %&gt;%\nmutate(\ngender = factor(gender, levels = c(1, 2),\nlabels = c(\"Male\", \"Female\")),\nResidence_type = factor(Residence_type, levels = c(1, 2),\nlabels = c(\"Urban\", \"Rural\")),\nsmoking_status = factor(smoking_status,\nlevels = c(1, 2, 3),\nlabels = c(\"Never\", \"Former\", \"Current\"))\n) %&gt;%\nselect(\nGender    = gender,\nResidence = Residence_type,\nSmoking   = smoking_status\n) %&gt;%\npivot_longer(\neverything(),\nnames_to  = \"Variable\",\nvalues_to = \"Category\"\n) %&gt;%\nfilter(!is.na(Category)) %&gt;%\ncount(Variable, Category) %&gt;%\ngroup_by(Variable) %&gt;%\nmutate(prop = n / sum(n))\n\nggplot(cat_df, aes(x = Category, y = prop, fill = Category)) +\ngeom_col(width = 0.7, colour = \"white\") +\ngeom_text(aes(label = percent(prop, accuracy = 1)),\nvjust = -0.3, size = 3) +\nfacet_wrap(~ Variable, scales = \"free_x\") +\nscale_y_continuous(\nlabels = percent_format(accuracy = 1),\nexpand = expansion(mult = c(0, 0.10))\n) +\nlabs(x = NULL, y = \"Percentage of patients\") +\ntheme_minimal(base_size = 12) +\ntheme(\nlegend.position  = \"none\",\nstrip.text       = element_text(face = \"bold\"),\npanel.grid.minor = element_blank()\n)\n\n\n\n\n\n\n\nFigure 1: Sample composition by gender, residence type, and smoking status.\n\n\n\n\n\nInterpreatation\n\nGender:The dataset has more female patients (61%) than males (39%). This imbalance should be noted because gender-related model effects may partly reflect sample composition.\nResidence Type: The population is nearly evenly split between urban (51%) and rural (49%) residents. This indicates no geographic bias and good representation of both environments.\nSmoking Status: Most participants never smoked (54%), while 25% are former smokers and 22% are current smokers. This provides enough variation to meaningfully examine smoking as a behavioral risk factor for stroke.\n\nStroke Risk for Clinical and Behavioral Predictors \n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(scales)\n\nstopifnot(exists(\"strokeclean\"))\n\n\nstrokeclean_plot = strokeclean %&gt;%\n  mutate(\n    stroke = factor(stroke, levels = c(\"No\", \"Yes\")),\n\n    hypertension = factor(\n      as.numeric(as.character(hypertension)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    heart_disease = factor(\n      as.numeric(as.character(heart_disease)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    smoking_status = factor(\n      as.numeric(as.character(smoking_status)),\n      levels = c(1, 2, 3),\n      labels = c(\"Never\", \"Former\", \"Current\")\n    )\n  )\n\n# 2. Helper: stroke proportion + 95% CI\nprop_ci = function(data, group) {\n  data %&gt;%\n    group_by({{ group }}) %&gt;%\n    summarise(\n      stroke_rate = mean(stroke == \"Yes\"),\n      n = n(),\n      se = sqrt(stroke_rate * (1 - stroke_rate) / n),\n      lower = pmax(0, stroke_rate - 1.96 * se),\n      upper = pmin(1, stroke_rate + 1.96 * se),\n      .groups = \"drop\"\n    )\n}\n\n\ndf_hyp   = prop_ci(strokeclean_plot, hypertension)\ndf_hd    = prop_ci(strokeclean_plot, heart_disease)\ndf_smoke = prop_ci(strokeclean_plot, smoking_status)\n\n\ntheme_stroke =\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 13, hjust = 0.5),\n    axis.title.x = element_blank()\n  )\n\n\ncols_hyp   = c(\"No\" = \"#FDE725FF\", \"Yes\" = \"#440154FF\")      \ncols_hd    = c(\"No\" = \"#20A387FF\", \"Yes\" = \"#F98400FF\")     \ncols_smoke = c(\"Never\" = \"#1F78B4\", \"Former\" = \"#33A02C\", \"Current\" = \"#E31A1C\")  \n\n\np1 =\n  ggplot(df_hyp, aes(x = hypertension, y = stroke_rate, fill = hypertension)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hyp) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Hypertension\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np2 =\n  ggplot(df_hd, aes(x = heart_disease, y = stroke_rate, fill = heart_disease)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hd) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Heart Disease\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np3 =\n  ggplot(df_smoke, aes(x = smoking_status, y = stroke_rate, fill = smoking_status)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_smoke) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Smoking Status\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\n\nggarrange(p1, p2, p3, ncol = 3, align = \"hv\")\n\n\n\n\n\n\n\nFigure 2: Stroke percentages (95% CI) by hypertension, heart disease, and smoking status.\n\n\n\n\n\nInterpretation\nThe figure summarises how stroke risk varies across key categorical predictors:\n\nHypertension\n\nStroke risk is clearly higher among hypertensive patients.\nConfidence intervals show a noticeable separation, supporting a strong association.\n\nHeart Disease\n\nPatients with heart disease show higher stroke percentages than those without.\nThe pattern is consistent with cardiovascular disease being a major clinical risk factor.\n\nSmoking Status\n\nFormer and current smokers have higher stroke percentages than never-smokers.\nThis reflects the long-term vascular effects of tobacco exposure.\n\n\nOverall, these categorical predictors show patterns aligned with clinical expectations:\nvascular risks (hypertension, heart disease) and behavioural risks (smoking) are all associated with elevated stroke likelihood.\nCorrelation among key numeric prediators\n\nlibrary(ggcorrplot)\nlibrary(RColorBrewer)\n\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\nggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   \n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n\nInterpretation\n\nCorrelation Heatmap of Key Numeric Predictors, all correlations are weak to moderate (0.00–0.26) = no multicollinearity concerns.\nAge shows small but meaningful positive correlations with:\nglucose (0.24)\nhypertension (0.26)\nheart disease (0.26) = consistent with known aging-related cardiovascular risk patterns.\nBMI has very weak correlations with all other predictors (0.04–0.16) = behaves independently in this dataset.\nAvg glucose moderately correlates with:\nhypertension (0.17)\nheart disease (0.14) = aligns with metabolic/vascular relationships.\nHypertension and heart disease are weakly correlated (0.11) = related but not redundant.\n\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\nLogistic Regression Model & its Coefficients\n\nlibrary(caret)\n\n#| label: logit_fit\n#| echo: true\n#| warning: false\n#| message: false\n\nset.seed(123)\n\nn &lt;- nrow(strokeclean)\ntrain_index &lt;- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train &lt;- strokeclean[train_index, ]\nstroke_test  &lt;- strokeclean[-train_index, ]\n\nfit_glm &lt;- glm(\n  stroke ~ age + hypertension + heart_disease +\n    avg_glucose_level + bmi + smoking_status +\n    gender + ever_married,\n  data   = stroke_train,\n  family = binomial(link = \"logit\")\n)\n\nsummary(fit_glm)\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   &lt;2e-16 ***\nage                0.072637   0.008089   8.979   &lt;2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7\n\n\nInterpretation — Logistic Regression Coefficients\n\nAge is a strong and highly significant predictor (p &lt; 0.001). Higher age is associated with a substantial increase in the odds of stroke.\nHypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\nAverage glucose level is also a important predictor (p = 0.0267). Higher glucose values modestly increase stroke risk.\nHeart disease shows a positive association but is only borderline significant (p = 0.0718). This suggests a potential effect, but not statistically explainable in this model.\nSmoking has likewise borderline significant (p = 0.0714), indicating a increased risk among smokers, but the evidence is not too much strong.\nBMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p &gt; 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\nModel fit improved substantially from the null model (deviance reduced from 953.4 to 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\nOdds ratios and confidence intervals\n\ncoef_est &lt;- coef(fit_glm)\nOR       &lt;- exp(coef_est)\n\nconf_int &lt;- exp(confint(fit_glm))  \n\nWaiting for profiling to be done...\n\nodds_table &lt;- cbind(OR, conf_int)\ncolnames(odds_table) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013\n\n\nInterpretation\nThe logistic regression results give us a clear picture of how each predictor influences the likelihood of having a stroke, assuming all other factors stay the same.\n\nAge (OR = 1.075, CI: 1.059–1.093) Age is by far the strongest continuous predictor. For every additional year of age, the odds of having a stroke increase by about 7.5%. The confidence interval is tight and stays well above 1, confirming that this is a highly significant risk factor.\nHypertension (OR = 1.577, CI: 0.996–2.450) Individuals with a history of hypertension have roughly 58% higher odds of stroke compared to those without it. However, the confidence interval dips just below 1, meaning the effect is on the borderline of statistical significance. Despite this uncertainty, the large increase in odds suggests it is still clinically important.\nHeart Disease (OR = 1.628, CI: 0.942–2.733) Similar to hypertension, heart disease raises stroke odds by about 63%. While the link is positive, the wide confidence interval (which crosses 1) indicates that the statistical evidence in this specific dataset is not definitive.\nAverage Glucose Level (OR = 1.004, CI: 1.000–1.007) Higher glucose levels are linked to a slightly increased risk. Although the per-unit effect looks small, the confidence interval suggests marginal significance, which aligns with the known medical link between metabolic health and stroke.\nBMI (OR = 1.007, CI: 0.975–1.037) Interestingly, BMI showed almost no meaningful effect on stroke risk in our model. The confidence interval overlaps 1, suggesting that once we account for other factors (like age and glucose), BMI itself is not a significant driver here.\nSmoking Status\n\nFormer Smokers (OR = 1.263): Show 26% higher odds, though the evidence is statistically weak.\nCurrent Smokers (OR = 1.598): Face nearly 60% higher odds of stroke. While the confidence interval still overlaps 1 (likely due to sample size), the trend clearly points to increased risk for active smokers.\n\nGender & Marital Status Females showed slightly higher odds (OR = 1.259), and Marital Status (OR = 1.126) showed a small positive association, but neither factor was statistically significant in this analysis.\n\nModel predictions and performance on the test set\n\nlibrary(caret)\n\nstroke_test$pred_prob &lt;- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\nstroke_test$stroke &lt;- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\nstroke_test$pred_class &lt;- ifelse(stroke_test$pred_prob &gt;= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class &lt;- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\ncm &lt;- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc &gt; NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\nFrom the confusion matrix, the following performance metrics are defined:\nAccuracy \\[\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n\\] Sensitivity (Recall / True Positive Rate)\n\\[\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n\\] Specificity (True Negative Rate)\n\\[\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n\\]\nPositive Predictive Value (Precision) \\[\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n\\] Negative Predictive Value (NPV)\n\\[\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n\\]\nInterpretation of Logistic Regression Performance (Test Set)\n\nAccuracy = 94.25% The model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\nSensitivity (True Positive Rate) = 0.017 The model correctly identified only 1 out of 59 actual stroke cases (≈1.7%). = This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\nSpecificity (True Negative Rate) = 1.00 The model correctly classified all non-stroke cases. = It is extremely good at predicting “No stroke,” which dominates the dataset.\nPositive Predictive Value (Precision) = 1.00 When the model predicts “Yes,” it is always correct — but it predicted “Yes” only once. High precision is misleading because the model rarely predicts a positive case.\nNegative Predictive Value = 0.942 Most “No” predictions are correct, matching the overall class imbalance.\nKappa = 0.031 Kappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\nBalanced Accuracy = 0.508 When weighting sensitivity and specificity equally, the model performs at chance level (~50%). = Confirms that stroke detection is weak.\nMcNemar’s Test p &lt; 0.0001 Strong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity. It performs well for the majority class (non-stroke), but fails for the minority class (stroke).\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\nROC curve and AUC for the logistic model\n\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Compute ROC\nroc_glm &lt;- roc(\n  response  = stroke_test$stroke,\n  predictor = stroke_test$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"&lt;\"\n)\n\nauc_val &lt;- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df &lt;- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\nInterpretation of ROC Curve and AUC (Test Set)\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\nThe AUC = 0.815, which indicates good discriminative performance.\nAUC = 0.5 is no discrimination (random guessing)\nAUC = 0.7–0.8 is acceptable\nAUC = 0.8–0.9 is good\nAUC &gt; 0.9 is excellent\n\nEven though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\nThe strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\nthreshold tuning,\ncost-sensitive training,\nresampling techniques (SMOTE / oversampling).\n\nMachine-learning model comparison\nData Splitting and prepration\n\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\n\n  No  Yes \n3177  180 \n\nset.seed(123)\nindex &lt;- createDataPartition(model_df$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- model_df[index, ]\ntest_data  &lt;- model_df[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\nTrain control settings\n\nlibrary(caret)   # &lt;- add this line to be safe\n\nctrl &lt;- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary,\n  verboseIter = FALSE\n)\n\nLogistic Regression (caret)\n\nmodel_lr &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nDecision Tree\n\nmodel_tree &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n\nRandom Forest\n\nmodel_rf &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n\nGradient Boosted Machine (GBM)\n\nmodel_gbm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n\nk-Nearest Neighbours (k-NN)\n\nmodel_knn &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nSupport Vector Machine (Radial)\n\nmodel_svm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nModel evaluation on the test set\n\nlibrary(pROC)   \nlibrary(caret)\nmodels_list &lt;- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl &lt;- models_list[[m]]\n\npreds_prob  &lt;- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\npreds_class &lt;- predict(mdl, test_data)\n\nroc_obj &lt;- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val &lt;- auc(roc_obj)\n\ncm_m &lt;- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults &lt;- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\nresults\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534\n\n\nInterpretation\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\nROC curve comparison across models\n\nlibrary(scales)\n\nroc_list &lt;- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\")\n)\n\nauc_vals &lt;- sapply(roc_list, auc)\n\nroc_df &lt;- do.call(rbind, lapply(names(roc_list), function(m) {\n  r &lt;- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\nroc_df$model &lt;- factor(roc_df$model, levels = names(roc_list))\n\nlabel_map &lt;- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) &lt;- names(auc_vals)\n\nmodel_cols &lt;- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\nggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n\n\n\n\n\n\n\n\nInterpretation\nInterpretation of ROC Comparison Across Models\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\nAll models perform above 0.5, meaning they all do better than random chance — but with large differences in quality.\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\nOdds ratios and risk stratification\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\nglm_lr &lt;- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\nlr_coef &lt;- summary(glm_lr)$coefficients           \nci_raw  &lt;- suppressMessages(confint(glm_lr))      \n\nor_df &lt;- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(&gt;|z|)\"]\n) %&gt;% \nfilter(Predictor != \"(Intercept)\") %&gt;%\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n\nSig = ifelse(p_value &lt; 0.05, \"p &lt; 0.05\", \"NS\")\n) %&gt;%\narrange(OR) %&gt;%\nmutate(Label = factor(Label, levels = Label))\n\nggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p &lt; 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n\n\n\n\n\n\n\n\nInterpretation\n\nHypertension (Yes vs No)\n\nThis is the strongest predictor. Its OR is clearly &gt; 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\n\nAge (per year)\n\nThe OR is slightly above 1 with a narrow CI fully above 1 (orange).\nEach additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\n\nAverage glucose level\n\nOR is just above 1 with a tight CI above 1 (orange).\nHigher glucose is associated with a modest but statistically reliable increase in stroke risk, consistent with metabolic / diabetes-related vascular risk.\n\nEver married, heart disease, smoking status, gender, BMI, residence, work type\n\nTheir confidence intervals all cross 1 (grey points), so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.Some (e.g., heart disease, smoking) still have ORs above 1, suggesting possible elevated risk, but the evidence is weaker in this dataset.\nOverall message: The forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\nThreshold tuning to 0.2 from 0.5\n\nnew_threshold &lt;- 0.2\n\nstroke_test$pred_class_02 &lt;- ifelse(stroke_test$pred_prob &gt;= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 &lt;- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\ncm_02 &lt;- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm_02\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nInterpretation (threshold = 0.2)\n\nWith a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\nSpecificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as “no stroke” (903 out of 949).\nWhile overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives.\n\n\nConclusion\nIn this study, we set out to determine if standard demographic, behavioral, and clinical records could effectively predict stroke risk. We compared a traditional Logistic Regression model against several machine learning algorithms using a cleaned dataset of 3,357 individuals. Because strokes were rare in our sample (occurring in only about 5% of cases), we faced a classic “class imbalance” challenge, which made identifying high-risk patients particularly difficult.\n\nKey Risk Factors\n\nOur baseline Logistic Regression model confirmed what we know from clinical literature: Age, hypertension, heart disease, and high glucose levels are the strongest predictors of stroke. Smoking also stood out as a substantial risk factor. The model produced odds ratios significantly greater than 1 for these variables (with confidence intervals that did not cross 1), confirming them as statistically significant drivers of risk. This validates Logistic Regression as a transparent tool for explaining why a specific patient is at risk.\n\nModel Performance and the “Imbalance” Challenge\n\nWhen we first ran the Logistic Regression model using the standard decision threshold of 0.5, the results were mixed. While the model performed better than random guessing (based on AUC scores), it struggled to actually find the stroke cases. Specifically, the sensitivity was extremely low (around 2%), meaning the model missed almost every true stroke case because it was biased toward the majority “No Stroke” class.\nTo fix this, we adjusted the decision threshold down to 0.2. This simple change had a dramatic effect: * Sensitivity jumped from ~2% to ~22%. * Specificity remained high at around 95%. * Overall Accuracy dipped slightly to 91%, but the Balanced Accuracy improved.\nThis experiment illustrates a critical lesson for medical screening: when dealing with dangerous but rare events like stroke, it is often better to accept a few false alarms (lower precision) in exchange for catching more true cases (higher sensitivity).\n\nLogistic Regression vs. Machine Learning\n\nWhen we pitted Logistic Regression against advanced models like Random Forest and Gradient Boosted Machines, the advanced models did achieve slightly higher AUC scores. They were better at discriminating between groups across various thresholds.\nHowever, this extra power came at a cost. The machine learning models are “black boxes”—harder to interpret and explain to a patient. In contrast, Logistic Regression provides precise odds ratios that doctors can easily translate into clinical advice.\n\nFuture Directions\n\nOverall, our findings show that even simple models using routine health data can meaningfully distinguish stroke risk. While tree-based models offer a slight performance edge, Logistic Regression remains a robust, interpretable baseline.\nFuture work should focus on: 1. External Validation: Testing these models on data from different hospitals or regions. 2. Calibration: Ensuring the predicted probabilities match real-world risk levels. 3. Data Enrichment: Incorporating longitudinal data (health changes over time) to move this from a theoretical exercise to a practical clinical tool.\n\n\nReferences\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2).\n\n\n9. Wang, M. (2014). Generalized estimating equations in longitudinal data analysis: A review and recent developments. Advances in Statistics, 2014."
  },
  {
    "objectID": "posts/renan-blog-post-week4/index.html",
    "href": "posts/renan-blog-post-week4/index.html",
    "title": "Literature Review Week 4",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "posts/renan-blog-post-week4/index.html#article-1",
    "href": "posts/renan-blog-post-week4/index.html#article-1",
    "title": "Literature Review Week 4",
    "section": "Article 1",
    "text": "Article 1\nIncorporating LLM Priors into Tabular Learners.[1]\nThere have been implementations of transformer based architectures for tabular data. Most of the time it has been utilized for generating synthetic data for likelihood free models or for cases where there is not enough data for fitting a model.\nThe goal of this research was to bootstrap a way so one could use off the shelf models like Chatgpt which are really good at generalization to perform similarly to dedicated models trained on tabular data such as tabLLM. This is important because it is fairly cheaper and more accessible than training a model from scratch and it overcomes the complexities of developing a specialized encoder.\nThe methodology is a pretty hacky solution where they serialized the tabular data so they could prompt the models are are just trying to obtain back a categorization through prompt engineering which will be attributed a value which is manually tuned by the authors and this value is later used on the Monotonic Logistic Regression.\nThe limitations are quite clear. There is no way to guarantee the black box model output will be consistent. You have to manually categorize and do some prompt engineering. The model has bias so it either works really well or it doesn’t.\nThe bright side is that this approach is extremely cheap and is accessible. It can be used to test ideas and hypothesis as well rapidly prototype before committing to a more definite solution such as tabLLM."
  },
  {
    "objectID": "posts/renan-blog-post-week4/index.html#article-2",
    "href": "posts/renan-blog-post-week4/index.html#article-2",
    "title": "Literature Review Week 4",
    "section": "Article 2",
    "text": "Article 2\nUsing a monotonic density ratio model to increase the power of the goodness-of-fit test for logistic regression models with case-control data.[2]\nCase-control sampling is used because it is a quick, economical, and efficient method for studying rare diseases or outcomes, long latent periods, or outbreaks. It allows researchers to investigate multiple potential risk factors simultaneously for a single outcome and is especially useful when prospective cohort studies are not feasible.\nThe author’s goal seems to be to improve the statistical power of the goodness-of-fit test for logistic regression models when used with case-control data. They improved upon a previous popular method from Qin and Zhang, instead of using the nonparametric empirical distribution function, we use the constrained nonparametric MLE of G(x) to further improve the power performance of the Kolmogorov-Smirnov-type goodness-of-fit test for logistic models.\nBefore drawing conclusions from a logistic regression model, it’s crucial to verify that the model’s assumptions hold true for the data and there are many limitations. Case Study data is specially complicated because there is not enough data and there are too many unknowns.\nThe authors spare no comments on the limitations, the bigger limitations are: - The test is designed for goodness-of-fit and cannot be used to compare two different logistic regression models - The test has no power when the only covariate is categorical. In this situation, the logistic model is “saturated,” meaning it perfectly fits the data by definition and cannot be misspecified.\nTheir results are overall quite interesting as they demonstrated that they could bootstrap an algorithm that is quite clever and intuitively it shouldn’t work. It is a hard problem to solve so it is interesting out of the box thinking\n\nReferences\n\n\n1. Zhu, M., Stanivuk, S., Petrovic, A., Nikolic, M., & Lio, P. (2023). Incorporating LLM priors into tabular learners. https://arxiv.org/abs/2311.11628\n\n\n2. Wang, C., Liu, Z., & Wang, X. (2024). Using a monotonic density ratio model to increase the power of the goodness-of-fit test for logistic regression models with case-control data. Statistics in Medicine, 43(22), 4272–4286."
  },
  {
    "objectID": "posts/renan-blog-post-week3/index.html",
    "href": "posts/renan-blog-post-week3/index.html",
    "title": "Literature Review Week 3",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "posts/renan-blog-post-week3/index.html#article-1",
    "href": "posts/renan-blog-post-week3/index.html#article-1",
    "title": "Literature Review Week 3",
    "section": "Article 1",
    "text": "Article 1\nBERT or FastText? A Comparative Analysis of Contextual as well as Non-Contextual Embeddings.[1]\nMy personal opinion: This research doesn’t explicitly state why Logistic Regression is important, but it did use it as the classifier for all of the experiments to maintain methodological simplicity. All embeddings were passed to a multinomial logistic regression (MLR) classifier for classification into target labels. Which shows the versatility of logistic regression when elaborating an experiment to test a hypothesis.\nThe main goal of the paper is to analyze the effectiveness of non-contextual embeddings from BERT models (MuRIL and MahaBERT) and FastText models (IndicFT and MahaFT) for NLP tasks. The authors compare these embeddings to contextual and compressed variants of BERT aiming to fill a research gap, because previous research did not explore non-contextual embeddings.\nThe research is important because it addresses the challenges faced by NLP in low-resource languages (The ones that lack big annotated datasets to properly train). The selection of an effective embedding method is extremely important for strong NLP performance. The research tries a promising alternative, non-contextual BERT embeddings, which can be obtained through a simple table lookup, unlike contextual embeddings that require a full forward pass through the model. This is particularly relevant for getting model performance with much better computational efficiency.\nThe methodology is quite interesting. For the FastText, which is a non-contextual embedding by default, they had to create a custom vocabulary. Which was achieved by concatenating the training and validation datasets and then passing them through a text vectorizer, which generated vectors for every word in the dataset. The vectorizer returned the vocabulary as a list of words in decreasing order of their frequency. Then the FastText model was then loaded using the FastText library, and for each word in the vocabulary, a word vector was retrieved to construct the embedding matrix. For each sentence, the text was split into individual words, and the corresponding embeddings were retrieved from the embedding matrix. These embeddings were then averaged to produce the final sentence embeddings.\nFurthermore they did not stop with FastText, they also experimented with compressed embeddings by reducing the dimensionality from 768 (the traditional BERT embedding dimension) to 300. This compression was performed using Singular Value Decomposition (SVD) to select the most relevant features, extracting the top 300 components for all the combinations of contextual as well as non-contextual for MahaBERT as well as Muril.\nIn this approach it’s interesting how they did use Logistic regression for simplicity. All embeddings were then passed to a multiple logistic regression(MLR) classifier for classification into target labels.\nI understood that as a result they did show that contextual BERT embeddings perform better than non-contextual ones, including both non-contextual BERT embeddings and FastText. So in the end they proved that their approach did not improve much or provided much resource to support this different approach. They also showed that when non-contextual BERT embeddings are compressed, their performance drops, and FastText performs better than compressed noncontextual BERT. But this is a questionable finding.\nThe limitations of the research is that even in most cases it was apparent that compression lowers the performance of non-contextual BERT embeddings. The effect of compression on contextual embeddings varies across datasets and there is no consistent way to properly derive conclusions."
  },
  {
    "objectID": "posts/renan-blog-post-week3/index.html#article-2",
    "href": "posts/renan-blog-post-week3/index.html#article-2",
    "title": "Literature Review Week 3",
    "section": "Article 2",
    "text": "Article 2\nPriority prediction of Asian Hornet sighting report using machine learning methods.[2]\nThe goal of the research is to create an automated system to predict the priority of Asian giant hornet sighting reports. Asian giant hornets are an invasive species that poses a significant threat to native bee populations and local beekeeping, as well as to public safety due to their aggressive nature and potent venom. So it’s very important that reports are properly assessed for priority.\nThe authors did model the priority prediction of sighting reports as a two-classification problem. This approach was pretty clever and simple. The goal was to just classify reports as either a “true positive” or a “false positive”.\nTheir methodology is a straightforward application of logistic regression with feature extraction. They came to realize that they needed Location Feature, Time Feature, Image Feature, Text Feature.\nLocation Feature considers the probability of a hornet being observed at a specific location based on known hornet migration patterns and habits. Time Feature accounts for the hornet’s seasonal behavior. Since hornets are most active from April to December, a report submitted during this period is more likely to be positive. Image Feature is the number of images attached to a report and they came to notice that it is correlated with the increase of its credibility. Text Feature is the textual description’s length and keywords. A longer text is considered more credible because it contains more evidence. The model also uses a specific dictionary of hornet characteristics to identify relevant keywords.\nThey then used a weighted binary cross-entropy function and the logistic regression is just mapping the probability given the feature vector.\nThe model achieved an average prediction accuracy of 83.5% on positive reports with the best weighting parameter settings, but still far from other works which achieved about 93% using Deep Learning. So this is the main limitation, still needs a lot of improvement or maybe it will never outmatch other methods due to hidden limitations.\nMy opinion on this paper is that the Logistic Regression has interesting properties, after all it is a generalized linear model, which conducts mapping from any real number to probability values.\n\nReferences\n\n\n1. Shanbhag, A., Jadhav, S., Thakurdesai, A., Sinare, R., & Joshi, R. (2025). Non-contextual BERT or FastText? A comparative analysis. https://arxiv.org/abs/2411.17661\n\n\n2. Liu, Y., Guo, J., Dong, J., Jiang, L., & Ouyang, H. (2021). Priority prediction of asian hornet sighting report using machine learning methods. 2021 IEEE International Conference on Software Engineering and Artificial Intelligence (SEAI), 7–11. https://doi.org/10.1109/seai52285.2021.9477549"
  },
  {
    "objectID": "posts/renan-blog-post-draft07/index.html",
    "href": "posts/renan-blog-post-draft07/index.html",
    "title": "Draft v07 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "Stroke affects people all around the world, resulting in numerous deaths and disabilities.[1]. If we are able to detection stroke early for those at increased risk is will be amazing for prevention and prompt intervention because stroke frequently happens quickly and can cause long-term neurological disability. Clinicians and public health experts can measure individual-level risk and target high-risk populations for clinical management and lifestyle counseling by using data-driven risk prediction models.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease is present in human or not[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset."
  },
  {
    "objectID": "posts/renan-blog-post-draft07/index.html#interpretation-of-key-continuous-predictors",
    "href": "posts/renan-blog-post-draft07/index.html#interpretation-of-key-continuous-predictors",
    "title": "Draft v07 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "Interpretation of Key Continuous Predictors",
    "text": "Interpretation of Key Continuous Predictors\n\nAge\n\nSmooth distribution from late teen.\nMajority between 40–70, is at high-risk .\nNo extreme clusters → good continuous predictor.\n\nAverage Glucose Level\n\nClear right-skew with a long tail above 200 mg/dL.\nIndicates a small group with poor metabolic problem (likely diabetic).\nHighly relevant for heart and stroke-related risk.\n\nBMI\n\nCompact distribution (~22–35) with few outliers.\nLess variation → weaker contribution compared to vascular predictors.\nPattern aligns with medical proven BMI as influence in our regression results.\n\n\nDistribution of Key Categorical Variables\nBar charts help visualize population composition. The dataset shows more females than males, a balanced rural–urban distribution, and substantial variation in work type and smoking behavior.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ncat_df = strokeclean %&gt;%\nmutate(\ngender = factor(gender, levels = c(1, 2),\nlabels = c(\"Male\", \"Female\")),\nResidence_type = factor(Residence_type, levels = c(1, 2),\nlabels = c(\"Urban\", \"Rural\")),\nsmoking_status = factor(smoking_status,\nlevels = c(1, 2, 3),\nlabels = c(\"Never\", \"Former\", \"Current\"))\n) %&gt;%\nselect(\nGender    = gender,\nResidence = Residence_type,\nSmoking   = smoking_status\n) %&gt;%\npivot_longer(\neverything(),\nnames_to  = \"Variable\",\nvalues_to = \"Category\"\n) %&gt;%\nfilter(!is.na(Category)) %&gt;%\ncount(Variable, Category) %&gt;%\ngroup_by(Variable) %&gt;%\nmutate(prop = n / sum(n))\n\nggplot(cat_df, aes(x = Category, y = prop, fill = Category)) +\ngeom_col(width = 0.7, colour = \"white\") +\ngeom_text(aes(label = percent(prop, accuracy = 1)),\nvjust = -0.3, size = 3) +\nfacet_wrap(~ Variable, scales = \"free_x\") +\nscale_y_continuous(\nlabels = percent_format(accuracy = 1),\nexpand = expansion(mult = c(0, 0.10))\n) +\nlabs(x = NULL, y = \"Percentage of patients\") +\ntheme_minimal(base_size = 12) +\ntheme(\nlegend.position  = \"none\",\nstrip.text       = element_text(face = \"bold\"),\npanel.grid.minor = element_blank()\n)\n\n\n\n\n\n\n\nFigure 1: Sample composition by gender, residence type, and smoking status.\n\n\n\n\n\nInterpreatation Gender: The dataset has more female patients (61%) than males (39%). This imbalance should be noted because gender-related model effects may partly reflect sample composition.\nResidence Type: The population is nearly evenly split between urban (51%) and rural (49%) residents. This indicates no geographic bias and good representation of both environments.\nSmoking Status: Most participants never smoked (54%), while 25% are former smokers and 22% are current smokers. This provides enough variation to meaningfully examine smoking as a behavioral risk factor for stroke.\nStroke Risk for Clinical and Behavioral Predictors \n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(scales)\n\nstopifnot(exists(\"strokeclean\"))\n\n# 1. Prepare a plotting data copy\nstrokeclean_plot = strokeclean %&gt;%\n  mutate(\n    stroke = factor(stroke, levels = c(\"No\", \"Yes\")),\n\n    hypertension = factor(\n      as.numeric(as.character(hypertension)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    heart_disease = factor(\n      as.numeric(as.character(heart_disease)),\n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    ),\n\n    smoking_status = factor(\n      as.numeric(as.character(smoking_status)),\n      levels = c(1, 2, 3),\n      labels = c(\"Never\", \"Former\", \"Current\")\n    )\n  )\n\n# 2. Helper: stroke proportion + 95% CI\nprop_ci = function(data, group) {\n  data %&gt;%\n    group_by({{ group }}) %&gt;%\n    summarise(\n      stroke_rate = mean(stroke == \"Yes\"),\n      n = n(),\n      se = sqrt(stroke_rate * (1 - stroke_rate) / n),\n      lower = pmax(0, stroke_rate - 1.96 * se),\n      upper = pmin(1, stroke_rate + 1.96 * se),\n      .groups = \"drop\"\n    )\n}\n\n# 3. Summary tables\ndf_hyp   = prop_ci(strokeclean_plot, hypertension)\ndf_hd    = prop_ci(strokeclean_plot, heart_disease)\ndf_smoke = prop_ci(strokeclean_plot, smoking_status)\n\n# 4. Professional theme\ntheme_stroke =\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 13, hjust = 0.5),\n    axis.title.x = element_blank()\n  )\n\n# 5. Distinct colors for internal comparisons\ncols_hyp   = c(\"No\" = \"#FDE725FF\", \"Yes\" = \"#440154FF\")      # yellow–purple\ncols_hd    = c(\"No\" = \"#20A387FF\", \"Yes\" = \"#F98400FF\")      # teal–orange\ncols_smoke = c(\"Never\" = \"#1F78B4\", \"Former\" = \"#33A02C\", \"Current\" = \"#E31A1C\")  # blue–green–red\n\n# 6. Individual panels\np1 =\n  ggplot(df_hyp, aes(x = hypertension, y = stroke_rate, fill = hypertension)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hyp) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Hypertension\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np2 =\n  ggplot(df_hd, aes(x = heart_disease, y = stroke_rate, fill = heart_disease)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_hd) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Heart Disease\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\np3 =\n  ggplot(df_smoke, aes(x = smoking_status, y = stroke_rate, fill = smoking_status)) +\n  geom_col(width = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +\n  scale_fill_manual(values = cols_smoke) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(title = \"Smoking Status\", y = \"Stroke (%)\") +\n  theme_stroke +\n  theme(legend.position = \"none\")\n\n# 7. Final combined figure\nggarrange(p1, p2, p3, ncol = 3, align = \"hv\")\n\n\n\n\n\n\n\nFigure 2: Stroke percentages (95% CI) by hypertension, heart disease, and smoking status.\n\n\n\n\n\nInterpretation\nThe figure summarises how stroke risk varies across key categorical predictors:\n\nHypertension\n\nStroke risk is clearly higher among hypertensive patients.\nConfidence intervals show a noticeable separation, supporting a strong association.\n\nHeart Disease\n\nPatients with heart disease show higher stroke percentages than those without.\nThe pattern is consistent with cardiovascular disease being a major clinical risk factor.\n\nSmoking Status\n\nFormer and current smokers have higher stroke percentages than never-smokers.\nThis reflects the long-term vascular effects of tobacco exposure.\n\n\nOverall, these categorical predictors show patterns aligned with clinical expectations:\nvascular risks (hypertension, heart disease) and behavioural risks (smoking) are all associated with elevated stroke likelihood.\nCorrelation among key numeric prediators\n\nlibrary(ggcorrplot)\nlibrary(RColorBrewer)\n\n# Select numeric predictors\nnumeric_vars = strokeclean[, c(\n  \"age\", \"bmi\", \"avg_glucose_level\", \"hypertension\", \"heart_disease\"\n)]\n\n# Correlation matrix\ncorr_matrix = cor(numeric_vars)\n\n# High-contrast heatmap\nggcorrplot(\n  corr_matrix,\n  method = \"square\",\n  type = \"lower\",\n  lab = TRUE,\n  lab_size = 4.5,\n  tl.cex = 12,\n  tl.srt = 45,\n  outline.col = NA,\n  colors = c(\"#B2182B\", \"white\", \"#2166AC\"),   # 🔥 high contrast red→white→blue\n  ggtheme = theme_minimal(base_size = 14)\n) +\n  ggtitle(\"Correlation Heatmap of Key Numeric Predictors\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(color = \"black\", size = 11)\n  )\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n\nInterpretation Correlation Heatmap of Key Numeric Predictors\nAll correlations are weak to moderate (0.00–0.26) → no multicollinearity concerns.\nAge shows small but meaningful positive correlations with:\nglucose (0.24)\nhypertension (0.26)\nheart disease (0.26) → consistent with known aging-related cardiovascular risk patterns.\nBMI has very weak correlations with all other predictors (0.04–0.16) → behaves independently in this dataset.\nAvg glucose moderately correlates with:\nhypertension (0.17)\nheart disease (0.14) → aligns with metabolic/vascular relationships.\nHypertension and heart disease are weakly correlated (0.11) → related but not redundant.\nThese correlations confirm that the predictors provide unique, non-overlapping information, and all can be safely included in the logistic regression model without multicollinearity issues.\nLogistic Regression Model & its Coefficients\n\nlibrary(caret)\n\n#| label: logit_fit\n#| echo: true\n#| warning: false\n#| message: false\n\nset.seed(123)\n\nn &lt;- nrow(strokeclean)\ntrain_index &lt;- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train &lt;- strokeclean[train_index, ]\nstroke_test  &lt;- strokeclean[-train_index, ]\n\nfit_glm &lt;- glm(\n  stroke ~ age + hypertension + heart_disease + avg_glucose_level + bmi + smoking_status + gender + ever_married,\n  data   = stroke_train,\n  family = binomial(link = \"logit\")\n)\n\nsummary(fit_glm)\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   &lt;2e-16 ***\nage                0.072637   0.008089   8.979   &lt;2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7\n\n\nInterpretation — Logistic Regression Coefficients\n\nAge is a strong and highly significant predictor (p &lt; 0.001). Higher age is associated with a substantial increase in the odds of stroke.\nHypertension has a significant positive effect on stroke risk (p = 0.0468), indicating hypertensive individuals are more likely to experience stroke.\nAverage glucose level is also a important predictor (p = 0.0267). Higher glucose values modestly increase stroke risk.\nHeart disease shows a positive association but is only borderline significant (p = 0.0718). This suggests a potential effect, but not statistically explainable in this model.\nSmoking has likewise borderline significant (p = 0.0714), indicating a increased risk among smokers, but the evidence is not too much strong.\nBMI, gender, and marital status show no meaningful statistical association with stroke in this dataset (all p &gt; 0.26). These variables did not contribute substantially to prediction after accounting for other factors.\nModel fit improved substantially from the null model (deviance reduced from 953.4 → 776.8; AIC = 794.8), indicating a reasonable fit and useful predictive value.\n\nOdds ratios and confidence intervals\n\n# Odds ratios and 95% confidence intervals\n\ncoef_est &lt;- coef(fit_glm)\nOR       &lt;- exp(coef_est)\n\nconf_int &lt;- exp(confint(fit_glm))  # confidence intervals on OR scale\n\nWaiting for profiling to be done...\n\nodds_table &lt;- cbind(OR, conf_int)\ncolnames(odds_table) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013\n\n\nInterpretation\nThe logistic regression findings demonstrate how each predictor impacts the likelihood of having a stroke, while keeping other variables constant:\n\nAge (OR = 1.075, CI: 1.059–1.093) Age is the strongest continuous predictor. Each additional year of age increases the odds of stroke by about 7.5%, and the confidence interval does not include 1, indicating strong statistical significance.\nHypertension (OR = 1.577, CI: 0.996–2.450) Individuals with hypertension have roughly 58% higher odds of stroke compared to those without hypertension, although the lower CI bound is just below 1. This suggests a borderline significant effect, but clinically important.\nHeart disease (OR = 1.628, CI: 0.942–2.733) Heart disease increases stroke odds by about 63%, but the CI includes 1, implying the association is positive but not statistically strong in this dataset.\nAverage glucose level (OR = 1.004, CI: 1.000–1.007) Higher glucose levels are associated with slightly increased stroke risk. Though the effect is small, the CI indicates marginal significance, aligning with known metabolic risk patterns.\nBMI (OR = 1.007, CI: 0.975–1.037) BMI shows almost no meaningful effect on stroke risk, and the CI overlaps 1. This predictor does not significantly influence stroke likelihood in this dataset.\nSmoking (Fsmoked OR = 1.263; Smokes OR = 1.598)\nFormer smokers have 26% higher odds, but CI crosses 1 → weak evidence.\nCurrent smokers have ~60% higher odds, but CI still overlaps 1 → suggests increased risk but not statistically conclusive here.\nGender (Female) (OR = 1.259; CI: 0.842–1.903) Females show slightly higher odds, but this effect is not statistically significant.\nEver married (OR = 1.126; CI: 0.590–2.013) Marital status has no clear effect on stroke odds in this sample.\n\nModel predictions and performance on the test set\n\nlibrary(caret)\n\n# 1) Predicted probabilities from logistic regression\nstroke_test$pred_prob &lt;- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\nstroke_test$stroke &lt;- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\nstroke_test$pred_class &lt;- ifelse(stroke_test$pred_prob &gt;= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class &lt;- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm &lt;- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc &gt; NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\nFrom the confusion matrix, the following performance metrics are defined:\nAccuracy \\[\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n\\] Sensitivity (Recall / True Positive Rate)\n\\[\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n\\] Specificity (True Negative Rate)\n\\[\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n\\]\nPositive Predictive Value (Precision) \\[\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n\\] Negative Predictive Value (NPV)\n\\[\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n\\]\nInterpretation of Logistic Regression Performance (Test Set)\n\nAccuracy = 94.25% The model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\nSensitivity (True Positive Rate) = 0.017 The model correctly identified only 1 out of 59 actual stroke cases (≈1.7%). → This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\nSpecificity (True Negative Rate) = 1.00 The model correctly classified all non-stroke cases. → It is extremely good at predicting “No stroke,” which dominates the dataset.\nPositive Predictive Value (Precision) = 1.00 When the model predicts “Yes,” it is always correct — but it predicted “Yes” only once. High precision is misleading because the model rarely predicts a positive case.\nNegative Predictive Value = 0.942 Most “No” predictions are correct, matching the overall class imbalance.\nKappa = 0.031 Kappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\nBalanced Accuracy = 0.508 When weighting sensitivity and specificity equally, the model performs at chance level (~50%). → Confirms that stroke detection is weak.\nMcNemar’s Test p &lt; 0.0001 Strong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity. It performs well for the majority class (non-stroke), but fails for the minority class (stroke).\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\nROC curve and AUC for the logistic model\n\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Compute ROC\nroc_glm &lt;- roc(\n  response  = stroke_test$stroke,\n  predictor = stroke_test$pred_prob,\n  levels    = c(\"No\",\"Yes\"),\n  direction = \"&lt;\"\n)\n\nauc_val &lt;- auc(roc_glm)\n\n# Extract data for ggplot\nroc_df &lt;- data.frame(\n  fpr = rev(1 - roc_glm$specificities),\n  tpr = rev(roc_glm$sensitivities)\n)\n\n# Plot\nggplot(roc_df, aes(x = fpr, y = tpr)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_abline(linetype = \"dashed\", color = \"gray60\", linewidth = 0.9) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  annotate(\"text\",\n           x = 0.70, y = 0.20,\n           label = paste0(\"AUC = \", round(auc_val, 3)),\n           size = 5) +\n  theme_bw(base_size = 13) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\nInterpretation of ROC Curve and AUC (Test Set)\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\nThe AUC = 0.815, which indicates good discriminative performance.\nAUC = 0.5 is no discrimination (random guessing)\nAUC = 0.7–0.8 is acceptable\nAUC = 0.8–0.9 is good\nAUC &gt; 0.9 is excellent\n\nEven though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\nThe strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\nthreshold tuning,\ncost-sensitive training,\nresampling techniques (SMOTE / oversampling).\n\nMachine-learning model comparison\nData Splitting and prepration\n\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\n\n  No  Yes \n3177  180 \n\nset.seed(123)\nindex &lt;- createDataPartition(model_df$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- model_df[index, ]\ntest_data  &lt;- model_df[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\nTrain control settings\n\nlibrary(caret)   # &lt;- add this line to be safe\n\nctrl &lt;- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary,\n  verboseIter = FALSE\n)\n\nLogistic Regression (caret)\n\nmodel_lr &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nDecision Tree\n\nmodel_tree &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n\nRandom Forest\n\nmodel_rf &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n\nGradient Boosted Machine (GBM)\n\nmodel_gbm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n\nk-Nearest Neighbours (k-NN)\n\nmodel_knn &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nSupport Vector Machine (Radial)\n\nmodel_svm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nModel evaluation on the test set\n\nlibrary(pROC)   \nlibrary(caret)\nmodels_list &lt;- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl &lt;- models_list[[m]]\n\n# Probabilities for the \"Yes\" class\n\npreds_prob  &lt;- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\n# Class predictions\n\npreds_class &lt;- predict(mdl, test_data)\n\n# ROC & AUC\n\nroc_obj &lt;- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val &lt;- auc(roc_obj)\n\n# Confusion matrix – positive = \"Yes\"\n\ncm_m &lt;- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults &lt;- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\nresults\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534\n\n\nInterpretation\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\nROC curve comparison across models\n\nlibrary(scales)\n\n# 1. Create ROC objects for each model\nroc_list &lt;- list(\n  LR   = roc(test_data$stroke,\n             predict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  Tree = roc(test_data$stroke,\n             predict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  RF   = roc(test_data$stroke,\n             predict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  GBM  = roc(test_data$stroke,\n             predict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  KNN  = roc(test_data$stroke,\n             predict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\"),\n  SVM  = roc(test_data$stroke,\n             predict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\n             levels = c(\"No\",\"Yes\"), direction = \"&lt;\")\n)\n\n# 2. AUC values\nauc_vals &lt;- sapply(roc_list, auc)\n\n# 3. Long data frame of ROC coordinates\nroc_df &lt;- do.call(rbind, lapply(names(roc_list), function(m) {\n  r &lt;- roc_list[[m]]\n  data.frame(\n    model       = m,\n    specificity = rev(r$specificities),\n    sensitivity = rev(r$sensitivities)\n  )\n}))\n\n# Treat model as factor in a consistent order\nroc_df$model &lt;- factor(roc_df$model, levels = names(roc_list))\n\n# 4. Legend labels with AUC\nlabel_map &lt;- paste0(names(auc_vals), \" (AUC = \", sprintf(\"%.3f\", auc_vals), \")\")\nnames(label_map) &lt;- names(auc_vals)\n\n# 5. Color palette by short model name\nmodel_cols &lt;- c(\n  LR   = \"#E69F00\",\n  Tree = \"#0072B2\",\n  RF   = \"#009E73\",\n  GBM  = \"#CC79A7\",\n  KNN  = \"#F0E442\",\n  SVM  = \"#000000\"\n)\n\n# 6. Plot\nggplot(roc_df, aes(x = 1 - specificity, y = sensitivity,\n                   colour = model, group = model)) +\n  geom_abline(intercept = 0, slope = 1,\n              linetype = \"dashed\", colour = \"grey70\", linewidth = 0.6) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = model_cols,\n    breaks = names(label_map),\n    labels = label_map,\n    name   = \"Model\"\n  ) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"1 – Specificity (False Positive Rate)\",\n    y = \"Sensitivity (True Positive Rate)\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position   = c(0.65, 0.25),\n    legend.background = element_rect(fill = \"white\", colour = \"grey80\"),\n    legend.title      = element_text(face = \"bold\"),\n    panel.grid.minor  = element_blank()\n  )\n\n\n\n\n\n\n\n\nInterpretation\nInterpretation of ROC Comparison Across Models\nLogistic Regression (AUC = 0.779) performs the best among all six models, showing the strongest ability to differentiate stroke vs. non-stroke cases.\nRandom Forest (AUC = 0.725) and GBM (AUC = 0.759) also show good discriminative ability and are close competitors to logistic regression.\nKNN (AUC = 0.667) performs moderately, better than random guessing but weaker than the tree-based and regression models.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) show the lowest AUC values, indicating weaker predictive performance.\nAll models perform above 0.5, meaning they all do better than random chance — but with large differences in quality.\nThe ROC curves demonstrate that tree-based ensemble models (RF, GBM) and logistic regression extract more meaningful patterns from the data compared to simpler (Tree) and distance-based (KNN, SVM) methods.\nOverall, logistic regression remains the most stable and best-performing model for this dataset, despite class imbalance challenges.\nOdds ratios and risk stratification\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Fit logistic regression on the same train_data used in the ML comparison\n\nglm_lr &lt;- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\n# Coefficients, CIs, p-values\n\nlr_coef &lt;- summary(glm_lr)$coefficients           # estimates + p-values\nci_raw  &lt;- suppressMessages(confint(glm_lr))      # CI on log-odds scale\n\nor_df &lt;- data.frame(\nPredictor = rownames(lr_coef),\nlogOR     = lr_coef[, \"Estimate\"],\nOR        = exp(lr_coef[, \"Estimate\"]),\nCI_lower  = exp(ci_raw[, 1]),\nCI_upper  = exp(ci_raw[, 2]),\np_value   = lr_coef[, \"Pr(&gt;|z|)\"]\n) %&gt;%\n\n# remove intercept\n\nfilter(Predictor != \"(Intercept)\") %&gt;%\n\n# nicer labels for the plot\n\nmutate(\nLabel = dplyr::recode(\nPredictor,\nage               = \"Age (per year)\",\ngender            = \"Female vs Male\",\nhypertension      = \"Hypertension (Yes vs No)\",\nheart_disease     = \"Heart disease (Yes vs No)\",\never_married      = \"Ever married (Yes vs No)\",\nwork_type         = \"Work type (higher level)\",\nResidence_type    = \"Residence: Rural vs Urban\",\navg_glucose_level = \"Average glucose level\",\nbmi               = \"BMI\",\nsmoking_status    = \"Smoking status (higher level)\"\n),\n# significance flag for colour\nSig = ifelse(p_value &lt; 0.05, \"p &lt; 0.05\", \"NS\")\n) %&gt;%\n\n# order from lower to higher OR so the plot reads nicely\n\narrange(OR) %&gt;%\nmutate(Label = factor(Label, levels = Label))\n\n# Forest plot\n\nggplot(or_df, aes(x = Label, y = OR, colour = Sig)) +\ngeom_hline(yintercept = 1, linetype = \"dashed\", colour = \"grey40\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),\nwidth = 0.15, linewidth = 0.6) +\ngeom_point(size = 3) +\ncoord_flip() +\nscale_y_log10(\nbreaks = c(0.5, 0.75, 1, 1.5, 2, 3, 4),\nlabels = c(\"0.5\", \"0.75\", \"1\", \"1.5\", \"2\", \"3\", \"4\")\n) +\nscale_colour_manual(\nvalues = c(\"p &lt; 0.05\" = \"#D55E00\", \"NS\" = \"#999999\")\n) +\nlabs(\ntitle  = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\nx      = NULL,\ny      = \"Odds Ratio (log scale)\",\ncolour = NULL\n) +\ntheme_minimal(base_size = 13) +\ntheme(\npanel.grid.minor = element_blank(),\nplot.title       = element_text(face = \"bold\", hjust = 0.5, size = 15),\naxis.text.y      = element_text(size = 11),\nlegend.position  = \"bottom\"\n)\n\n\n\n\n\n\n\n\nInterpretation\nHypertension (Yes vs No)\nThis is the strongest predictor. Its OR is clearly &gt; 2, and the whole 95% CI lies above 1 (orange point), meaning hypertensive patients have more than double the odds of stroke, with strong statistical evidence.\nAge (per year)\nThe OR is slightly above 1 with a narrow CI fully above 1 (orange).\nEach additional year of age increases stroke odds by a small but consistent amount, making age an important continuous risk factor.\nAverage glucose level\nOR is just above 1 with a tight CI above 1 (orange).\nHigher glucose is associated with a modest but statistically reliable increase in stroke risk, consistent with metabolic / diabetes-related vascular risk.\nEver married, heart disease, smoking status, gender, BMI, residence, work type\nTheir confidence intervals all cross 1 (grey points), so in this multivariable model they do not show statistically significant effects after adjusting for age, hypertension and glucose.\nSome (e.g., heart disease, smoking) still have ORs above 1, suggesting possible elevated risk, but the evidence is weaker in this dataset.\nOverall message: The forest plot shows that, after adjusting for other variables, hypertension, older age, and higher average glucose level are the clearest independent predictors of stroke, while other factors have smaller or more uncertain effects. This aligns well with established clinical knowledge and supports your logistic regression model as a sensible risk-stratification tool.\nThreshold tuning to 0.2 from 0.5\n\n# Threshold tuning: use 0.2 instead of 0.5\nnew_threshold &lt;- 0.2\n\nstroke_test$pred_class_02 &lt;- ifelse(stroke_test$pred_prob &gt;= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 &lt;- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\n# Confusion matrix for threshold = 0.2\ncm_02 &lt;- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm_02\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nInterpretation (threshold = 0.2)\n\nWith a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\nSpecificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as “no stroke” (903 out of 949).\nWhile overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives."
  },
  {
    "objectID": "posts/renan-blog-post-week2/index.html",
    "href": "posts/renan-blog-post-week2/index.html",
    "title": "Literature Review Week 2",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "posts/renan-blog-post-week2/index.html#article-1",
    "href": "posts/renan-blog-post-week2/index.html#article-1",
    "title": "Literature Review Week 2",
    "section": "Article 1",
    "text": "Article 1\nFrom Logistic Regression to the Perceptron Algorithm: Exploring Gradient Descent with Large Step Sizes.[1]\nThe author presents some interesting findings that by connecting Logistic regression with gradient descent there is a link with the perceptron algorithm. With really large steps it acts like a perceptron which in some sense links it back to the Deep Equilibrium networks study. This paper is interesting because it is counter intuitive and brings a lot of things to reflect about classification and optimization theory."
  },
  {
    "objectID": "posts/renan-blog-post-week2/index.html#article-2",
    "href": "posts/renan-blog-post-week2/index.html#article-2",
    "title": "Literature Review Week 2",
    "section": "Article 2",
    "text": "Article 2\nLarge Language Model Confidence Estimation via Black-Box Access.[2]\nThis paper addresses the problem of estimating the confidence of large language model (LLM) outputs when only black-box (query-only) access is available. It is a simple technique that uses Logistic Regression to classify and validate the confidence of the outputs. The problem of using the black-box models is that there is no control over the model itself, but in some cases the benefits and the value of buying these services that provide a black-box model outweighs training your own custom so this is a framework that attempts to overcome the challenges.\n\nReferences\n\n\n1. Tyurin, A. (2024). From logistic regression to the perceptron algorithm: Exploring gradient descent with large step sizes. https://arxiv.org/abs/2412.08424\n\n\n2. Pedapati, T., Dhurandhar, A., Ghosh, S., Dan, S., & Sattigeri, P. (2025). Large language model confidence estimation via black-box access. https://arxiv.org/abs/2406.04370"
  },
  {
    "objectID": "posts/renan-blog-post-draft06/index.html",
    "href": "posts/renan-blog-post-draft06/index.html",
    "title": "Draft v06 — Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "This draft was a direct implementation of the student Shree Krishna M.S Basnet code in attempt to promote the collaborative effort of the project.\n\n\nIntroduction\nStroke affects people all around the world, resulting in numerous deaths and disabilities.[1]. If we are able to detection stroke early for those at increased risk is will be amazing for prevention and prompt intervention because stroke frequently happens quickly and can cause long-term neurological disability. Clinicians and public health experts can measure individual-level risk and target high-risk populations for clinical management and lifestyle counseling by using data-driven risk prediction models.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease is present in human or not[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and recode the variables into appropriate numeric formats and then develop a series of supervised learning models for stroke prediction.\nLogistic Regression is used as the primary, interpretable baseline model, but its performance is compared against several more complex machine-learning techniques, including Decision Tree, Random Forest, Gradient Boosted Machine, k-Nearest Neighbours, and Support Vector Machine (radial). Model performance is evaluated using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices. The main objectives are to identify the most influential predictors of stroke and to determine whether advanced machine-learning models offer meaningful improvements over Logistic Regression for classification of stroke risk in this dataset.\n\n\nMethodology\nThis part explains about our stoke dataset, variables, preprocessing steps, logistic regression formulation, and the machine-learning modelling framework used to compare classifiers.\nOur datset contains 5,110 observations and 11 predictors commonly associated with cerebrovascular risk. After cleaning missing and inconsistent entries (e.g., “Unknown”, “N/A”, or rare textual categories such as “children” and “other”), a final dataset of 3,357 individuals remained for analysis. The cleaned dataset is stored in the object strokeclean.\nRespose we get is in binary so logestic regression is the best approach to observe whether the patient has had stroke=1 or not stroke=0[hosmer2013applied?,james2021isl?]\nVariables\nThe key predictors are listed below.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\n\nage\nNumeric\nAge of the individual (years)\n\n\ngender\nCategorical (1=Male, 2=Female)\nBiological sex\n\n\nhypertension\nBinary (0/1)\nPrior hypertension diagnosis\n\n\nheart_disease\nBinary (0/1)\nPresence of heart disease\n\n\never_married\nBinary\nMarital status\n\n\nwork_type\nCategorical (1–4)\nEmployment category\n\n\nResidence_type\nBinary (1=Urban, 2=Rural)\nPlace of residence\n\n\nsmoking_status\nCategorical\nNever/Former/Smokes\n\n\nbmi\nNumeric\nBody Mass Index\n\n\navg_glucose_level\nNumeric\nAverage glucose level\n\n\nstroke\nBinary outcome (0=No, 1=Yes)\nStroke occurrence\n\n\n\nStroke is a highly unbalanced outcome variable: - Yes (stroke): about 5% - No (no stroke): around 95%\nBecause it is possible to achieve high overall accuracy by merely forecasting the majority class, this class imbalance directly affects model evaluation. Because of this, in addition to accuracy, we also concentrate on sensitivity, specificity, ROC curves, AUC, and Youden’s J statistic.\nDataset Prepration To guarantee model validity and stop data leakage, data preprocessing is performed.[9].\nAmong the steps were:\n\nElimination of non-predictive identifiers (patient ID)\nTransforming categorical variables into dummy numerical representations\nManaging uncommon or irregular categories (e.g., “Other” gender values handled as absent)\nBMI, glucose, and age conversion to numerical\nRows with unintelligible labels (“Unknown,” “N/A”) are removed.\nValid range and consistency verification\nAfter recoding, missing values might be imputed or removed.\nDuring splitting, stratified sampling is used to maintain the stroke/no-stroke ratio[6].\nThe outcome stroke was defined as a factor with levels “No” and “Yes” in the cleaned dataset strokeclean.\n\nTo check sample performance, the data were split into training and test sets. For the baseline logistic regression model, a simple random 70/30 split was used. For the full machine-learning comparison, a stratified partition (via caret::createDataPartition) was applied to preserve the stroke/no-stroke ratio in both sets.\nLogistic regression model \nLet \\(Y_i\\) denote the stroke status for patient \\(i\\), where\n\n\\(Y_i = 1\\) if patient \\(i\\) experienced a stroke\n\n\\(Y_i = 0\\) otherwise.\n\nLet the predictor vector for patient \\(i\\) be\n\\[\n\\mathbf{x}_i = (x_{i1}, x_{i2}, \\ldots, x_{ip})^\\top,\n\\]\nwhere the \\(p\\) predictors such as age, hypertension, heart disease, average glucose level, BMI, and smoking status.\nThe logistic regression model specifies the conditional probability of stroke as\n\\[\nP(Y_i = 1 \\mid \\mathbf{x}_i)\n= \\pi(\\mathbf{x}_i)\n= \\frac{\\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}\n       {1 + \\exp\\big(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\big)}.\n\\]\nEquivalently, the logit (log-odds) of stroke is modeled as a linear combination of the predictors:\n\\[\n\\log\\left(\\frac{\\pi(\\mathbf{x}_i)}{1 - \\pi(\\mathbf{x}_i)}\\right)\n  = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}.\n\\]\nHere, \\(\\beta_0\\) is the intercept, \\(\\beta_j\\) is the change in log-odds of stroke for a one-unit increase in predictor \\(x_j\\), holding other variables constant.\nExponentiating \\(\\beta_j\\) gives the odds ratio (OR): \\[\n\\text{OR}_j = e^{\\beta_j},\n\\]\nwhich represents the multiplicative change in the odds of stroke for a one-unit increase in \\(x_j\\).\nModel Estimation\nLet \\(\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^\\top\\) denote the vector of regression coefficients. For independent observations, the likelihood of the data is \\[\nL(\\boldsymbol{\\beta})\n= \\prod_{i=1}^{n}\n  \\pi(\\mathbf{x}_i)^{\\,y_i}\n  \\left[1 - \\pi(\\mathbf{x}_i)\\right]^{\\,1-y_i},\n\\]\nwhere \\(\\pi(\\mathbf{x}_i) = P(Y_i = 1 \\mid \\mathbf{x}_i)\\).\nThe log-likelihood is\n\\[\n\\ell(\\boldsymbol{\\beta})\n= \\sum_{i=1}^{n}\n\\left[\n  y_i \\log\\big(\\pi(\\mathbf{x}_i)\\big)\n  +\n  (1 - y_i)\\log\\big(1 - \\pi(\\mathbf{x}_i)\\big)\n\\right].\n\\]\nThe maximum likelihood estimate \\(\\hat{\\boldsymbol{\\beta}}\\) is the value of \\(\\boldsymbol{\\beta}\\) that maximizes \\(\\ell(\\boldsymbol{\\beta})\\). In R, this optimization is carried out automatically using glm(..., family = binomial)\nMachine learning models and evaluation\nSix supervised models were fitted using the caret framework in order to determine whether more sophisticated methods may significantly enhance stroke classification:\n\nLogistic Regression (LR)\nDecision Tree (rpart)\nRandom Forest (RF)\nGradient Boosted Machine (GBM)\nk-Nearest Neighbours (k-NN)\nSupport Vector Machine with radial kernel (SVM-Radial)\n\nAll models used the same 70% training / 30% test split and a consistent cross-validation procedure to ensure fair comparison. To guarantee a fair comparison, all models employed the same cross-validation process and a 70% training/30% test split.\nData Splitting and Model Fitting in R\nThe cleaned dataset is stored in the object strokeclean, where the outcome variable is stroke (0 = No stroke, 1 = Stroke), and predictors include age, hypertension, heart_disease, avg_glucose_level, bmi, smoking_status, and others.\nFirst, the dataset is randomly divided into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, logistic regression model is then fitted on the training data:\nFrom this model, estimated odds ratios and 95% confidence intervals are computed as:\nModel Predictions and Performance Measures\nPredicted probabilities on the test set are obtained as:\nUsing a classification threshold \\(c = 0.5\\), the predicted class for patient \\(i\\) is\n\\[\n\\hat{y}_i =\n\\begin{cases}\n1, & \\text{if } \\hat{\\pi}_i \\ge c, \\\\\\\\\n0, & \\text{if } \\hat{\\pi}_i &lt; c.\n\\end{cases}\n\\]\nwhere \\(\\hat{\\pi}_i\\) is the predicted probability of stroke for patient \\(i\\).\nEvaluation Metrics\nModels were evaluated using standard clinical classification metrics:\n\nAccuracy\nSensitivity (Recall)\nSpecificity\nPrecision\nF1-Score\nReceiver Operating Characteristic (ROC) curve\nArea Under the Curve (AUC)\n\nYouden’s J Statistic, Used to determine optimal classification threshold:\n\\(J = \\text{Sensitivity} + \\text{Specificity} - 1\\)\nThese metrics are widely used in stroke-risk modeling literature and as per article it is often used to find optimial classidfication threshhold.[6].\n\n\nAnalysis\nBefore starting to generate predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nDistribution of Key Continuous Variables\nHistograms were used to assess the spread of the primary numeric predictors (Age, BMI, and Average Glucose Level). These variables demonstrate clinically expected right-skewness, particularly glucose and BMI, consistent with published literature on metabolic and cardiovascular risk distributions.\n\n# Histograms for key numeric variables\nlibrary(ggplot2)\n\np_age  = ggplot(strokeclean, aes(age)) + geom_histogram(binwidth=5, fill=\"green\") +\n  labs(title=\"Age Distribution\", x=\"Age\", y=\"Count\")\n\np_bmi  = ggplot(strokeclean, aes(bmi)) + geom_histogram(binwidth=2, fill=\"pink\") +\n  labs(title=\"BMI Distribution\", x=\"BMI\", y=\"Count\")\n\np_gluc = ggplot(strokeclean, aes(avg_glucose_level)) + \n  geom_histogram(binwidth=10, fill=\"yellow\") +\n  labs(title=\"Average Glucose Level\", x=\"Glucose Level\", y=\"Count\")\n\nggpubr::ggarrange(p_age, p_bmi, p_gluc, ncol=3)\n\n\n\n\n\n\n\n\nInterpretation\nOur histograms is generating valuable variation of primary numerical predictors.\n\nAge is distributed with phase of life mainly from teenage till old age, with most individuals concentrated between 40–70 years, reflecting a typical mid-to-older population where stroke risk naturally increases.\nBMI displays a moderately right-skewed pattern, with most values falling between 22–35, consistent with a population where overweight status is common but extreme obesity is rare.\nThe average glucose level is substantially skewed to the right, with many people having glucose levels below 120 but a large tail that extends beyond 200, suggesting the presence of people with metabolic problems or possibly diabetes, which is a significant clinical risk factor for stroke.\n\nWhen combined, these distributions show common clinical trends and offer a strong basis for predictive modeling.\nDistribution of Key Categorical Variables\nBar charts help visualize population composition. The dataset shows more females than males, a balanced rural–urban distribution, and substantial variation in work type and smoking behavior.\n\n# Bar charts for categorical variables\n\n# Fix labels for plotting only\n\n# Gender: 1 = Male, 2 = Female\nstrokeclean$gender = factor(\n  strokeclean$gender,\n  levels = c(1, 2),\n  labels = c(\"Male\", \"Female\")\n)\n\n# Smoking status: 1 = Never, 2 = Formerly, 3 = Smokes\nstrokeclean$smoking_status = factor(\n  strokeclean$smoking_status,\n  levels = c(1, 2, 3),\n  labels = c(\"Nsmoked\", \"Fsmoked\", \"Smokes\")\n)\n\n# Residence type: 1 = Urban, 2 = Rural\nstrokeclean$Residence_type = factor(\n  strokeclean$Residence_type,\n  levels = c(1, 2),\n  labels = c(\"Urban\", \"Rural\")\n)\n\n\np_gender = ggplot(strokeclean, aes(gender)) + geom_bar(fill=\"red\") +\nlabs(title=\"Gender Distribution\", x=\"G\", y=\"Count\")\n\np_smoke = ggplot(strokeclean, aes(smoking_status)) + geom_bar(fill=\"blue\") +\nlabs(title=\"Smoking Status\", x=\"S\", y=\"Count\")\n\np_res = ggplot(strokeclean, aes(Residence_type)) + geom_bar(fill=\"green\") +\nlabs(title=\"Residence Type\", x=\"R\", y=\"Count\")\n\nggpubr::ggarrange(p_gender, p_smoke, p_res, ncol=3)\n\n\n\n\n\n\n\n\nInterpretation\nBar plots were created to visualize demographic and behavioral attributes.\n\nGender: Females account for a significantly bigger proportion of the sample than males, which may influence overall stroke estimates and must be addressed when interpreting model results.\nSmoking status shows a large “never smoked” group\nResidence Type: Urban and rural residents are almost evenly represented, suggesting a balanced dataset with respect to geographical living conditions\n\nOverall, these distributions show that the dataset includes a diverse mix of demographic and lifestyle categories, helping ensure that the predictive models capture variation across different subpopulations.\nCorrelation among key numeric prediators\n\nnumeric_vars = strokeclean[, c(\"age\", \"bmi\", \"avg_glucose_level\",\n\"hypertension\", \"heart_disease\")]\n\ncorr_matrix = cor(numeric_vars)\n\nggcorrplot::ggcorrplot(\n  corr_matrix,\n  lab = TRUE,\n  colors = c(\"purple\", \"gold\", \"grey\"),\n  title = \"Correlation Heatmap of Key Predictors\"\n)\n\n\n\n\n\n\n\n\nInterpretation\nThe correlation heatmap shows that relationships among the key predictors are generally weak to moderate, indicating low multicollinearity and confirming that these variables can be safely used together in a logistic regression model.\n\nAge, hypertension, and heart disease all have small positive connections (about 0.24-0.26), which is to be expected given that cardiovascular problems tend to worsen as people age.\nThe average glucose level displays minor positive associations with age and hypertension, indicating known metabolic risk patterns.\nBMI shows almost no correlation with the other predictors, suggesting it contributes unique information.\nNo correlation values approach levels that would threaten model stability (e.g., &gt; 0.7).\n\nOverall, the predictors are reasonably independent, supporting their combined use in further statistical and machine-learning models.\nStroke rates for key risk factors\nHypertension and stroke\n\nggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\ngeom_bar(position = \"fill\") +\nscale_y_continuous(labels = scales::percent) +\nlabs(\ntitle = \"Stroke Rate by Hypertension Status\",\nx     = \"Hypertension (0 = No, 1 = Yes)\",\ny     = \"Percentage\"\n) +\nscale_fill_manual(values = c(\"No\" = \"yellow\", \"Yes\" = \"red\")) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nInterpretation\nHypertensive individuals have a noticeably higher percentage of stroke events compared with non-hypertensive individuals, reinforcing hypertension as a major modifiable risk factor.\nHeart disease and stroke\n\nggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\ngeom_bar(position = \"fill\") +\nscale_y_continuous(labels = scales::percent) +\nlabs(\ntitle = \"Stroke Rate by Heart Disease\",\nx     = \"Heart Disease (0 = No, 1 = Yes)\",\ny     = \"Percentage\"\n) +\nscale_fill_manual(values = c(\"No\" = \"pink\", \"Yes\" = \"green\")) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nInterpretation\nIndividuals with heart disease show substantially higher stroke rates than those without heart disease, consistent with clinical understanding that cardiovascular disease and stroke share many underlying mechanisms.\nSmoking status and stroke\n\nggplot(strokeclean, aes(x = smoking_status, fill = stroke)) +\ngeom_bar(position = \"fill\") +\nscale_y_continuous(labels = scales::percent) +\nlabs(\ntitle = \"Stroke Rate by Smoking Behavior\",\nx     = \"1 = Never, 2 = Former, 3 = Smokes\",\ny     = \"Percentage\"\n) +\nscale_fill_manual(values = c(\"No\" = \"grey70\", \"Yes\" = \"red\")) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nInterpretation\nBoth former and current smokers exhibit higher stroke percentages than never-smokers, illustrating the lasting impact of smoking on vascular risk. This supports public health messages around smoking cessation and risk reduction.\n. Baseline logistic regression model\n\nTrain/test split and model fitting\n\n\nset.seed(123)\n\nn &lt;- nrow(strokeclean)\ntrain_index &lt;- sample(seq_len(n), size = 0.7 * n)\n\nstroke_train &lt;- strokeclean[train_index, ]\nstroke_test  &lt;- strokeclean[-train_index, ]\n\nfit_glm &lt;- glm(\nstroke ~ age + hypertension + heart_disease +\navg_glucose_level + bmi + smoking_status +\ngender + ever_married,\ndata   = stroke_train,\nfamily = binomial(link = \"logit\")\n)\n\nsummary(fit_glm)\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -8.459296   0.898462  -9.415   &lt;2e-16 ***\nage                    0.072640   0.008172   8.889   &lt;2e-16 ***\nhypertension           0.455371   0.229016   1.988   0.0468 *  \nheart_disease          0.487364   0.270854   1.799   0.0720 .  \navg_glucose_level      0.003777   0.001707   2.213   0.0269 *  \nbmi                    0.006537   0.015715   0.416   0.6774    \nsmoking_statusFsmoked  0.233821   0.227332   1.029   0.3037    \nsmoking_statusSmokes   0.468664   0.266313   1.760   0.0784 .  \ngenderFemale           0.230554   0.207568   1.111   0.2667    \never_married           0.118482   0.311089   0.381   0.7033    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2339  degrees of freedom\nAIC: 796.77\n\nNumber of Fisher Scoring iterations: 7\n\n\nThe model includes age, hypertension, heart disease, average glucose level, BMI, smoking status, gender, and marital status as predictors.\nOdds ratios and confidence intervals\n\n# Odds ratios and 95% confidence intervals\n\ncoef_est &lt;- coef(fit_glm)\nOR       &lt;- exp(coef_est)\n\nconf_int &lt;- exp(confint(fit_glm))  # confidence intervals on OR scale\n\nWaiting for profiling to be done...\n\nodds_table &lt;- cbind(OR, conf_int)\ncolnames(odds_table) &lt;- c(\"OR\", \"2.5 %\", \"97.5 %\")\nround(odds_table, 3)\n\n                         OR 2.5 % 97.5 %\n(Intercept)           0.000 0.000  0.001\nage                   1.075 1.059  1.093\nhypertension          1.577 0.996  2.450\nheart_disease         1.628 0.942  2.733\navg_glucose_level     1.004 1.000  1.007\nbmi                   1.007 0.975  1.037\nsmoking_statusFsmoked 1.263 0.806  1.969\nsmoking_statusSmokes  1.598 0.938  2.674\ngenderFemale          1.259 0.842  1.903\never_married          1.126 0.590  2.013\n\n\nInterpretation\nThe logistic regression findings demonstrate how each predictor impacts the likelihood of having a stroke, while keeping other variables constant:\n\nAge (OR = 1.075, CI: 1.059–1.093) Age is the strongest continuous predictor. Each additional year of age increases the odds of stroke by about 7.5%, and the confidence interval does not include 1, indicating strong statistical significance.\nHypertension (OR = 1.577, CI: 0.996–2.450) Individuals with hypertension have roughly 58% higher odds of stroke compared to those without hypertension, although the lower CI bound is just below 1. This suggests a borderline significant effect, but clinically important.\nHeart disease (OR = 1.628, CI: 0.942–2.733) Heart disease increases stroke odds by about 63%, but the CI includes 1, implying the association is positive but not statistically strong in this dataset.\nAverage glucose level (OR = 1.004, CI: 1.000–1.007) Higher glucose levels are associated with slightly increased stroke risk. Though the effect is small, the CI indicates marginal significance, aligning with known metabolic risk patterns.\nBMI (OR = 1.007, CI: 0.975–1.037) BMI shows almost no meaningful effect on stroke risk, and the CI overlaps 1. This predictor does not significantly influence stroke likelihood in this dataset.\nSmoking (Fsmoked OR = 1.263; Smokes OR = 1.598)\nFormer smokers have 26% higher odds, but CI crosses 1 → weak evidence.\nCurrent smokers have ~60% higher odds, but CI still overlaps 1 → suggests increased risk but not statistically conclusive here.\nGender (Female) (OR = 1.259; CI: 0.842–1.903) Females show slightly higher odds, but this effect is not statistically significant.\nEver married (OR = 1.126; CI: 0.590–2.013) Marital status has no clear effect on stroke odds in this sample.\n\nModel predictions and performance on the test set\n\nlibrary(caret)\n\n# 1) Predicted probabilities from logistic regression\nstroke_test$pred_prob &lt;- predict(\n  fit_glm,\n  newdata = stroke_test,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\nstroke_test$stroke &lt;- factor(stroke_test$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\nstroke_test$pred_class &lt;- ifelse(stroke_test$pred_prob &gt;= 0.5, \"Yes\", \"No\")\nstroke_test$pred_class &lt;- factor(stroke_test$pred_class,\n                                 levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm &lt;- confusionMatrix(\n  data      = stroke_test$pred_class,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc &gt; NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\nFrom the confusion matrix, the following performance metrics are defined:\nAccuracy \\[\n\\text{Accuracy} =\n\\frac{TP + TN}{TP + TN + FP + FN}.\n\\] Sensitivity (Recall / True Positive Rate)\n\\[\n\\text{Sensitivity} =\n\\frac{TP}{TP + FN}.\n\\] Specificity (True Negative Rate)\n\\[\n\\text{Specificity} =\n\\frac{TN}{TN + FP}.\n\\]\nPositive Predictive Value (Precision) \\[\n\\text{PPV} =\n\\frac{TP}{TP + FP}.\n\\] Negative Predictive Value (NPV)\n\\[\n\\text{NPV} =\n\\frac{TN}{TN + FN}.\n\\]\nInterpretation of Logistic Regression Performance (Test Set)\n\nAccuracy = 94.25% The model correctly classified most cases, mainly because the dataset is highly imbalanced (only ~6% stroke cases). High accuracy here does not mean good stroke detection.\nSensitivity (True Positive Rate) = 0.017 The model correctly identified only 1 out of 59 actual stroke cases (≈1.7%). → This shows the model fails to detect stroke cases, which is common in rare-event medical datasets.\nSpecificity (True Negative Rate) = 1.00 The model correctly classified all non-stroke cases. → It is extremely good at predicting “No stroke,” which dominates the dataset.\nPositive Predictive Value (Precision) = 1.00 When the model predicts “Yes,” it is always correct — but it predicted “Yes” only once. High precision is misleading because the model rarely predicts a positive case.\nNegative Predictive Value = 0.942 Most “No” predictions are correct, matching the overall class imbalance.\nKappa = 0.031 Kappa measures agreement beyond chance. A value near zero shows the model performs only slightly better than random when considering class imbalance.\nBalanced Accuracy = 0.508 When weighting sensitivity and specificity equally, the model performs at chance level (~50%). → Confirms that stroke detection is weak.\nMcNemar’s Test p &lt; 0.0001 Strong evidence that the model’s errors are systematically skewed—it overwhelmingly predicts “No stroke.”\n\nThe logistic regression model achieves high accuracy only because the negative class dominates.It detects almost no true stroke cases, giving extremely poor sensitivity. It performs well for the majority class (non-stroke), but fails for the minority class (stroke).\nThese results highlight the challenge of severe class imbalance, which requires additional techniques (e.g., SMOTE, class weights, resampling) to improve medical-event prediction.\nROC curve and AUC for the logistic model\n\n# Sanity check\ntable(stroke_test$stroke)\n\n\n No Yes \n949  59 \n\n# ROC and AUC using factor outcome directly\nroc_glm &lt;- roc(\n  response  = stroke_test$stroke,    # factor: No / Yes\n  predictor = stroke_test$pred_prob, # predicted probabilities from glm\n  levels    = c(\"No\", \"Yes\"),        # \"No\" = control, \"Yes\" = case\n  direction = \"&lt;\"\n)\n\nauc(roc_glm)\n\nArea under the curve: 0.8154\n\nplot(roc_glm, main = \"ROC Curve – Logistic Regression (Test Set)\")\n\n\n\n\n\n\n\n\nA higher AUC (closer to 1) indicates better discrimination between stroke and non-stroke cases. Values substantially above 0.5 indicate that the model performs better than random classification.\nInterpretation of ROC Curve and AUC (Test Set)\nThe ROC curve evaluates the model’s ability to distinguish between stroke and non-stroke cases across all possible classification thresholds, not just the default 0.5 cutoff.\nThe AUC = 0.815, which indicates good discriminative performance.\nAUC = 0.5 is no discrimination (random guessing)\nAUC = 0.7–0.8 is acceptable\nAUC = 0.8–0.9 is good\nAUC &gt; 0.9 is excellent\n\nEven though the confusion matrix showed poor sensitivity at threshold 0.5, the AUC reveals that the model can separate the two classes reasonably well if a better threshold is chosen.\nThe strong AUC compared to weak sensitivity highlights the impact of severe class imbalance and the importance of customizing the probability cutoff for medical prediction tasks.\n\nOverall, the ROC analysis suggests that the logistic model contains useful predictive signal, but performance for detecting stroke can be improved with:\n\nthreshold tuning,\ncost-sensitive training,\nresampling techniques (SMOTE / oversampling).\n\nMachine-learning model comparison\nData Splitting and prepration\n\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\n\n  No  Yes \n3177  180 \n\nset.seed(123)\nindex &lt;- createDataPartition(model_df$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- model_df[index, ]\ntest_data  &lt;- model_df[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\nTrain control settings\n\nctrl &lt;- trainControl(\nmethod = \"repeatedcv\",\nnumber = 5,\nrepeats = 3,\nclassProbs = TRUE,\nsummaryFunction = twoClassSummary,\nverboseIter = FALSE\n)\n\nLogistic Regression (caret)\n\nmodel_lr &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nDecision Tree\n\nmodel_tree &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rpart\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 10\n)\n\nRandom Forest\n\nmodel_rf &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"rf\",\nmetric = \"ROC\",\ntrControl = ctrl,\ntuneLength = 5\n)\n\nGradient Boosted Machine (GBM)\n\nmodel_gbm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"gbm\",\nmetric = \"ROC\",\ntrControl = ctrl,\nverbose = FALSE\n)\n\nk-Nearest Neighbours (k-NN)\n\nmodel_knn &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"knn\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nSupport Vector Machine (Radial)\n\nmodel_svm &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"svmRadial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\nModel evaluation on the test set\n\nmodels_list &lt;- list(\nLR   = model_lr,\nTREE = model_tree,\nRF   = model_rf,\nGBM  = model_gbm,\nKNN  = model_knn,\nSVM  = model_svm\n)\n\nresults &lt;- data.frame(\nModel       = character(),\nAUC         = numeric(),\nAccuracy    = numeric(),\nSensitivity = numeric(),\nSpecificity = numeric()\n)\n\nfor (m in names(models_list)) {\nmdl &lt;- models_list[[m]]\n\n# Probabilities for the \"Yes\" class\n\npreds_prob  &lt;- predict(mdl, test_data, type = \"prob\")[, \"Yes\"]\n\n# Class predictions\n\npreds_class &lt;- predict(mdl, test_data)\n\n# ROC & AUC\n\nroc_obj &lt;- roc(test_data$stroke, preds_prob,\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\nauc_val &lt;- auc(roc_obj)\n\n# Confusion matrix – positive = \"Yes\"\n\ncm_m &lt;- confusionMatrix(preds_class, test_data$stroke, positive = \"Yes\")\n\nresults &lt;- rbind(\nresults,\ndata.frame(\nModel       = m,\nAUC         = as.numeric(auc_val),\nAccuracy    = cm_m$overall[\"Accuracy\"],\nSensitivity = cm_m$byClass[\"Sensitivity\"],\nSpecificity = cm_m$byClass[\"Specificity\"]\n)\n)\n}\n\nresults\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7788854 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7275465 0.9433962  0.01851852   0.9958027\nAccuracy3   GBM 0.7636994 0.9453823  0.01851852   0.9979014\nAccuracy4   KNN 0.6633730 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6256655 0.9453823  0.00000000   0.9989507\n\n\nInterpretation\nAcross all six models, overall accuracy and specificity are very high, mainly because the dataset is highly imbalanced (only ~6% stroke cases). However, sensitivity is extremely low across every model, meaning that almost none of the models correctly identify stroke cases.\nLogistic Regression (AUC = 0.78) and GBM (AUC = 0.76) show the best overall discrimination, indicated by the highest AUC values. These models are better at ranking high-risk vs. low-risk individuals, even though they still fail at detecting positives under the default 0.5 threshold.\nTree-based models (Decision Tree, Random Forest, GBM) achieve slightly higher sensitivity than LR, but only marginally (still around 1–2%). KNN and SVM detect 0 stroke cases at this threshold, despite high accuracy.\nAll models appear to perform well based on accuracy and specificity, but this is misleading—they are failing at the most important task: detecting stroke cases. This confirms that class imbalance severely affects performance and requires threshold tuning, resampling, or cost-sensitive learning to achieve meaningful sensitivity.\nROC curve comparison across models\n\n# ROC objects for each model\n\nroc_lr   &lt;- roc(test_data$stroke,\npredict(model_lr,   test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\nroc_tree &lt;- roc(test_data$stroke,\npredict(model_tree, test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\nroc_rf   &lt;- roc(test_data$stroke,\npredict(model_rf,   test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\nroc_gbm  &lt;- roc(test_data$stroke,\npredict(model_gbm,  test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\nroc_knn  &lt;- roc(test_data$stroke,\npredict(model_knn,  test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\nroc_svm  &lt;- roc(test_data$stroke,\npredict(model_svm,  test_data, type = \"prob\")[, \"Yes\"],\nlevels = c(\"No\", \"Yes\"), direction = \"&lt;\")\n\n# Plot ROC curves\n\nplot(roc_lr,   col = \"red\",       main = \"ROC Comparison for Six Models\")\nplot(roc_tree, col = \"blue\",      add = TRUE)\nplot(roc_rf,   col = \"darkgreen\", add = TRUE)\nplot(roc_gbm,  col = \"purple\",    add = TRUE)\nplot(roc_knn,  col = \"orange\",    add = TRUE)\nplot(roc_svm,  col = \"black\",     add = TRUE)\n\nlegend(\n\"bottomright\",\nlegend = c(\"LR\", \"Tree\", \"RF\", \"GBM\", \"KNN\", \"SVM\"),\ncol    = c(\"red\", \"blue\", \"darkgreen\", \"purple\", \"orange\", \"black\"),\nlwd    = 2\n)\n\n\n\n\n\n\n\n\nInterpretation\nThe ROC curves show how well each of the six models distinguishes between stroke and non-stroke cases at all probability thresholds. All models outperform random guessing (the diagonal line), indicating that they include useful predictive information.\n\nLogistic Regression (red) and Gradient Boosted Machine (purple) have the most robust ROC curves, consistently outperforming the others across the majority of the sensitivity-specificity range. This is consistent with their higher AUC values, implying that these models provide the most accurate ranking of individuals by stroke risk. Random Forest (green) also performs well, trailing just LR and GBM, demonstrating its capacity to capture nonlinear interactions.\nThe Decision Tree, k-NN, and SVM models have weaker curves, indicating lower discriminative capacity than the ensemble-based and logistic models. SVM (black) performs the worst, remaining closest to the diagonal, implying little distinction between classes.\n\nOverall, the ROC comparison reveals that, while all models outperform chance, Logistic Regression, GBM, and Random Forest provide the best trade-off between sensitivity and specificity, despite the fact that sensitivity remains low at the default threshold due to severe class imbalance.\nOdds ratios and risk stratification\n\nglm_lr &lt;- glm(\nstroke ~ age + gender + hypertension + heart_disease + ever_married +\nwork_type + Residence_type + avg_glucose_level + bmi + smoking_status,\ndata   = train_data,\nfamily = binomial\n)\n\nlr_coef &lt;- summary(glm_lr)$coefficients\n\n# Odds ratios and 95% CI\n\nor_vals &lt;- exp(lr_coef[, \"Estimate\"])\nci_raw  &lt;- suppressMessages(confint(glm_lr)) # CI on log-odds scale\nci_or   &lt;- exp(ci_raw)                       # convert to OR scale\n\nplot_df &lt;- data.frame(\nPredictor = rownames(lr_coef),\nOR        = or_vals,\nCI_lower  = ci_or[, 1],\nCI_upper  = ci_or[, 2]\n)\n\nplot_df &lt;- subset(plot_df, Predictor != \"(Intercept)\")\n\nggplot(plot_df, aes(x = reorder(Predictor, OR), y = OR)) +\ngeom_point(size = 3, color = \"red\") +\ngeom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.2) +\ncoord_flip() +\nlabs(\ntitle = \"Odds Ratios for Stroke Predictors (Logistic Regression)\",\ny     = \"Odds Ratio (log scale)\",\nx     = \"\"\n) +\nscale_y_log10() +\ngeom_hline(yintercept = 1, linetype = \"dashed\") +\ntheme_minimal()\n\n\n\n\n\n\n\nplot_df[order(-plot_df$OR), ]\n\n                                  Predictor        OR  CI_lower CI_upper\nhypertension                   hypertension 2.5159353 1.6453888 3.810548\never_married                   ever_married 1.7023436 0.9357451 2.967095\nheart_disease                 heart_disease 1.4392416 0.8218664 2.439382\nsmoking_statusSmokes   smoking_statusSmokes 1.4246818 0.8360264 2.380571\nsmoking_statusFsmoked smoking_statusFsmoked 1.2340439 0.7883483 1.920422\ngenderFemale                   genderFemale 1.1132391 0.7481511 1.670149\nage                                     age 1.0804344 1.0630608 1.099392\navg_glucose_level         avg_glucose_level 1.0054691 1.0021701 1.008745\nbmi                                     bmi 1.0025648 0.9719311 1.032772\nResidence_typeRural     Residence_typeRural 0.9325388 0.6311308 1.374361\nwork_type                         work_type 0.8371811 0.6210602 1.130333\n\n\nInterpretation\nThe odds-ratio graphic illustrates how each predictor affects the risk of having a stroke while keeping all other variables constant. Values greater than 1 imply higher odds, whereas values less than 1 indicate lower odds. Confidence intervals that do not cross 1 indicate statistically significant evidence.\n\nHypertension (OR ≈ 2.52, CI: 1.65–3.81) Hypertension is one of the strongest predictors of stroke. Individuals with hypertension have more than 2.5 times higher odds of stroke compared to non-hypertensive individuals. The confidence interval does not cross 1, indicating strong statistical significance.\nAge (OR ≈ 1.08 per year, CI: 1.06–1.10) Each additional year of age increases stroke odds by about 8%, making age a consistent and significant risk factor.\nAverage glucose level (OR ≈ 1.005, CI: 1.002–1.009) Higher glucose levels slightly increase stroke odds. Although the effect size is small, the very tight CI above 1 suggests a reliable association linked to metabolic risk.\nHeart disease (OR ≈ 1.44, CI: 0.82–2.44) People with heart disease show elevated stroke odds (≈44% higher), but the CI crosses 1, meaning evidence is suggestive but not statistically conclusive in this dataset.\nSmoking behavior:\nCurrent smokers (OR ≈ 1.42)\nFormer smokers (OR ≈ 1.23) Both groups show increased stroke odds compared to never-smokers, though their confidence intervals cross 1. This indicates a positive trend consistent with clinical knowledge, but weaker statistical support here.\nEver married (OR ≈ 1.70, CI: 0.94–2.97) Shows higher odds of stroke, but the wide CI overlapping 1 indicates uncertainty.\nGender (Female) (OR ≈ 1.11, CI: 0.75–1.67) Minimal effect, not statistically significant.\nBMI (OR ≈ 1.00) Virtually no effect on stroke odds.\nResidence type (Rural vs Urban) (OR ≈ 0.93) No meaningful association with stroke.\nWork type (OR ≈ 0.84) Slightly lower odds of stroke, but not statistically meaningful.\n\nThreshold tuning to 0.2 from 0.5\n\n# Threshold tuning: use 0.2 instead of 0.5\nnew_threshold &lt;- 0.2\n\nstroke_test$pred_class_02 &lt;- ifelse(stroke_test$pred_prob &gt;= new_threshold,\n                                    \"Yes\", \"No\")\n\nstroke_test$pred_class_02 &lt;- factor(stroke_test$pred_class_02,\n                                    levels = c(\"No\", \"Yes\"))\n\n# Confusion matrix for threshold = 0.2\ncm_02 &lt;- confusionMatrix(\n  data      = stroke_test$pred_class_02,\n  reference = stroke_test$stroke,\n  positive  = \"Yes\"\n)\n\ncm_02\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nInterpretation (threshold = 0.2)\n\nWith a lower decision criterion of 0.2, the model successfully identifies 13 out of 59 stroke cases (sensitivity = 22%), compared to only one case with the default 0.5 threshold.\nSpecificity remains high at almost 95%, indicating that the majority of non-stroke patients are still properly categorized as “no stroke” (903 out of 949).\nWhile overall accuracy declines from 94% to 91%, balanced accuracy improves (from ≈0.51 to ≈0.59), indicating a greater balance of sensitivity and specificity.\n\nThis change indicates a therapeutically reasonable compromise: the model detects more possible stroke patients (fewer missed cases) at the expense of a moderate rise in false positives.\n\n\nconclusion\nThis experiment compared a conventional logistic regression model with several machine-learning algorithms and examined whether common demographic, behavioral, and clinical characteristics may be used to predict stroke risk using a stroke dataset. Stroke was a rare outcome (about 5% of cases) in the final sample of 3,357 people that was analyzed after the data was cleaned and inconsistent or missing values were eliminated. In addition to reflecting actual epidemiology, this significant class disparity complicates classification, particularly when it comes to identifying the minority (stroke) class.\nAge, hypertension, cardiac disease, and raised average glucose levels are among the best predictors of stroke, according to the baseline logistic regression model. Smoking status substantially increased risk. These variables were identified as significant risk factors by odds ratios significantly greater than 1 and confidence intervals that did not cross 1. These results support the use of logistic regression as an interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness.\nThe logistic regression model performed reasonably well overall in terms of prediction; however, sensitivity for stroke cases was more constrained at the default 0.5 probability threshold, as would be expected with an imbalanced outcome. The model clearly outperformed random guessing, according to the ROC curve and AUC values, but there was still space for improvement in terms of differentiating between stroke and non-stroke patients. Youden’s J statistic offers a method for selecting a different categorization threshold that enhances the ratio of sensitivity to specificity, which may be crucial in a screening setting when it is expensive to miss actual stroke cases.\nMore sophisticated models, such Random Forest and Gradient Boosted Machine, were able to attain somewhat higher AUC values than logistic regression in the machine-learning comparison, showing superior discrimination across a range of thresholds. However, these increases in AUC came at the expense of decreased interpretability and were not always accompanied by significant increases in sensitivity at fixed cut-offs. Logistic regression, on the other hand, offers precise odds ratios and confidence intervals that are simpler for public health professionals and doctors to understand when discussing risk and developing interventions.\nBecause of the severe class imbalance, sensitivity for stroke cases was extremely low (around 2%), meaning that the model almost never predicted “stroke = Yes” and therefore missed most true stroke cases.\nTo address this, the decision threshold was lowered from 0.5 to 0.2. At this cut-off, sensitivity increased from roughly 2% to about 22%, while specificity remained high at around 95%. Overall accuracy dropped slightly to about 91%, but balanced accuracy improved, indicating a more reasonable trade-off between detecting stroke cases and avoiding false positives. This threshold experiment illustrates a key practical point: for rare but serious outcomes such as stroke, it can be preferable to sacrifice some overall accuracy in order to reduce the number of missed high-risk individuals. In this setting, the logistic model is more appropriately viewed as a screening or risk-flagging tool rather than a definitive diagnostic rule.\nOverall, the findings show that relatively simple models built from routinely collected health indicators can meaningfully distinguish between individuals with and without stroke, even in the presence of substantial class imbalance. Logistic regression emerges as a strong, interpretable baseline, while tree-based ensemble methods provide incremental performance improvements at the cost of transparency. Future work could focus on external validation, calibration assessment, more sophisticated imbalance-handling techniques, and the inclusion of additional clinical or longitudinal information. These extensions would help move from proof-of-concept modelling toward robust, clinically usable tools for stroke risk stratification and targeted prevention.\n#References\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2).\n\n\n9. Wang, M. (2014). Generalized estimating equations in longitudinal data analysis: A review and recent developments. Advances in Statistics, 2014."
  },
  {
    "objectID": "posts/renan-blog-post-week6/Readme.html",
    "href": "posts/renan-blog-post-week6/Readme.html",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data.\n\n\n\nMissing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature.\nFrom the section 3.1 Visualizing Key Features"
  },
  {
    "objectID": "posts/renan-blog-post-week6/Readme.html#features-correlation-matrix",
    "href": "posts/renan-blog-post-week6/Readme.html#features-correlation-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data."
  },
  {
    "objectID": "posts/renan-blog-post-week6/Readme.html#sparsity-matrix",
    "href": "posts/renan-blog-post-week6/Readme.html#sparsity-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature.\nFrom the section 3.1 Visualizing Key Features"
  },
  {
    "objectID": "posts/kristina-blog-post-week5/index.html",
    "href": "posts/kristina-blog-post-week5/index.html",
    "title": "Literature Review Week 5",
    "section": "",
    "text": "Article Title: Identification of factors influencing severity of motorcycle crashes in Dhaka, Bangladesh using binary logistic regression model.[1]\nAuthors: Hamidur Rahman, Niaz Mahmud Zafri, Tamanna Akter, Shahrior Pervaz\nProblem: - One of the most common unnatural causes of death across the world is road accidents, so it is important to identify strong predictors associated with such accidents. - According to the World Health Organization, most of the road crash deaths that occur worldwide happen in developing countries. - Researchers focus on motorcycle crashes in Dhaka, the capital city of Bangladesh. It is stated that the rate of road crashes in Bangladesh is significantly greater than other developing countries, and Dhaka has the greatest amount of motorists and reported motorcycle crashes. - It is noted that most research about this topic is done on data from developed countries and not developing countries. So the conclusions drawn from existing studies may not be applicable to the problems the developing countries are facing - Knowing which predictors are strongly associated with motorcycle crashes in Dhaka helps builders and developers eliminate or reduce these risk factors as they are building new roads. This study serves as a step in preventing more motorcycle road crashes as developing countries are being built.\nSolution: - Researchers conduct a binary logistic regression analysis to identify predictors most strongly associated with the occurrence of the outcome, motorcycle crash severity (fatal/ non- fatal) - They began the study by choosing predictors identified in previous literature about similar topics. Commonly identified predictors of motorcycle crashes are grouped into five broad categories: environment, road characteristics, driver characteristics, motorcycle features, and type of collision. - The binary logistic regression equation is given as the log odds of the probability of the occurrence of the outcome. An explanation of every variable in the equation is given (slopes, intercept, odds ratio, and relation to the outcome variable).\nData: - Data was collected from 2006 to 2015 from the Accident Research Institute of Bangladesh University of Engineering and Technology. Only 316 data points were used, and each contained information about motorcycle crashes. - There are five broad categories encompassing all predictors. The five categories and predictors are: 1. Environmental factors- date/time, lighting, weather 2. Collision type- five different types of collisions 3. Driver characteristics- gender, age, alcohol consumption, and use of a helmet 4. Road characteristics-location, traffic characteristics, road conditions 5. vehicle characteristics- type of other vehicle in crash, weight of other vehicle in crash, motorcycle condition, and more - The outcome variable, crash injury severity, originally had four levels. Observations from this predictor were then reclassified as either “fatal” or “non-fatal” for a binary outcome. - To determine which predictors to include in the dataset, researchers conducted a univariate analysis and a chi- square test of each individual predictor to assess significance. All significant predicators were then chosen for the dataset, used for the binary logistic regression. After this, multicollinearity was assessed using the VIF and none of the predictors showed multicollinearity.\nResults/ Conclusions: - After conducting the binary logistic regression, 11 out of the 16 included predictors were found to be significantly associated with the outcome. The significant predictors were day of the week, seasonal condition, time of day, three types of road characteristics, crash type, condition of motorcycle, type of other vehicle in accident, use of helmet, and alcohol consumption - The regression curve from the analysis was also found to be significant - Goodness of fit was assessed using a test called the Hosmer and Lemeshow test - The discussion section details each significant predictor, and interpretations of slopes are given in relation to the outcome variable and the reference groups. - Some of the findings were consistent with other studies, and some of the findings contradict conclusions in previous studies. - Most notable conclusions from this study that researchers believe would improve road safety and reduce motorcycle accident severity in developing countries: 1. better lighting conditions for enhanced visibility 2. solution to wet/ slippery roads during rainy season 3. educate drivers about how to drive during unsafe conditions, such as nighttime, heavy rain, and heavy traffic on weekends. Also educate drivers to follow proper safety and speeding regulations. And better education/ training/ evaluation for drivers operating larger vehicles 4. improved pedestrian walkways and road areas 5. strict enforcement of laws regarding helmet use and alcohol while driving Limitations: - Missing information in the data: Some important predictors were entirely excluded from the study due to missing information in the dataset. So there may be some extremely relevant predictors that have yet to be studied. There is also an ongoing issue of accidents that go unreported due to lack of fatality, and drivers do not report these incident."
  },
  {
    "objectID": "posts/kristina-blog-post-week5/index.html#article-1",
    "href": "posts/kristina-blog-post-week5/index.html#article-1",
    "title": "Literature Review Week 5",
    "section": "",
    "text": "Article Title: Identification of factors influencing severity of motorcycle crashes in Dhaka, Bangladesh using binary logistic regression model.[1]\nAuthors: Hamidur Rahman, Niaz Mahmud Zafri, Tamanna Akter, Shahrior Pervaz\nProblem: - One of the most common unnatural causes of death across the world is road accidents, so it is important to identify strong predictors associated with such accidents. - According to the World Health Organization, most of the road crash deaths that occur worldwide happen in developing countries. - Researchers focus on motorcycle crashes in Dhaka, the capital city of Bangladesh. It is stated that the rate of road crashes in Bangladesh is significantly greater than other developing countries, and Dhaka has the greatest amount of motorists and reported motorcycle crashes. - It is noted that most research about this topic is done on data from developed countries and not developing countries. So the conclusions drawn from existing studies may not be applicable to the problems the developing countries are facing - Knowing which predictors are strongly associated with motorcycle crashes in Dhaka helps builders and developers eliminate or reduce these risk factors as they are building new roads. This study serves as a step in preventing more motorcycle road crashes as developing countries are being built.\nSolution: - Researchers conduct a binary logistic regression analysis to identify predictors most strongly associated with the occurrence of the outcome, motorcycle crash severity (fatal/ non- fatal) - They began the study by choosing predictors identified in previous literature about similar topics. Commonly identified predictors of motorcycle crashes are grouped into five broad categories: environment, road characteristics, driver characteristics, motorcycle features, and type of collision. - The binary logistic regression equation is given as the log odds of the probability of the occurrence of the outcome. An explanation of every variable in the equation is given (slopes, intercept, odds ratio, and relation to the outcome variable).\nData: - Data was collected from 2006 to 2015 from the Accident Research Institute of Bangladesh University of Engineering and Technology. Only 316 data points were used, and each contained information about motorcycle crashes. - There are five broad categories encompassing all predictors. The five categories and predictors are: 1. Environmental factors- date/time, lighting, weather 2. Collision type- five different types of collisions 3. Driver characteristics- gender, age, alcohol consumption, and use of a helmet 4. Road characteristics-location, traffic characteristics, road conditions 5. vehicle characteristics- type of other vehicle in crash, weight of other vehicle in crash, motorcycle condition, and more - The outcome variable, crash injury severity, originally had four levels. Observations from this predictor were then reclassified as either “fatal” or “non-fatal” for a binary outcome. - To determine which predictors to include in the dataset, researchers conducted a univariate analysis and a chi- square test of each individual predictor to assess significance. All significant predicators were then chosen for the dataset, used for the binary logistic regression. After this, multicollinearity was assessed using the VIF and none of the predictors showed multicollinearity.\nResults/ Conclusions: - After conducting the binary logistic regression, 11 out of the 16 included predictors were found to be significantly associated with the outcome. The significant predictors were day of the week, seasonal condition, time of day, three types of road characteristics, crash type, condition of motorcycle, type of other vehicle in accident, use of helmet, and alcohol consumption - The regression curve from the analysis was also found to be significant - Goodness of fit was assessed using a test called the Hosmer and Lemeshow test - The discussion section details each significant predictor, and interpretations of slopes are given in relation to the outcome variable and the reference groups. - Some of the findings were consistent with other studies, and some of the findings contradict conclusions in previous studies. - Most notable conclusions from this study that researchers believe would improve road safety and reduce motorcycle accident severity in developing countries: 1. better lighting conditions for enhanced visibility 2. solution to wet/ slippery roads during rainy season 3. educate drivers about how to drive during unsafe conditions, such as nighttime, heavy rain, and heavy traffic on weekends. Also educate drivers to follow proper safety and speeding regulations. And better education/ training/ evaluation for drivers operating larger vehicles 4. improved pedestrian walkways and road areas 5. strict enforcement of laws regarding helmet use and alcohol while driving Limitations: - Missing information in the data: Some important predictors were entirely excluded from the study due to missing information in the dataset. So there may be some extremely relevant predictors that have yet to be studied. There is also an ongoing issue of accidents that go unreported due to lack of fatality, and drivers do not report these incident."
  },
  {
    "objectID": "posts/kristina-blog-post-week5/index.html#article-2",
    "href": "posts/kristina-blog-post-week5/index.html#article-2",
    "title": "Literature Review Week 5",
    "section": "Article 2",
    "text": "Article 2\nTitle of article: Risk factors for airplane headache: A multivariate logistic regression analysis in a population of career flight personnel.[2]\nAuthors: Johannes Prottengeier, Isabelle Kaiser, Andreas Moritz, Fabian Konrad\nProblem: - Airplane headache (AH) is a headache disorder described as a headache induced while taking off or landing in an airplane. It was not until 2004 that the disorder was recognized and classified as a medical issue. Because this disorder has just recently been recognized, there is little existing research on it. - There is a lot of previous literature and research regarding other headache types and disorders, but AH is still lacking appropriate research. - Specifically, this study aims to identify predictors and risk factors that occur before onset of airplane headache. Knowing the predictors would help both travelers and employees of airlines. - AH is a common disorder affecting about 65 million people worldwide every year, so helping prevent and treat it is crucial. Future research is therefore a must.\nSolution: - Conduct a logistic regression analysis to determine significant predictors of airplane headache. Two binary logistic regression models were constructed; one model’s outcome was either airplane headache (1) or no headache (0), and the other model’s outcomes were airplane headache (1) or other headache (0). - Used R to conduct statistical analysis\nData: - Data was collected from a voluntary online survey sent out to about 20,000 pilots who fly frequently due to work. A total of 2237 complete questionnaires from a 3 month period in 2014 were received and used in the dataset for this study. - The data/ questions in the survey were determined by pain specialists - Predictors included in the survey were: demographic information, health history, substance use, medication use, stress levels, and headache/ physical symptoms while flying. - The outcome variable was divided into three categories: airplane headache, no headache, and other type of headache. - Predictors were tested for multicollinearity before models were constructed - Data was further reduced using stepwise backward elimination (starting with all predictors and then eliminating least significant predictors)\nResults/ Conclusions: - Survey results revealed that a vast majority of participants said they had some form of headache while flying on an airplane (82%) - The first model comparing airplane headache with no headache was found to have 10 significant predictors. The AUC for this model showed that it had strong predictive power. - The second model comparing airplane headache with other headache was found to have only four significant predictors. The AUC also showed that this model had low predictive power. This is likely attributed to the fact that airplane headache and other types of headaches all have similar predictors, so it is not easy to distinguish between strong predictors for just AH as compared to all types of headaches. - Conclusions: supplementing with folic acid before flight may help reduce risk of airplane headache. Other strong predictors of airplane headache are occupation, work stress, and preexisting headache medical conditions. - Further research about airplane headache is necessary because of all the ongoing negative subsequent events caused by it. It causes people loss of productivity, avoidance behaviors, stress, and anxiety.\nLimitations: - Only 12% of surveyed individuals submitted their survey. It could be the case that only the people who suffered from headaches responded to the survey, so the proportions of individuals with airplane headache in this study are not representative of the entire population. This is called positive selection bias. - Participants in the survey may not be reporting accurate information because a lot of time passes between the event of their airplane travel and the time when they take the survey.\n\nReferences\n\n\n1. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n2. Prottengeier, J., Kaiser, I., Moritz, A., & Konrad, F. (2025). Risk factors for airplane headache: A multivariable logistic regression analysis in a population of career flight personnel. Cephalalgia, 45(4), 03331024251329837."
  },
  {
    "objectID": "posts/renan-blog-post-week12/index.html",
    "href": "posts/renan-blog-post-week12/index.html",
    "title": "Dataset Exploration - Week 12",
    "section": "",
    "text": "Reproducing Steve code in baseFirthFlic1116.qmd and RFirth11116asfactor_allbutflac.R using the dataset Stroke Prediction Dataset."
  },
  {
    "objectID": "posts/renan-blog-post-week12/index.html#introduction",
    "href": "posts/renan-blog-post-week12/index.html#introduction",
    "title": "Dataset Exploration - Week 12",
    "section": "",
    "text": "Reproducing Steve code in baseFirthFlic1116.qmd and RFirth11116asfactor_allbutflac.R using the dataset Stroke Prediction Dataset."
  },
  {
    "objectID": "posts/renan-blog-post-week12/index.html#setup-and-data-loading",
    "href": "posts/renan-blog-post-week12/index.html#setup-and-data-loading",
    "title": "Dataset Exploration - Week 12",
    "section": "1. Setup and Data Loading",
    "text": "1. Setup and Data Loading\nFirst, we need to load the required R packages and the dataset. The dataset is publicly available on Kaggle and was originally created by McKinsey & Company[1].\n\n1.1 Load Libraries\n\n\nCode\n# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\")\n# install.packages(packages)\n\n\nWe can use this to check installed packages:\n```{r}\nrenv::activate(\"website\")\n\"yardstick\" %in% rownames(installed.packages())\n```\n\n\nCode\nlapply(packages, library, character.only = TRUE)\n\n\n[[1]]\n[1] \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\" \"datasets\"  \"utils\"    \n[7] \"methods\"   \"base\"     \n\n[[2]]\n [1] \"car\"       \"carData\"   \"dplyr\"     \"stats\"     \"graphics\"  \"grDevices\"\n [7] \"datasets\"  \"utils\"     \"methods\"   \"base\"     \n\n[[3]]\n [1] \"ResourceSelection\" \"car\"               \"carData\"          \n [4] \"dplyr\"             \"stats\"             \"graphics\"         \n [7] \"grDevices\"         \"datasets\"          \"utils\"            \n[10] \"methods\"           \"base\"             \n\n[[4]]\n [1] \"caret\"             \"lattice\"           \"ggplot2\"          \n [4] \"ResourceSelection\" \"car\"               \"carData\"          \n [7] \"dplyr\"             \"stats\"             \"graphics\"         \n[10] \"grDevices\"         \"datasets\"          \"utils\"            \n[13] \"methods\"           \"base\"             \n\n[[5]]\n [1] \"pROC\"              \"caret\"             \"lattice\"          \n [4] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n [7] \"carData\"           \"dplyr\"             \"stats\"            \n[10] \"graphics\"          \"grDevices\"         \"datasets\"         \n[13] \"utils\"             \"methods\"           \"base\"             \n\n[[6]]\n [1] \"logistf\"           \"pROC\"              \"caret\"            \n [4] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n [7] \"car\"               \"carData\"           \"dplyr\"            \n[10] \"stats\"             \"graphics\"          \"grDevices\"        \n[13] \"datasets\"          \"utils\"             \"methods\"          \n[16] \"base\"             \n\n[[7]]\n [1] \"Hmisc\"             \"logistf\"           \"pROC\"             \n [4] \"caret\"             \"lattice\"           \"ggplot2\"          \n [7] \"ResourceSelection\" \"car\"               \"carData\"          \n[10] \"dplyr\"             \"stats\"             \"graphics\"         \n[13] \"grDevices\"         \"datasets\"          \"utils\"            \n[16] \"methods\"           \"base\"             \n\n[[8]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[9]]\n [1] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n [4] \"pROC\"              \"caret\"             \"lattice\"          \n [7] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[10] \"carData\"           \"dplyr\"             \"stats\"            \n[13] \"graphics\"          \"grDevices\"         \"datasets\"         \n[16] \"utils\"             \"methods\"           \"base\"             \n\n[[10]]\n [1] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n [4] \"logistf\"           \"pROC\"              \"caret\"            \n [7] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[10] \"car\"               \"carData\"           \"dplyr\"            \n[13] \"stats\"             \"graphics\"          \"grDevices\"        \n[16] \"datasets\"          \"utils\"             \"methods\"          \n[19] \"base\"             \n\n[[11]]\n [1] \"lubridate\"         \"forcats\"           \"stringr\"          \n [4] \"purrr\"             \"readr\"             \"tidyr\"            \n [7] \"tibble\"            \"tidyverse\"         \"summarytools\"     \n[10] \"rcompanion\"        \"Hmisc\"             \"logistf\"          \n[13] \"pROC\"              \"caret\"             \"lattice\"          \n[16] \"ggplot2\"           \"ResourceSelection\" \"car\"              \n[19] \"carData\"           \"dplyr\"             \"stats\"            \n[22] \"graphics\"          \"grDevices\"         \"datasets\"         \n[25] \"utils\"             \"methods\"           \"base\"             \n\n[[12]]\n [1] \"knitr\"             \"lubridate\"         \"forcats\"          \n [4] \"stringr\"           \"purrr\"             \"readr\"            \n [7] \"tidyr\"             \"tibble\"            \"tidyverse\"        \n[10] \"summarytools\"      \"rcompanion\"        \"Hmisc\"            \n[13] \"logistf\"           \"pROC\"              \"caret\"            \n[16] \"lattice\"           \"ggplot2\"           \"ResourceSelection\"\n[19] \"car\"               \"carData\"           \"dplyr\"            \n[22] \"stats\"             \"graphics\"          \"grDevices\"        \n[25] \"datasets\"          \"utils\"             \"methods\"          \n[28] \"base\"             \n\n\nCode\n# Set seed for reproducibility\nset.seed(123)\n\n\nMight need to deal with the conflicts later:\n\n\n1.2 Load Data\nWe will load the dataset and handle the data given the exploration done in Week5. The id column is unnecessary for prediction as well there are only 2 genders significant for prediction.\nBelow will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile in (the same one you got for us Renan)#\nsteve_dataset_path &lt;- file.path(datasets_path, \"steve/stroke.csv\")\nstroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)\n\n\nCoding the Predictors and Omitting irrelevant values\nBecause we are using Logistic Regression a Quantitative tool, all predictors and the outcome variable must also be coded to quantitative equivalents. We also had to deal with N/A… so there were predictor variables in the dataset that had “N/A”, Unknown, Children and Other. It would be easier to recode all the irrelevant values as “N/A” and get rid of them all at the same time. We also recoded gender to 1 as male and 2 as female. We also limited the bmi predictor to 2 places after the decimal.Finally we recoded all text categorical variables into numeric variables.\n\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\nWarning: NAs introduced by coercion\n\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 2\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\n\nShowing Descriptive Statistics for all variables, Mean, Std Deviation, and Interquartile Range\n\ndfSummary(strokeclean)\n\nData Frame Summary  \nstrokeclean  \nDimensions: 3357 x 11  \nDuplicates: 0  \n\n----------------------------------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values             Freqs (% of Valid)     Graph                  Valid      Missing  \n---- ------------------- -------------------------- ---------------------- ---------------------- ---------- ---------\n1    gender              Min  : 1                   1 : 1305 (38.9%)       IIIIIII                3357       0        \n     [numeric]           Mean : 1.6                 2 : 2052 (61.1%)       IIIIIIIIIIII           (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n2    age                 Mean (sd) : 49.4 (18.3)    70 distinct values             . : .          3357       0        \n     [numeric]           min &lt; med &lt; max:                                    . . : : : : .   :    (100.0%)   (0.0%)   \n                         13 &lt; 50 &lt; 82                                        : : : : : : : : :                        \n                         IQR (CV) : 28 (0.4)                               : : : : : : : : : :                        \n                                                                           : : : : : : : : : :                        \n\n3    hypertension        Min  : 0                   0 : 2949 (87.8%)       IIIIIIIIIIIIIIIII      3357       0        \n     [numeric]           Mean : 0.1                 1 :  408 (12.2%)       II                     (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n4    heart_disease       Min  : 0                   0 : 3151 (93.9%)       IIIIIIIIIIIIIIIIII     3357       0        \n     [numeric]           Mean : 0.1                 1 :  206 ( 6.1%)       I                      (100.0%)   (0.0%)   \n                         Max  : 1                                                                                     \n\n5    ever_married        Min  : 1                   1 : 2599 (77.4%)       IIIIIIIIIIIIIII        3357       0        \n     [numeric]           Mean : 1.2                 2 :  758 (22.6%)       IIII                   (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n6    work_type           Mean (sd) : 2 (0.6)        1 :  514 (15.3%)       III                    3357       0        \n     [numeric]           min &lt; med &lt; max:           2 : 2200 (65.5%)       IIIIIIIIIIIII          (100.0%)   (0.0%)   \n                         1 &lt; 2 &lt; 4                  3 :  629 (18.7%)       III                                        \n                         IQR (CV) : 0 (0.3)         4 :   14 ( 0.4%)                                                  \n\n7    Residence_type      Min  : 1                   1 : 1709 (50.9%)       IIIIIIIIII             3357       0        \n     [numeric]           Mean : 1.5                 2 : 1648 (49.1%)       IIIIIIIII              (100.0%)   (0.0%)   \n                         Max  : 2                                                                                     \n\n8    avg_glucose_level   Mean (sd) : 108.4 (47.9)   2861 distinct values     :                    3357       0        \n     [numeric]           min &lt; med &lt; max:                                  . :                    (100.0%)   (0.0%)   \n                         55.1 &lt; 92.3 &lt; 271.7                               : : :                                      \n                         IQR (CV) : 39 (0.4)                               : : :                                      \n                                                                           : : : : . . . . .                          \n\n9    bmi                 Mean (sd) : 30.4 (7.2)     364 distinct values      . :                  3357       0        \n     [numeric]           min &lt; med &lt; max:                                    : :                  (100.0%)   (0.0%)   \n                         11.5 &lt; 29.2 &lt; 92                                    : :                                      \n                         IQR (CV) : 8.8 (0.2)                                : : :                                    \n                                                                           . : : : .                                  \n\n10   smoking_status      Mean (sd) : 1.7 (0.8)      1 : 1798 (53.6%)       IIIIIIIIII             3357       0        \n     [numeric]           min &lt; med &lt; max:           2 :  824 (24.5%)       IIII                   (100.0%)   (0.0%)   \n                         1 &lt; 1 &lt; 3                  3 :  735 (21.9%)       IIII                                       \n                         IQR (CV) : 1 (0.5)                                                                           \n\n11   stroke              1. 0                       3177 (94.6%)           IIIIIIIIIIIIIIIIII     3357       0        \n     [factor]            2. 1                        180 ( 5.4%)           I                      (100.0%)   (0.0%)   \n----------------------------------------------------------------------------------------------------------------------\n\n\nLooking at the distribution of all the predictor indicators and the outcome indicator with Histograms\n\n# Histogram of gender\nggplot(strokeclean, aes(x = gender)) +\n  geom_bar(fill = \"blue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of gender\", \n       x = \"gender\", \n       y = \"Frequency\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n# Histogram of Age\nggplot(strokeclean, aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"green\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Age\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of hypertension\nggplot(strokeclean, aes(x = hypertension)) +\n  geom_bar(fill = \"purple\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of hypertension\", \n       x = \"hypertension\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of heart_disease\nggplot(strokeclean, aes(x = heart_disease)) +\n  geom_bar( fill = \"orange\",\n            color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of heart_disease\", \n       x = \"HeartDisease\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of ever_married\nggplot(strokeclean, aes(x = ever_married)) +\n  geom_bar(fill = \"aquamarine\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of ever_married\", \n       x = \"EverMarried\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of work_type\nggplot(strokeclean, aes(x = work_type)) +\n  geom_bar(fill = \"steelblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of work_type\", \n       x = \"WorkType\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of Residence_type\nggplot(strokeclean, aes(x = Residence_type)) +\n  geom_bar(fill = \"magenta\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Residence_type\", \n       x = \"Residence_type\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of avg_gloucose_level\nggplot(strokeclean, aes(x = avg_glucose_level)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"chartreuse\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of avg_gloucose_level\",\n       x = \"avg-glucose_level\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of bmi\nggplot(strokeclean, aes(x = bmi)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"gold\", \n                 color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of bmi\", \n       x = \"bmi\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# smoking_status\nggplot(strokeclean, aes(x = smoking_status)) +\n  geom_bar(fill = \"deepskyblue\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"smoking_status\", \n       x = \"smoking_status\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n# Histogram of Age\nggplot(strokeclean, aes(x = stroke)) +\n  geom_bar(fill = \"tan\", \n           color = \"white\") +\n  stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 5) +\n  labs(title = \"Histogram of Age\", \n       x = \"stroke\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\n\nReview of Logistic Regression\nLogistic regression is a statistical modeling technique that predicts the probability of a binary outcome (such as 0 or 1) using one or more independent variables.\n\nMathematics Behind Logistic Regression\nThe key idea is to model the log odds (also called the logit) of the probability of the event as a linear function of the predictors:\n\nThe key idea is to model the log odds (also called the logit) of the probability of the event as a linear function of the predictors:\nlog⁡(p1−p)=β0+β1x1+β2x2+…+βkxklog(1−pp)=β0+β1x1+β2x2+…+βkxk\nwhere pp is the probability of the outcome (e.g., stroke), the xixi are predictors, and the βiβi are their coefficients.​\nSolving for pp, the equation becomes:\np=11+e−(β0+β1x1+…+βkxk)p=1+e−(β0+β1x1+…+βkxk)1\nThis is the logistic function, which always outputs values between 0 and 1, making it ideal for probabilities.​\n\n\n\nCore Concepts\n(1) Odds are defined as p/(1−p)p/(1-p)p/(1−p), the ratio of the probability of the event to the probability of its complement.\n(2) The logit transformation (natural log of the odds) turns this nonlinear problem into a linear one, so standard linear modeling techniques can be used for estimation.\n(3) Coefficients (β) are commonly estimated using maximum likelihood methods, not ordinary least squares.\n\nformula &lt;- stroke ~ gender + age + hypertension + heart_disease + ever_married +\n  work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n\nA comparison between Logistic Regression and Multiple Regression is shown below\n\n\n\n\n\n\n\n\nFeature\nMultiple Regression\nLogistic Regression\n\n\n\n\nOutcome variable type\nContinuous (real numbers)\nCategorical/Binary (e.g., 0 or 1)\n\n\nExample prediction\nPredicting house prices\nPredicting disease presence/absence\n\n\nModel equation\nLinear combination of predictors\nLog odds/logit (S-shaped curve: logistic function)\n\n\nEstimation method\nLeast squares\nMaximum likelihood\n\n\nOutput type\nActual values (e.g., $125,000)\nProbability of being in a category (e.g., 87%)\n\n\nUsage\nContinuous outcome (income, cost, score)\nCategorical outcome (yes/no, 0/1)\n\n\n\nAs you can see the prediction of having a stroke or not with the outcome variable clearly shows we should use Logistic Regression. Note. The predictor variables can be either categorical or continuous. Its the outcome variable that is critical in choosing.\nBut before we can run the all the models of Logistic Regression, there are 4 assumptions of Logistic Regression that we need to determine if the dataset and models can run without violating any or all of the assumptions of Logistic Regression. Note testing the assumptions are done for numerical predictors only statistically speaking. Categorical predictors are tested visually with the histograms above.\n\n# Assumption 1: The Outcome Variable is 0 or 1\nunique(fourassume$stroke)\n\n[1] 1 0\nLevels: 0 1\n\n# Assumption 2: There is linear relationship between the outcome variable and each predictor that is numeric. Categorical predictors are reviewed in the histograms avove\nfourassume$ageadj &lt;- fourassume$age + abs(min(fourassume$age)) + 1\nfourassume$avg_glucose_leveladj &lt;- fourassume$avg_glucose_level + abs(min(fourassume$avg_glucose_level)) + 1\nfourassume$bmiadj &lt;- fourassume$bmi + abs(min(fourassume$bmi)) + 1\nstr(fourassume)\n\ntibble [3,357 × 14] (S3: tbl_df/tbl/data.frame)\n $ gender              : num [1:3357] 1 1 2 2 1 1 2 2 2 2 ...\n $ age                 : num [1:3357] 67 80 49 79 81 74 69 81 61 54 ...\n $ hypertension        : num [1:3357] 0 0 0 1 0 1 0 1 0 0 ...\n $ heart_disease       : num [1:3357] 1 1 0 0 0 1 0 0 1 0 ...\n $ ever_married        : num [1:3357] 1 1 1 1 1 1 2 1 1 1 ...\n $ work_type           : num [1:3357] 2 2 2 3 2 2 2 2 1 2 ...\n $ Residence_type      : num [1:3357] 1 2 1 2 1 2 1 2 2 1 ...\n $ avg_glucose_level   : num [1:3357] 229 106 171 174 186 ...\n $ bmi                 : num [1:3357] 36.6 32.5 34.4 24 29 27.4 22.8 29.7 36.8 27.3 ...\n $ smoking_status      : num [1:3357] 2 1 3 1 2 1 1 1 3 3 ...\n $ stroke              : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n $ ageadj              : num [1:3357] 81 94 63 93 95 88 83 95 75 68 ...\n $ avg_glucose_leveladj: num [1:3357] 285 162 227 230 242 ...\n $ bmiadj              : num [1:3357] 49.1 45 46.9 36.5 41.5 39.9 35.3 42.2 49.3 39.8 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:1753] 2 9 10 14 20 24 28 30 32 39 ...\n  ..- attr(*, \"names\")= chr [1:1753] \"2\" \"9\" \"10\" \"14\" ...\n\nnumeric_vars &lt;- sapply(fourassume, is.numeric)\nfourassume_numeric &lt;- fourassume[, numeric_vars]\nrcorr(as.matrix(fourassume_numeric))\n\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nageadj                -0.06  1.00         0.26          0.26        -0.49\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nageadj                    0.14          -0.02              0.24  0.04\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender                        -0.08  -0.06                -0.07  -0.02\nage                            0.03   1.00                 0.24   0.04\nhypertension                  -0.01   0.26                 0.17   0.13\nheart_disease                  0.06   0.26                 0.14   0.00\never_married                  -0.06  -0.49                -0.12  -0.13\nwork_type                     -0.02   0.14                 0.03  -0.02\nResidence_type                -0.04  -0.02                 0.01   0.01\navg_glucose_level              0.01   0.24                 1.00   0.16\nbmi                            0.03   0.04                 0.16   1.00\nsmoking_status                 1.00   0.03                 0.01   0.03\nageadj                         0.03   1.00                 0.24   0.04\navg_glucose_leveladj           0.01   0.24                 1.00   0.16\nbmiadj                         0.03   0.04                 0.16   1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nageadj               0.0000    0.3076         0.0000            0.0144\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender               0.0000         0.0012 0.0000               0.2487\nage                  0.0448         0.0000 0.0000               0.0144\nhypertension         0.7537         0.0000 0.0000               0.0000\nheart_disease        0.0005         0.0000 0.0000               0.8185\never_married         0.0009         0.0000 0.0000               0.0000\nwork_type            0.3764         0.0000 0.0467               0.3243\nResidence_type       0.0208         0.3076 0.6427               0.5689\navg_glucose_level    0.7679         0.0000 0.0000               0.0000\nbmi                  0.0925         0.0144 0.0000               0.0000\nsmoking_status                      0.0448 0.7679               0.0925\nageadj               0.0448                0.0000               0.0144\navg_glucose_leveladj 0.7679         0.0000                      0.0000\nbmiadj               0.0925         0.0144 0.0000                     \n\nfourAdj &lt;- fourassume\nfourAdj &lt;- fourAdj[ , !(names(fourAdj) %in% c(\"age\", \"heart_disease\", \"avg_glucose_level\", \"bmi\")) ]\nmodel4 &lt;- glm(stroke ~ ageadj + avg_glucose_leveladj + bmiadj, data=fourAdj, family=binomial)\nresidualPlots(model4)\n\n\n\n\n\n\n\n\n                     Test stat Pr(&gt;|Test stat|)\nageadj                  1.9958           0.1577\navg_glucose_leveladj    0.0070           0.9331\nbmiadj                  0.3549           0.5514\n\n# Assumption 3: Assess Influentional Outliers that are numeric. Categorical predictors are reviewed n the hhistrams above\nalias(model4)\n\nModel :\nstroke ~ ageadj + avg_glucose_leveladj + bmiadj\n\nrcorr(as.matrix(fourassume_numeric))\n\n                     gender   age hypertension heart_disease ever_married\ngender                 1.00 -0.06        -0.04         -0.10         0.03\nage                   -0.06  1.00         0.26          0.26        -0.49\nhypertension          -0.04  0.26         1.00          0.11        -0.11\nheart_disease         -0.10  0.26         0.11          1.00        -0.07\never_married           0.03 -0.49        -0.11         -0.07         1.00\nwork_type              0.01  0.14         0.05          0.03        -0.02\nResidence_type        -0.01 -0.02         0.00         -0.01         0.01\navg_glucose_level     -0.07  0.24         0.17          0.14        -0.12\nbmi                   -0.02  0.04         0.13          0.00        -0.13\nsmoking_status        -0.08  0.03        -0.01          0.06        -0.06\nageadj                -0.06  1.00         0.26          0.26        -0.49\navg_glucose_leveladj  -0.07  0.24         0.17          0.14        -0.12\nbmiadj                -0.02  0.04         0.13          0.00        -0.13\n                     work_type Residence_type avg_glucose_level   bmi\ngender                    0.01          -0.01             -0.07 -0.02\nage                       0.14          -0.02              0.24  0.04\nhypertension              0.05           0.00              0.17  0.13\nheart_disease             0.03          -0.01              0.14  0.00\never_married             -0.02           0.01             -0.12 -0.13\nwork_type                 1.00          -0.01              0.03 -0.02\nResidence_type           -0.01           1.00              0.01  0.01\navg_glucose_level         0.03           0.01              1.00  0.16\nbmi                      -0.02           0.01              0.16  1.00\nsmoking_status           -0.02          -0.04              0.01  0.03\nageadj                    0.14          -0.02              0.24  0.04\navg_glucose_leveladj      0.03           0.01              1.00  0.16\nbmiadj                   -0.02           0.01              0.16  1.00\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender                        -0.08  -0.06                -0.07  -0.02\nage                            0.03   1.00                 0.24   0.04\nhypertension                  -0.01   0.26                 0.17   0.13\nheart_disease                  0.06   0.26                 0.14   0.00\never_married                  -0.06  -0.49                -0.12  -0.13\nwork_type                     -0.02   0.14                 0.03  -0.02\nResidence_type                -0.04  -0.02                 0.01   0.01\navg_glucose_level              0.01   0.24                 1.00   0.16\nbmi                            0.03   0.04                 0.16   1.00\nsmoking_status                 1.00   0.03                 0.01   0.03\nageadj                         0.03   1.00                 0.24   0.04\navg_glucose_leveladj           0.01   0.24                 1.00   0.16\nbmiadj                         0.03   0.04                 0.16   1.00\n\nn= 3357 \n\n\nP\n                     gender age    hypertension heart_disease ever_married\ngender                      0.0012 0.0204       0.0000        0.1140      \nage                  0.0012        0.0000       0.0000        0.0000      \nhypertension         0.0204 0.0000              0.0000        0.0000      \nheart_disease        0.0000 0.0000 0.0000                     0.0000      \never_married         0.1140 0.0000 0.0000       0.0000                    \nwork_type            0.3863 0.0000 0.0051       0.0862        0.2313      \nResidence_type       0.5077 0.3076 0.8569       0.5527        0.5150      \navg_glucose_level    0.0000 0.0000 0.0000       0.0000        0.0000      \nbmi                  0.2487 0.0144 0.0000       0.8185        0.0000      \nsmoking_status       0.0000 0.0448 0.7537       0.0005        0.0009      \nageadj               0.0012 0.0000 0.0000       0.0000        0.0000      \navg_glucose_leveladj 0.0000 0.0000 0.0000       0.0000        0.0000      \nbmiadj               0.2487 0.0144 0.0000       0.8185        0.0000      \n                     work_type Residence_type avg_glucose_level bmi   \ngender               0.3863    0.5077         0.0000            0.2487\nage                  0.0000    0.3076         0.0000            0.0144\nhypertension         0.0051    0.8569         0.0000            0.0000\nheart_disease        0.0862    0.5527         0.0000            0.8185\never_married         0.2313    0.5150         0.0000            0.0000\nwork_type                      0.6768         0.0467            0.3243\nResidence_type       0.6768                   0.6427            0.5689\navg_glucose_level    0.0467    0.6427                           0.0000\nbmi                  0.3243    0.5689         0.0000                  \nsmoking_status       0.3764    0.0208         0.7679            0.0925\nageadj               0.0000    0.3076         0.0000            0.0144\navg_glucose_leveladj 0.0467    0.6427         0.0000            0.0000\nbmiadj               0.3243    0.5689         0.0000            0.0000\n                     smoking_status ageadj avg_glucose_leveladj bmiadj\ngender               0.0000         0.0012 0.0000               0.2487\nage                  0.0448         0.0000 0.0000               0.0144\nhypertension         0.7537         0.0000 0.0000               0.0000\nheart_disease        0.0005         0.0000 0.0000               0.8185\never_married         0.0009         0.0000 0.0000               0.0000\nwork_type            0.3764         0.0000 0.0467               0.3243\nResidence_type       0.0208         0.3076 0.6427               0.5689\navg_glucose_level    0.7679         0.0000 0.0000               0.0000\nbmi                  0.0925         0.0144 0.0000               0.0000\nsmoking_status                      0.0448 0.7679               0.0925\nageadj               0.0448                0.0000               0.0144\navg_glucose_leveladj 0.7679         0.0000                      0.0000\nbmiadj               0.0925         0.0144 0.0000                     \n\ninfluencePlot(model4)\n\n\n\n\n\n\n\n\n        StudRes          Hat       CookD\n17    2.3495313 0.0040917969 0.014793349\n83    2.5500288 0.0045425981 0.026906139\n87    3.0778217 0.0004677603 0.012890963\n131   3.2110607 0.0003364260 0.014101935\n186  -0.7488292 0.0184781611 0.001532740\n2583 -0.7113787 0.0167417735 0.001232964\n\n# Assumption 4: Assess Multicollinearity for numeric predictors\nvif(model4)\n\n              ageadj avg_glucose_leveladj               bmiadj \n            1.070909             1.081460             1.101382 \n\n# Fit of the Model with Nagelkerke R\nhoslem.test(model4$y, fitted(model4), g = 10)\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  model4$y, fitted(model4)\nX-squared = 8.8522, df = 8, p-value = 0.3549\n\nnagelkerke(model4)\n\n$Models\n                                                                                \nModel: \"glm, stroke ~ ageadj + avg_glucose_leveladj + bmiadj, binomial, fourAdj\"\nNull:  \"glm, stroke ~ 1, binomial, fourAdj\"                                     \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                            0.1713030\nCox and Snell (ML)                  0.0691131\nNagelkerke (Cragg and Uhler)        0.2022700\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq   p.value\n      -3     -120.21 240.42 7.721e-52\n\n$Number.of.observations\n           \nModel: 3357\nNull:  3357\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n# Predictive Capability\nmodel4_CM &lt;- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=fourassume, family = binomial)\n\nThe three different models of Logistic Regression: Baseline, Firth and Flic Corrections. We are creating 3 different models to really test to see if the dataset had a stroke percentage that is less than the real percentage of stroke to population ratio in the US. Because this is a so called “rare event” Firth regression takes this into account as does its refinement FLIC.\n\n# Baseline Logistic Regression\nmodel_base &lt;- glm(formula, data=strokeclean, family=binomial)\nprob_base &lt;- predict(model_base, type=\"response\")\n\n# Firth Logistic Regression\nmodel_firth &lt;- logistf(formula, data=strokeclean)\nprob_firth &lt;- predict(model_firth, type=\"response\")\n\n# FLIC Correction (this correction changes the intercept)\nmodel_flic &lt;- flic(formula, data=strokeclean)\nprob_flic &lt;- predict(model_flic, type=\"response\")\n\nlabels &lt;- strokeclean$stroke\n\nCreating Youdens J. Youden’s J is a good way to look at how well each model balances sensitivity and selectivity. The closer to the curve, a Youden’s J is the better the model can distinguish between sensitiviy and selectivity.\n\nyouden_point &lt;- function(roc_obj) {\n  coords &lt;- coords(roc_obj, \"best\", best.method = \"youden\", ret=c(\"threshold\", \"sensitivity\", \"specificity\", \"youden\"))\n  return(coords)\n}\n\nThe Three Types of Prediction with 0.5 for consistency\n\n# Predictions with default threshold 0.5 (for output consistency)\npred_base &lt;- factor(ifelse(prob_base &gt; 0.5, 1, 0), levels=c(0,1))\npred_firth &lt;- factor(ifelse(prob_firth &gt; 0.5, 1, 0), levels=c(0,1))\npred_flic &lt;- factor(ifelse(prob_flic &gt; 0.5, 1, 0), levels=c(0,1))\n\nThe Function to Compute Metrics\n\npred_base &lt;- factor(ifelse(prob_base &gt; 0.5, 1, 0), levels=c(0,1))\npred_firth &lt;- factor(ifelse(prob_firth &gt; 0.5, 1, 0), levels=c(0,1))\npred_flic &lt;- factor(ifelse(prob_flic &gt; 0.5, 1, 0), levels=c(0,1))\n\nmetrics &lt;- function(pred, prob, labels, name) {\n  cm &lt;- confusionMatrix(pred, labels, positive = \"1\")\n  roc_obj &lt;- roc(labels, as.numeric(prob))\n  auc_val &lt;- auc(roc_obj)\n  precision &lt;- cm$byClass[\"Pos Pred Value\"]\n  recall &lt;- cm$byClass[\"Sensitivity\"]\n  f1 &lt;- 2 * ((precision * recall) / (precision + recall))\n  youden &lt;- youden_point(roc_obj)\n  # All list arguments separated by commas only, no '+'\n  list(\n    confusion = cm$table,\n    precision = precision,\n    recall = recall,\n    f1 = f1,\n    auc = auc_val,\n    roc_obj = roc_obj,\n    youden = youden,\n    model = name\n  )\n}\n\nIntialize Results. We have to initialize results before calling the model\n\nresults_base &lt;- metrics(pred_base, prob_base, labels, \"Baseline LR\")\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nresults_firth &lt;- metrics(pred_firth, prob_firth, labels, \"firth LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\nresults_flic &lt;- metrics(pred_flic, prob_flic, labels, \"flic LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\n\nPrint Results\n\ncat(\"\\n== Baseline Logistic Regression ==\\n\")\n\n\n== Baseline Logistic Regression ==\n\nprint(results_base[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_base$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06934436   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== Firth Logistic Regression ==\\n\")\n\n\n== Firth Logistic Regression ==\n\nprint(results_firth[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3176  178\n         1    1    2\n\n$precision\nPos Pred Value \n     0.6666667 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02185792 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_firth$youden)\n\n   threshold sensitivity specificity   youden\n1 0.07100345   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== FLIC Logistic Regression ==\\n\")\n\n\n== FLIC Logistic Regression ==\n\nprint(results_flic[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_flic$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06935441   0.7444444   0.7777778 1.522222\n\n\nPlot the ROC curves and Annotate Youden’s J on each of the Curves\n\nplot(results_base$roc_obj, col=\"cyan\", main=\"ROC Curves: Baseline (blue) vs Firth (red)\")\nplot(results_firth$roc_obj, col=\"magenta\", add=TRUE)\nplot(results_flic$roc_obj, col =\"gold\", add=TRUE)\nauc(results_base$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_firth$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_flic$roc_obj)\n\nArea under the curve: 0.8285\n\npoints(\n  1-results_base$youden[\"specificity\"],\n  results_base$youden[\"sensitivity\"],\n  col=\"cyan\", pch=19, cex=1.5\n)\npoints(\n  1-results_firth$youden[\"specificity\"],\n  results_firth$youden[\"sensitivity\"],\n  col=\"magenta\", pch=19, cex=1.5\n)\npoints(\n  1-results_flic$youden[\"specificity\"],\n  results_flic$youden[\"sensitivity\"],\n  col=\"gold\", pch=19, cex=1.5\n)\n\nlegend(\"bottomright\", legend=c(\"Baseline\", \"Firth\",\"flic\"), col=c(\"cyan\", \"magenta\", \"gold\"), lwd=2)\n\ntext(\n  x=1-results_base$youden[\"specificity\"], y=results_base$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_base$youden[\"youden\"], 3)),\n  pos=4, col=\"cyan\"\n)\ntext(\n  x=1-results_firth$youden[\"specificity\"], y=results_firth$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_firth$youden[\"youden\"], 3)),\n  pos=4, col=\"magenta\"\n)\ntext(\n  x=1-results_flic$youden[\"specificity\"], y=results_flic$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_flic$youden[\"youden\"], 3)),\n  pos=4, col=\"gold\"\n)\n\n\n\n\n\n\n\n\nHere we see the results. Note that overlaying the curves and Youden’s J is EXACTLY the same for all three models. This is a strong indication that the dataset is currently balanced enough to distinguish between stroke and non stroke. The bias if any would have shown up in a different AUC curve, and a different Youden’s J. It does not.\nPlot the Confusion Matrices\n\npar(mfrow = c(3, 1), mar = c(6, 5, 6, 2))  # more top margin for all\nfourfoldplot(results_base$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Baseline Confusion Matrix\")\nfourfoldplot(results_firth$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Firth Confusion Matrix\")\nfourfoldplot(results_flic$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Flic Confusion Matrix\")\n\n\n\n\n\n\n\npar(mfrow = c(1,1), mar = c(5, 4, 4, 2)) # Reset to default after\n\nThe results indicate exactly that the confusion matrices are exactly the same. So the conclusion we can reach is the there was no significant bias in the dataset. The dataset can distinguish between stroke and non stroke events with sufficient selectivity.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# stroke1 &lt;- read.csv(\"stroke.csv\")\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 2\nstroke1$gender &lt;- as.numeric(stroke1$gender)\n\n\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\n\nThe model For Logistic Regression predicting Stroke\n\nformula &lt;- stroke ~ gender + age + hypertension + heart_disease + ever_married +\n  work_type + Residence_type + avg_glucose_level + bmi + smoking_status\n\nHistograms for all the predictors and the Outcome variable\n\nggplot(strokeclean, aes(x = gender)) +\n  geom_bar(fill = \"blue\", \n           color = \"white\") +\n  labs(title = \"Histogram of gender\", \n       x = \"gender\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"green\", \n                 color = \"white\") +\n  labs(title = \"Histogram of Age\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = hypertension)) +\n  geom_bar(fill = \"purple\", \n           color = \"white\") +\n  labs(title = \"Histogram of hypertension\", \n       x = \"hypertension\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = heart_disease)) +\n  geom_bar( fill = \"orange\",\n            color = \"white\") +\n  labs(title = \"Histogram of heart_diseasd\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = ever_married)) +\n  geom_bar(fill = \"aquamarine\", \n           color = \"white\") +\n  labs(title = \"Histogram of ever_married\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = work_type)) +\n  geom_bar(fill = \"steelblue\", \n           color = \"white\") +\n  labs(title = \"Histogram of work_type\", \n       x = \"Age\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = Residence_type)) +\n  geom_bar(fill = \"magenta\", \n           color = \"white\") +\n  labs(title = \"Histogram of Residence_type\", \n       x = \"Residence_type\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = avg_glucose_level)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"chartreuse\", \n                 color = \"white\") +\n  labs(title = \"Histogram of avg_gloucose_level\",\n       x = \"avg-glucose_level\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = bmi)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"gold\", \n                 color = \"white\") +\n  labs(title = \"Histogram of bmi\", \n       x = \"bmi\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = smoking_status)) +\n  geom_bar(fill = \"deepskyblue\", \n           color = \"white\") +\n  labs(title = \"smoking_status\", \n       x = \"smoking_status\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nggplot(strokeclean, aes(x = stroke)) +\n  geom_bar(fill = \"tan\", \n           color = \"white\") +\n  labs(title = \"Histogram of Age\", \n       x = \"stroke\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nThe Three different Models of Logistic Regression: Baseline Firth and Flic Correction\n\n# Baseline Logistic Regression\nmodel_base &lt;- glm(formula, data=strokeclean, family=binomial)\nprob_base &lt;- predict(model_base, type=\"response\")\n\n# Firth Logistic Regression\nmodel_firth &lt;- logistf(formula, data=strokeclean)\nprob_firth &lt;- predict(model_firth, type=\"response\")\n\n# FLIC Correction (this correction changes the intercept)\nmodel_flic &lt;- flic(formula, data=strokeclean)\nprob_flic &lt;- predict(model_flic, type=\"response\")\n\nlabels &lt;- strokeclean$stroke\n\nCreating Youdens J\n\nyouden_point &lt;- function(roc_obj) {\n  coords &lt;- coords(roc_obj, \"best\", best.method = \"youden\", ret=c(\"threshold\", \"sensitivity\", \"specificity\", \"youden\"))\n  return(coords)\n}\n\nThe Three Types of Prediction with 0.5 for consistency\n\n# Predictions with default threshold 0.5 (for output consistency)\npred_base &lt;- factor(ifelse(prob_base &gt; 0.5, 1, 0), levels=c(0,1))\npred_firth &lt;- factor(ifelse(prob_firth &gt; 0.5, 1, 0), levels=c(0,1))\npred_flic &lt;- factor(ifelse(prob_flic &gt; 0.5, 1, 0), levels=c(0,1))\n\nThe Function to Compute Metrics\n\n  pred_base &lt;- factor(ifelse(prob_base &gt; 0.5, 1, 0), levels=c(0,1))\n  pred_firth &lt;- factor(ifelse(prob_firth &gt; 0.5, 1, 0), levels=c(0,1))\n  pred_flic &lt;- factor(ifelse(prob_flic &gt; 0.5, 1, 0), levels=c(0,1))\n\n  metrics &lt;- function(pred, prob, labels, name) {\n    cm &lt;- confusionMatrix(pred, labels, positive = \"1\")\n    roc_obj &lt;- roc(labels, as.numeric(prob))\n    auc_val &lt;- auc(roc_obj)\n    precision &lt;- cm$byClass[\"Pos Pred Value\"]\n    recall &lt;- cm$byClass[\"Sensitivity\"]\n    f1 &lt;- 2 * ((precision * recall) / (precision + recall))\n    youden &lt;- youden_point(roc_obj)\n    # All list arguments separated by commas only, no '+'\n    list(\n      confusion = cm$table,\n      precision = precision,\n      recall = recall,\n      f1 = f1,\n      auc = auc_val,\n      roc_obj = roc_obj,\n      youden = youden,\n      model = name\n    )\n  }\n\nIntialize Results\n\nresults_base &lt;- metrics(pred_base, prob_base, labels, \"Baseline LR\")\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nresults_firth &lt;- metrics(pred_firth, prob_firth, labels, \"firth LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\nresults_flic &lt;- metrics(pred_flic, prob_flic, labels, \"flic LR\")\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\n\nPrint Results\n\ncat(\"\\n== Baseline Logistic Regression ==\\n\")\n\n\n== Baseline Logistic Regression ==\n\nprint(results_base[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_base$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06934436   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== Firth Logistic Regression ==\\n\")\n\n\n== Firth Logistic Regression ==\n\nprint(results_firth[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3176  178\n         1    1    2\n\n$precision\nPos Pred Value \n     0.6666667 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02185792 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_firth$youden)\n\n   threshold sensitivity specificity   youden\n1 0.07100345   0.7444444   0.7777778 1.522222\n\ncat(\"\\n== FLIC Logistic Regression ==\\n\")\n\n\n== FLIC Logistic Regression ==\n\nprint(results_flic[1:6])\n\n$confusion\n          Reference\nPrediction    0    1\n         0 3177  178\n         1    0    2\n\n$precision\nPos Pred Value \n             1 \n\n$recall\nSensitivity \n 0.01111111 \n\n$f1\nPos Pred Value \n    0.02197802 \n\n$auc\nArea under the curve: 0.8285\n\n$roc_obj\n\nCall:\nroc.default(response = labels, predictor = as.numeric(prob))\n\nData: as.numeric(prob) in 3177 controls (labels 0) &lt; 180 cases (labels 1).\nArea under the curve: 0.8285\n\ncat(\"\\nYouden's J (optimal threshold):\\n\")\n\n\nYouden's J (optimal threshold):\n\nprint(results_flic$youden)\n\n   threshold sensitivity specificity   youden\n1 0.06935441   0.7444444   0.7777778 1.522222\n\n\nPlot the ROC curves and Annotate Youden’s J on each of the Curves\n\nplot(results_base$roc_obj, col=\"cyan\", main=\"ROC Curves: Baseline (blue) vs Firth (red)\")\nplot(results_firth$roc_obj, col=\"magenta\", add=TRUE)\nplot(results_flic$roc_obj, col =\"gold\", add=TRUE)\nauc(results_base$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_firth$roc_obj)\n\nArea under the curve: 0.8285\n\nauc(results_flic$roc_obj)\n\nArea under the curve: 0.8285\n\npoints(\n  1-results_base$youden[\"specificity\"],\n  results_base$youden[\"sensitivity\"],\n  col=\"cyan\", pch=19, cex=1.5\n)\npoints(\n  1-results_firth$youden[\"specificity\"],\n  results_firth$youden[\"sensitivity\"],\n  col=\"magenta\", pch=19, cex=1.5\n)\npoints(\n  1-results_flic$youden[\"specificity\"],\n  results_flic$youden[\"sensitivity\"],\n  col=\"gold\", pch=19, cex=1.5\n)\n\nlegend(\"bottomright\", legend=c(\"Baseline\", \"Firth\",\"flic\"), col=c(\"cyan\", \"magenta\", \"gold\"), lwd=2)\n\ntext(\n  x=1-results_base$youden[\"specificity\"], y=results_base$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_base$youden[\"youden\"], 3)),\n  pos=4, col=\"cyan\"\n)\ntext(\n  x=1-results_firth$youden[\"specificity\"], y=results_firth$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_firth$youden[\"youden\"], 3)),\n  pos=4, col=\"magenta\"\n)\ntext(\n  x=1-results_flic$youden[\"specificity\"], y=results_flic$youden[\"sensitivity\"],\n  labels=paste0(\"Youden: \", round(results_flic$youden[\"youden\"], 3)),\n  pos=4, col=\"gold\"\n)\n\n\n\n\n\n\n\n\nPlot the Confusion Matrices\n\npar(mfrow=c(1,2))\nfourfoldplot(results_base$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Baseline Confusion Matrix\")\nfourfoldplot(results_firth$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Firth Confusion Matrix\")\n\n\n\n\n\n\n\nfourfoldplot(results_flic$confusion, color = c(\"lightskyblue\", \"plum2\"),\n             conf.level = 0, margin = 1, main = \"Flic Confusion Matrix\")\n\npar(mfrow=c(1,1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\n1. fedesoriano. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "posts/renan-blog-post-week11/Readme.html",
    "href": "posts/renan-blog-post-week11/Readme.html",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data.\n\n\n\nMissing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature.\nFrom the section 3.1 Visualizing Key Features"
  },
  {
    "objectID": "posts/renan-blog-post-week11/Readme.html#features-correlation-matrix",
    "href": "posts/renan-blog-post-week11/Readme.html#features-correlation-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Features Correlation Matrix, it is on the Page 6 of the paper.\nFigure 4.  Features correlation heatmap for the dataset. Color intensity indicates the strength and direction of correlations, aiding in the identification of potential patterns and dependencies in the data."
  },
  {
    "objectID": "posts/renan-blog-post-week11/Readme.html#sparsity-matrix",
    "href": "posts/renan-blog-post-week11/Readme.html#sparsity-matrix",
    "title": "Notes on project Week 6",
    "section": "",
    "text": "Missing the Sparsity Matrix, it is on the Page 6 of the paper.\nFigure 5.  Sparsity matrix for the dataset. The empty spaces found in the corresponding column signify the presence of missing data values for the specific feature.\nFrom the section 3.1 Visualizing Key Features"
  },
  {
    "objectID": "posts/shree-blog-post-week2/index.html",
    "href": "posts/shree-blog-post-week2/index.html",
    "title": "Literature Review Week 2",
    "section": "",
    "text": "link: https://robertominguez.altervista.org/DocumentacionAcreditativa/Articulos/GuancheMM13.pdf\nAutoregressive Logistic Regression Applied to Atmospheric Circulation Patterns” (Guanche, Mínguez & Méndez, 2013).[1]\nArticel incorporates autoregressive time dependencies into logistic regression for climate modeling. work with complex climatological dynamics instead of common data set like health or business. Explains both interpretation and simulation capabilities for weather patterns.\nData used : They took data of measured sea-level pressure (SLP) fields to determine daily atmospheric circulation patterns over the Northeastern Atlantic. A limited number of circulation types (weather regimes) are created by summarizing the SLP fields, for example, through clustering or categorization. Data setup for the autoregressive logistic regression applied to weather types” shows how they organized lagged types, covariates,\nSteps on summary: - Sort daily SLP data into distinct circulation categories. - create autoregressive terms, covariates, and lagged indicators (trend, seasonal) - Comparing anticipated and empirical probability allows for diagnostic checks. - Utilize the fitted model to replicate artificial circulatory state sequences. - Check for simulation statistics (frequencies, transitions, persistence) against historical data."
  },
  {
    "objectID": "posts/shree-blog-post-week2/index.html#article-1",
    "href": "posts/shree-blog-post-week2/index.html#article-1",
    "title": "Literature Review Week 2",
    "section": "",
    "text": "link: https://robertominguez.altervista.org/DocumentacionAcreditativa/Articulos/GuancheMM13.pdf\nAutoregressive Logistic Regression Applied to Atmospheric Circulation Patterns” (Guanche, Mínguez & Méndez, 2013).[1]\nArticel incorporates autoregressive time dependencies into logistic regression for climate modeling. work with complex climatological dynamics instead of common data set like health or business. Explains both interpretation and simulation capabilities for weather patterns.\nData used : They took data of measured sea-level pressure (SLP) fields to determine daily atmospheric circulation patterns over the Northeastern Atlantic. A limited number of circulation types (weather regimes) are created by summarizing the SLP fields, for example, through clustering or categorization. Data setup for the autoregressive logistic regression applied to weather types” shows how they organized lagged types, covariates,\nSteps on summary: - Sort daily SLP data into distinct circulation categories. - create autoregressive terms, covariates, and lagged indicators (trend, seasonal) - Comparing anticipated and empirical probability allows for diagnostic checks. - Utilize the fitted model to replicate artificial circulatory state sequences. - Check for simulation statistics (frequencies, transitions, persistence) against historical data."
  },
  {
    "objectID": "posts/shree-blog-post-week2/index.html#article-2",
    "href": "posts/shree-blog-post-week2/index.html#article-2",
    "title": "Literature Review Week 2",
    "section": "Article 2",
    "text": "Article 2\nA Descriptive Study of Variable Discretization and Cost-Sensitive Logistic Regression on Imbalanced Credit Data.[2]\nLink: https://arxiv.org/pdf/1812.10857\nPurpose : The author looks out for a problem related to credit scoring where the minority class (defaults and delinquencies) is comparatively uncommon. Their main concept is to contrast cost-sensitive logistic regression (assigning various misclassification fees) with variable discretization (converting continuous predictors into categorical bins) in order to reduce class bias. When used real credit scoring dataset event rate was 6.68% that was highly imbalanced.\nModels used: - trained logestic regression in different versions\n- Standard logistic regression on continuous predictors (baseline). - Logistic regression on discretized predictors (using different binning strategies). - Cost-sensitive logistic regression on the continuous predictors (i.e. weight adjustments for minority class). - Possibly combined approaches (discretized + cost-sensitive). - They use 10-fold cross-validation to ensure robustness. PMC - Performance metrics include: - ROC / AUC - Type I error (false positive rate) - Type II error (false negative rate) - Accuracy - F1 score - They also examine coefficient estimates and interpretability\nSummary:\nIn their study of unbalanced credit scoring (default rate ~6.68%), Zhang et al. used 10-fold CV to examine standard, discretized, and cost-sensitive logistic regression. They discovered that variable discretization works better than cost-sensitive weighting, producing models that are more resilient, stable, and interpretable. These models also generalize well to other domains, such as biology and wine quality.\n\nReferences\n\n\n1. Guanche, Y., Mı́nguez, R., & Méndez, F. J. (2014). Autoregressive logistic regression applied to atmospheric circulation patterns. Climate Dynamics, 42(1), 537–552.\n\n\n2. Zhang, L., Ray, H., Priestley, J., & Tan, S. (2020). A descriptive study of variable discretization and cost-sensitive logistic regression on imbalanced credit data. Journal of Applied Statistics, 47(3), 568–581."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "",
    "text": "Slides: slides.html"
  },
  {
    "objectID": "report.html#introduction",
    "href": "report.html#introduction",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "1. Introduction",
    "text": "1. Introduction\nStroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Because stroke often occurs suddenly and can result in long-term neurological impairment, early identification of individuals at elevated risk is critical for prevention and timely intervention. Data-driven risk prediction models enable clinicians and public health professionals to quantify individual-level risk and to target high-risk groups for lifestyle counselling and clinical management.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease presence or absence[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and encode the variables into the appropriate data types in order to develop and fit a Logistic Regression model for predicting the outcome of stroke.\nThen we proceed to analyse one of the fundamental issues in the application of Logistic Regression or statistical models overal, the data imbalance issue. Data imbalance is a big problem for stroke ­prediction[9]. Because of many reasons ranging from privacy to the difficulty of doing cohort studies, the fact that pre-stroke datasets are rare, dataset often contain imbalanced classifications, with most instances being non-stroke c­ases[10]. So its unnecessary to say that this imbalance can result in biased models that favour the majority and ignore the minority, resulting in low forecast accuracy. To solve this issue and increase the effectiveness of the predictive models, we plan on exploring several oversampling and undersampling methods and much more are explored and employed, the popular of which is the ­SMOTE[11],[12]."
  },
  {
    "objectID": "report.html#methods",
    "href": "report.html#methods",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "2. Methods",
    "text": "2. Methods\nThe binary logistic regression model is part of a family of statistical models called generalised linear models. The main characteristic that differentiates binary logistic regression from other generalised linear models is the type of dependent (or outcome) variable.[13] A dependent variable in a binary logistic regression has two levels. For example, a variable that records whether or not someone has ever been diagnosed with a health condition like Stroke could be measured in two categories, yes and no. Likewise, someone might have coronary heart disease or not, be physically active or not, be a current smoker or not, or have any one of thousands of diagnoses or personal behaviours and characteristics that are of interest in family medicine.\nThe binary logistic regression algorithm below:\n\\[ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}x_{1} + \\cdots + \\beta_{k}x_{k}\\]\nWhere \\(\\pi = P[Y =1]\\) is the probability of the outcome.\n\nAssumptions\nBinary logistic regression relies on the following underlying assumptions to be true:\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers\nThe Sample Size is Sufficiently Large. Field recommends a minimum of 50 cases.[14] Hosmer, Lemeshow, and Sturdivant[15] suggest a minimum sample of 10 observations per independent variable in the model. Leblanc and Fitzgerald (2000)[16] suggest a minimum of 30 observations per independent variable."
  },
  {
    "objectID": "report.html#analysis-and-results",
    "href": "report.html#analysis-and-results",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nImport all the dependencies:\n\n\nCode\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\", \"ggcorrplot\", \"randomForest\", \"gbm\", \"kernlab\", \"skimr\", \"corrplot\", \"scales\", \"tidyr\", \"RColorBrewer\", \"mice\", \"ROSE\", \"ranger\", \"stacks\", \"tidymodels\", \"themis\", \"gghighlight\")\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n3.1. Data Ingestion\nData source: Stroke Prediction Dataset[17]\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nstroke_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(stroke_path, show_col_types = FALSE)\n\n\n\n\n3.2. Exploratory Data Analysis (EDA)\nDataset Description\nThe Stroke Prediction Dataset[17] is a publically available dataset for educational purposes containing 5,110 observations containing predictors commonly associated with cerebrovascular risk. The dataset is composed of 11 clinical and demographic features and 1 feature which is id a unique identifier for the patient. The dataset has features including patient’s age, gender, presence of conditions like hypertension and heart disease, work type, residence type, average glucose level, and BMI. This dataset is primarily intended for educational purposes as it shares a lot of similarities with the Jackson Heart Study (JHS) dataset but it is not as descriptive.\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nKey Values/Range\n\n\n\n\nid\nUnique identifier for the patient\nNumeric\nUnique numeric ID\n\n\ngender\nPatient’s gender\nCharacter\nMale, Female, Other\n\n\nage\nPatient’s age in years\nNumeric\n0.08 to 82\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nCharacter\nNo, Yes\n\n\nwork_type\nType of occupation\nCharacter\nPrivate, Self-employed, Govt_job, children, Never_worked\n\n\nResidence_type\nPatient’s area of residence\nCharacter\nRural, Urban\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\n≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nCharacter\n≈10.3 to 97.6 (has NA values)\n\n\nsmoking_status\nPatient’s smoking status\nCharacter\nformerly smoked, never smoked, smokes, Unknown\n\n\nstroke\nTarget Variable: Whether the patient had a stroke\nNumeric (binary)\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.1 Dataset Preprocessing\n\n\nCode\n# Handle dataset features\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 0\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 0\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n# Remove NAs and clean dataset\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\n\nstrokeclean$stroke &lt;- factor(\n  strokeclean$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\nfourassume$stroke &lt;- factor(\n  fourassume$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\n\nThe initial exploration demonstrated that the Stroke Prediction Dataset[17] has several issues requiring changes for handling missing values, converting character (categorical) features into numerical codes, and removing the identifier column.\n\nSo as part of data preprocessing we will be focused on establishing consistency and ensuring all variables are in a format suitable for predictive modeling. This process starts by systematically addressing non-standard representations of missing data. Specifically, all instances of the string values “N/A”, “Unknown”, “children”, and “other” found across the dataset were unified and replaced with the standard statistical missing value representation, NA.\nThen we proceed with converting several character-based (categorical) features into numerical features, which is necessary for predictive modeling. \nThe feature bmi, initially read as a character variable was first converted to a numeric data type and subsequently rounded to two decimal places.\nThe binary categorical features were encoded into numerical indicators. The feature gender was transformed so that “Male” was encoded to 1 and “Female” was encoded to 0, and the ever_married was transformed so that “Yes” encoded to 1 and “No” encoded to 0.\nFeatures with multiple categories were also numerically encoded into numerical indicators. The work_type feature had its categories encoded so that “Govt_job” = 1, “Private” = 2, “Self-employed” = 3, and “Never_worked” = 4. The Residence_type was encoded so that “Urban” = 1 and “Rural” = 2. Finally, the smoking_status feature was encoded into three numerical levels, those being “never smoked” = 1, “formerly smoked” = 2, and “smokes” = 3.\nAdditionally, the continuous numerical variables avg_glucose_level, heart_disease, and hypertension were explicitly confirmed as numeric data types, with the age feature also being rounded to two decimal places for consistency.\n\nThe final stage of preprocessing involved removing the id column, which served only as a unique identifier and held no predictive value. This action left the dataset with 11 core predictors. The target variable, stroke, was then converted into a factor (a categorical data type in R) named stroke1, and its levels were explicitly labeled as \\(\\text{\"No\"} = 0\\) and \\(\\text{\"Yes\"} = 1\\). The entire process concluded with the removal of all remaining observations containing missing or inconsistent entries, resulting in the creation of the final, clean data frames, strokeclean and fourassume.\nDataset Preprocessing Conclusion\nThe Stroke Prediction Dataset[17] that started containing 5,110 observations and 12 features. After cleaning missing and inconsistent entries among other necessarychanges, ended as a dataset containing 3,357 observations and 11 predictors commonly associated with cerebrovascular risk. Those key predictors are listed below.\n\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nValues\n\n\n\n\ngender\nPatient’s gender\nNumeric\n1 (Male), 0 (Female)\n\n\nage\nPatient’s age in years\nNumeric\nRange 0.08 to 82; rounded to 2 decimal places\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nNumeric\n1 (Yes), 0 (No)\n\n\nwork_type\nType of occupation\nNumeric\n1 (Govt_job), 2 (Private), 3 (Self-employed), 4 (Never_worked)\n\n\nResidence_type\nPatient’s area of residence\nNumeric\n1 (Urban), 2 (Rural)\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\nRange ≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nNumeric\nRange ≈10.3 to 97.6; converted from character, rounded to 2 decimals\n\n\nsmoking_status\nPatient’s smoking status\nNumeric\n1 (never smoked), 2 (formerly smoked), 3 (smokes)\n\n\nstroke\nTarget Variable: Whether the patient had stroke\nNumeric\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n# skim(stroke1)\n# nrow(fourassume)\n# class(strokeclean$stroke)\n# unique(strokeclean$gender)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Dataset Visualization\nBefore developing predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nHistograms\n\n\nCode\n# 1. Get the total number of rows in your data frame\nTOTAL_ROWS &lt;- nrow(strokeclean)\n\n# 2. Use the modified ggplot code\np1a &lt;- ggplot(strokeclean, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # The calculation is (bar_count / TOTAL_ROWS) * 100, rounded to 1 decimal place.\n    position = position_dodge(width = 0.9),\n    aes(\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1), \n    labels = c(\"Female\", \"Male\")\n  ) +\n  labs(title = \"(a) Gender\", x = \"Gender\", y = \"Count\")\n\n# (b) Histogram of Age\np1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n# (b) Bivariate Density Plot of Age\n# p1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) + # Keep fill=stroke\n#   geom_density(alpha = 0.5) + # Overlap the two density curves\n#   labs(title = \"(b) Age\", x = \"Age\", y = \"Density\")\n\n# (c) Histogram of hypertension\np1c &lt;- ggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(c) Hypertension\", x = \"Hypertension\", y = \"Frequency\")\n\n# (d) Histogram of heart_disease\np1d &lt;- ggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(d) Heart Disease\", x = \"Heart Disease\", y = \"Frequency\")\n\n# (e) Histogram of ever_married\np1e &lt;- ggplot(strokeclean, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  # Assuming 'No'/'Yes' are string/factor values, use scale_x_discrete if needed\n  labs(title = \"(e) Ever Married\", x = \"Ever Married\", y = \"Frequency\")\n\n# (f) Histogram of work_type\np1f &lt;- ggplot(strokeclean, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, # Shift text right for horizontal bar\n    size = 3,\n    color = \"black\"\n  ) +\n  # Expand X-axis (Frequency) for horizontal bar\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) +\n  # Adding Work type labels make it too convoluted\n  # scale_y_continuous(\n  #   breaks = c(1, 2, 3, 4), \n  #   labels = c(\"Govt_job\", \"Private\", \"Self-employed\", \"Never_worked\")\n  # ) + \n  labs(title = \"(f) Work Type\", y = \"Work Type\", x = \"Frequency\")\n\n# (g) Histogram of Residence_type\np1g &lt;- ggplot(strokeclean, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # Crucial for aligning text labels with the dodged bars\n    position = position_dodge(width = 0.9), \n    aes(\n      # Defines the group for position_dodge to work correctly on text\n      group = stroke, \n      \n      # Combined label: Percentage (top line) + Count (bottom line)\n      label = paste0(\n        # Percentage calculation: (count / TOTAL_ROWS) * 100\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5, # Moves the two-line label slightly above the bar\n    size = 3,\n    color = \"black\" # Ensures better visibility\n  ) +\n  # Adds 15% extra space to the top of the y-axis to prevent label clipping\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + \n  scale_x_continuous(\n    breaks = c(1, 2),\n    labels = c(\"Urban\", \"Rural\")\n  ) +\n  labs(title = \"(g) Residence Type\", x = \"Residence Type\", y = \"Frequency (Count)\")\n\n# (h) Histogram of avg_gloucose_level\np1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(h) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Frequency\")\n\n# (h) Bivariate Density plot of avg_gloucose_level\n# p1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"Avg. Glucose Level by Stroke Status\", x = \"Average Glucose Level\", y = \"Density\")\n\n# (i) Histogram of bmi\np1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(i) BMI\", x = \"BMI\", y = \"Frequency\")\n\n# (i) Bivariate Density plot of bmi\n# p1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"BMI Distribution by Stroke Status\", x = \"BMI\", y = \"Density\")\n\n# (j) smoking_status\np1j &lt;- ggplot(strokeclean, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke, \n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, \n    size = 3,\n    color = \"black\" \n  ) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) + \n  labs(title = \"(j) Smoking Status\", y = \"Smoking Status\", x = \"Frequency (Count)\")\n\n\nWe can observe from the histograms (a), (b), (c) and (d) the following:\nThe data appears to be slightly imbalanced towards female gender and the proportion of stroke cases relative to the total number of individuals in each gender appears similar for both genders, even if it looks slightly higher in the male doesnt seem to be significant difference.\nThe number of stroke cases increases dramatically after the age of \\(\\approx 50\\) and peaks in the 60 to 80 age range. This strongly suggests age is a critical risk factor for stroke.\nThe majority of patients do not have hypertension and the proportion of stroke cases (blue bar) is visibly much higher in the group with hypertension. This indicates that hypertension is a strong risk factor for stroke.\nSimilar to hypertension, the majority of patients do not have heart disease and the proportion of stroke cases (blue bar) is visibly much higher in the group with heart disease. This indicates that heart disease is a very strong risk factor for stroke, even stronger than hypertension when based alone on the observed proportions.\n\n\nCode\n# p1a, p1b, p1c, p1d\n# (a) Histogram of gender \n# (b) Histogram of Age\n# (c) Histogram of hypertension\n# (d) Histogram of heart_disease\nggarrange(p1a, p1b, p1c, p1d, \n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (a)gender, (b)age, (c)hypertension, (d)heart_disease.\n\n\n\n\nWe can observe from the histograms (e), (f), (g) and (h) the following:\nThe stroke rate appears higher for those who have ever been married which is a fascinating plot that catches our attention, this must be correlated with another variable. Our guess is that having been married being associated with a higher stroke risk in this dataset, is possibly due to the married group skewing toward older ages\nAcross the four work types encoded, “Govt_job” = 1, “Private” = 2 “Self-employed” = 3, “Never Worked” = 4. Self-employed individuals appear to have the highest risk proportion among the working groups. Followed by the Private which is the largest group (total \\(\\approx 2200\\)) and naturally accounts for the highest raw count of stroke cases (109) with a proportion of stoke incidence sligthly higher than Govt_job.\nThe stroke outcomes based on the patient’s residence type has a very similar raw count their proportions seems to be similar as well. This suggests that residence type does not appear to be a significant factor for stroke risk.\nFrom the distribution of average glucose (HbA1c) we can visually spot that the stroke cases are more frequent for high-glucose relative to the total population at those high levels. This higher propportion indicates that high average glucose (HbA1c) level is a significant risk factor for stroke.\n\n\nCode\n# p1e p1f p1g p1h\n# (e) Histogram of ever_married\n# (f) Histogram of work_type\n# (g) Histogram of Residence_type\n# (h) Histogram of avg_gloucose_level\nggarrange(p1e, p1f, p1g, p1h,\n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (e)ever_married, (f)work_type, (g)Residence_type, (h)avg_gloucose_level.\n\n\n\n\nWe can observe from the histograms (i) and (j) the following:\nFor the BMI distribution we can observe that the majority of the patient population (pink bars) falls within the overweight to obese range (BMI \\(\\approx 25\\) to \\(35\\)). So as a consequence we can expect that the frequency of stroke cases (blue bars) will follow the distribution of the overall population, meaning most strokes occur where the largest number of people are located which are the BMI values between \\(25\\) and \\(35\\).\nHowever, we can visually spot that the stroke occurence is drops significantly closer to a healthy BMI of 20. So although the risk of stroke does seem to be generally higher than average once BMI exceeds the ideal range and moves into the overweight and obese categories because there is a larger distribution within the overweight to obese range, we can conclude that because the skewed distributin that BMI is a significant risk factor predictor for stroke.\nThe stroke outcomes are compared across the three smoking status categories encoded: smokes = 3, formerly smoked = 2, and never smoked = 1.\nThis plot is highlights a particularly interesting aspect of this dataset. The highest proportional risk of stroke appears to be in the formerly smoked group. This finding is common in medical literature[18], as individuals who have a history of smoking may have accrued vascular damage that persists, but their stroke risk is still lower than the risk for current smokers if they continue to smoke.\nThis information is importante, because the formerly smoked group shows the highest rate, suggesting that a history of smoking is a significant indicator of risk.\n\n\nCode\n# p1i p1j\n# (i) Histogram of bmi\n# (j) smoking_status\nggarrange(p1i, p1j,\n          ncol = 2, nrow = 1, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (i)bmi, (j)smoking_status.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Correlation Analysis\n\n\nCode\ndf_numeric &lt;- model.matrix(~.-1, data = strokeclean) |&gt;\n  as.data.frame()\n\n# Rename columns for clarity (model.matrix adds prefixes)\ncolnames(df_numeric) &lt;- gsub(\"gender|work_type|smoking_status|Residence_type|ever_married\", \"\", colnames(df_numeric))\n\n# 1. Calculate the correlation matrix\ncorrelation_matrix &lt;- cor(df_numeric)\n\n# 2. Define a green sequential color palette\n# green_palette &lt;- colorRampPalette(c(\"#E5F5E0\", \"#31A354\"))(200) # Light to dark green\ngreen_palette &lt;- colorRampPalette(c(\"#d5ffc8ff\", \"#245332ff\"))(200) \n\n# corrplot(correlation_matrix, method = 'number') # colorful number\n# 3. Create the heatmap with the correct palette\np2 &lt;- corrplot(correlation_matrix, \n         method = \"color\",\n         type = \"full\", # change to full or upper\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         addCoef.col = \"black\",\n         number.cex = 0.7,\n         col = green_palette, # Use the new palette here\n         diag = FALSE)\n\n\n\n\n\nCorrelation Analysis.\n\n\n\n\nThe correlation analysis confirms that the strongest linear predictors for stroke outcome in this dataset are age, hypertension, and average glucose level. Furthermore, age is highly correlated with hypertension, suggesting these factors may have overlapping or compounding effects on stroke risk.\nThis information will be further explored during statistical modelling were we will evaluate the statistical significance of those variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3. Statistical Modelling\nInitially, we split the dataset into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, then we used this training data for our statistical modelling. It is important to note that during splitting, stratified sampling was used (via caret::createDataPartition) to maintain the stroke/no-stroke ratio.[6]\nAlso the categorical variables were converted into the appropiate Data Types for correctly fitting the GLM binomial regression model.\n\n\n\nCode\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\nindex &lt;- createDataPartition(strokeclean$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- strokeclean[index, ]\ntest_data  &lt;- strokeclean[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\n# ---------------------------------------------\n# Convert all multi-level categoricals to factors with a clear reference level\ntrain_data$work_type     &lt;- factor(train_data$work_type)\ntrain_data$Residence_type&lt;- factor(train_data$Residence_type)\ntrain_data$smoking_status&lt;- factor(train_data$smoking_status)\n\n# The same should be done for test_data and the binary variables \ntest_data$work_type     &lt;- factor(test_data$work_type)\ntest_data$Residence_type&lt;- factor(test_data$Residence_type)\ntest_data$smoking_status&lt;- factor(test_data$smoking_status)\n# ---------------------------------------------\n# Note: if you want the output to label the levels (e.g., \"Male\" vs \"Female\") instead of \"gender\" and \"gender1\" (for Male = 1 vs Female = 0).\n# For 0/1, R's glm is usually fine, but for clean output factors are better.\n# For multi-level, it's essential.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.1. Repeated K-fold cross-validation\nThe trainControl() function in the R caret package is used to control the computational nuances and resampling methods employed by the train() function. It allows us to implement Repeated K-fold cross-validation (“repeatedcv”).\n\n\nCode\nctrl &lt;- trainControl(\nmethod = \"repeatedcv\",\nnumber = 5,\nrepeats = 3,\nclassProbs = TRUE,\nsummaryFunction = twoClassSummary,\nverboseIter = FALSE\n)\n\n\n\n\n3.3.2. Logistic Regression\n\n\nCode\n# Using the GLM package without K fold cross validation\nmodel_lr &lt;- glm(\n  stroke ~ . , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\n\n# Checking if the wrapper as.factor has any difference\n# model_lr &lt;- glm(\n#   stroke ~ age +\n#   avg_glucose_level +\n#   bmi +\n#   as.factor(gender) +\n#   as.factor(hypertension) +\n#   as.factor(heart_disease) +\n#   as.factor(ever_married) +\n#   as.factor(work_type) +\n#   as.factor(Residence_type) +\n#   as.factor(smoking_status)\n#   , \n#   data=train_data , \n#   family = \"binomial\" (link=logit)\n#   )\n\ns1 &lt;- summary(model_lr)\nc1 &lt;- coefficients(model_lr)\nanova1 &lt;- car::Anova(model_lr, type = 3)\nconfint1 &lt;- confint(model_lr, level=0.95)\n\n# Logistic Regression with the Caret package\nmodel_lr2 &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\nLogistic Regression Preliminary conclusions\n\ns1\n\n\nCall:\nglm(formula = stroke ~ ., family = binomial(link = logit), data = train_data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -8.113391   0.854545  -9.494  &lt; 2e-16 ***\ngender             -0.112742   0.204658  -0.551  0.58172    \nage                 0.078380   0.008614   9.099  &lt; 2e-16 ***\nhypertension        0.914733   0.214191   4.271 1.95e-05 ***\nheart_disease       0.339604   0.277662   1.223  0.22130    \never_married       -0.532738   0.293381  -1.816  0.06939 .  \nwork_type2          0.072261   0.288269   0.251  0.80207    \nwork_type3         -0.290608   0.324634  -0.895  0.37069    \nwork_type4         -9.306169 649.652359  -0.014  0.98857    \nResidence_type2    -0.072792   0.198250  -0.367  0.71349    \navg_glucose_level   0.005488   0.001670   3.287  0.00101 ** \nbmi                 0.002103   0.015554   0.135  0.89245    \nsmoking_status2     0.208775   0.226763   0.921  0.35722    \nsmoking_status3     0.345133   0.266423   1.295  0.19517    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 982.44  on 2349  degrees of freedom\nResidual deviance: 767.21  on 2336  degrees of freedom\nAIC: 795.21\n\nNumber of Fisher Scoring iterations: 14\n\nanova1\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \ngender               0.305  1   0.580683    \nage                107.200  1  &lt; 2.2e-16 ***\nhypertension        17.103  1   3.54e-05 ***\nheart_disease        1.439  1   0.230228    \never_married         3.064  1   0.080044 .  \nwork_type            2.479  3   0.479126    \nResidence_type       0.135  1   0.713341    \navg_glucose_level   10.535  1   0.001171 ** \nbmi                  0.018  1   0.892611    \nsmoking_status       1.905  2   0.385861    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n107.200\n1\n&lt;2.2e-16\n***\nReject H0. Age is statistically significant in predicting stroke.\n\n\nhypertension\n17.103\n1\n3.54e-05\n***\nReject H0. Hypertension status is statistically significant in predicting stroke.\n\n\navg_glucose_level\n10.535\n1\n0.001171\n**\nReject H0. The average glucose level is statistically significant in predicting stroke.\n\n\ngender\n0.305\n1\n0.580683\n\nFail to Reject H0. Gender is not statistically significant in predicting stroke.\n\n\nheart_disease\n1.439\n1\n0.230228\n\nFail to Reject H0. Heart Disease is not statistically significant in predicting stroke.\n\n\never_married\n3.064\n1\n0.080044\n.\nFail to Reject H0. Marital Status is not statistically significant. Note: Significant at α = 0.1 level.\n\n\nwork_type\n2.479\n3\n0.479126\n\nFail to Reject H0. The factor is not statistically significant in predicting stroke.\n\n\nResidence_type\n0.135\n1\n0.713341\n\nFail to Reject H0. The residence type is not statistically significant in predicting stroke.\n\n\nbmi\n0.018\n1\n0.892611\n\nFail to Reject H0. The BMI is not statistically significant in predicting stroke.\n\n\nsmoking_status\n1.905\n2\n0.385861\n\nFail to Reject H0. The smoking status is not statistically significant in predicting stroke.\n\n\n\nFrom the ANOVA test we could observe that the variables age, hypertension, and avg_glucose_level are statistically significant in predicting the odds of having a stroke. As well we could observe that the variables gender, heart_disease, work_type, Residence_type, bmi, and smoking_status do not show a statistically significant effect on the odds of stroke at the \\(\\alpha=0.05\\) level. Additionally, there is an interesting observation that the variable ever_married is close to significance indicing some curiosity and further exploration.\nTherefore, based solely on this ANOVA table the performance evaluation suggests that we consider removing all the statistically not significant variables and keeping the statistically significant varibles: \\(\\text{age}\\), \\(\\text{hypertension}\\), \\(\\text{avg\\_glucose\\_level}\\).\n\n\nCode\n# Using the GLM package without K fold cross validation\nmodel2_lr &lt;- glm(\n  stroke ~ age +\n  hypertension +\n  avg_glucose_level , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\n\ns2 &lt;- summary(model2_lr)\nc2 &lt;- coefficients(model2_lr)\nanova2 &lt;- car::Anova(model2_lr, type = 3)\nconfint2 &lt;- confint(model2_lr, level=0.95)\n\n\n\ns2\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + avg_glucose_level, \n    family = binomial(link = logit), data = train_data)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.232810   0.560826 -14.680  &lt; 2e-16 ***\nage                0.075044   0.007904   9.495  &lt; 2e-16 ***\nhypertension       0.929501   0.210279   4.420 9.85e-06 ***\navg_glucose_level  0.005427   0.001582   3.430 0.000603 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 982.44  on 2349  degrees of freedom\nResidual deviance: 777.43  on 2346  degrees of freedom\nAIC: 785.43\n\nNumber of Fisher Scoring iterations: 7\n\nanova2\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \nage                120.407  1  &lt; 2.2e-16 ***\nhypertension        18.205  1  1.983e-05 ***\navg_glucose_level   11.337  1  0.0007598 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n120.407\n1\n&lt;2.2e-16\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\nhypertension\n18.205\n1\n1.983e-05\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\navg_glucose_level\n11.337\n1\n0.0007598\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\n\nWe could see a marginal improvement on the model with and AIC of 785.43 versus the previous AIC of 795.21 and its now even easier to observe that age seems to be the most powerful predictor in the model.\n\n\n\n\n3.3.3. Addressing Class Imbalance with SMOTE\nThe dataset is highly imbalanced, with only a small number of cases being stroke instances. This can bias machine learning models. We will use SMOTE to create balanced versions of our imputed datasets by generating synthetic minority (stroke) class samples.\n\n\nCode\n# Ensure the stroke column is a factor for SMOTE\n# df_mice$stroke &lt;- as.factor(df_mice$stroke)\n# df_mean$stroke &lt;- as.factor(df_mean$stroke)\n# df_age_group$stroke &lt;- as.factor(df_age_group$stroke)\n\n# Create balanced datasets using SMOTE\n# Using the MICE imputed dataset as the primary example for balancing\n\n# Get the number of non-stroke (majority) cases\n# n_majority &lt;- sum(df_mice$stroke == \"0\")\nn_majority &lt;- sum(train_data$stroke == \"No\")\n\n# Calculate the desired total size for a balanced dataset\ndesired_N &lt;- 2 * n_majority\n\n# Create the balanced dataset\ndata_balanced_mice &lt;- ROSE::ovun.sample(\n  stroke ~ ., \n  data = train_data, \n  method = \"over\", \n  N = desired_N, \n  seed = 123\n)$data\n\n\nWe can observe the class distribution before handling the class imbalance with a small number of cases being stroke instances.\n\n\nCode\n# Check the new class distribution\n# cat(\"Original Class Distribution (MICE imputed):\\n\")\nprint(table(train_data$stroke))\n\n\n\n  No  Yes \n2224  126 \n\n\nAfter the class distribution balancing the number of cases being stroke instances is much higher.\n\n\nCode\n# Check the new class distribution\n# cat(\"\\nBalanced Class Distribution (SMOTE):\\n\")\nprint(table(data_balanced_mice$stroke))\n\n\n\n  No  Yes \n2224 2224 \n\n\n\n\n3.3.4. Fitting Logistic Regression with Balanced Data\nWe will use the balanced dataset for modeling. Same as before the dataset is split into training (70%) and testing (30%).\n\n\nCode\n# data_bal &lt;- ROSE(stroke ~ ., data = train_data, seed = 123)$data\nmodel3_lr &lt;- glm(\n  stroke ~ age +\n  hypertension +\n  avg_glucose_level , \n  data=data_balanced_mice , \n  family = \"binomial\" (link=logit)\n  )\n\ns3 &lt;- summary(model3_lr)\nc3 &lt;- coefficients(model3_lr)\nanova3 &lt;- car::Anova(model3_lr, type = 3)\nconfint3 &lt;- confint(model3_lr, level=0.95)\n\n\n\ns3\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + avg_glucose_level, \n    family = binomial(link = logit), data = data_balanced_mice)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -5.6444885  0.1854899 -30.430   &lt;2e-16 ***\nage                0.0782316  0.0027115  28.852   &lt;2e-16 ***\nhypertension       1.1193216  0.0932833  11.999   &lt;2e-16 ***\navg_glucose_level  0.0055918  0.0006791   8.234   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6166.2  on 4447  degrees of freedom\nResidual deviance: 4254.9  on 4444  degrees of freedom\nAIC: 4262.9\n\nNumber of Fisher Scoring iterations: 5\n\nanova3\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \nage                1201.85  1  &lt; 2.2e-16 ***\nhypertension        154.34  1  &lt; 2.2e-16 ***\navg_glucose_level    69.73  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n1201.85\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\nhypertension\n154.34\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\navg_glucose_level\n69.73\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\n\nAll the three variables we kept (age, hypertension, and avg_glucose_level) remained statistically significant. what confirms that the relationships between these key clinical factors and stroke outcome are robust.\n\n\n\n\n\n\n\n\n\nFactor\nLR χ² (Original, anova2)\nLR χ² (Balanced, anova3)\nChange in χ²\n\n\n\n\nage\n120.407\n1201.85\n≈10.0× Increase\n\n\nhypertension\n18.205\n154.34\n≈8.5× Increase\n\n\navg_glucose_level\n11.337\n69.73\n≈6.1× Increase\n\n\n\nWe additionally can observe that there is an massive increase in the \\(\\chi^2\\) values which demonstrates that the oversampling technique has significantly increased the statistical power of the model.\nIn summary, the ANOVA test confirmed that balancing the training data has dramatically increased the statistical confidence in the predictive power of the model, which directly led to the massive improvement in the model’s ability to identify true stroke cases what will be explored in the next section with a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.5. Confusion Matrix\nThis section the confusion matrix demonstrates conclusive evidence the undersampling of Stroke cases yields a model with no predictive capability.\n\n\nCode\n# 1) Predicted probabilities from logistic regression\ntest_data$pred_prob &lt;- predict(\n  model_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\ntest_data$pred_prob2 &lt;- predict(\n  model2_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\ntest_data$pred_prob3 &lt;- predict(\n  model3_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\ntest_data$stroke &lt;- factor(test_data$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\ntest_data$pred_class &lt;- ifelse(test_data$pred_prob &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class2 &lt;- ifelse(test_data$pred_prob2 &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class3 &lt;- ifelse(test_data$pred_prob3 &gt;= 0.5, \"Yes\", \"No\")\n\ntest_data$pred_class &lt;- factor(test_data$pred_class, levels = c(\"No\", \"Yes\"))\ntest_data$pred_class2 &lt;- factor(test_data$pred_class2, levels = c(\"No\", \"Yes\"))\ntest_data$pred_class3 &lt;- factor(test_data$pred_class3, levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm &lt;- confusionMatrix(\n  data      = test_data$pred_class,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\ncm2 &lt;- confusionMatrix(\n  data      = test_data$pred_class2,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\ncm3 &lt;- confusionMatrix(\n  data      = test_data$pred_class3,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n# cm\n# cm2\n# cm3\n\n\n\n\nCode\n# --------------------------------------------------------\n# 1. Define a function to extract key metrics and counts\n# --------------------------------------------------------\nextract_metrics &lt;- function(cm_object, model_name) {\n  # Extract per-class statistics (Sensitivity, Specificity) and Overall Accuracy\n  stats &lt;- cm_object$byClass\n  Accuracy &lt;- cm_object$overall['Accuracy']\n  \n  # Extract Confusion Matrix table for counts\n  cm_table &lt;- cm_object$table\n  \n  # Extract the counts (Assuming 'Yes' is the positive class, top-left is TN)\n  TP &lt;- cm_table['Yes', 'Yes'] # True Positives\n  FN &lt;- cm_table['Yes', 'No']  # False Negatives\n  TN &lt;- cm_table['No', 'No']   # True Negatives\n  FP &lt;- cm_table['No', 'Yes']  # False Positives\n  \n  # Create a data frame with metrics as rows\n  data.frame(\n    Metric = c(\n      \"Accuracy\",\n      \"Sensitivity (Recall)\",\n      \"Specificity\",\n      \"True Positives (TP)\",\n      \"False Negatives (FN)\",\n      \"True Negatives (TN)\",\n      \"False Positives (FP)\"\n    ),\n    Value = c(\n      Accuracy,\n      stats['Sensitivity'],\n      stats['Specificity'],\n      TP,\n      FN,\n      TN,\n      FP\n    ),\n    stringsAsFactors = FALSE\n  ) %&gt;%\n    # Rename the Value column to the model name\n    dplyr::rename(!!model_name := Value)\n}\n\n# --------------------------------------------------------\n# 2. Extract metrics for all three models\n# --------------------------------------------------------\nmetrics_cm &lt;- extract_metrics(cm, \"Model 1 (Full, Imbalanced)\")\nmetrics_cm2 &lt;- extract_metrics(cm2, \"Model 2 (Reduced, Imbalanced)\")\nmetrics_cm3 &lt;- extract_metrics(cm3, \"Model 3 (Reduced, Balanced)\")\n\n# --------------------------------------------------------\n# 3. Merge the three data frames into one comparison table\n# --------------------------------------------------------\ncomparison_table &lt;- metrics_cm %&gt;%\n  dplyr::full_join(metrics_cm2, by = \"Metric\") %&gt;%\n  dplyr::full_join(metrics_cm3, by = \"Metric\")\n\n# --------------------------------------------------------\n# 4. Format the table for clean output\n# --------------------------------------------------------\n\n# Select the rows that are proportions/percentages (1-3) and format to 4 decimal places\ncomparison_table[1:3, 2:4] &lt;- lapply(\n  comparison_table[1:3, 2:4],\n  function(x) { format(as.numeric(x), digits = 4, scientific = FALSE) }\n)\n\n# Select the rows that are counts (4-7) and format as integers\ncomparison_table[4:7, 2:4] &lt;- lapply(\n  comparison_table[4:7, 2:4],\n  function(x) { format(as.integer(x), big.mark = \",\") }\n)\n\n# Print the final formatted table\nprint(comparison_table)\n\n\n                Metric Model 1 (Full, Imbalanced) Model 2 (Reduced, Imbalanced)\n1             Accuracy                    0.94538                        0.9444\n2 Sensitivity (Recall)                    0.01852                        0.0000\n3          Specificity                    0.99790                        0.9979\n4  True Positives (TP)                          1                             0\n5 False Negatives (FN)                          2                             2\n6  True Negatives (TN)                        951                           951\n7 False Positives (FP)                         53                            54\n  Model 3 (Reduced, Balanced)\n1                      0.7269\n2                      0.6481\n3                      0.7314\n4                          35\n5                         256\n6                         697\n7                          19\n\n\n\n\n\n\n\n\n\n\n\nMetric\nModel 1 (Full, Imbalanced)\nModel 2 (Reduced, Imbalanced)\nModel 3 (Reduced, Balanced)\n\n\n\n\nAccuracy\n0.94538\n0.9444\n0.7269\n\n\nSensitivity (Recall)\n0.01852\n0.0000\n0.6481\n\n\nSpecificity\n0.99790\n0.9979\n0.7314\n\n\nTrue Positives (TP)\n1\n0\n35\n\n\nFalse Negatives (FN)\n2\n2\n256\n\n\nTrue Negatives (TN)\n951\n951\n697\n\n\nFalse Positives (FP)\n53\n54\n19\n\n\n\nThe comparison of the three Logistic Regression models using the confusion matrix reveals that while the imbalanced models (Model 1 and Model 2) achieved high Accuracy (\\(\\approx 94.5\\%\\)) and Specificity (\\(\\approx 0.998\\)), they were practically useless for stroke prediction with a near-zero Sensitivity and missing almost all actual stroke cases. By contrast, Model 3 which utilized oversampling to address the severe class imbalance in stroke outcome, demonstrated a significant improvement in predictive capability: Sensitivity dramatically improved to \\(0.6481\\) being able to identifying 35 True Positives, confirming that balancing successfully forced the model to learn the patterns of the minority class of stroke outcome. However, this critical gain in recall came with a trade-off, it lowered the Accuracy to \\(0.7269\\) and Specificity to \\(0.7314\\) due to an increase in False Negatives registering 256 cases, but the resulting model is a far more functional screening tool, prioritizing the detection of the outcome stroke over overall classification correctness.\n\n\n\nCheck Multicollinearity\nIn OLS regression, multicollinearity can be calculated either from the correlations among the predictors, or from the correlations among the coefficient estimates, and these result in the same variance inflaction factors (VIFs).\nIn GLMs, these two approaches yield similar but different VIFs. John Fox, one of the authors of the car package where the vif() function is found, opts for calculating the VIFs from the coefficient estimates.\n\nvif(model_lr)\n\n                      GVIF Df GVIF^(1/(2*Df))\ngender            1.042583  1        1.021069\nage               1.224353  1        1.106505\nhypertension      1.038949  1        1.019288\nheart_disease     1.072781  1        1.035751\never_married      1.023266  1        1.011566\nwork_type         1.083443  3        1.013447\nResidence_type    1.012883  1        1.006421\navg_glucose_level 1.118062  1        1.057384\nbmi               1.158761  1        1.076457\nsmoking_status    1.086902  2        1.021051\n\nvif(model2_lr)\n\n              age      hypertension avg_glucose_level \n         1.017823          1.016305          1.017019 \n\nvif(model3_lr)\n\n              age      hypertension avg_glucose_level \n         1.006566          1.009300          1.015890"
  },
  {
    "objectID": "report.html#conclusion",
    "href": "report.html#conclusion",
    "title": "Predicting stroke risk from common health indicators: a binary logistic regression analysis",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThis experiment evaluated the performance of a logistic regression model with common demographic, behavioral, and clinical characteristics using a public stroke dataset.[17] The findings were not promising because stroke is a rare outcome (about 5% of cases) and even after dealing with the class imbalance there is only marginal improvements, too many false positives. Althought the improvements were marginal the logistic regression model was a great interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness. For example we could identify that Age, hypertension, and raised average glucose levels are among the best predictors of stroke outcome.\nOur findings of the undesirable performance of Logistic Regression are on pair with other research[19]. More advanced techniques seem to be required for preprocessing the dataset such as Mean Imputation for replacing some missing values with the column’s mean, Multivariate Imputation by Chained Equations (MICE) where we synthetically generate missing values based on other variables, and Age Group-based Imputation where we we categorize the age groups and replace missing BMI values with the mean BMI of the corresponding age group.\nBut the main solution for the problem might be implementation of the Dense Stacking Ensemble (DSE) Model, which uses the best-performing model (Random Forest) as a meta-classifier. This multi-model approach as epxlored in[19] seems to combine the simplicity and interpretability of Logistic Regression models with the superior performance of more sophisticated models. Overall, the findings show that relatively simple models built from routinely collected health indicators can generate meaningfull results when the proper class imbalance is deal and that proves that logistic regression emerges as a strong, interpretable baseline that can be further improved as demonstrated in[19]. In Future work we could explore the use of synthetically generate data and other Imputation techinques and the implementation of Dense Stacking Ensemble (DSE) Model. These extensions would help move towards a robust model with low false positive predictions, making the research into a clinically usable tool for stroke risk stratification and targeted prevention.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2).\n\n\n9. Kokkotis, C., Giarmatzis, G., Giannakou, E., Moustakidis, S., Tsatalas, T., Tsiptsios, D., Vadikolias, K., & Aggelousis, N. (2022). An explainable machine learning pipeline for stroke prediction on imbalanced data. Diagnostics, 12(10), 2392.\n\n\n10. Sirsat, M. S., Fermé, E., & Câmara, J. (2020). Machine learning for brain stroke: A review. Journal of Stroke and Cerebrovascular Diseases, 29(10), 105162.\n\n\n11. Wongvorachan, T., He, S., & Bulut, O. (2023). A comparison of undersampling, oversampling, and SMOTE methods for dealing with imbalanced classification in educational data mining. Information, 14(1), 54.\n\n\n12. Sowjanya, A. M., & Mrudula, O. (2023). Effective treatment of imbalanced datasets in health care using modified SMOTE coupled with stacked deep learning algorithms. Applied Nanoscience, 13(3), 1829–1840.\n\n\n13. Harris, J. K. (2019). Statistics with r: Solving problems using real-world data. SAGE Publications.\n\n\n14. Field, A. (2024). Discovering statistics using IBM SPSS statistics. Sage publications limited.\n\n\n15. Hosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). Applied logistic regression. John Wiley & Sons.\n\n\n16. LeBlanc, M., & Fitzgerald, S. (2000). Logistic regression for school psychologists. School Psychology Quarterly, 15(3), 344.\n\n\n17. Palacios, F. S. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n\n\n18. Oshunbade, A. A., Yimer, W. K., Valle, K. A., Clark III, D., Kamimura, D., White, W. B., DeFilippis, A. P., Blaha, M. J., Benjamin, E. J., O’Brien, E. C., et al. (2020). Cigarette smoking and incident stroke in blacks of the jackson heart study. Journal of the American Heart Association, 9(12), e014990.\n\n\n19. Hassan, A., Gulzar Ahmad, S., Ullah Munir, E., Ali Khan, I., & Ramzan, N. (2024). Predictive modelling and identification of key risk factors for stroke using machine learning. Scientific Reports, 14(1), 11498."
  },
  {
    "objectID": "slides.html#stroke-analysis-and-early-prediction",
    "href": "slides.html#stroke-analysis-and-early-prediction",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Stroke analysis and early prediction",
    "text": "Stroke analysis and early prediction\n\n\nStroke comes without warning ,fatal , and can be partly prevented. Known to be major cause of death and long-term disability; a single event can even make humanbeing paralysis for life long.\n\n\nFactors that can be catalyst possess more risk such as hypertension, high glucose / diabetes, heart disease, smoking, and obesity (BMI).\n\n\nThese factors are already recorded in routine care (age, blood-pressure history, glucose, BMI, smoking status) but are always overlooked without quality analysis till depth.\n\n\nMotivation for analysis : use these routine measurements to build an interpretable logistic regression model, and compare it with machine-learning methods, to help us find high risk patient for prevention and counselling."
  },
  {
    "objectID": "slides.html#research-motivation-objectives",
    "href": "slides.html#research-motivation-objectives",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Research motivation & Objectives",
    "text": "Research motivation & Objectives\n\n\nWhich is common, most vital health indicator connected with stroke risk?\n\n\nHow well can a binary logistic regression model separate stroke cases from non-stroke?\n\n\nDo more complex machine learning models (Decision Tree, Random Forest, GBM, kNN, SVM) provide upgrade or liable, relevant result over logistic regression?\n\n\nHow does class imbalance (rare stroke outcome) affect model performance and choice of probability threshold?\n\n\n Objectives \n\n\nBuild an interpretable logistic regression model for stroke prediction.\n\n\nCompare performance with several ML classifiers on the same train/test split.\n\n\nEvaluate using Accuracy, Sensitivity, Specificity, ROC, AUC, and Youden’s J.\n\n\nExplore threshold tuning to improve detection of stroke cases."
  },
  {
    "objectID": "slides.html#data-key-variables",
    "href": "slides.html#data-key-variables",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Data & Key Variables",
    "text": "Data & Key Variables\n 1. Dataset \n\n\nPublic stroke dataset (Kaggle).\n\n\nN = 3,357 patients after cleaning and removing missing values.\n\n\nBinary outcome: Stroke (Yes / No).\n\n\n\n 2. Main predictors \n\n\nDemographic: Age, Gender, Ever_married, Work_type, Residence_type.\n\n\nClinical: Hypertension, Heart_disease.\n\n\nBehavioural / metabolic: Smoking_status, BMI, Average glucose level.\n\n\n\n 3. Coding \n\n\nCategorical variables recoded to numeric levels (1, 2, 3, …).\n\n\nOutcome stroke coded as factor with levels No and Yes.\n\n\nNon-predictive ID column removed."
  },
  {
    "objectID": "slides.html#class-imbalance-in-stroke-outcome",
    "href": "slides.html#class-imbalance-in-stroke-outcome",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Class Imbalance in Stroke Outcome",
    "text": "Class Imbalance in Stroke Outcome\n1. Outcome distribution\n\n\nStroke (Yes): ≈ 5–6% of patients\n\n\nNo stroke (No): ≈ 94–95% of patients\n\n\n2. Why this matters\n\n\nA model can reach &gt; 90% accuracy by predicting “No stroke.”\n\n\nHigh accuracy does not mean good stroke detection.\n\n\nMust evaluate using Sensitivity, Specificity, and AUC.\n\n\n3. Evaluation focus\n\n\nSensitivity: detects stroke cases (true positives)\n\n\nSpecificity: detects non-stroke cases\n\n\nPrecision: correctness of predicted stroke cases\n\n\nAUC: overall ranking ability"
  },
  {
    "objectID": "slides.html#data-preparation",
    "href": "slides.html#data-preparation",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n\nRemoved rows with missing or inconsistent values(e.g., “Unknown”, “N/A”).\n\n\nConverted variables to numeric / factor formats appropriate for modelling.\n\n\nChecked ranges of Age, BMI, and Glucose for obvious data errors or outliers.\n\n\nDefined strokeclean as the final cleaned dataset used in modelling.\n\n\nUsed a 70% training / 30% test split to assess out-of-sample performance."
  },
  {
    "objectID": "slides.html#exploratory-data-analysis-overview",
    "href": "slides.html#exploratory-data-analysis-overview",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Exploratory Data Analysis (Overview)",
    "text": "Exploratory Data Analysis (Overview)\n Our goal is to understand how key health indicators changes between patients with and without stroke. \n\n We first examine: \n\n\n\nDistributions of Age, BMI, and Average Glucose\n\n\nStroke rates across Hypertension, Heart Disease, Smoking\n\n\nCorrelations among numeric predictors\n\n\n\n\n These insights help identify which predictors may have the strongest relationship with stroke risk."
  },
  {
    "objectID": "slides.html#density-plots-for-age-bmi-and-glucose",
    "href": "slides.html#density-plots-for-age-bmi-and-glucose",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Density Plots for Age, BMI, and Glucose",
    "text": "Density Plots for Age, BMI, and Glucose\n\n\nFigure 1"
  },
  {
    "objectID": "slides.html#interpretation-of-key-continuous-predictors",
    "href": "slides.html#interpretation-of-key-continuous-predictors",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation of Key Continuous Predictors",
    "text": "Interpretation of Key Continuous Predictors\n\n\nAge\n\n\nSmooth distribution from late teens.\n\n\nMajority in 40–70 = highest-risk band.\n\n\nNo sharp clusters = good continuous predictor.\n\n\n\n\nAverage Glucose Level\n\n\nClear right-skew; tail extends beyond 200 mg/dL.\n\n\nSmall subgroup with metabolic issues (likely diabetic).\n\n\nStrong link to cardiovascular and stroke risk.\n\n\n\n\nBMI\n\n\nCompact range (~22–35) with few outliers.\n\n\nLess variation = weaker predictive power.\n\n\nConsistent with medical evidence and our model."
  },
  {
    "objectID": "slides.html#interpretation-of-key-categorical-predictors",
    "href": "slides.html#interpretation-of-key-categorical-predictors",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation of Key Categorical Predictors",
    "text": "Interpretation of Key Categorical Predictors\n\n\nGender\n\n\nMore females (61%) than males (39%).\n\n\nImbalance may influence how gender appears in the model.\n\n\n\n\nResidence Type\n\n\nNearly equal Urban (51%) and Rural (49%) split.\n\n\nNo major geographic bias in the sample.\n\n\n\n\nSmoking Status\n\n\nNever smokers (54%) form the majority.\n\n\nFormer (25%) and current (22%) smokers well represented.\n\n\nEnough variation to assess smoking as a stroke risk factor."
  },
  {
    "objectID": "slides.html#stroke-risk-for-clinical-and-behavioral-predictors",
    "href": "slides.html#stroke-risk-for-clinical-and-behavioral-predictors",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Stroke Risk for Clinical and Behavioral Predictors",
    "text": "Stroke Risk for Clinical and Behavioral Predictors\n\n\nFigure 3: Stroke percentages (95% CI) by hypertension, heart disease, and smoking status."
  },
  {
    "objectID": "slides.html#interpretation-of-stroke-risk-vs-predictors",
    "href": "slides.html#interpretation-of-stroke-risk-vs-predictors",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation of stroke risk vs predictors",
    "text": "Interpretation of stroke risk vs predictors\n\n\nHypertension\n\n\nHigher stroke risk in hypertensive patients.\n\n\nClear CI separation → strong association.\n\n\n\n\nHeart Disease\n\n\nHigher stroke percentages among those with heart disease.\n\n\nConsistent with known cardiovascular risk patterns.\n\n\n\n\nSmoking Status\n\n\nFormer and current smokers show higher stroke risk.\n\n\nReflects long-term vascular impact of tobacco exposure.\n\n\n\n\nOverall\n\n\nVascular risks (hypertension, heart disease) and behavioural risk (smoking)\n\n\nall show elevated stroke likelihood. Clinically consistent."
  },
  {
    "objectID": "slides.html#correlation-among-key-numeric-prediators",
    "href": "slides.html#correlation-among-key-numeric-prediators",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Correlation among key numeric prediators",
    "text": "Correlation among key numeric prediators"
  },
  {
    "objectID": "slides.html#interpretation-correlation-heatmap",
    "href": "slides.html#interpretation-correlation-heatmap",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Correlation Heatmap",
    "text": "Interpretation — Correlation Heatmap\n\n\nOverall\n\n\nCorrelations are weak–moderate (0.00–0.26).\n\n\nNo multicollinearity concerns.\n\n\n\n\nAge\n\n\nPositive links with glucose (0.24), hypertension (0.26), heart disease (0.26).\n\n\nMatches aging-related cardiovascular risk trends.\n\n\n\n\nBMI\n\n\nVery weak correlations (0.04–0.16).\n\n\nActs independently in this dataset.\n\n\n\n\nAverage Glucose\n\n\nModerate links with hypertension (0.17) and heart disease (0.14).\n\n\nConsistent with metabolic–vascular patterns.\n\n\n\n\nHypertension & Heart Disease\n\n\nWeak correlation (0.11) → related but not redundant."
  },
  {
    "objectID": "slides.html#odds-ratios-and-confidence-intervals",
    "href": "slides.html#odds-ratios-and-confidence-intervals",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Odds ratios and confidence intervals",
    "text": "Odds ratios and confidence intervals\n\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   &lt;2e-16 ***\nage                0.072637   0.008089   8.979   &lt;2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "slides.html#odds-ratios-and-confidence-intervals-1",
    "href": "slides.html#odds-ratios-and-confidence-intervals-1",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Odds ratios and confidence intervals",
    "text": "Odds ratios and confidence intervals\n\n\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013"
  },
  {
    "objectID": "slides.html#interpretation-odds-ratios-logistic-regression",
    "href": "slides.html#interpretation-odds-ratios-logistic-regression",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Odds Ratios (Logistic Regression)",
    "text": "Interpretation — Odds Ratios (Logistic Regression)\n\n\nAge (OR 1.075, CI 1.059–1.093)\nStrongest predictor; each year ↑ stroke odds ~7.5%.\nHypertension (OR 1.577, CI 0.996–2.450)\n~58% higher odds; borderline but clinically meaningful.\nHeart disease (OR 1.628, CI 0.942–2.733)\n~63% higher odds; CI includes 1 → not statistically strong.\nAvg glucose (OR 1.004, CI 1.000–1.007)\nSlight ↑ in odds; marginal significance; aligns with metabolic risk.\nBMI (OR 1.007, CI 0.975–1.037)\nNo meaningful effect; CI overlaps 1.\nSmoking\nFormer: OR 1.263 (weak).\nCurrent: OR 1.598 (suggestive ↑ risk).\nGender (Female) (OR 1.259, CI 0.842–1.903)\nSlight ↑ odds; not significant.\nEver married (OR 1.126, CI 0.590–2.013)\nNo clear effect."
  },
  {
    "objectID": "slides.html#logistic-regression-performance-test-set",
    "href": "slides.html#logistic-regression-performance-test-set",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Logistic Regression performance (Test Set)",
    "text": "Logistic Regression performance (Test Set)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc &gt; NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes"
  },
  {
    "objectID": "slides.html#interpretation-logistic-regression-performance-test-set",
    "href": "slides.html#interpretation-logistic-regression-performance-test-set",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Logistic Regression Performance (Test Set)",
    "text": "Interpretation — Logistic Regression Performance (Test Set)\n\n\nAccuracy: 94.25%\nHigh due to class imbalance (only ~6% stroke cases); not meaningful for detection.\nSensitivity: 0.017\nDetected 1 of 59 stroke cases → model fails to identify strokes.\nSpecificity: 1.00\nPerfect for non-stroke cases; predicts “No stroke” extremely well.\nPrecision (PPV): 1.00\nWhen predicting “Yes,” it was correct — but it predicted yes only once → misleadingly high.\nNPV: 0.942\nMost “No” predictions are correct, consistent with majority class.\nKappa: 0.031\nNear zero → model performs only slightly better than random for imbalanced data.\nBalanced Accuracy: 0.508\nEquivalent to chance level when sensitivity and specificity are weighted equally.\nMcNemar’s Test: p &lt; 0.0001\nErrors are systematically biased toward predicting “No stroke.”\n\nOverall:\nModel performs well for non-stroke patients but fails severely for stroke detection.\nClass imbalance dominates performance → requires resampling, class weights, or other imbalance-handling methods."
  },
  {
    "objectID": "slides.html#roc-curve-and-auc-for-the-logistic-model",
    "href": "slides.html#roc-curve-and-auc-for-the-logistic-model",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "ROC curve and AUC for the logistic model",
    "text": "ROC curve and AUC for the logistic model"
  },
  {
    "objectID": "slides.html#interpretation-roc-curve-auc",
    "href": "slides.html#interpretation-roc-curve-auc",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — ROC Curve & AUC",
    "text": "Interpretation — ROC Curve & AUC\n\n\nAUC = 0.815 → indicates good discriminative ability.\n(0.5 = none, 0.7–0.8 = acceptable, 0.8–0.9 = good, &gt;0.9 = excellent)\nROC evaluates performance across all thresholds, not just 0.5.\nDespite poor sensitivity at the 0.5 cutoff,\nthe AUC shows the model can separate stroke vs non-stroke reasonably well if a better threshold is chosen.\nThe gap between strong AUC and weak sensitivity reflects:\n• severe class imbalance\n• the need for customized probability cutoffs in medical prediction\n\nImplications for improvement: - Threshold tuning\n- Cost-sensitive / class-weighted training\n- Resampling (e.g., SMOTE, oversampling)\n\n\n\n\n  No  Yes \n3177  180"
  },
  {
    "objectID": "slides.html#machine-learning-model-comparison",
    "href": "slides.html#machine-learning-model-comparison",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Machine-learning model comparison",
    "text": "Machine-learning model comparison\n\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534"
  },
  {
    "objectID": "slides.html#interpretation-model-comparison",
    "href": "slides.html#interpretation-model-comparison",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Model Comparison",
    "text": "Interpretation — Model Comparison\n\n\nAll six models show very high accuracy & specificity, driven by the dataset’s ~6% stroke rate (strong class imbalance).\nSensitivity is extremely low for every model → almost none correctly identify stroke cases.\nBest AUC values:\n• Logistic Regression: 0.78\n• GBM: 0.76\n→ These models discriminate high- vs low-risk patients better than others, despite poor sensitivity at the 0.5 threshold.\nTree-based models (DT, RF, GBM) show slightly higher sensitivity than LR, but still only ~1–2%.\nKNN and SVM detect 0 stroke cases at the default threshold, despite high accuracy.\nOverall: Accuracy is misleading; all models excel at predicting “No stroke” but fail at detecting positives.\nConfirms severe class imbalance → meaningful improvement requires:\n• threshold tuning,\n• resampling (SMOTE/oversampling),\n• cost-sensitive learning."
  },
  {
    "objectID": "slides.html#roc-comaprision-for-all-6-model",
    "href": "slides.html#roc-comaprision-for-all-6-model",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "ROC comaprision for all 6 model",
    "text": "ROC comaprision for all 6 model"
  },
  {
    "objectID": "slides.html#interpretation-roc-comparison-across-models",
    "href": "slides.html#interpretation-roc-comparison-across-models",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — ROC Comparison Across Models",
    "text": "Interpretation — ROC Comparison Across Models\n\n\nLogistic Regression (AUC = 0.779) shows the best overall discrimination between stroke vs non-stroke.\nGBM (AUC = 0.759) and Random Forest (AUC = 0.725) also perform well, close to LR.\nKNN (AUC = 0.667) performs moderately — better than chance, but weaker than LR and tree ensembles.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) have the lowest AUC values → weakest discrimination.\nAll models score above 0.5, meaning they perform better than random guessing, but with clear differences in quality.\nROC curves show that LR, RF, and GBM extract the strongest predictive patterns, outperforming simpler tree models and distance-based/SVM methods.\n\nOverall: Logistic Regression is the most stable and best-performing model for this dataset, despite class imbalance."
  },
  {
    "objectID": "slides.html#odds-ratios-and-risk-stratification",
    "href": "slides.html#odds-ratios-and-risk-stratification",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Odds ratios and risk stratification",
    "text": "Odds ratios and risk stratification"
  },
  {
    "objectID": "slides.html#interpretation-forest-plot-odds-ratios",
    "href": "slides.html#interpretation-forest-plot-odds-ratios",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Forest Plot (Odds Ratios)",
    "text": "Interpretation — Forest Plot (Odds Ratios)\n\n\nHypertension\nStrongest predictor. OR &gt; 2 with CI fully above 1 → hypertensive patients have more than double the odds of stroke.\nAge (per year)\nOR slightly &gt; 1 with a narrow CI above 1 → each year adds a consistent increase in stroke risk.\nAverage glucose level\nOR just above 1 with CI above 1 → higher glucose gives a modest but reliable rise in stroke risk.\nOther predictors (ever married, heart disease, smoking, gender, BMI, residence, work type)\nCIs cross 1 → not statistically significant after adjustment.\nSome ORs are &gt; 1 (e.g., heart disease, smoking), suggesting possible risk, but evidence is weak in this dataset.\n\nOverall:\nHypertension, older age, and higher glucose are the clearest independent predictors of stroke.\nOther factors show smaller or uncertain effects.\nThis pattern aligns with known clinical risk factors and supports the logistic model’s value for risk stratification."
  },
  {
    "objectID": "slides.html#threshold-tuning-to-0.2-from-0.5",
    "href": "slides.html#threshold-tuning-to-0.2-from-0.5",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Threshold tuning to 0.2 from 0.5",
    "text": "Threshold tuning to 0.2 from 0.5\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "slides.html#interpretation-threshold-0.2",
    "href": "slides.html#interpretation-threshold-0.2",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "Interpretation — Threshold = 0.2",
    "text": "Interpretation — Threshold = 0.2\n\n\nSensitivity improves from 1 stroke detected → 13/59 detected\n(22%, up from 1.7%) when lowering the cutoff to 0.2.\nSpecificity stays high (≈95%), correctly classifying most non-stroke patients\n(903 out of 949 remain correctly labeled).\nOverall accuracy drops slightly (94% → 91%), but balanced accuracy improves\n(≈0.51 → ≈0.59), reflecting better sensitivity–specificity trade-off.\n\nOverall:\nLowering the threshold captures more true stroke cases with only a moderate increase in false positives — a clinically reasonable trade-off for early risk detection."
  },
  {
    "objectID": "slides.html#conclusion",
    "href": "slides.html#conclusion",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "4. Conclusion",
    "text": "4. Conclusion"
  },
  {
    "objectID": "slides.html#references",
    "href": "slides.html#references",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "References",
    "text": "References\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Palacios, F. S. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "people/barbosa-renan/index.html#education",
    "href": "people/barbosa-renan/index.html#education",
    "title": "Renan Monteiro Barbosa",
    "section": "Education",
    "text": "Education\nB.S. Mechanical Engineering | Univevrsity of West Florida"
  },
  {
    "objectID": "people/basnet-shree/index.html#education",
    "href": "people/basnet-shree/index.html#education",
    "title": "Shree Krishna Basnet",
    "section": "Education",
    "text": "Education\nB.S. Mechanical Engineering | Univevrsity of West Florida"
  },
  {
    "objectID": "stroke_slides.html#predicting-stroke-risk-from-common-health-indicators",
    "href": "stroke_slides.html#predicting-stroke-risk-from-common-health-indicators",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Predicting Stroke Risk from Common Health Indicators",
    "text": "Predicting Stroke Risk from Common Health Indicators\nA Binary Logistic Regression and Machine Learning Comparison  Author:  Shree Krishna M.S Basnet, Renan\nSupervisor:   Dr.Cohen"
  },
  {
    "objectID": "stroke_slides.html#stroke-analysis-and-early-prediction",
    "href": "stroke_slides.html#stroke-analysis-and-early-prediction",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Stroke analysis and early prediction",
    "text": "Stroke analysis and early prediction\n\n\nStroke comes without warning ,fatal , and can be partly prevented. Known to be major cause of death and long-term disability; a single event can even make humanbeing paralysis for life long.\n\n\nFactors that can be catalyst possess more risk such as hypertension, high glucose / diabetes, heart disease, smoking, and obesity (BMI).\n\n\nThese factors are already recorded in routine care (age, blood-pressure history, glucose, BMI, smoking status) but are always overlooked without quality analysis till depth.\n\n\nMotivation for analysis : use these routine measurements to build an interpretable logistic regression model, and compare it with machine-learning methods, to help us find high risk patient for prevention and counselling."
  },
  {
    "objectID": "stroke_slides.html#research-motivation-objectives",
    "href": "stroke_slides.html#research-motivation-objectives",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Research motivation & Objectives",
    "text": "Research motivation & Objectives\n\n\nWhich is common, most vital health indicator connected with stroke risk?\n\n\nHow well can a binary logistic regression model separate stroke cases from non-stroke?\n\n\nDo more complex machine learning models (Decision Tree, Random Forest, GBM, kNN, SVM) provide upgrade or liable, relevant result over logistic regression?\n\n\nHow does class imbalance (rare stroke outcome) affect model performance and choice of probability threshold?\n\n\n Objectives \n\n\nBuild an interpretable logistic regression model for stroke prediction.\n\n\nCompare performance with several ML classifiers on the same train/test split.\n\n\nEvaluate using Accuracy, Sensitivity, Specificity, ROC, AUC, and Youden’s J.\n\n\nExplore threshold tuning to improve detection of stroke cases."
  },
  {
    "objectID": "stroke_slides.html#data-key-variables",
    "href": "stroke_slides.html#data-key-variables",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Data & Key Variables",
    "text": "Data & Key Variables\n 1. Dataset \n\n\nPublic stroke dataset (Kaggle).\n\n\nN = 3,357 patients after cleaning and removing missing values.\n\n\nBinary outcome: Stroke (Yes / No).\n\n\n\n 2. Main predictors \n\n\nDemographic: Age, Gender, Ever_married, Work_type, Residence_type.\n\n\nClinical: Hypertension, Heart_disease.\n\n\nBehavioural / metabolic: Smoking_status, BMI, Average glucose level.\n\n\n\n 3. Coding \n\n\nCategorical variables recoded to numeric levels (1, 2, 3, …).\n\n\nOutcome stroke coded as factor with levels No and Yes.\n\n\nNon-predictive ID column removed."
  },
  {
    "objectID": "stroke_slides.html#class-imbalance-in-stroke-outcome",
    "href": "stroke_slides.html#class-imbalance-in-stroke-outcome",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Class Imbalance in Stroke Outcome",
    "text": "Class Imbalance in Stroke Outcome\n1. Outcome distribution\n\n\nStroke (Yes): ≈ 5–6% of patients\n\n\nNo stroke (No): ≈ 94–95% of patients\n\n\n2. Why this matters\n\n\nA model can reach &gt; 90% accuracy by predicting “No stroke.”\n\n\nHigh accuracy does not mean good stroke detection.\n\n\nMust evaluate using Sensitivity, Specificity, and AUC.\n\n\n3. Evaluation focus\n\n\nSensitivity: detects stroke cases (true positives)\n\n\nSpecificity: detects non-stroke cases\n\n\nPrecision: correctness of predicted stroke cases\n\n\nAUC: overall ranking ability"
  },
  {
    "objectID": "stroke_slides.html#data-preparation",
    "href": "stroke_slides.html#data-preparation",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n\nRemoved rows with missing or inconsistent values(e.g., “Unknown”, “N/A”).\n\n\nConverted variables to numeric / factor formats appropriate for modelling.\n\n\nChecked ranges of Age, BMI, and Glucose for obvious data errors or outliers.\n\n\nDefined strokeclean as the final cleaned dataset used in modelling.\n\n\nUsed a 70% training / 30% test split to assess out-of-sample performance."
  },
  {
    "objectID": "stroke_slides.html#exploratory-data-analysis-overview",
    "href": "stroke_slides.html#exploratory-data-analysis-overview",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Exploratory Data Analysis (Overview)",
    "text": "Exploratory Data Analysis (Overview)\n Our goal is to understand how key health indicators changes between patients with and without stroke. \n\n We first examine: \n\n\n\nDistributions of Age, BMI, and Average Glucose\n\n\nStroke rates across Hypertension, Heart Disease, Smoking\n\n\nCorrelations among numeric predictors\n\n\n\n\n These insights help identify which predictors may have the strongest relationship with stroke risk."
  },
  {
    "objectID": "stroke_slides.html#density-plots-for-age-bmi-and-glucose",
    "href": "stroke_slides.html#density-plots-for-age-bmi-and-glucose",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Density Plots for Age, BMI, and Glucose",
    "text": "Density Plots for Age, BMI, and Glucose\n\n\nFigure 1"
  },
  {
    "objectID": "stroke_slides.html#interpretation-of-key-continuous-predictors",
    "href": "stroke_slides.html#interpretation-of-key-continuous-predictors",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation of Key Continuous Predictors",
    "text": "Interpretation of Key Continuous Predictors\n\n\nAge\n\n\nSmooth distribution from late teens.\n\n\nMajority in 40–70 = highest-risk band.\n\n\nNo sharp clusters = good continuous predictor.\n\n\n\n\nAverage Glucose Level\n\n\nClear right-skew; tail extends beyond 200 mg/dL.\n\n\nSmall subgroup with metabolic issues (likely diabetic).\n\n\nStrong link to cardiovascular and stroke risk.\n\n\n\n\nBMI\n\n\nCompact range (~22–35) with few outliers.\n\n\nLess variation = weaker predictive power.\n\n\nConsistent with medical evidence and our model."
  },
  {
    "objectID": "stroke_slides.html#interpretation-of-key-categorical-predictors",
    "href": "stroke_slides.html#interpretation-of-key-categorical-predictors",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation of Key Categorical Predictors",
    "text": "Interpretation of Key Categorical Predictors\n\n\nGender\n\n\nMore females (61%) than males (39%).\n\n\nImbalance may influence how gender appears in the model.\n\n\n\n\nResidence Type\n\n\nNearly equal Urban (51%) and Rural (49%) split.\n\n\nNo major geographic bias in the sample.\n\n\n\n\nSmoking Status\n\n\nNever smokers (54%) form the majority.\n\n\nFormer (25%) and current (22%) smokers well represented.\n\n\nEnough variation to assess smoking as a stroke risk factor."
  },
  {
    "objectID": "stroke_slides.html#stroke-risk-for-clinical-and-behavioral-predictors",
    "href": "stroke_slides.html#stroke-risk-for-clinical-and-behavioral-predictors",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Stroke Risk for Clinical and Behavioral Predictors",
    "text": "Stroke Risk for Clinical and Behavioral Predictors\n\n\nFigure 2: Stroke percentages (95% CI) by hypertension, heart disease, and smoking status."
  },
  {
    "objectID": "stroke_slides.html#interpretation-of-stroke-risk-vs-prediators",
    "href": "stroke_slides.html#interpretation-of-stroke-risk-vs-prediators",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation of stroke risk vs prediators",
    "text": "Interpretation of stroke risk vs prediators\n\n\nHypertension\n\n\nHigher stroke risk in hypertensive patients.\n\n\nClear CI separation → strong association.\n\n\n\n\nHeart Disease\n\n\nHigher stroke percentages among those with heart disease.\n\n\nConsistent with known cardiovascular risk patterns.\n\n\n\n\nSmoking Status\n\n\nFormer and current smokers show higher stroke risk.\n\n\nReflects long-term vascular impact of tobacco exposure.\n\n\n\n\nOverall\n\n\nVascular risks (hypertension, heart disease) and behavioural risk (smoking)\n\n\nall show elevated stroke likelihood. Clinically consistent."
  },
  {
    "objectID": "stroke_slides.html#correlation-among-key-numeric-prediators",
    "href": "stroke_slides.html#correlation-among-key-numeric-prediators",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Correlation among key numeric prediators",
    "text": "Correlation among key numeric prediators"
  },
  {
    "objectID": "stroke_slides.html#interpretation-correlation-heatmap",
    "href": "stroke_slides.html#interpretation-correlation-heatmap",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Correlation Heatmap",
    "text": "Interpretation — Correlation Heatmap\n\n\nOverall\n\n\nCorrelations are weak–moderate (0.00–0.26).\n\n\nNo multicollinearity concerns.\n\n\n\n\nAge\n\n\nPositive links with glucose (0.24), hypertension (0.26), heart disease (0.26).\n\n\nMatches aging-related cardiovascular risk trends.\n\n\n\n\nBMI\n\n\nVery weak correlations (0.04–0.16).\n\n\nActs independently in this dataset.\n\n\n\n\nAverage Glucose\n\n\nModerate links with hypertension (0.17) and heart disease (0.14).\n\n\nConsistent with metabolic–vascular patterns.\n\n\n\n\nHypertension & Heart Disease\n\n\nWeak correlation (0.11) → related but not redundant."
  },
  {
    "objectID": "stroke_slides.html#odds-ratios-and-confidence-intervals",
    "href": "stroke_slides.html#odds-ratios-and-confidence-intervals",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Odds ratios and confidence intervals",
    "text": "Odds ratios and confidence intervals\n\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + heart_disease + avg_glucose_level + \n    bmi + smoking_status + gender + ever_married, family = binomial(link = \"logit\"), \n    data = stroke_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.924079   0.992603  -8.991   &lt;2e-16 ***\nage                0.072637   0.008089   8.979   &lt;2e-16 ***\nhypertension       0.455377   0.229005   1.988   0.0468 *  \nheart_disease      0.487385   0.270707   1.800   0.0718 .  \navg_glucose_level  0.003777   0.001705   2.215   0.0267 *  \nbmi                0.006536   0.015709   0.416   0.6774    \nsmoking_status     0.234263   0.129934   1.803   0.0714 .  \ngender             0.230592   0.206934   1.114   0.2651    \never_married       0.118496   0.311030   0.381   0.7032    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 953.42  on 2348  degrees of freedom\nResidual deviance: 776.77  on 2340  degrees of freedom\nAIC: 794.77\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "stroke_slides.html#odds-ratios-and-confidence-intervals-1",
    "href": "stroke_slides.html#odds-ratios-and-confidence-intervals-1",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Odds ratios and confidence intervals",
    "text": "Odds ratios and confidence intervals\n\n\n                     OR 2.5 % 97.5 %\n(Intercept)       0.000 0.000  0.001\nage               1.075 1.059  1.093\nhypertension      1.577 0.996  2.450\nheart_disease     1.628 0.942  2.732\navg_glucose_level 1.004 1.000  1.007\nbmi               1.007 0.975  1.037\nsmoking_status    1.264 0.978  1.629\ngender            1.259 0.843  1.901\never_married      1.126 0.590  2.013"
  },
  {
    "objectID": "stroke_slides.html#interpretation-odds-ratios-logistic-regression",
    "href": "stroke_slides.html#interpretation-odds-ratios-logistic-regression",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Odds Ratios (Logistic Regression)",
    "text": "Interpretation — Odds Ratios (Logistic Regression)\n\n\nAge (OR 1.075, CI 1.059–1.093)\nStrongest predictor; each year ↑ stroke odds ~7.5%.\nHypertension (OR 1.577, CI 0.996–2.450)\n~58% higher odds; borderline but clinically meaningful.\nHeart disease (OR 1.628, CI 0.942–2.733)\n~63% higher odds; CI includes 1 → not statistically strong.\nAvg glucose (OR 1.004, CI 1.000–1.007)\nSlight ↑ in odds; marginal significance; aligns with metabolic risk.\nBMI (OR 1.007, CI 0.975–1.037)\nNo meaningful effect; CI overlaps 1.\nSmoking\nFormer: OR 1.263 (weak).\nCurrent: OR 1.598 (suggestive ↑ risk).\nGender (Female) (OR 1.259, CI 0.842–1.903)\nSlight ↑ odds; not significant.\nEver married (OR 1.126, CI 0.590–2.013)\nNo clear effect."
  },
  {
    "objectID": "stroke_slides.html#logistic-regression-performance-test-set",
    "href": "stroke_slides.html#logistic-regression-performance-test-set",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Logistic Regression performance (Test Set)",
    "text": "Logistic Regression performance (Test Set)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  949  58\n       Yes   0   1\n                                         \n               Accuracy : 0.9425         \n                 95% CI : (0.9262, 0.956)\n    No Information Rate : 0.9415         \n    P-Value [Acc &gt; NIR] : 0.4811         \n                                         \n                  Kappa : 0.0314         \n                                         \n Mcnemar's Test P-Value : 7.184e-14      \n                                         \n            Sensitivity : 0.0169492      \n            Specificity : 1.0000000      \n         Pos Pred Value : 1.0000000      \n         Neg Pred Value : 0.9424032      \n             Prevalence : 0.0585317      \n         Detection Rate : 0.0009921      \n   Detection Prevalence : 0.0009921      \n      Balanced Accuracy : 0.5084746      \n                                         \n       'Positive' Class : Yes"
  },
  {
    "objectID": "stroke_slides.html#interpretation-logistic-regression-performance-test-set",
    "href": "stroke_slides.html#interpretation-logistic-regression-performance-test-set",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Logistic Regression Performance (Test Set)",
    "text": "Interpretation — Logistic Regression Performance (Test Set)\n\n\nAccuracy: 94.25%\nHigh due to class imbalance (only ~6% stroke cases); not meaningful for detection.\nSensitivity: 0.017\nDetected 1 of 59 stroke cases → model fails to identify strokes.\nSpecificity: 1.00\nPerfect for non-stroke cases; predicts “No stroke” extremely well.\nPrecision (PPV): 1.00\nWhen predicting “Yes,” it was correct — but it predicted yes only once → misleadingly high.\nNPV: 0.942\nMost “No” predictions are correct, consistent with majority class.\nKappa: 0.031\nNear zero → model performs only slightly better than random for imbalanced data.\nBalanced Accuracy: 0.508\nEquivalent to chance level when sensitivity and specificity are weighted equally.\nMcNemar’s Test: p &lt; 0.0001\nErrors are systematically biased toward predicting “No stroke.”\n\nOverall:\nModel performs well for non-stroke patients but fails severely for stroke detection.\nClass imbalance dominates performance → requires resampling, class weights, or other imbalance-handling methods."
  },
  {
    "objectID": "stroke_slides.html#roc-curve-and-auc-for-the-logistic-model",
    "href": "stroke_slides.html#roc-curve-and-auc-for-the-logistic-model",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "ROC curve and AUC for the logistic model",
    "text": "ROC curve and AUC for the logistic model"
  },
  {
    "objectID": "stroke_slides.html#interpretation-roc-curve-auc",
    "href": "stroke_slides.html#interpretation-roc-curve-auc",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — ROC Curve & AUC",
    "text": "Interpretation — ROC Curve & AUC\n\n\nAUC = 0.815 → indicates good discriminative ability.\n(0.5 = none, 0.7–0.8 = acceptable, 0.8–0.9 = good, &gt;0.9 = excellent)\nROC evaluates performance across all thresholds, not just 0.5.\nDespite poor sensitivity at the 0.5 cutoff,\nthe AUC shows the model can separate stroke vs non-stroke reasonably well if a better threshold is chosen.\nThe gap between strong AUC and weak sensitivity reflects:\n• severe class imbalance\n• the need for customized probability cutoffs in medical prediction\n\nImplications for improvement: - Threshold tuning\n- Cost-sensitive / class-weighted training\n- Resampling (e.g., SMOTE, oversampling)\n\n\n\n\n  No  Yes \n3177  180"
  },
  {
    "objectID": "stroke_slides.html#machine-learning-model-comparison",
    "href": "stroke_slides.html#machine-learning-model-comparison",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Machine-learning model comparison",
    "text": "Machine-learning model comparison\n\n\n          Model       AUC  Accuracy Sensitivity Specificity\nAccuracy     LR 0.7793712 0.9433962  0.00000000   0.9968520\nAccuracy1  TREE 0.6475263 0.9414101  0.01851852   0.9937041\nAccuracy2    RF 0.7250496 0.9463754  0.00000000   1.0000000\nAccuracy3   GBM 0.7592884 0.9433962  0.00000000   0.9968520\nAccuracy4   KNN 0.6668998 0.9463754  0.00000000   1.0000000\nAccuracy5   SVM 0.6390929 0.9414101  0.00000000   0.9947534"
  },
  {
    "objectID": "stroke_slides.html#interpretation-model-comparison",
    "href": "stroke_slides.html#interpretation-model-comparison",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Model Comparison",
    "text": "Interpretation — Model Comparison\n\n\nAll six models show very high accuracy & specificity, driven by the dataset’s ~6% stroke rate (strong class imbalance).\nSensitivity is extremely low for every model → almost none correctly identify stroke cases.\nBest AUC values:\n• Logistic Regression: 0.78\n• GBM: 0.76\n→ These models discriminate high- vs low-risk patients better than others, despite poor sensitivity at the 0.5 threshold.\nTree-based models (DT, RF, GBM) show slightly higher sensitivity than LR, but still only ~1–2%.\nKNN and SVM detect 0 stroke cases at the default threshold, despite high accuracy.\nOverall: Accuracy is misleading; all models excel at predicting “No stroke” but fail at detecting positives.\nConfirms severe class imbalance → meaningful improvement requires:\n• threshold tuning,\n• resampling (SMOTE/oversampling),\n• cost-sensitive learning."
  },
  {
    "objectID": "stroke_slides.html#roc-comaprision-for-all-6-model",
    "href": "stroke_slides.html#roc-comaprision-for-all-6-model",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "ROC comaprision for all 6 model",
    "text": "ROC comaprision for all 6 model"
  },
  {
    "objectID": "stroke_slides.html#interpretation-roc-comparison-across-models",
    "href": "stroke_slides.html#interpretation-roc-comparison-across-models",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — ROC Comparison Across Models",
    "text": "Interpretation — ROC Comparison Across Models\n\n\nLogistic Regression (AUC = 0.779) shows the best overall discrimination between stroke vs non-stroke.\nGBM (AUC = 0.759) and Random Forest (AUC = 0.725) also perform well, close to LR.\nKNN (AUC = 0.667) performs moderately — better than chance, but weaker than LR and tree ensembles.\nDecision Tree (AUC = 0.648) and SVM (AUC = 0.639) have the lowest AUC values → weakest discrimination.\nAll models score above 0.5, meaning they perform better than random guessing, but with clear differences in quality.\nROC curves show that LR, RF, and GBM extract the strongest predictive patterns, outperforming simpler tree models and distance-based/SVM methods.\n\nOverall: Logistic Regression is the most stable and best-performing model for this dataset, despite class imbalance."
  },
  {
    "objectID": "stroke_slides.html#interpretation-forest-plot-odds-ratios",
    "href": "stroke_slides.html#interpretation-forest-plot-odds-ratios",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Forest Plot (Odds Ratios)",
    "text": "Interpretation — Forest Plot (Odds Ratios)\n\n\nHypertension\nStrongest predictor. OR &gt; 2 with CI fully above 1 → hypertensive patients have more than double the odds of stroke.\nAge (per year)\nOR slightly &gt; 1 with a narrow CI above 1 → each year adds a consistent increase in stroke risk.\nAverage glucose level\nOR just above 1 with CI above 1 → higher glucose gives a modest but reliable rise in stroke risk.\nOther predictors (ever married, heart disease, smoking, gender, BMI, residence, work type)\nCIs cross 1 → not statistically significant after adjustment.\nSome ORs are &gt; 1 (e.g., heart disease, smoking), suggesting possible risk, but evidence is weak in this dataset.\n\nOverall:\nHypertension, older age, and higher glucose are the clearest independent predictors of stroke.\nOther factors show smaller or uncertain effects.\nThis pattern aligns with known clinical risk factors and supports the logistic model’s value for risk stratification."
  },
  {
    "objectID": "stroke_slides.html#threshold-tuning-to-0.2-from-0.5",
    "href": "stroke_slides.html#threshold-tuning-to-0.2-from-0.5",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Threshold tuning to 0.2 from 0.5",
    "text": "Threshold tuning to 0.2 from 0.5\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  903  46\n       Yes  46  13\n                                          \n               Accuracy : 0.9087          \n                 95% CI : (0.8892, 0.9258)\n    No Information Rate : 0.9415          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1719          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.22034         \n            Specificity : 0.95153         \n         Pos Pred Value : 0.22034         \n         Neg Pred Value : 0.95153         \n             Prevalence : 0.05853         \n         Detection Rate : 0.01290         \n   Detection Prevalence : 0.05853         \n      Balanced Accuracy : 0.58593         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "stroke_slides.html#interpretation-threshold-0.2",
    "href": "stroke_slides.html#interpretation-threshold-0.2",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Interpretation — Threshold = 0.2",
    "text": "Interpretation — Threshold = 0.2\n\n\nSensitivity improves from 1 stroke detected → 13/59 detected\n(22%, up from 1.7%) when lowering the cutoff to 0.2.\nSpecificity stays high (≈95%), correctly classifying most non-stroke patients\n(903 out of 949 remain correctly labeled).\nOverall accuracy drops slightly (94% → 91%), but balanced accuracy improves\n(≈0.51 → ≈0.59), reflecting better sensitivity–specificity trade-off.\n\nOverall:\nLowering the threshold captures more true stroke cases with only a moderate increase in false positives — a clinically reasonable trade-off for early risk detection."
  },
  {
    "objectID": "stroke_slides.html#conclusion",
    "href": "stroke_slides.html#conclusion",
    "title": "IDC-6940 - Capstone Project Fall-2025",
    "section": "Conclusion",
    "text": "Conclusion\n\n\nStroke was a rare outcome (~5%), creating strong class imbalance and making detection of positive cases difficult.\nKey predictors across models were age, hypertension, heart disease, average glucose, and smoking — consistent with established clinical risk factors.\nLogistic Regression showed good discrimination (AUC ≈ 0.78) and remains a strong interpretable baseline model.\nDespite good AUC, sensitivity at the default 0.5 threshold was extremely low due to class imbalance.\nLowering the threshold to 0.2 improved sensitivity (~22%) while maintaining high specificity (~95%), offering a more clinically reasonable trade-off.\nTree-based ensembles (RF, GBM) achieved slightly higher AUC but did not dramatically improve sensitivity and were less interpretable.\nAccuracy and specificity were high for all models, but misleading, as they mainly reflected the dominance of the non-stroke class.\nResults show that routine health indicators can meaningfully separate higher- vs lower-risk individuals, but handling class imbalance is critical."
  },
  {
    "objectID": "literature/renan-blog-post-week2/index.html",
    "href": "literature/renan-blog-post-week2/index.html",
    "title": "Literature Review Assignment for Week 2",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "literature/renan-blog-post-week2/index.html#article-1",
    "href": "literature/renan-blog-post-week2/index.html#article-1",
    "title": "Literature Review Assignment for Week 2",
    "section": "Article 1",
    "text": "Article 1\nFrom Logistic Regression to the Perceptron Algorithm: Exploring Gradient Descent with Large Step Sizes.[1]\nThe author presents some interesting findings that by connecting Logistic regression with gradient descent there is a link with the perceptron algorithm. With really large steps it acts like a perceptron which in some sense links it back to the Deep Equilibrium networks study. This paper is interesting because it is counter intuitive and brings a lot of things to reflect about classification and optimization theory."
  },
  {
    "objectID": "literature/renan-blog-post-week2/index.html#article-2",
    "href": "literature/renan-blog-post-week2/index.html#article-2",
    "title": "Literature Review Assignment for Week 2",
    "section": "Article 2",
    "text": "Article 2\nLarge Language Model Confidence Estimation via Black-Box Access.[2]\nThis paper addresses the problem of estimating the confidence of large language model (LLM) outputs when only black-box (query-only) access is available. It is a simple technique that uses Logistic Regression to classify and validate the confidence of the outputs. The problem of using the black-box models is that there is no control over the model itself, but in some cases the benefits and the value of buying these services that provide a black-box model outweighs training your own custom so this is a framework that attempts to overcome the challenges.\n\nReferences\n\n\n1. Tyurin, A. (2024). From logistic regression to the perceptron algorithm: Exploring gradient descent with large step sizes. https://arxiv.org/abs/2412.08424\n\n\n2. Pedapati, T., Dhurandhar, A., Ghosh, S., Dan, S., & Sattigeri, P. (2025). Large language model confidence estimation via black-box access. https://arxiv.org/abs/2406.04370"
  },
  {
    "objectID": "literature/renan-blog-post-week4/index.html",
    "href": "literature/renan-blog-post-week4/index.html",
    "title": "Literature Review Assignment for Week 4",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "literature/renan-blog-post-week4/index.html#article-1",
    "href": "literature/renan-blog-post-week4/index.html#article-1",
    "title": "Literature Review Assignment for Week 4",
    "section": "Article 1",
    "text": "Article 1\nIncorporating LLM Priors into Tabular Learners.[1]\nThere have been implementations of transformer based architectures for tabular data. Most of the time it has been utilized for generating synthetic data for likelihood free models or for cases where there is not enough data for fitting a model.\nThe goal of this research was to bootstrap a way so one could use off the shelf models like Chatgpt which are really good at generalization to perform similarly to dedicated models trained on tabular data such as tabLLM. This is important because it is fairly cheaper and more accessible than training a model from scratch and it overcomes the complexities of developing a specialized encoder.\nThe methodology is a pretty hacky solution where they serialized the tabular data so they could prompt the models are are just trying to obtain back a categorization through prompt engineering which will be attributed a value which is manually tuned by the authors and this value is later used on the Monotonic Logistic Regression.\nThe limitations are quite clear. There is no way to guarantee the black box model output will be consistent. You have to manually categorize and do some prompt engineering. The model has bias so it either works really well or it doesn’t.\nThe bright side is that this approach is extremely cheap and is accessible. It can be used to test ideas and hypothesis as well rapidly prototype before committing to a more definite solution such as tabLLM."
  },
  {
    "objectID": "literature/renan-blog-post-week4/index.html#article-2",
    "href": "literature/renan-blog-post-week4/index.html#article-2",
    "title": "Literature Review Assignment for Week 4",
    "section": "Article 2",
    "text": "Article 2\nUsing a monotonic density ratio model to increase the power of the goodness-of-fit test for logistic regression models with case-control data.[2]\nCase-control sampling is used because it is a quick, economical, and efficient method for studying rare diseases or outcomes, long latent periods, or outbreaks. It allows researchers to investigate multiple potential risk factors simultaneously for a single outcome and is especially useful when prospective cohort studies are not feasible.\nThe author’s goal seems to be to improve the statistical power of the goodness-of-fit test for logistic regression models when used with case-control data. They improved upon a previous popular method from Qin and Zhang, instead of using the nonparametric empirical distribution function, we use the constrained nonparametric MLE of G(x) to further improve the power performance of the Kolmogorov-Smirnov-type goodness-of-fit test for logistic models.\nBefore drawing conclusions from a logistic regression model, it’s crucial to verify that the model’s assumptions hold true for the data and there are many limitations. Case Study data is specially complicated because there is not enough data and there are too many unknowns.\nThe authors spare no comments on the limitations, the bigger limitations are: - The test is designed for goodness-of-fit and cannot be used to compare two different logistic regression models - The test has no power when the only covariate is categorical. In this situation, the logistic model is “saturated,” meaning it perfectly fits the data by definition and cannot be misspecified.\nTheir results are overall quite interesting as they demonstrated that they could bootstrap an algorithm that is quite clever and intuitively it shouldn’t work. It is a hard problem to solve so it is interesting out of the box thinking\n\nReferences\n\n\n1. Zhu, M., Stanivuk, S., Petrovic, A., Nikolic, M., & Lio, P. (2023). Incorporating LLM priors into tabular learners. https://arxiv.org/abs/2311.11628\n\n\n2. Wang, C., Liu, Z., & Wang, X. (2024). Using a monotonic density ratio model to increase the power of the goodness-of-fit test for logistic regression models with case-control data. Statistics in Medicine, 43(22), 4272–4286."
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature Review",
    "section": "",
    "text": "These are the literature review done by all the students during this semester.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiterature Review Assignment for Week 2\n\n\n\nliterature review\n\nweek 2\n\nrenan\n\n\n\nLiterature review for the Week 2 of the course IDC-6940 for Fall 2025\n\n\n\n\n\nRenan monteiro barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nLiterature Review Assignment for Week 3\n\n\n\nliterature review\n\nweek 3\n\nrenan\n\n\n\nLiterature review for the Week 3 of the course IDC-6940 for Fall 2025\n\n\n\n\n\nRenan monteiro barbosa\n\n\n\n\n\n\n\n\n\n\n\n\nLiterature Review Assignment for Week 4\n\n\n\nliterature review\n\nweek 4\n\nrenan\n\n\n\nLiterature review for the Week 4 of the course IDC-6940 for Fall 2025\n\n\n\n\n\nRenan monteiro barbosa\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "literature/renan-blog-post-week3/index.html",
    "href": "literature/renan-blog-post-week3/index.html",
    "title": "Literature Review Assignment for Week 3",
    "section": "",
    "text": "This week I review 2 articles"
  },
  {
    "objectID": "literature/renan-blog-post-week3/index.html#article-1",
    "href": "literature/renan-blog-post-week3/index.html#article-1",
    "title": "Literature Review Assignment for Week 3",
    "section": "Article 1",
    "text": "Article 1\nBERT or FastText? A Comparative Analysis of Contextual as well as Non-Contextual Embeddings.[1]\nMy personal opinion: This research doesn’t explicitly state why Logistic Regression is important, but it did use it as the classifier for all of the experiments to maintain methodological simplicity. All embeddings were passed to a multinomial logistic regression (MLR) classifier for classification into target labels. Which shows the versatility of logistic regression when elaborating an experiment to test a hypothesis.\nThe main goal of the paper is to analyze the effectiveness of non-contextual embeddings from BERT models (MuRIL and MahaBERT) and FastText models (IndicFT and MahaFT) for NLP tasks. The authors compare these embeddings to contextual and compressed variants of BERT aiming to fill a research gap, because previous research did not explore non-contextual embeddings.\nThe research is important because it addresses the challenges faced by NLP in low-resource languages (The ones that lack big annotated datasets to properly train). The selection of an effective embedding method is extremely important for strong NLP performance. The research tries a promising alternative, non-contextual BERT embeddings, which can be obtained through a simple table lookup, unlike contextual embeddings that require a full forward pass through the model. This is particularly relevant for getting model performance with much better computational efficiency.\nThe methodology is quite interesting. For the FastText, which is a non-contextual embedding by default, they had to create a custom vocabulary. Which was achieved by concatenating the training and validation datasets and then passing them through a text vectorizer, which generated vectors for every word in the dataset. The vectorizer returned the vocabulary as a list of words in decreasing order of their frequency. Then the FastText model was then loaded using the FastText library, and for each word in the vocabulary, a word vector was retrieved to construct the embedding matrix. For each sentence, the text was split into individual words, and the corresponding embeddings were retrieved from the embedding matrix. These embeddings were then averaged to produce the final sentence embeddings.\nFurthermore they did not stop with FastText, they also experimented with compressed embeddings by reducing the dimensionality from 768 (the traditional BERT embedding dimension) to 300. This compression was performed using Singular Value Decomposition (SVD) to select the most relevant features, extracting the top 300 components for all the combinations of contextual as well as non-contextual for MahaBERT as well as Muril.\nIn this approach it’s interesting how they did use Logistic regression for simplicity. All embeddings were then passed to a multiple logistic regression(MLR) classifier for classification into target labels.\nI understood that as a result they did show that contextual BERT embeddings perform better than non-contextual ones, including both non-contextual BERT embeddings and FastText. So in the end they proved that their approach did not improve much or provided much resource to support this different approach. They also showed that when non-contextual BERT embeddings are compressed, their performance drops, and FastText performs better than compressed noncontextual BERT. But this is a questionable finding.\nThe limitations of the research is that even in most cases it was apparent that compression lowers the performance of non-contextual BERT embeddings. The effect of compression on contextual embeddings varies across datasets and there is no consistent way to properly derive conclusions."
  },
  {
    "objectID": "literature/renan-blog-post-week3/index.html#article-2",
    "href": "literature/renan-blog-post-week3/index.html#article-2",
    "title": "Literature Review Assignment for Week 3",
    "section": "Article 2",
    "text": "Article 2\nPriority prediction of Asian Hornet sighting report using machine learning methods.[2]\nThe goal of the research is to create an automated system to predict the priority of Asian giant hornet sighting reports. Asian giant hornets are an invasive species that poses a significant threat to native bee populations and local beekeeping, as well as to public safety due to their aggressive nature and potent venom. So it’s very important that reports are properly assessed for priority.\nThe authors did model the priority prediction of sighting reports as a two-classification problem. This approach was pretty clever and simple. The goal was to just classify reports as either a “true positive” or a “false positive”.\nTheir methodology is a straightforward application of logistic regression with feature extraction. They came to realize that they needed Location Feature, Time Feature, Image Feature, Text Feature.\nLocation Feature considers the probability of a hornet being observed at a specific location based on known hornet migration patterns and habits. Time Feature accounts for the hornet’s seasonal behavior. Since hornets are most active from April to December, a report submitted during this period is more likely to be positive. Image Feature is the number of images attached to a report and they came to notice that it is correlated with the increase of its credibility. Text Feature is the textual description’s length and keywords. A longer text is considered more credible because it contains more evidence. The model also uses a specific dictionary of hornet characteristics to identify relevant keywords.\nThey then used a weighted binary cross-entropy function and the logistic regression is just mapping the probability given the feature vector.\nThe model achieved an average prediction accuracy of 83.5% on positive reports with the best weighting parameter settings, but still far from other works which achieved about 93% using Deep Learning. So this is the main limitation, still needs a lot of improvement or maybe it will never outmatch other methods due to hidden limitations.\nMy opinion on this paper is that the Logistic Regression has interesting properties, after all it is a generalized linear model, which conducts mapping from any real number to probability values.\n\nReferences\n\n\n1. Shanbhag, A., Jadhav, S., Thakurdesai, A., Sinare, R., & Joshi, R. (2025). Non-contextual BERT or FastText? A comparative analysis. https://arxiv.org/abs/2411.17661\n\n\n2. Liu, Y., Guo, J., Dong, J., Jiang, L., & Ouyang, H. (2021). Priority prediction of asian hornet sighting report using machine learning methods. 2021 IEEE International Conference on Software Engineering and Artificial Intelligence (SEAI), 7–11. https://doi.org/10.1109/seai52285.2021.9477549"
  },
  {
    "objectID": "posts/renan-blog-post-draft10/index.html",
    "href": "posts/renan-blog-post-draft10/index.html",
    "title": "Draft Final Report - v10",
    "section": "",
    "text": "This draft attempts to return to original research goals as presented on the Week 06"
  },
  {
    "objectID": "posts/renan-blog-post-draft10/index.html#introduction",
    "href": "posts/renan-blog-post-draft10/index.html#introduction",
    "title": "Draft Final Report - v10",
    "section": "1. Introduction",
    "text": "1. Introduction\nStroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Because stroke often occurs suddenly and can result in long-term neurological impairment, early identification of individuals at elevated risk is critical for prevention and timely intervention. Data-driven risk prediction models enable clinicians and public health professionals to quantify individual-level risk and to target high-risk groups for lifestyle counselling and clinical management.\nLogistic Regression (LR) is one of the most widely used approaches for modelling binary outcomes such as disease presence or absence[2]. It extends linear regression to cases where the outcome is categorical and provides interpretable coefficients and odds ratios that describe how each predictor is associated with the probability of the event. LR has been applied across a wide range of domains, including child undernutrition and anaemia[3], road traffic safety[4–6], health-care utilisation and clinical admission decisions[7], and fraud detection[8]. These applications highlight both the flexibility of LR and its suitability for real-world decision-making problems.\nIn this project, we analyse a publicly available stroke dataset that includes key demographic, behavioural, and clinical predictors such as age, gender, hypertension status, heart disease, marital status, work type, residence type, smoking status, body mass index (BMI), and average glucose level. These variables are commonly reported in the stroke and cardiovascular literature as important determinants of risk. Using this dataset, we first clean and encode the variables into the appropriate data types in order to develop and fit a Logistic Regression model for predicting the outcome of stroke.\nThen we proceed to analyse one of the fundamental issues in the application of Logistic Regression or statistical models overal, the data imbalance issue. Data imbalance is a big problem for stroke ­prediction[9]. Because of many reasons ranging from privacy to the difficulty of doing cohort studies, the fact that pre-stroke datasets are rare, dataset often contain imbalanced classifications, with most instances being non-stroke c­ases[10]. So its unnecessary to say that this imbalance can result in biased models that favour the majority and ignore the minority, resulting in low forecast accuracy. To solve this issue and increase the effectiveness of the predictive models, we plan on exploring several oversampling and undersampling methods and much more are explored and employed, the popular of which is the ­SMOTE[11],[12]."
  },
  {
    "objectID": "posts/renan-blog-post-draft10/index.html#methods",
    "href": "posts/renan-blog-post-draft10/index.html#methods",
    "title": "Draft Final Report - v10",
    "section": "2. Methods",
    "text": "2. Methods\nThe binary logistic regression model is part of a family of statistical models called generalised linear models. The main characteristic that differentiates binary logistic regression from other generalised linear models is the type of dependent (or outcome) variable.[13] A dependent variable in a binary logistic regression has two levels. For example, a variable that records whether or not someone has ever been diagnosed with a health condition like Stroke could be measured in two categories, yes and no. Likewise, someone might have coronary heart disease or not, be physically active or not, be a current smoker or not, or have any one of thousands of diagnoses or personal behaviours and characteristics that are of interest in family medicine.\nThe binary logistic regression algorithm below:\n\\[ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}x_{1} + \\cdots + \\beta_{k}x_{k}\\]\nWhere \\(\\pi = P[Y =1]\\) is the probability of the outcome.\n\nAssumptions\nBinary logistic regression relies on the following underlying assumptions to be true:\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers\nThe Sample Size is Sufficiently Large. Field recommends a minimum of 50 cases.[14] Hosmer, Lemeshow, and Sturdivant[15] suggest a minimum sample of 10 observations per independent variable in the model. Leblanc and Fitzgerald (2000)[16] suggest a minimum of 30 observations per independent variable."
  },
  {
    "objectID": "posts/renan-blog-post-draft10/index.html#analysis-and-results",
    "href": "posts/renan-blog-post-draft10/index.html#analysis-and-results",
    "title": "Draft Final Report - v10",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nImport all the dependencies:\n\n\nCode\npackages &lt;- c(\"dplyr\", \"car\", \"ResourceSelection\", \"caret\", \"pROC\",  \"logistf\", \"Hmisc\", \"rcompanion\", \"ggplot2\", \"summarytools\", \"tidyverse\", \"knitr\", \"ggpubr\", \"ggcorrplot\", \"randomForest\", \"gbm\", \"kernlab\", \"skimr\", \"corrplot\", \"scales\", \"tidyr\", \"RColorBrewer\", \"mice\", \"ROSE\", \"ranger\", \"stacks\", \"tidymodels\", \"themis\", \"gghighlight\")\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n# Set seed for reproducibility\nset.seed(123)\n\n# library(mice)\n# library(ROSE) # For SMOTE\n# library(ranger) # A fast implementation of random forests\n# library(stacks)\n# library(tidymodels)\n# library(themis)\n# library(gghighlight)\n\n\n\n\n3.1. Data Ingestion\nData source: Stroke Prediction Dataset[17]\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile healthcare-dataset-stroke-data\nstroke_path &lt;- file.path(datasets_path, \"kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv\")\nstroke1 = read_csv(stroke_path, show_col_types = FALSE)\n\n\n\n\n3.2. Exploratory Data Analysis (EDA)\nDataset Description\nThe Stroke Prediction Dataset[17] is a publically available dataset for educational purposes containing 5,110 observations containing predictors commonly associated with cerebrovascular risk. The dataset is composed of 11 clinical and demographic features and 1 feature which is id a unique identifier for the patient. The dataset has features including patient’s age, gender, presence of conditions like hypertension and heart disease, work type, residence type, average glucose level, and BMI. This dataset is primarily intended for educational purposes as it shares a lot of similarities with the Jackson Heart Study (JHS) dataset but it is not as descriptive.\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nKey Values/Range\n\n\n\n\nid\nUnique identifier for the patient\nNumeric\nUnique numeric ID\n\n\ngender\nPatient’s gender\nCharacter\nMale, Female, Other\n\n\nage\nPatient’s age in years\nNumeric\n0.08 to 82\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric (binary)\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nCharacter\nNo, Yes\n\n\nwork_type\nType of occupation\nCharacter\nPrivate, Self-employed, Govt_job, children, Never_worked\n\n\nResidence_type\nPatient’s area of residence\nCharacter\nRural, Urban\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\n≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nCharacter\n≈10.3 to 97.6 (has NA values)\n\n\nsmoking_status\nPatient’s smoking status\nCharacter\nformerly smoked, never smoked, smokes, Unknown\n\n\nstroke\nTarget Variable: Whether the patient had a stroke\nNumeric (binary)\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.1 Dataset Preprocessing\n\n\nCode\n# Handle dataset features\nstroke1[stroke1 == \"N/A\" | stroke1 == \"Unknown\" | stroke1 == \"children\" | stroke1 == \"other\"] &lt;- NA\nstroke1$bmi &lt;- round(as.numeric(stroke1$bmi), 2)\nstroke1$gender[stroke1$gender == \"Male\"] &lt;- 1\nstroke1$gender[stroke1$gender == \"Female\"] &lt;- 0\nstroke1$gender &lt;- as.numeric(stroke1$gender)\nstroke1$ever_married[stroke1$ever_married == \"Yes\"] &lt;- 1\nstroke1$ever_married[stroke1$ever_married == \"No\"] &lt;- 0\nstroke1$ever_married &lt;- as.numeric(stroke1$ever_married)\nstroke1$work_type[stroke1$work_type == \"Govt_job\"] &lt;- 1\nstroke1$work_type[stroke1$work_type == \"Private\"] &lt;- 2\nstroke1$work_type[stroke1$work_type == \"Self-employed\"] &lt;- 3\nstroke1$work_type[stroke1$work_type == \"Never_worked\"] &lt;- 4\nstroke1$work_type &lt;- as.numeric(stroke1$work_type)\nstroke1$Residence_type[stroke1$Residence_type == \"Urban\"] &lt;- 1\nstroke1$Residence_type[stroke1$Residence_type == \"Rural\"] &lt;- 2\nstroke1$Residence_type &lt;- as.numeric(stroke1$Residence_type)\nstroke1$avg_glucose_level &lt;- as.numeric(stroke1$avg_glucose_level)\nstroke1$heart_disease &lt;- as.numeric(stroke1$heart_disease)\nstroke1$hypertension &lt;- as.numeric(stroke1$hypertension)\nstroke1$age &lt;- round(as.numeric(stroke1$age), 2)\nstroke1$stroke &lt;- as.numeric(stroke1$stroke)\nstroke1$smoking_status[stroke1$smoking_status == \"never smoked\"] &lt;- 1\nstroke1$smoking_status[stroke1$smoking_status == \"formerly smoked\"] &lt;- 2\nstroke1$smoking_status[stroke1$smoking_status == \"smokes\"] &lt;- 3\nstroke1$smoking_status &lt;- as.numeric(stroke1$smoking_status)\nstroke1 &lt;- stroke1[, !(names(stroke1) %in% \"id\")]\n\n# Remove NAs and clean dataset\nstroke1$stroke &lt;- as.factor(stroke1$stroke)\nstroke1_clean &lt;- na.omit(stroke1)\nstrokeclean &lt;- stroke1_clean\nfourassume &lt;- stroke1_clean\n\nstrokeclean$stroke &lt;- factor(\n  strokeclean$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\nfourassume$stroke &lt;- factor(\n  fourassume$stroke,\n  levels = c(\"0\", \"1\"),\n  labels = c(\"No\", \"Yes\")\n)\n\n\nThe initial exploration demonstrated that the Stroke Prediction Dataset[17] has several issues requiring changes for handling missing values, converting character (categorical) features into numerical codes, and removing the identifier column.\n\nSo as part of data preprocessing we will be focused on establishing consistency and ensuring all variables are in a format suitable for predictive modeling. This process starts by systematically addressing non-standard representations of missing data. Specifically, all instances of the string values “N/A”, “Unknown”, “children”, and “other” found across the dataset were unified and replaced with the standard statistical missing value representation, NA.\nThen we proceed with converting several character-based (categorical) features into numerical features, which is necessary for predictive modeling. \nThe feature bmi, initially read as a character variable was first converted to a numeric data type and subsequently rounded to two decimal places.\nThe binary categorical features were encoded into numerical indicators. The feature gender was transformed so that “Male” was encoded to 1 and “Female” was encoded to 0, and the ever_married was transformed so that “Yes” encoded to 1 and “No” encoded to 0.\nFeatures with multiple categories were also numerically encoded into numerical indicators. The work_type feature had its categories encoded so that “Govt_job” = 1, “Private” = 2, “Self-employed” = 3, and “Never_worked” = 4. The Residence_type was encoded so that “Urban” = 1 and “Rural” = 2. Finally, the smoking_status feature was encoded into three numerical levels, those being “never smoked” = 1, “formerly smoked” = 2, and “smokes” = 3.\nAdditionally, the continuous numerical variables avg_glucose_level, heart_disease, and hypertension were explicitly confirmed as numeric data types, with the age feature also being rounded to two decimal places for consistency.\n\nThe final stage of preprocessing involved removing the id column, which served only as a unique identifier and held no predictive value. This action left the dataset with 11 core predictors. The target variable, stroke, was then converted into a factor (a categorical data type in R) named stroke1, and its levels were explicitly labeled as \\(\\text{\"No\"} = 0\\) and \\(\\text{\"Yes\"} = 1\\). The entire process concluded with the removal of all remaining observations containing missing or inconsistent entries, resulting in the creation of the final, clean data frames, strokeclean and fourassume.\nDataset Preprocessing Conclusion\nThe Stroke Prediction Dataset[17] that started containing 5,110 observations and 12 features. After cleaning missing and inconsistent entries among other necessarychanges, ended as a dataset containing 3,357 observations and 11 predictors commonly associated with cerebrovascular risk. Those key predictors are listed below.\n\n\n\n\n\n\n\n\n\n\nFeature Name\nDescription\nData Type\nValues\n\n\n\n\ngender\nPatient’s gender\nNumeric\n1 (Male), 0 (Female)\n\n\nage\nPatient’s age in years\nNumeric\nRange 0.08 to 82; rounded to 2 decimal places\n\n\nhypertension\nIndicates if the patient has hypertension\nNumeric\n0 (No), 1 (Yes)\n\n\nheart_disease\nIndicates if the patient has any heart diseases\nNumeric\n0 (No), 1 (Yes)\n\n\never_married\nWhether the patient has ever been married\nNumeric\n1 (Yes), 0 (No)\n\n\nwork_type\nType of occupation\nNumeric\n1 (Govt_job), 2 (Private), 3 (Self-employed), 4 (Never_worked)\n\n\nResidence_type\nPatient’s area of residence\nNumeric\n1 (Urban), 2 (Rural)\n\n\navg_glucose_level\nAverage glucose level in blood\nNumeric\nRange ≈55.12 to 271.74\n\n\nbmi\nBody Mass Index\nNumeric\nRange ≈10.3 to 97.6; converted from character, rounded to 2 decimals\n\n\nsmoking_status\nPatient’s smoking status\nNumeric\n1 (never smoked), 2 (formerly smoked), 3 (smokes)\n\n\nstroke\nTarget Variable: Whether the patient had stroke\nNumeric\n0 (No Stroke), 1 (Stroke)\n\n\n\n\n\n# skim(stroke1)\n# nrow(fourassume)\n# class(strokeclean$stroke)\n# unique(strokeclean$gender)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Dataset Visualization\nBefore developing predictive models, an exploratory analysis was conducted to understand the distribution, structure, and relationships within the cleaned dataset (N = 3,357). This step is crucial in rare-event medical modeling because data imbalance, skewed predictors, or correlated variables can directly influence model behavior and classification performance.\nHistograms\n\n\nCode\n# 1. Get the total number of rows in your data frame\nTOTAL_ROWS &lt;- nrow(strokeclean)\n\n# 2. Use the modified ggplot code\np1a &lt;- ggplot(strokeclean, aes(x = gender, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # The calculation is (bar_count / TOTAL_ROWS) * 100, rounded to 1 decimal place.\n    position = position_dodge(width = 0.9),\n    aes(\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1), \n    labels = c(\"Female\", \"Male\")\n  ) +\n  labs(title = \"(a) Gender\", x = \"Gender\", y = \"Count\")\n\n# (b) Histogram of Age\np1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(b) Age\", x = \"Age\", y = \"Frequency\")\n\n# (b) Bivariate Density Plot of Age\n# p1b &lt;- ggplot(strokeclean, aes(x = age, fill = stroke)) + # Keep fill=stroke\n#   geom_density(alpha = 0.5) + # Overlap the two density curves\n#   labs(title = \"(b) Age\", x = \"Age\", y = \"Density\")\n\n# (c) Histogram of hypertension\np1c &lt;- ggplot(strokeclean, aes(x = hypertension, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(c) Hypertension\", x = \"Hypertension\", y = \"Frequency\")\n\n# (d) Histogram of heart_disease\np1d &lt;- ggplot(strokeclean, aes(x = heart_disease, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  # Map 0/1 to Yes/No\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(title = \"(d) Heart Disease\", x = \"Heart Disease\", y = \"Frequency\")\n\n# (e) Histogram of ever_married\np1e &lt;- ggplot(strokeclean, aes(x = ever_married, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9),\n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5,\n    size = 3\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  # Assuming 'No'/'Yes' are string/factor values, use scale_x_discrete if needed\n  labs(title = \"(e) Ever Married\", x = \"Ever Married\", y = \"Frequency\")\n\n# (f) Histogram of work_type\np1f &lt;- ggplot(strokeclean, aes(y = work_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke,\n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, # Shift text right for horizontal bar\n    size = 3,\n    color = \"black\"\n  ) +\n  # Expand X-axis (Frequency) for horizontal bar\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) +\n  # Adding Work type labels make it too convoluted\n  # scale_y_continuous(\n  #   breaks = c(1, 2, 3, 4), \n  #   labels = c(\"Govt_job\", \"Private\", \"Self-employed\", \"Never_worked\")\n  # ) + \n  labs(title = \"(f) Work Type\", y = \"Work Type\", x = \"Frequency\")\n\n# (g) Histogram of Residence_type\np1g &lt;- ggplot(strokeclean, aes(x = Residence_type, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    # Crucial for aligning text labels with the dodged bars\n    position = position_dodge(width = 0.9), \n    aes(\n      # Defines the group for position_dodge to work correctly on text\n      group = stroke, \n      \n      # Combined label: Percentage (top line) + Count (bottom line)\n      label = paste0(\n        # Percentage calculation: (count / TOTAL_ROWS) * 100\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    vjust = -0.5, # Moves the two-line label slightly above the bar\n    size = 3,\n    color = \"black\" # Ensures better visibility\n  ) +\n  # Adds 15% extra space to the top of the y-axis to prevent label clipping\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + \n  scale_x_continuous(\n    breaks = c(1, 2),\n    labels = c(\"Urban\", \"Rural\")\n  ) +\n  labs(title = \"(g) Residence Type\", x = \"Residence Type\", y = \"Frequency (Count)\")\n\n# (h) Histogram of avg_gloucose_level\np1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n  geom_histogram(binwidth = 5, position = \"identity\", alpha = 0.7) +\n  # stat_count(aes(label = ..count..), geom = \"text\", vjust = -0.5, size = 2) +\n  labs(title = \"(h) Avg. Glucose Level\", x = \"Glucose Level\", y = \"Frequency\")\n\n# (h) Bivariate Density plot of avg_gloucose_level\n# p1h &lt;- ggplot(strokeclean, aes(x = avg_glucose_level, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"Avg. Glucose Level by Stroke Status\", x = \"Average Glucose Level\", y = \"Density\")\n\n# (i) Histogram of bmi\np1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n  geom_histogram(binwidth = 2, position = \"identity\", alpha = 0.7) +\n  labs(title = \"(i) BMI\", x = \"BMI\", y = \"Frequency\")\n\n# (i) Bivariate Density plot of bmi\n# p1i &lt;- ggplot(strokeclean, aes(x = bmi, fill = stroke)) +\n#   geom_density(alpha = 0.5) +\n#   labs(title = \"BMI Distribution by Stroke Status\", x = \"BMI\", y = \"Density\")\n\n# (j) smoking_status\np1j &lt;- ggplot(strokeclean, aes(y = smoking_status, fill = stroke)) +\n  geom_bar(position = \"dodge\") +\n  stat_count(\n    position = position_dodge(width = 0.9), \n    aes(\n      group = stroke, \n      label = paste0(\n        round(after_stat(count) / TOTAL_ROWS * 100, 1), \"% \", \"or \",\n        after_stat(count)\n      )\n    ),\n    geom = \"text\",\n    hjust = -0.1, \n    size = 3,\n    color = \"black\" \n  ) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.5))) + \n  labs(title = \"(j) Smoking Status\", y = \"Smoking Status\", x = \"Frequency (Count)\")\n\n\nWe can observe from the histograms (a), (b), (c) and (d) the following:\nThe data appears to be slightly imbalanced towards female gender and the proportion of stroke cases relative to the total number of individuals in each gender appears similar for both genders, even if it looks slightly higher in the male doesnt seem to be significant difference.\nThe number of stroke cases increases dramatically after the age of \\(\\approx 50\\) and peaks in the 60 to 80 age range. This strongly suggests age is a critical risk factor for stroke.\nThe majority of patients do not have hypertension and the proportion of stroke cases (blue bar) is visibly much higher in the group with hypertension. This indicates that hypertension is a strong risk factor for stroke.\nSimilar to hypertension, the majority of patients do not have heart disease and the proportion of stroke cases (blue bar) is visibly much higher in the group with heart disease. This indicates that heart disease is a very strong risk factor for stroke, even stronger than hypertension when based alone on the observed proportions.\n\n\nCode\n# p1a, p1b, p1c, p1d\n# (a) Histogram of gender \n# (b) Histogram of Age\n# (c) Histogram of hypertension\n# (d) Histogram of heart_disease\nggarrange(p1a, p1b, p1c, p1d, \n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (a)gender, (b)age, (c)hypertension, (d)heart_disease.\n\n\n\n\nWe can observe from the histograms (e), (f), (g) and (h) the following:\nThe stroke rate appears higher for those who have ever been married which is a fascinating plot that catches our attention, this must be correlated with another variable. Our guess is that having been married being associated with a higher stroke risk in this dataset, is possibly due to the married group skewing toward older ages\nAcross the four work types encoded, “Govt_job” = 1, “Private” = 2 “Self-employed” = 3, “Never Worked” = 4. Self-employed individuals appear to have the highest risk proportion among the working groups. Followed by the Private which is the largest group (total \\(\\approx 2200\\)) and naturally accounts for the highest raw count of stroke cases (109) with a proportion of stoke incidence sligthly higher than Govt_job.\nThe stroke outcomes based on the patient’s residence type has a very similar raw count their proportions seems to be similar as well. This suggests that residence type does not appear to be a significant factor for stroke risk.\nFrom the distribution of average glucose (HbA1c) we can visually spot that the stroke cases are more frequent for high-glucose relative to the total population at those high levels. This higher propportion indicates that high average glucose (HbA1c) level is a significant risk factor for stroke.\n\n\nCode\n# p1e p1f p1g p1h\n# (e) Histogram of ever_married\n# (f) Histogram of work_type\n# (g) Histogram of Residence_type\n# (h) Histogram of avg_gloucose_level\nggarrange(p1e, p1f, p1g, p1h,\n          ncol = 2, nrow = 2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (e)ever_married, (f)work_type, (g)Residence_type, (h)avg_gloucose_level.\n\n\n\n\nWe can observe from the histograms (i) and (j) the following:\nFor the BMI distribution we can observe that the majority of the patient population (pink bars) falls within the overweight to obese range (BMI \\(\\approx 25\\) to \\(35\\)). So as a consequence we can expect that the frequency of stroke cases (blue bars) will follow the distribution of the overall population, meaning most strokes occur where the largest number of people are located which are the BMI values between \\(25\\) and \\(35\\).\nHowever, we can visually spot that the stroke occurence is drops significantly closer to a healthy BMI of 20. So although the risk of stroke does seem to be generally higher than average once BMI exceeds the ideal range and moves into the overweight and obese categories because there is a larger distribution within the overweight to obese range, we can conclude that because the skewed distributin that BMI is a significant risk factor predictor for stroke.\nThe stroke outcomes are compared across the three smoking status categories encoded: smokes = 3, formerly smoked = 2, and never smoked = 1.\nThis plot is highlights a particularly interesting aspect of this dataset. The highest proportional risk of stroke appears to be in the formerly smoked group. This finding is common in medical literature[18], as individuals who have a history of smoking may have accrued vascular damage that persists, but their stroke risk is still lower than the risk for current smokers if they continue to smoke.\nThis information is importante, because the formerly smoked group shows the highest rate, suggesting that a history of smoking is a significant indicator of risk.\n\n\nCode\n# p1i p1j\n# (i) Histogram of bmi\n# (j) smoking_status\nggarrange(p1i, p1j,\n          ncol = 2, nrow = 1, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nHistogram of (i)bmi, (j)smoking_status.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Correlation Analysis\n\n\nCode\ndf_numeric &lt;- model.matrix(~.-1, data = strokeclean) |&gt;\n  as.data.frame()\n\n# Rename columns for clarity (model.matrix adds prefixes)\ncolnames(df_numeric) &lt;- gsub(\"gender|work_type|smoking_status|Residence_type|ever_married\", \"\", colnames(df_numeric))\n\n# 1. Calculate the correlation matrix\ncorrelation_matrix &lt;- cor(df_numeric)\n\n# 2. Define a green sequential color palette\n# green_palette &lt;- colorRampPalette(c(\"#E5F5E0\", \"#31A354\"))(200) # Light to dark green\ngreen_palette &lt;- colorRampPalette(c(\"#d5ffc8ff\", \"#245332ff\"))(200) \n\n# corrplot(correlation_matrix, method = 'number') # colorful number\n# 3. Create the heatmap with the correct palette\np2 &lt;- corrplot(correlation_matrix, \n         method = \"color\",\n         type = \"full\", # change to full or upper\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         addCoef.col = \"black\",\n         number.cex = 0.7,\n         col = green_palette, # Use the new palette here\n         diag = FALSE)\n\n\n\n\n\nCorrelation Analysis.\n\n\n\n\nThe correlation analysis confirms that the strongest linear predictors for stroke outcome in this dataset are age, hypertension, and average glucose level. Furthermore, age is highly correlated with hypertension, suggesting these factors may have overlapping or compounding effects on stroke risk.\nThis information will be further explored during statistical modelling were we will evaluate the statistical significance of those variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3. Statistical Modelling\nInitially, we split the dataset into a training set (70%) and a test set (30%) to evaluate out-of-sample performance, then we used this training data for our statistical modelling. It is important to note that during splitting, stratified sampling was used (via caret::createDataPartition) to maintain the stroke/no-stroke ratio.[6]\nAlso the categorical variables were converted into the appropiate Data Types for correctly fitting the GLM binomial regression model.\n\n\n\nCode\nmodel_df &lt;- strokeclean\nmodel_df &lt;- na.omit(model_df)\nmodel_df$stroke &lt;- factor(model_df$stroke)\nlevels(model_df$stroke) &lt;- c(\"No\", \"Yes\")\ntable(model_df$stroke)\n\nindex &lt;- createDataPartition(strokeclean$stroke, p = 0.70, list = FALSE)\ntrain_data &lt;- strokeclean[index, ]\ntest_data  &lt;- strokeclean[-index, ]\n\ntrain_data$stroke &lt;- factor(train_data$stroke, levels = c(\"No\",\"Yes\"))\ntest_data$stroke  &lt;- factor(test_data$stroke,  levels = c(\"No\",\"Yes\"))\n\n# ---------------------------------------------\n# Convert all multi-level categoricals to factors with a clear reference level\ntrain_data$work_type     &lt;- factor(train_data$work_type)\ntrain_data$Residence_type&lt;- factor(train_data$Residence_type)\ntrain_data$smoking_status&lt;- factor(train_data$smoking_status)\n\n# The same should be done for test_data and the binary variables \ntest_data$work_type     &lt;- factor(test_data$work_type)\ntest_data$Residence_type&lt;- factor(test_data$Residence_type)\ntest_data$smoking_status&lt;- factor(test_data$smoking_status)\n# ---------------------------------------------\n# Note: if you want the output to label the levels (e.g., \"Male\" vs \"Female\") instead of \"gender\" and \"gender1\" (for Male = 1 vs Female = 0).\n# For 0/1, R's glm is usually fine, but for clean output factors are better.\n# For multi-level, it's essential.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.1. Repeated K-fold cross-validation\nThe trainControl() function in the R caret package is used to control the computational nuances and resampling methods employed by the train() function. It allows us to implement Repeated K-fold cross-validation (“repeatedcv”).\n\n\nCode\nctrl &lt;- trainControl(\nmethod = \"repeatedcv\",\nnumber = 5,\nrepeats = 3,\nclassProbs = TRUE,\nsummaryFunction = twoClassSummary,\nverboseIter = FALSE\n)\n\n\n\n\n3.3.2. Logistic Regression\n\n\nCode\n# Using the GLM package without K fold cross validation\nmodel_lr &lt;- glm(\n  stroke ~ . , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\n\n# Checking if the wrapper as.factor has any difference\n# model_lr &lt;- glm(\n#   stroke ~ age +\n#   avg_glucose_level +\n#   bmi +\n#   as.factor(gender) +\n#   as.factor(hypertension) +\n#   as.factor(heart_disease) +\n#   as.factor(ever_married) +\n#   as.factor(work_type) +\n#   as.factor(Residence_type) +\n#   as.factor(smoking_status)\n#   , \n#   data=train_data , \n#   family = \"binomial\" (link=logit)\n#   )\n\ns1 &lt;- summary(model_lr)\nc1 &lt;- coefficients(model_lr)\nanova1 &lt;- car::Anova(model_lr, type = 3)\nconfint1 &lt;- confint(model_lr, level=0.95)\n\n# Logistic Regression with the Caret package\nmodel_lr2 &lt;- train(\nstroke ~ .,\ndata = train_data,\nmethod = \"glm\",\nfamily = \"binomial\",\nmetric = \"ROC\",\ntrControl = ctrl\n)\n\n\nLogistic Regression Preliminary conclusions\n\ns1\n\n\nCall:\nglm(formula = stroke ~ ., family = binomial(link = logit), data = train_data)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -8.113391   0.854545  -9.494  &lt; 2e-16 ***\ngender             -0.112742   0.204658  -0.551  0.58172    \nage                 0.078380   0.008614   9.099  &lt; 2e-16 ***\nhypertension        0.914733   0.214191   4.271 1.95e-05 ***\nheart_disease       0.339604   0.277662   1.223  0.22130    \never_married       -0.532738   0.293381  -1.816  0.06939 .  \nwork_type2          0.072261   0.288269   0.251  0.80207    \nwork_type3         -0.290608   0.324634  -0.895  0.37069    \nwork_type4         -9.306169 649.652359  -0.014  0.98857    \nResidence_type2    -0.072792   0.198250  -0.367  0.71349    \navg_glucose_level   0.005488   0.001670   3.287  0.00101 ** \nbmi                 0.002103   0.015554   0.135  0.89245    \nsmoking_status2     0.208775   0.226763   0.921  0.35722    \nsmoking_status3     0.345133   0.266423   1.295  0.19517    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 982.44  on 2349  degrees of freedom\nResidual deviance: 767.21  on 2336  degrees of freedom\nAIC: 795.21\n\nNumber of Fisher Scoring iterations: 14\n\nanova1\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \ngender               0.305  1   0.580683    \nage                107.200  1  &lt; 2.2e-16 ***\nhypertension        17.103  1   3.54e-05 ***\nheart_disease        1.439  1   0.230228    \never_married         3.064  1   0.080044 .  \nwork_type            2.479  3   0.479126    \nResidence_type       0.135  1   0.713341    \navg_glucose_level   10.535  1   0.001171 ** \nbmi                  0.018  1   0.892611    \nsmoking_status       1.905  2   0.385861    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n107.200\n1\n&lt;2.2e-16\n***\nReject H0. Age is statistically significant in predicting stroke.\n\n\nhypertension\n17.103\n1\n3.54e-05\n***\nReject H0. Hypertension status is statistically significant in predicting stroke.\n\n\navg_glucose_level\n10.535\n1\n0.001171\n**\nReject H0. The average glucose level is statistically significant in predicting stroke.\n\n\ngender\n0.305\n1\n0.580683\n\nFail to Reject H0. Gender is not statistically significant in predicting stroke.\n\n\nheart_disease\n1.439\n1\n0.230228\n\nFail to Reject H0. Heart Disease is not statistically significant in predicting stroke.\n\n\never_married\n3.064\n1\n0.080044\n.\nFail to Reject H0. Marital Status is not statistically significant. Note: Significant at α = 0.1 level.\n\n\nwork_type\n2.479\n3\n0.479126\n\nFail to Reject H0. The factor is not statistically significant in predicting stroke.\n\n\nResidence_type\n0.135\n1\n0.713341\n\nFail to Reject H0. The residence type is not statistically significant in predicting stroke.\n\n\nbmi\n0.018\n1\n0.892611\n\nFail to Reject H0. The BMI is not statistically significant in predicting stroke.\n\n\nsmoking_status\n1.905\n2\n0.385861\n\nFail to Reject H0. The smoking status is not statistically significant in predicting stroke.\n\n\n\nFrom the ANOVA test we could observe that the variables age, hypertension, and avg_glucose_level are statistically significant in predicting the odds of having a stroke. As well we could observe that the variables gender, heart_disease, work_type, Residence_type, bmi, and smoking_status do not show a statistically significant effect on the odds of stroke at the \\(\\alpha=0.05\\) level. Additionally, there is an interesting observation that the variable ever_married is close to significance indicing some curiosity and further exploration.\nTherefore, based solely on this ANOVA table the performance evaluation suggests that we consider removing all the statistically not significant variables and keeping the statistically significant varibles: \\(\\text{age}\\), \\(\\text{hypertension}\\), \\(\\text{avg\\_glucose\\_level}\\).\n\n\nCode\n# Using the GLM package without K fold cross validation\nmodel2_lr &lt;- glm(\n  stroke ~ age +\n  hypertension +\n  avg_glucose_level , \n  data=train_data , \n  family = \"binomial\" (link=logit)\n  )\n\ns2 &lt;- summary(model2_lr)\nc2 &lt;- coefficients(model2_lr)\nanova2 &lt;- car::Anova(model2_lr, type = 3)\nconfint2 &lt;- confint(model2_lr, level=0.95)\n\n\n\ns2\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + avg_glucose_level, \n    family = binomial(link = logit), data = train_data)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -8.232810   0.560826 -14.680  &lt; 2e-16 ***\nage                0.075044   0.007904   9.495  &lt; 2e-16 ***\nhypertension       0.929501   0.210279   4.420 9.85e-06 ***\navg_glucose_level  0.005427   0.001582   3.430 0.000603 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 982.44  on 2349  degrees of freedom\nResidual deviance: 777.43  on 2346  degrees of freedom\nAIC: 785.43\n\nNumber of Fisher Scoring iterations: 7\n\nanova2\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \nage                120.407  1  &lt; 2.2e-16 ***\nhypertension        18.205  1  1.983e-05 ***\navg_glucose_level   11.337  1  0.0007598 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n120.407\n1\n&lt;2.2e-16\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\nhypertension\n18.205\n1\n1.983e-05\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\navg_glucose_level\n11.337\n1\n0.0007598\n***\nReject H0. The factor is statistically significant in predicting stroke.\n\n\n\nWe could see a marginal improvement on the model with and AIC of 785.43 versus the previous AIC of 795.21 and its now even easier to observe that age seems to be the most powerful predictor in the model.\n\n\n\n\n3.3.3. Addressing Class Imbalance with SMOTE\nThe dataset is highly imbalanced, with only a small number of cases being stroke instances. This can bias machine learning models. We will use SMOTE to create balanced versions of our imputed datasets by generating synthetic minority (stroke) class samples.\n\n\nCode\n# Ensure the stroke column is a factor for SMOTE\n# df_mice$stroke &lt;- as.factor(df_mice$stroke)\n# df_mean$stroke &lt;- as.factor(df_mean$stroke)\n# df_age_group$stroke &lt;- as.factor(df_age_group$stroke)\n\n# Create balanced datasets using SMOTE\n# Using the MICE imputed dataset as the primary example for balancing\n\n# Get the number of non-stroke (majority) cases\n# n_majority &lt;- sum(df_mice$stroke == \"0\")\nn_majority &lt;- sum(train_data$stroke == \"No\")\n\n# Calculate the desired total size for a balanced dataset\ndesired_N &lt;- 2 * n_majority\n\n# Create the balanced dataset\ndata_balanced_mice &lt;- ROSE::ovun.sample(\n  stroke ~ ., \n  data = train_data, \n  method = \"over\", \n  N = desired_N, \n  seed = 123\n)$data\n\n\nWe can observe the class distribution before handling the class imbalance with a small number of cases being stroke instances.\n\n\nCode\n# Check the new class distribution\n# cat(\"Original Class Distribution (MICE imputed):\\n\")\nprint(table(train_data$stroke))\n\n\n\n  No  Yes \n2224  126 \n\n\nAfter the class distribution balancing the number of cases being stroke instances is much higher.\n\n\nCode\n# Check the new class distribution\n# cat(\"\\nBalanced Class Distribution (SMOTE):\\n\")\nprint(table(data_balanced_mice$stroke))\n\n\n\n  No  Yes \n2224 2224 \n\n\n\n\n3.3.4. Fitting Logistic Regression with Balanced Data\nWe will use the balanced dataset for modeling. Same as before the dataset is split into training (70%) and testing (30%).\n\n\nCode\n# data_bal &lt;- ROSE(stroke ~ ., data = train_data, seed = 123)$data\nmodel3_lr &lt;- glm(\n  stroke ~ age +\n  hypertension +\n  avg_glucose_level , \n  data=data_balanced_mice , \n  family = \"binomial\" (link=logit)\n  )\n\ns3 &lt;- summary(model3_lr)\nc3 &lt;- coefficients(model3_lr)\nanova3 &lt;- car::Anova(model3_lr, type = 3)\nconfint3 &lt;- confint(model3_lr, level=0.95)\n\n\n\ns3\n\n\nCall:\nglm(formula = stroke ~ age + hypertension + avg_glucose_level, \n    family = binomial(link = logit), data = data_balanced_mice)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -5.6444885  0.1854899 -30.430   &lt;2e-16 ***\nage                0.0782316  0.0027115  28.852   &lt;2e-16 ***\nhypertension       1.1193216  0.0932833  11.999   &lt;2e-16 ***\navg_glucose_level  0.0055918  0.0006791   8.234   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6166.2  on 4447  degrees of freedom\nResidual deviance: 4254.9  on 4444  degrees of freedom\nAIC: 4262.9\n\nNumber of Fisher Scoring iterations: 5\n\nanova3\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: stroke\n                  LR Chisq Df Pr(&gt;Chisq)    \nage                1201.85  1  &lt; 2.2e-16 ***\nhypertension        154.34  1  &lt; 2.2e-16 ***\navg_glucose_level    69.73  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nLR χ²\nDf\np-value\nSignif.\nInterpretation (α=0.05)\n\n\n\n\nage\n1201.85\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\nhypertension\n154.34\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\navg_glucose_level\n69.73\n1\n&lt;2.2e-16\n***\nReject H0. The factor is highly statistically significant.\n\n\n\nAll the three variables we kept (age, hypertension, and avg_glucose_level) remained statistically significant. what confirms that the relationships between these key clinical factors and stroke outcome are robust.\n\n\n\n\n\n\n\n\n\nFactor\nLR χ² (Original, anova2)\nLR χ² (Balanced, anova3)\nChange in χ²\n\n\n\n\nage\n120.407\n1201.85\n≈10.0× Increase\n\n\nhypertension\n18.205\n154.34\n≈8.5× Increase\n\n\navg_glucose_level\n11.337\n69.73\n≈6.1× Increase\n\n\n\nWe additionally can observe that there is an massive increase in the \\(\\chi^2\\) values which demonstrates that the oversampling technique has significantly increased the statistical power of the model.\nIn summary, the ANOVA test confirmed that balancing the training data has dramatically increased the statistical confidence in the predictive power of the model, which directly led to the massive improvement in the model’s ability to identify true stroke cases what will be explored in the next section with a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.5. Confusion Matrix\nThis section the confusion matrix demonstrates conclusive evidence the undersampling of Stroke cases yields a model with no predictive capability.\n\n\nCode\n# 1) Predicted probabilities from logistic regression\ntest_data$pred_prob &lt;- predict(\n  model_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\ntest_data$pred_prob2 &lt;- predict(\n  model2_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\ntest_data$pred_prob3 &lt;- predict(\n  model3_lr,\n  newdata = test_data,\n  type    = \"response\"\n)\n\n# 2) Make sure the TRUE outcome is a factor with levels No / Yes\ntest_data$stroke &lt;- factor(test_data$stroke,\n                             levels = c(\"No\", \"Yes\"))\n\n# 3) Class predictions at threshold c = 0.5\ntest_data$pred_class &lt;- ifelse(test_data$pred_prob &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class2 &lt;- ifelse(test_data$pred_prob2 &gt;= 0.5, \"Yes\", \"No\")\ntest_data$pred_class3 &lt;- ifelse(test_data$pred_prob3 &gt;= 0.5, \"Yes\", \"No\")\n\ntest_data$pred_class &lt;- factor(test_data$pred_class, levels = c(\"No\", \"Yes\"))\ntest_data$pred_class2 &lt;- factor(test_data$pred_class2, levels = c(\"No\", \"Yes\"))\ntest_data$pred_class3 &lt;- factor(test_data$pred_class3, levels = c(\"No\", \"Yes\"))\n\n# 4) Confusion matrix: positive = \"Yes\"\ncm &lt;- confusionMatrix(\n  data      = test_data$pred_class,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\ncm2 &lt;- confusionMatrix(\n  data      = test_data$pred_class2,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\ncm3 &lt;- confusionMatrix(\n  data      = test_data$pred_class3,\n  reference = test_data$stroke,\n  positive  = \"Yes\"\n)\n# cm\n# cm2\n# cm3\n\n\n\n\nCode\n# --------------------------------------------------------\n# 1. Define a function to extract key metrics and counts\n# --------------------------------------------------------\nextract_metrics &lt;- function(cm_object, model_name) {\n  # Extract per-class statistics (Sensitivity, Specificity) and Overall Accuracy\n  stats &lt;- cm_object$byClass\n  Accuracy &lt;- cm_object$overall['Accuracy']\n  \n  # Extract Confusion Matrix table for counts\n  cm_table &lt;- cm_object$table\n  \n  # Extract the counts (Assuming 'Yes' is the positive class, top-left is TN)\n  TP &lt;- cm_table['Yes', 'Yes'] # True Positives\n  FN &lt;- cm_table['Yes', 'No']  # False Negatives\n  TN &lt;- cm_table['No', 'No']   # True Negatives\n  FP &lt;- cm_table['No', 'Yes']  # False Positives\n  \n  # Create a data frame with metrics as rows\n  data.frame(\n    Metric = c(\n      \"Accuracy\",\n      \"Sensitivity (Recall)\",\n      \"Specificity\",\n      \"True Positives (TP)\",\n      \"False Negatives (FN)\",\n      \"True Negatives (TN)\",\n      \"False Positives (FP)\"\n    ),\n    Value = c(\n      Accuracy,\n      stats['Sensitivity'],\n      stats['Specificity'],\n      TP,\n      FN,\n      TN,\n      FP\n    ),\n    stringsAsFactors = FALSE\n  ) %&gt;%\n    # Rename the Value column to the model name\n    dplyr::rename(!!model_name := Value)\n}\n\n# --------------------------------------------------------\n# 2. Extract metrics for all three models\n# --------------------------------------------------------\nmetrics_cm &lt;- extract_metrics(cm, \"Model 1 (Full, Imbalanced)\")\nmetrics_cm2 &lt;- extract_metrics(cm2, \"Model 2 (Reduced, Imbalanced)\")\nmetrics_cm3 &lt;- extract_metrics(cm3, \"Model 3 (Reduced, Balanced)\")\n\n# --------------------------------------------------------\n# 3. Merge the three data frames into one comparison table\n# --------------------------------------------------------\ncomparison_table &lt;- metrics_cm %&gt;%\n  dplyr::full_join(metrics_cm2, by = \"Metric\") %&gt;%\n  dplyr::full_join(metrics_cm3, by = \"Metric\")\n\n# --------------------------------------------------------\n# 4. Format the table for clean output\n# --------------------------------------------------------\n\n# Select the rows that are proportions/percentages (1-3) and format to 4 decimal places\ncomparison_table[1:3, 2:4] &lt;- lapply(\n  comparison_table[1:3, 2:4],\n  function(x) { format(as.numeric(x), digits = 4, scientific = FALSE) }\n)\n\n# Select the rows that are counts (4-7) and format as integers\ncomparison_table[4:7, 2:4] &lt;- lapply(\n  comparison_table[4:7, 2:4],\n  function(x) { format(as.integer(x), big.mark = \",\") }\n)\n\n# Print the final formatted table\nprint(comparison_table)\n\n\n                Metric Model 1 (Full, Imbalanced) Model 2 (Reduced, Imbalanced)\n1             Accuracy                    0.94538                        0.9444\n2 Sensitivity (Recall)                    0.01852                        0.0000\n3          Specificity                    0.99790                        0.9979\n4  True Positives (TP)                          1                             0\n5 False Negatives (FN)                          2                             2\n6  True Negatives (TN)                        951                           951\n7 False Positives (FP)                         53                            54\n  Model 3 (Reduced, Balanced)\n1                      0.7269\n2                      0.6481\n3                      0.7314\n4                          35\n5                         256\n6                         697\n7                          19\n\n\n\n\n\n\n\n\n\n\n\nMetric\nModel 1 (Full, Imbalanced)\nModel 2 (Reduced, Imbalanced)\nModel 3 (Reduced, Balanced)\n\n\n\n\nAccuracy\n0.94538\n0.9444\n0.7269\n\n\nSensitivity (Recall)\n0.01852\n0.0000\n0.6481\n\n\nSpecificity\n0.99790\n0.9979\n0.7314\n\n\nTrue Positives (TP)\n1\n0\n35\n\n\nFalse Negatives (FN)\n2\n2\n256\n\n\nTrue Negatives (TN)\n951\n951\n697\n\n\nFalse Positives (FP)\n53\n54\n19\n\n\n\nFrom the confusion matrix, the following performance metrics are defined:\nThe comparison of the three Logistic Regression models using the confusion matrix reveals that while the imbalanced models (Model 1 and Model 2) achieved high Accuracy (\\(\\approx 94.5\\%\\)) and Specificity (\\(\\approx 0.998\\)), they were practically useless for stroke prediction with a near-zero Sensitivity and missing almost all actual stroke cases. By contrast, Model 3 which utilized oversampling to address the severe class imbalance in stroke outcome, demonstrated a significant improvement in predictive capability: Sensitivity dramatically improved to \\(0.6481\\) being able to identifying 35 True Positives, confirming that balancing successfully forced the model to learn the patterns of the minority class of stroke outcome. However, this critical gain in recall came with a trade-off, it lowered the Accuracy to \\(0.7269\\) and Specificity to \\(0.7314\\) due to an increase in False Negatives registering 256 cases, but the resulting model is a far more functional screening tool, prioritizing the detection of the outcome stroke over overall classification correctness.\n\n\n\nThe observations must be independent.\nThere must be no perfect multicollinearity among independent variables. Use the VIF.\nLogistic regression assumes linearity of independent variables and log odds.\nThere are no extreme outliers, check using Cooks D\nThe Sample Size is Sufficiently Large.\n\nCheck Multicollinearity\nIn OLS regression, multicollinearity can be calculated either from the correlations among the predictors, or from the correlations among the coefficient estimates, and these result in the same variance inflaction factors (VIFs).\nIn GLMs, these two approaches yield similar but different VIFs. John Fox, one of the authors of the car package where the vif() function is found, opts for calculating the VIFs from the coefficient estimates.\n\nvif(model_lr)\n\n                      GVIF Df GVIF^(1/(2*Df))\ngender            1.042583  1        1.021069\nage               1.224353  1        1.106505\nhypertension      1.038949  1        1.019288\nheart_disease     1.072781  1        1.035751\never_married      1.023266  1        1.011566\nwork_type         1.083443  3        1.013447\nResidence_type    1.012883  1        1.006421\navg_glucose_level 1.118062  1        1.057384\nbmi               1.158761  1        1.076457\nsmoking_status    1.086902  2        1.021051\n\nvif(model2_lr)\n\n              age      hypertension avg_glucose_level \n         1.017823          1.016305          1.017019 \n\nvif(model3_lr)\n\n              age      hypertension avg_glucose_level \n         1.006566          1.009300          1.015890"
  },
  {
    "objectID": "posts/renan-blog-post-draft10/index.html#conclusion",
    "href": "posts/renan-blog-post-draft10/index.html#conclusion",
    "title": "Draft Final Report - v10",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThis experiment evaluated the performance of a logistic regression model with common demographic, behavioral, and clinical characteristics using a public stroke dataset.[17] The findings were not promising because stroke is a rare outcome (about 5% of cases) and even after dealing with the class imbalance there is only marginal improvements, too many false positives. Althought the improvements were marginal the logistic regression model was a great interpretable tool for comprehending the relationship between particular risk variables and the likelihood of stroke and are in line with the clinical literature on cerebrovascular illness. For example we could identify that Age, hypertension, and raised average glucose levels are among the best predictors of stroke outcome.\nOur findings of the undesirable performance of Logistic Regression are on pair with other research[19]. More advanced techniques seem to be required for preprocessing the dataset such as Mean Imputation for replacing some missing values with the column’s mean, Multivariate Imputation by Chained Equations (MICE) where we synthetically generate missing values based on other variables, and Age Group-based Imputation where we we categorize the age groups and replace missing BMI values with the mean BMI of the corresponding age group.\nBut the main solution for the problem might be implementation of the Dense Stacking Ensemble (DSE) Model, which uses the best-performing model (Random Forest) as a meta-classifier. This multi-model approach as epxlored in[19] seems to combine the simplicity and interpretability of Logistic Regression models with the superior performance of more sophisticated models. Overall, the findings show that relatively simple models built from routinely collected health indicators can generate meaningfull results when the proper class imbalance is deal and that proves that logistic regression emerges as a strong, interpretable baseline that can be further improved as demonstrated in[19]. In Future work we could explore the use of synthetically generate data and other Imputation techinques and the implementation of Dense Stacking Ensemble (DSE) Model. These extensions would help move towards a robust model with low false positive predictions, making the research into a clinically usable tool for stroke risk stratification and targeted prevention.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\n1. World Health Organization. (2025). The top 10 causes of death. https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death.\n\n\n2. Sperandei, S. (2014). Understanding logistic regression analysis. Biochemia Medica, 24(1), 12–18.\n\n\n3. Asmare, A. A., & Agmas, Y. A. (2024). Determinants of coexistence of undernutrition and anemia among under-five children in rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model. Plos One, 19(4), e0290111.\n\n\n4. Rahman, M. H., Zafri, N. M., Akter, T., & Pervaz, S. (2021). Identification of factors influencing severity of motorcycle crashes in dhaka, bangladesh using binary logistic regression model. International Journal of Injury Control and Safety Promotion, 28(2), 141–152.\n\n\n5. Chen, Y., You, P., & Chang, Z. (2024). Binary logistic regression analysis of factors affecting urban road traffic safety. Advances in Transportation Studies, 3.\n\n\n6. Chen, M.-M., & Chen, M.-C. (2020). Modeling road accident severity with comparisons of logistic regression, decision tree and random forest. Information, 11(5), 270.\n\n\n7. Hutchinson, A., Pickering, A., Williams, P., & Johnson, M. (2023). Predictors of hospital admission when presenting with acute-on-chronic breathlessness: Binary logistic regression. PLoS One, 18(8), e0289263.\n\n\n8. Samara, B. (2024). Using binary logistic regression to detect health insurance fraud. Pakistan Journal of Life & Social Sciences, 22(2).\n\n\n9. Kokkotis, C., Giarmatzis, G., Giannakou, E., Moustakidis, S., Tsatalas, T., Tsiptsios, D., Vadikolias, K., & Aggelousis, N. (2022). An explainable machine learning pipeline for stroke prediction on imbalanced data. Diagnostics, 12(10), 2392.\n\n\n10. Sirsat, M. S., Fermé, E., & Câmara, J. (2020). Machine learning for brain stroke: A review. Journal of Stroke and Cerebrovascular Diseases, 29(10), 105162.\n\n\n11. Wongvorachan, T., He, S., & Bulut, O. (2023). A comparison of undersampling, oversampling, and SMOTE methods for dealing with imbalanced classification in educational data mining. Information, 14(1), 54.\n\n\n12. Sowjanya, A. M., & Mrudula, O. (2023). Effective treatment of imbalanced datasets in health care using modified SMOTE coupled with stacked deep learning algorithms. Applied Nanoscience, 13(3), 1829–1840.\n\n\n13. Harris, J. K. (2019). Statistics with r: Solving problems using real-world data. SAGE Publications.\n\n\n14. Field, A. (2024). Discovering statistics using IBM SPSS statistics. Sage publications limited.\n\n\n15. Hosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). Applied logistic regression. John Wiley & Sons.\n\n\n16. LeBlanc, M., & Fitzgerald, S. (2000). Logistic regression for school psychologists. School Psychology Quarterly, 15(3), 344.\n\n\n17. Palacios, F. S. (n.d.). Stroke Prediction Dataset. https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n\n\n18. Oshunbade, A. A., Yimer, W. K., Valle, K. A., Clark III, D., Kamimura, D., White, W. B., DeFilippis, A. P., Blaha, M. J., Benjamin, E. J., O’Brien, E. C., et al. (2020). Cigarette smoking and incident stroke in blacks of the jackson heart study. Journal of the American Heart Association, 9(12), e014990.\n\n\n19. Hassan, A., Gulzar Ahmad, S., Ullah Munir, E., Ali Khan, I., & Ramzan, N. (2024). Predictive modelling and identification of key risk factors for stroke using machine learning. Scientific Reports, 14(1), 11498."
  },
  {
    "objectID": "slides.html#introduction",
    "href": "slides.html#introduction",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "1. Introduction",
    "text": "1. Introduction\nStroke is one of the leading causes of death and disability worldwide and remains a major public health challenge[1]. Early identification of high-risk individuals is crucial for prevention and timely intervention. Therefore we develop and fit a Logistic Regression model using key health indicators to evaluate the effectiveness of a much simpler method.\nOccam’s Razor: The simplest solution is always the best"
  },
  {
    "objectID": "slides.html#methodology-logistic-regression",
    "href": "slides.html#methodology-logistic-regression",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "2. Methodology: Logistic Regression",
    "text": "2. Methodology: Logistic Regression\nThe Binary Logistic ModelThe Logistic Regression model uses the logit link function to model the probability of the outcome (\\(\\pi = P[Y =1]\\)):\n\\[ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}x_{1} + \\cdots + \\beta_{k}x_{k} \\quad \\text{}\\]"
  },
  {
    "objectID": "slides.html#analysis-and-results",
    "href": "slides.html#analysis-and-results",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\nData source: Stroke Prediction Dataset[2]"
  },
  {
    "objectID": "slides.html#statistical-modelling",
    "href": "slides.html#statistical-modelling",
    "title": "Predicting Stroke Risk from Common Health Indicators",
    "section": "3. Statistical Modelling",
    "text": "3. Statistical Modelling"
  }
]